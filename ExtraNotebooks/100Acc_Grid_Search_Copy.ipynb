{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1642c04-1b40-406f-82e6-ab922f6a1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f8bdc2-f5d4-40cc-9599-f0cbd402867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  1\n",
      "Training data shape: (4832, 64, 64, 6)\n",
      "Validation data shape: (1208, 64, 64, 6)\n",
      "Training labels shape: (4832, 2)\n",
      "Validation labels shape: (1208, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\Θάνος\\\\Desktop\\\\Thesis Thanasis\\\\data_aug_3'\n",
    "subfolders = ['clear', 'clouds']\n",
    "categories = ['Healthy_augmented', 'Damaged_augmented']\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def load_data(base_dir, subfolders, categories, img_height, img_width):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        class_num = categories.index(category)\n",
    "        clear_path = os.path.join(base_dir, subfolders[0], category)\n",
    "        clouds_path = os.path.join(base_dir, subfolders[1], category)\n",
    "        clear_images = sorted(os.listdir(clear_path))\n",
    "        clouds_images = sorted(os.listdir(clouds_path))\n",
    "        \n",
    "        for clear_img_name, clouds_img_name in zip(clear_images, clouds_images):\n",
    "            if clear_img_name.endswith('.png') and clouds_img_name.endswith('.png'):\n",
    "                clear_img_path = os.path.join(clear_path, clear_img_name)\n",
    "                clouds_img_path = os.path.join(clouds_path, clouds_img_name)\n",
    "                \n",
    "                clear_img = tf.keras.preprocessing.image.load_img(clear_img_path, target_size=(img_height, img_width))\n",
    "                clouds_img = tf.keras.preprocessing.image.load_img(clouds_img_path, target_size=(img_height, img_width))\n",
    "                \n",
    "                clear_img_array = tf.keras.preprocessing.image.img_to_array(clear_img)\n",
    "                clouds_img_array = tf.keras.preprocessing.image.img_to_array(clouds_img)\n",
    "                \n",
    "                combined_img = np.concatenate((clear_img_array, clouds_img_array), axis=-1)\n",
    "                \n",
    "                data.append(combined_img)\n",
    "                labels.append(class_num)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_data(base_dir, subfolders, categories, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Normalize the images\n",
    "data = data / 255.0\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc106b-9cfb-409d-b6b2-07bc9ac7784e",
   "metadata": {},
   "source": [
    "# Retraining with best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d2a256-ba9a-49c4-b650-d42ee5d93221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.8640915593705293, 1: 1.18664047151277}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:2094: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1063 - accuracy: 0.5160Epoch 1/50: loss=1.1064, accuracy=0.5159, val_loss=1.1343, val_accuracy=0.4520\n",
      "604/604 [==============================] - 33s 41ms/step - loss: 1.1064 - accuracy: 0.5159 - val_loss: 1.1343 - val_accuracy: 0.4520 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.5350Epoch 2/50: loss=0.8343, accuracy=0.5350, val_loss=0.7431, val_accuracy=0.4884\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.8343 - accuracy: 0.5350 - val_loss: 0.7431 - val_accuracy: 0.4884 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.5851Epoch 3/50: loss=0.7546, accuracy=0.5851, val_loss=0.8029, val_accuracy=0.4917\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.7546 - accuracy: 0.5851 - val_loss: 0.8029 - val_accuracy: 0.4917 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6966 - accuracy: 0.6244Epoch 4/50: loss=0.6965, accuracy=0.6244, val_loss=0.7482, val_accuracy=0.5886\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.6965 - accuracy: 0.6244 - val_loss: 0.7482 - val_accuracy: 0.5886 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6483 - accuracy: 0.6646Epoch 5/50: loss=0.6480, accuracy=0.6647, val_loss=0.6373, val_accuracy=0.6763\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.6480 - accuracy: 0.6647 - val_loss: 0.6373 - val_accuracy: 0.6763 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6169 - accuracy: 0.6907Epoch 6/50: loss=0.6168, accuracy=0.6908, val_loss=0.5523, val_accuracy=0.7235\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.6168 - accuracy: 0.6908 - val_loss: 0.5523 - val_accuracy: 0.7235 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.7063Epoch 7/50: loss=0.5946, accuracy=0.7063, val_loss=0.6705, val_accuracy=0.5902\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.5946 - accuracy: 0.7063 - val_loss: 0.6705 - val_accuracy: 0.5902 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6162 - accuracy: 0.6905Epoch 8/50: loss=0.6163, accuracy=0.6902, val_loss=0.7140, val_accuracy=0.5099\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.6163 - accuracy: 0.6902 - val_loss: 0.7140 - val_accuracy: 0.5099 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.7049Epoch 9/50: loss=0.6025, accuracy=0.7049, val_loss=0.5730, val_accuracy=0.7012\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.6025 - accuracy: 0.7049 - val_loss: 0.5730 - val_accuracy: 0.7012 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6160 - accuracy: 0.6965Epoch 10/50: loss=0.6163, accuracy=0.6966, val_loss=1.2216, val_accuracy=0.6647\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.6163 - accuracy: 0.6966 - val_loss: 1.2216 - val_accuracy: 0.6647 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6170 - accuracy: 0.6897\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/50: loss=0.6170, accuracy=0.6896, val_loss=0.5595, val_accuracy=0.7401\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.6170 - accuracy: 0.6896 - val_loss: 0.5595 - val_accuracy: 0.7401 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.7597Epoch 12/50: loss=0.5112, accuracy=0.7597, val_loss=0.6349, val_accuracy=0.6879\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.5112 - accuracy: 0.7597 - val_loss: 0.6349 - val_accuracy: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7917Epoch 13/50: loss=0.4585, accuracy=0.7920, val_loss=0.3989, val_accuracy=0.8303\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.4585 - accuracy: 0.7920 - val_loss: 0.3989 - val_accuracy: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.8121Epoch 14/50: loss=0.4241, accuracy=0.8121, val_loss=0.4057, val_accuracy=0.8212\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.4241 - accuracy: 0.8121 - val_loss: 0.4057 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3970 - accuracy: 0.8350Epoch 15/50: loss=0.3967, accuracy=0.8351, val_loss=0.3414, val_accuracy=0.8667\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.3967 - accuracy: 0.8351 - val_loss: 0.3414 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8466Epoch 16/50: loss=0.3623, accuracy=0.8466, val_loss=0.3815, val_accuracy=0.8179\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.3623 - accuracy: 0.8466 - val_loss: 0.3815 - val_accuracy: 0.8179 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8599Epoch 17/50: loss=0.3292, accuracy=0.8601, val_loss=0.2659, val_accuracy=0.8891\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.3292 - accuracy: 0.8601 - val_loss: 0.2659 - val_accuracy: 0.8891 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8711Epoch 18/50: loss=0.3186, accuracy=0.8711, val_loss=0.6427, val_accuracy=0.6515\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.3186 - accuracy: 0.8711 - val_loss: 0.6427 - val_accuracy: 0.6515 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2971 - accuracy: 0.8798Epoch 19/50: loss=0.2973, accuracy=0.8796, val_loss=0.2628, val_accuracy=0.8990\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.2973 - accuracy: 0.8796 - val_loss: 0.2628 - val_accuracy: 0.8990 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.8907Epoch 20/50: loss=0.2667, accuracy=0.8907, val_loss=0.2406, val_accuracy=0.9040\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.2667 - accuracy: 0.8907 - val_loss: 0.2406 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.8930Epoch 21/50: loss=0.2638, accuracy=0.8930, val_loss=0.1355, val_accuracy=0.9636\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.2638 - accuracy: 0.8930 - val_loss: 0.1355 - val_accuracy: 0.9636 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9080Epoch 22/50: loss=0.2298, accuracy=0.9077, val_loss=0.1135, val_accuracy=0.9768\n",
      "604/604 [==============================] - 23s 38ms/step - loss: 0.2298 - accuracy: 0.9077 - val_loss: 0.1135 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9129Epoch 23/50: loss=0.2212, accuracy=0.9131, val_loss=0.1862, val_accuracy=0.9214\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.2212 - accuracy: 0.9131 - val_loss: 0.1862 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9135Epoch 24/50: loss=0.2159, accuracy=0.9135, val_loss=0.2853, val_accuracy=0.8907\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.2159 - accuracy: 0.9135 - val_loss: 0.2853 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9241Epoch 25/50: loss=0.1899, accuracy=0.9243, val_loss=0.0841, val_accuracy=0.9743\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1899 - accuracy: 0.9243 - val_loss: 0.0841 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9260Epoch 26/50: loss=0.1921, accuracy=0.9261, val_loss=0.1759, val_accuracy=0.9305\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1921 - accuracy: 0.9261 - val_loss: 0.1759 - val_accuracy: 0.9305 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9255Epoch 27/50: loss=0.1936, accuracy=0.9255, val_loss=0.1025, val_accuracy=0.9561\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.1936 - accuracy: 0.9255 - val_loss: 0.1025 - val_accuracy: 0.9561 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9404Epoch 28/50: loss=0.1604, accuracy=0.9404, val_loss=0.2329, val_accuracy=0.8924\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1604 - accuracy: 0.9404 - val_loss: 0.2329 - val_accuracy: 0.8924 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9341Epoch 29/50: loss=0.1671, accuracy=0.9342, val_loss=0.0705, val_accuracy=0.9702\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.1671 - accuracy: 0.9342 - val_loss: 0.0705 - val_accuracy: 0.9702 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.9494Epoch 30/50: loss=0.1373, accuracy=0.9493, val_loss=0.0901, val_accuracy=0.9719\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1373 - accuracy: 0.9493 - val_loss: 0.0901 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9532Epoch 31/50: loss=0.1221, accuracy=0.9532, val_loss=0.0536, val_accuracy=0.9876\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1221 - accuracy: 0.9532 - val_loss: 0.0536 - val_accuracy: 0.9876 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9558Epoch 32/50: loss=0.1248, accuracy=0.9557, val_loss=0.1021, val_accuracy=0.9677\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1248 - accuracy: 0.9557 - val_loss: 0.1021 - val_accuracy: 0.9677 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9515Epoch 33/50: loss=0.1301, accuracy=0.9516, val_loss=0.1838, val_accuracy=0.9329\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.1301 - accuracy: 0.9516 - val_loss: 0.1838 - val_accuracy: 0.9329 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9466Epoch 34/50: loss=0.1477, accuracy=0.9466, val_loss=0.1355, val_accuracy=0.9371\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1477 - accuracy: 0.9466 - val_loss: 0.1355 - val_accuracy: 0.9371 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9443Epoch 35/50: loss=0.1575, accuracy=0.9443, val_loss=0.1159, val_accuracy=0.9578\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.1575 - accuracy: 0.9443 - val_loss: 0.1159 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9585\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 36/50: loss=0.1207, accuracy=0.9580, val_loss=0.0607, val_accuracy=0.9776\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.1207 - accuracy: 0.9580 - val_loss: 0.0607 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9716Epoch 37/50: loss=0.0929, accuracy=0.9716, val_loss=0.0133, val_accuracy=0.9967\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.0929 - accuracy: 0.9716 - val_loss: 0.0133 - val_accuracy: 0.9967 - lr: 2.0000e-05\n",
      "Epoch 38/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9743Epoch 38/50: loss=0.0716, accuracy=0.9743, val_loss=0.0128, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0716 - accuracy: 0.9743 - val_loss: 0.0128 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9824Epoch 39/50: loss=0.0588, accuracy=0.9824, val_loss=0.0088, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.0088 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9851Epoch 40/50: loss=0.0481, accuracy=0.9851, val_loss=0.0101, val_accuracy=0.9975\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.0101 - val_accuracy: 0.9975 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9803Epoch 41/50: loss=0.0657, accuracy=0.9803, val_loss=0.0051, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0657 - accuracy: 0.9803 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9772Epoch 42/50: loss=0.0568, accuracy=0.9772, val_loss=0.0053, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0568 - accuracy: 0.9772 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9782Epoch 43/50: loss=0.0646, accuracy=0.9783, val_loss=0.0094, val_accuracy=0.9975\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 0.0094 - val_accuracy: 0.9975 - lr: 2.0000e-05\n",
      "Epoch 44/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9890Epoch 44/50: loss=0.0388, accuracy=0.9890, val_loss=0.0026, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 45/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9838Epoch 45/50: loss=0.0546, accuracy=0.9839, val_loss=0.0034, val_accuracy=1.0000\n",
      "604/604 [==============================] - 23s 39ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.0034 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 46/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9867Epoch 46/50: loss=0.0395, accuracy=0.9868, val_loss=0.0039, val_accuracy=0.9975\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.0039 - val_accuracy: 0.9975 - lr: 2.0000e-05\n",
      "Epoch 47/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9853Epoch 47/50: loss=0.0471, accuracy=0.9853, val_loss=0.0084, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.0084 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 48/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9859Epoch 48/50: loss=0.0422, accuracy=0.9859, val_loss=0.0056, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0056 - val_accuracy: 1.0000 - lr: 2.0000e-05\n",
      "Epoch 49/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9874\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 49/50: loss=0.0395, accuracy=0.9874, val_loss=0.0046, val_accuracy=0.9992\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0046 - val_accuracy: 0.9992 - lr: 2.0000e-05\n",
      "Epoch 50/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9857Epoch 50/50: loss=0.0423, accuracy=0.9857, val_loss=0.0028, val_accuracy=1.0000\n",
      "604/604 [==============================] - 24s 39ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.0028 - val_accuracy: 1.0000 - lr: 4.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Define data augmentation\n",
    "def create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip):\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=rotation_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "def residual_block(x, filters, kernel_size):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('tanh')(x)\n",
    "    return x\n",
    "\n",
    "def build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function):\n",
    "    # Input layer for combined images\n",
    "    combined_input = Input(shape=(input_shape[1], input_shape[2], input_shape[3]), name='combined_input')\n",
    "    \n",
    "    # Convolutional base\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), activation=activation_function, padding='same')(combined_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, filters, kernel_size)\n",
    "        if x.shape[1] >= 2 and x.shape[2] >= 2:\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        x = Dense(2048, activation=activation_function)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# Define the specified parameters\n",
    "num_residual_blocks = 9\n",
    "dropout_rate = 0.35\n",
    "learning_rate = 0.0005\n",
    "filters = 128\n",
    "kernel_size = 1\n",
    "num_dense_layers = 1\n",
    "activation_function = 'tanh'\n",
    "rotation_range = 0\n",
    "width_shift_range = 0.0\n",
    "height_shift_range = 0.0\n",
    "shear_range = 0.4\n",
    "zoom_range = 0.0\n",
    "horizontal_flip = False\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Callbacks for training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Custom callback to print epoch details\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']}: loss={logs['loss']:.4f}, accuracy={logs['accuracy']:.4f}, val_loss={logs['val_loss']:.4f}, val_accuracy={logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Create data generator\n",
    "datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "datagen.fit(X_train)\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Build the model\n",
    "model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function)\n",
    "\n",
    "# Train the model\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66952fe-8736-4b7f-99f5-04c1216efba1",
   "metadata": {},
   "source": [
    "# Re-Validation of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1316d7-2a6c-4d6b-9390-657454ac0b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 23ms/step\n",
      "Confusion Matrix:\n",
      "[[724   0]\n",
      " [  0 484]]\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Healthy_augmented       1.00      1.00      1.00       724\n",
      "Damaged_augmented       1.00      1.00      1.00       484\n",
      "\n",
      "         accuracy                           1.00      1208\n",
      "        macro avg       1.00      1.00      1.00      1208\n",
      "     weighted avg       1.00      1.00      1.00      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "with tf.device('/GPU:0'):\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_val_true, y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2bbc0c-2bcf-47d3-9010-752748bf20e0",
   "metadata": {},
   "source": [
    "# Save the best model v2 with 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c650e1f4-f520-4b7b-8deb-821503fd4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to best_refined_model_v2_50Epochs.h5\n"
     ]
    }
   ],
   "source": [
    "# Saving the best refined version 2\n",
    "# Save the best model to a local directory\n",
    "model_save_path = 'best_refined_model_v2_50Epochs.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Best model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e786ea7-2ef8-472d-b045-7021934a475f",
   "metadata": {},
   "source": [
    "# Load and predict the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea01ace-517d-4f02-a7c2-3f1c5c126051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_refined_model_v2_50Epochs.h5\n",
      "38/38 [==============================] - 1s 10ms/step\n",
      "Confusion Matrix for loaded model:\n",
      "[[722   2]\n",
      " [  0 484]]\n",
      "Classification Report for loaded model:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Healthy_augmented       1.00      1.00      1.00       724\n",
      "Damaged_augmented       1.00      1.00      1.00       484\n",
      "\n",
      "         accuracy                           1.00      1208\n",
      "        macro avg       1.00      1.00      1.00      1208\n",
      "     weighted avg       1.00      1.00      1.00      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from the local directory\n",
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "with tf.device('/GPU:0'):\n",
    "    loaded_val_predictions = loaded_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "loaded_y_val_pred = np.argmax(loaded_val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix for the loaded model\n",
    "loaded_conf_matrix = confusion_matrix(y_val_true, loaded_y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix for loaded model:\")\n",
    "print(loaded_conf_matrix)\n",
    "\n",
    "# Generate the classification report for the loaded model\n",
    "loaded_class_report = classification_report(y_val_true, loaded_y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report for loaded model:\")\n",
    "print(loaded_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4f752-6f17-43d9-8d05-8b46fef5973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e45b77-4273-40c5-80e6-1be7bae8dd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932e664-f440-406e-ae04-b492dcd3568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76048222-5f6c-4deb-b320-e6e80c0b3bf7",
   "metadata": {},
   "source": [
    "# Initial Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e019777-904e-4eb7-a10c-0102459ba622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  1\n",
      "Training data shape: (4832, 64, 64, 6)\n",
      "Validation data shape: (1208, 64, 64, 6)\n",
      "Training labels shape: (4832, 2)\n",
      "Validation labels shape: (1208, 2)\n",
      "Class weights: {0: 0.8640915593705293, 1: 1.18664047151277}\n",
      "\n",
      "Refined Training Combination 1/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.4, zoom_range=0.0, horizontal_flip=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:2094: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n",
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1164 - accuracy: 0.5099Epoch 1/40: loss=1.1164, accuracy=0.5099, val_loss=1.1476, val_accuracy=0.3998\n",
      "604/604 [==============================] - 13s 16ms/step - loss: 1.1164 - accuracy: 0.5099 - val_loss: 1.1476 - val_accuracy: 0.3998 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8675 - accuracy: 0.5150Epoch 2/40: loss=0.8680, accuracy=0.5141, val_loss=0.8804, val_accuracy=0.4776\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8680 - accuracy: 0.5141 - val_loss: 0.8804 - val_accuracy: 0.4776 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8590 - accuracy: 0.5135Epoch 3/40: loss=0.8590, accuracy=0.5135, val_loss=0.7617, val_accuracy=0.5919\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8590 - accuracy: 0.5135 - val_loss: 0.7617 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.5348Epoch 4/40: loss=0.7965, accuracy=0.5348, val_loss=0.6949, val_accuracy=0.5985\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7965 - accuracy: 0.5348 - val_loss: 0.6949 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8024 - accuracy: 0.5406Epoch 5/40: loss=0.8020, accuracy=0.5408, val_loss=0.7472, val_accuracy=0.5604\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8020 - accuracy: 0.5408 - val_loss: 0.7472 - val_accuracy: 0.5604 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.6113Epoch 6/40: loss=0.7263, accuracy=0.6113, val_loss=0.6807, val_accuracy=0.5944\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7263 - accuracy: 0.6113 - val_loss: 0.6807 - val_accuracy: 0.5944 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8477 - accuracy: 0.5326Epoch 7/40: loss=0.8482, accuracy=0.5325, val_loss=0.7949, val_accuracy=0.5993\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8482 - accuracy: 0.5325 - val_loss: 0.7949 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8535 - accuracy: 0.4917Epoch 8/40: loss=0.8535, accuracy=0.4917, val_loss=0.6823, val_accuracy=0.5646\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8535 - accuracy: 0.4917 - val_loss: 0.6823 - val_accuracy: 0.5646 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.4950Epoch 9/40: loss=0.8211, accuracy=0.4950, val_loss=0.6925, val_accuracy=0.5464\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8211 - accuracy: 0.4950 - val_loss: 0.6925 - val_accuracy: 0.5464 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8074 - accuracy: 0.5021Epoch 10/40: loss=0.8074, accuracy=0.5021, val_loss=0.7748, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8074 - accuracy: 0.5021 - val_loss: 0.7748 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7972 - accuracy: 0.5077Epoch 11/40: loss=0.7974, accuracy=0.5075, val_loss=0.6736, val_accuracy=0.5985\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7974 - accuracy: 0.5075 - val_loss: 0.6736 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8384 - accuracy: 0.5083Epoch 12/40: loss=0.8389, accuracy=0.5077, val_loss=0.7056, val_accuracy=0.4478\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8389 - accuracy: 0.5077 - val_loss: 0.7056 - val_accuracy: 0.4478 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7914 - accuracy: 0.4967Epoch 13/40: loss=0.7914, accuracy=0.4967, val_loss=0.6835, val_accuracy=0.5844\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7914 - accuracy: 0.4967 - val_loss: 0.6835 - val_accuracy: 0.5844 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7962 - accuracy: 0.4886Epoch 14/40: loss=0.7957, accuracy=0.4892, val_loss=0.7414, val_accuracy=0.5803\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7957 - accuracy: 0.4892 - val_loss: 0.7414 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7990 - accuracy: 0.5087Epoch 15/40: loss=0.7986, accuracy=0.5085, val_loss=0.8052, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7986 - accuracy: 0.5085 - val_loss: 0.8052 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8033 - accuracy: 0.5023\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 16/40: loss=0.8028, accuracy=0.5027, val_loss=0.7108, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8028 - accuracy: 0.5027 - val_loss: 0.7108 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.4894Epoch 17/40: loss=0.7448, accuracy=0.4894, val_loss=0.6943, val_accuracy=0.5381\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7448 - accuracy: 0.4894 - val_loss: 0.6943 - val_accuracy: 0.5381 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7429 - accuracy: 0.4952Epoch 18/40: loss=0.7433, accuracy=0.4946, val_loss=0.6858, val_accuracy=0.5364\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7433 - accuracy: 0.4946 - val_loss: 0.6858 - val_accuracy: 0.5364 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.5102Epoch 19/40: loss=0.7274, accuracy=0.5106, val_loss=0.6947, val_accuracy=0.4636\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7274 - accuracy: 0.5106 - val_loss: 0.6947 - val_accuracy: 0.4636 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7402 - accuracy: 0.4863Epoch 20/40: loss=0.7402, accuracy=0.4863, val_loss=0.6877, val_accuracy=0.5248\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7402 - accuracy: 0.4863 - val_loss: 0.6877 - val_accuracy: 0.5248 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7348 - accuracy: 0.5029\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.7345, accuracy=0.5035, val_loss=0.7986, val_accuracy=0.5356\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7345 - accuracy: 0.5035 - val_loss: 0.7986 - val_accuracy: 0.5356 - lr: 2.0000e-04\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "Model with validation accuracy 0.5993377566337585 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 2/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9767 - accuracy: 0.5021Epoch 1/40: loss=0.9751, accuracy=0.5031, val_loss=0.7920, val_accuracy=0.5281\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9751 - accuracy: 0.5031 - val_loss: 0.7920 - val_accuracy: 0.5281 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9131 - accuracy: 0.5195Epoch 2/40: loss=0.9131, accuracy=0.5195, val_loss=0.7360, val_accuracy=0.5679\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.9131 - accuracy: 0.5195 - val_loss: 0.7360 - val_accuracy: 0.5679 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8717 - accuracy: 0.5305Epoch 3/40: loss=0.8709, accuracy=0.5312, val_loss=0.7616, val_accuracy=0.5124\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8709 - accuracy: 0.5312 - val_loss: 0.7616 - val_accuracy: 0.5124 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8615 - accuracy: 0.5176Epoch 4/40: loss=0.8615, accuracy=0.5176, val_loss=0.7859, val_accuracy=0.4669\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8615 - accuracy: 0.5176 - val_loss: 0.7859 - val_accuracy: 0.4669 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8340 - accuracy: 0.5266Epoch 5/40: loss=0.8334, accuracy=0.5269, val_loss=0.7092, val_accuracy=0.5588\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8334 - accuracy: 0.5269 - val_loss: 0.7092 - val_accuracy: 0.5588 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8098 - accuracy: 0.5432Epoch 6/40: loss=0.8095, accuracy=0.5433, val_loss=0.8511, val_accuracy=0.4768\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8095 - accuracy: 0.5433 - val_loss: 0.8511 - val_accuracy: 0.4768 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7887 - accuracy: 0.5480Epoch 7/40: loss=0.7883, accuracy=0.5482, val_loss=0.7148, val_accuracy=0.5364\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7883 - accuracy: 0.5482 - val_loss: 0.7148 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7840 - accuracy: 0.5326Epoch 8/40: loss=0.7839, accuracy=0.5325, val_loss=0.7879, val_accuracy=0.4925\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7839 - accuracy: 0.5325 - val_loss: 0.7879 - val_accuracy: 0.4925 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7687 - accuracy: 0.5439Epoch 9/40: loss=0.7688, accuracy=0.5435, val_loss=0.6642, val_accuracy=0.6142\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7688 - accuracy: 0.5435 - val_loss: 0.6642 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7545 - accuracy: 0.5465Epoch 10/40: loss=0.7543, accuracy=0.5468, val_loss=0.6747, val_accuracy=0.6018\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7543 - accuracy: 0.5468 - val_loss: 0.6747 - val_accuracy: 0.6018 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.5764Epoch 11/40: loss=0.7252, accuracy=0.5764, val_loss=0.7065, val_accuracy=0.5588\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7252 - accuracy: 0.5764 - val_loss: 0.7065 - val_accuracy: 0.5588 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7160 - accuracy: 0.5793Epoch 12/40: loss=0.7160, accuracy=0.5793, val_loss=0.6879, val_accuracy=0.5753\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7160 - accuracy: 0.5793 - val_loss: 0.6879 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.5971Epoch 13/40: loss=0.7006, accuracy=0.5971, val_loss=0.6778, val_accuracy=0.5811\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7006 - accuracy: 0.5971 - val_loss: 0.6778 - val_accuracy: 0.5811 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.5916\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 14/40: loss=0.6917, accuracy=0.5915, val_loss=0.7644, val_accuracy=0.5745\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6917 - accuracy: 0.5915 - val_loss: 0.7644 - val_accuracy: 0.5745 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.6150Epoch 15/40: loss=0.6711, accuracy=0.6144, val_loss=0.6496, val_accuracy=0.6134\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6711 - accuracy: 0.6144 - val_loss: 0.6496 - val_accuracy: 0.6134 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.6200Epoch 16/40: loss=0.6676, accuracy=0.6200, val_loss=0.6445, val_accuracy=0.6374\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6676 - accuracy: 0.6200 - val_loss: 0.6445 - val_accuracy: 0.6374 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.6296Epoch 17/40: loss=0.6512, accuracy=0.6293, val_loss=0.6058, val_accuracy=0.6656\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6512 - accuracy: 0.6293 - val_loss: 0.6058 - val_accuracy: 0.6656 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6449 - accuracy: 0.6356Epoch 18/40: loss=0.6444, accuracy=0.6362, val_loss=0.5829, val_accuracy=0.6863\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6444 - accuracy: 0.6362 - val_loss: 0.5829 - val_accuracy: 0.6863 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6350 - accuracy: 0.6424Epoch 19/40: loss=0.6352, accuracy=0.6422, val_loss=0.6100, val_accuracy=0.6647\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6352 - accuracy: 0.6422 - val_loss: 0.6100 - val_accuracy: 0.6647 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6244 - accuracy: 0.6638Epoch 20/40: loss=0.6245, accuracy=0.6635, val_loss=0.5923, val_accuracy=0.6846\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6245 - accuracy: 0.6635 - val_loss: 0.5923 - val_accuracy: 0.6846 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6221 - accuracy: 0.6570Epoch 21/40: loss=0.6223, accuracy=0.6571, val_loss=0.5714, val_accuracy=0.7012\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6223 - accuracy: 0.6571 - val_loss: 0.5714 - val_accuracy: 0.7012 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.6615Epoch 22/40: loss=0.6239, accuracy=0.6614, val_loss=0.5859, val_accuracy=0.6854\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6239 - accuracy: 0.6614 - val_loss: 0.5859 - val_accuracy: 0.6854 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6028 - accuracy: 0.6739Epoch 23/40: loss=0.6034, accuracy=0.6734, val_loss=0.6005, val_accuracy=0.6805\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6034 - accuracy: 0.6734 - val_loss: 0.6005 - val_accuracy: 0.6805 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.6770Epoch 24/40: loss=0.6072, accuracy=0.6769, val_loss=0.6068, val_accuracy=0.6871\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6072 - accuracy: 0.6769 - val_loss: 0.6068 - val_accuracy: 0.6871 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.6606Epoch 25/40: loss=0.6225, accuracy=0.6608, val_loss=0.5981, val_accuracy=0.6887\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6225 - accuracy: 0.6608 - val_loss: 0.5981 - val_accuracy: 0.6887 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.6728\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 26/40: loss=0.6041, accuracy=0.6726, val_loss=0.6323, val_accuracy=0.6300\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6041 - accuracy: 0.6726 - val_loss: 0.6323 - val_accuracy: 0.6300 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.6845Epoch 27/40: loss=0.5914, accuracy=0.6848, val_loss=0.6008, val_accuracy=0.6755\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5914 - accuracy: 0.6848 - val_loss: 0.6008 - val_accuracy: 0.6755 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.6841Epoch 28/40: loss=0.5922, accuracy=0.6838, val_loss=0.5958, val_accuracy=0.6846\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5922 - accuracy: 0.6838 - val_loss: 0.5958 - val_accuracy: 0.6846 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.6819Epoch 29/40: loss=0.5998, accuracy=0.6821, val_loss=0.5843, val_accuracy=0.6995\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5998 - accuracy: 0.6821 - val_loss: 0.5843 - val_accuracy: 0.6995 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5867 - accuracy: 0.6880Epoch 30/40: loss=0.5868, accuracy=0.6879, val_loss=0.6114, val_accuracy=0.6730\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5868 - accuracy: 0.6879 - val_loss: 0.6114 - val_accuracy: 0.6730 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.6743\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 31/40: loss=0.6034, accuracy=0.6743, val_loss=0.5929, val_accuracy=0.6780\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6034 - accuracy: 0.6743 - val_loss: 0.5929 - val_accuracy: 0.6780 - lr: 4.0000e-06\n",
      "Epoch 31: early stopping\n",
      "Validation accuracy: 0.7011589407920837\n",
      "Model with validation accuracy 0.7011589407920837 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 3/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9208 - accuracy: 0.5405Epoch 1/40: loss=0.9208, accuracy=0.5408, val_loss=0.7203, val_accuracy=0.5753\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9208 - accuracy: 0.5408 - val_loss: 0.7203 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9188 - accuracy: 0.5265Epoch 2/40: loss=0.9189, accuracy=0.5263, val_loss=0.7822, val_accuracy=0.5397\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.9189 - accuracy: 0.5263 - val_loss: 0.7822 - val_accuracy: 0.5397 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8593 - accuracy: 0.5495Epoch 3/40: loss=0.8598, accuracy=0.5493, val_loss=0.8106, val_accuracy=0.5141\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.8598 - accuracy: 0.5493 - val_loss: 0.8106 - val_accuracy: 0.5141 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8402 - accuracy: 0.5507Epoch 4/40: loss=0.8401, accuracy=0.5507, val_loss=0.7696, val_accuracy=0.5281\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.8401 - accuracy: 0.5507 - val_loss: 0.7696 - val_accuracy: 0.5281 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8092 - accuracy: 0.5529Epoch 5/40: loss=0.8086, accuracy=0.5530, val_loss=0.6724, val_accuracy=0.6084\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8086 - accuracy: 0.5530 - val_loss: 0.6724 - val_accuracy: 0.6084 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7731 - accuracy: 0.5845Epoch 6/40: loss=0.7724, accuracy=0.5849, val_loss=0.6821, val_accuracy=0.6068\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7724 - accuracy: 0.5849 - val_loss: 0.6821 - val_accuracy: 0.6068 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7625 - accuracy: 0.5826Epoch 7/40: loss=0.7623, accuracy=0.5824, val_loss=0.6999, val_accuracy=0.5911\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7623 - accuracy: 0.5824 - val_loss: 0.6999 - val_accuracy: 0.5911 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7254 - accuracy: 0.5982Epoch 8/40: loss=0.7256, accuracy=0.5981, val_loss=0.6969, val_accuracy=0.5861\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7256 - accuracy: 0.5981 - val_loss: 0.6969 - val_accuracy: 0.5861 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7055 - accuracy: 0.6283Epoch 9/40: loss=0.7055, accuracy=0.6281, val_loss=0.6617, val_accuracy=0.6184\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7055 - accuracy: 0.6281 - val_loss: 0.6617 - val_accuracy: 0.6184 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6896 - accuracy: 0.6321Epoch 10/40: loss=0.6886, accuracy=0.6331, val_loss=0.6805, val_accuracy=0.6076\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6886 - accuracy: 0.6331 - val_loss: 0.6805 - val_accuracy: 0.6076 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.6362Epoch 11/40: loss=0.6676, accuracy=0.6364, val_loss=0.5908, val_accuracy=0.6780\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6676 - accuracy: 0.6364 - val_loss: 0.5908 - val_accuracy: 0.6780 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.6513Epoch 12/40: loss=0.6425, accuracy=0.6513, val_loss=0.6145, val_accuracy=0.6995\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6425 - accuracy: 0.6513 - val_loss: 0.6145 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6415 - accuracy: 0.6604Epoch 13/40: loss=0.6417, accuracy=0.6604, val_loss=0.6757, val_accuracy=0.6051\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6417 - accuracy: 0.6604 - val_loss: 0.6757 - val_accuracy: 0.6051 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6726Epoch 14/40: loss=0.6139, accuracy=0.6726, val_loss=0.6057, val_accuracy=0.6879\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6139 - accuracy: 0.6726 - val_loss: 0.6057 - val_accuracy: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.6694Epoch 15/40: loss=0.6242, accuracy=0.6695, val_loss=0.5837, val_accuracy=0.6929\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6242 - accuracy: 0.6695 - val_loss: 0.5837 - val_accuracy: 0.6929 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5878 - accuracy: 0.6998Epoch 16/40: loss=0.5878, accuracy=0.6997, val_loss=0.5883, val_accuracy=0.6954\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5878 - accuracy: 0.6997 - val_loss: 0.5883 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.6978Epoch 17/40: loss=0.5831, accuracy=0.6978, val_loss=0.5249, val_accuracy=0.7334\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5831 - accuracy: 0.6978 - val_loss: 0.5249 - val_accuracy: 0.7334 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5783 - accuracy: 0.7046Epoch 18/40: loss=0.5780, accuracy=0.7047, val_loss=0.5550, val_accuracy=0.7310\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5780 - accuracy: 0.7047 - val_loss: 0.5550 - val_accuracy: 0.7310 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5665 - accuracy: 0.7096Epoch 19/40: loss=0.5669, accuracy=0.7092, val_loss=0.6023, val_accuracy=0.6722\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5669 - accuracy: 0.7092 - val_loss: 0.6023 - val_accuracy: 0.6722 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5568 - accuracy: 0.7177Epoch 20/40: loss=0.5570, accuracy=0.7177, val_loss=0.5346, val_accuracy=0.7376\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5570 - accuracy: 0.7177 - val_loss: 0.5346 - val_accuracy: 0.7376 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7197Epoch 21/40: loss=0.5568, accuracy=0.7198, val_loss=0.7178, val_accuracy=0.6093\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5568 - accuracy: 0.7198 - val_loss: 0.7178 - val_accuracy: 0.6093 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5484 - accuracy: 0.7250\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 22/40: loss=0.5474, accuracy=0.7258, val_loss=0.5565, val_accuracy=0.7202\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5474 - accuracy: 0.7258 - val_loss: 0.5565 - val_accuracy: 0.7202 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.7384Epoch 23/40: loss=0.5289, accuracy=0.7386, val_loss=0.5551, val_accuracy=0.7210\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5289 - accuracy: 0.7386 - val_loss: 0.5551 - val_accuracy: 0.7210 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5298 - accuracy: 0.7421Epoch 24/40: loss=0.5299, accuracy=0.7419, val_loss=0.5171, val_accuracy=0.7334\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5299 - accuracy: 0.7419 - val_loss: 0.5171 - val_accuracy: 0.7334 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.7440Epoch 25/40: loss=0.5230, accuracy=0.7442, val_loss=0.4985, val_accuracy=0.7550\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5230 - accuracy: 0.7442 - val_loss: 0.4985 - val_accuracy: 0.7550 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.7521Epoch 26/40: loss=0.5125, accuracy=0.7519, val_loss=0.5145, val_accuracy=0.7401\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5125 - accuracy: 0.7519 - val_loss: 0.5145 - val_accuracy: 0.7401 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.7419Epoch 27/40: loss=0.5255, accuracy=0.7421, val_loss=0.4848, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5255 - accuracy: 0.7421 - val_loss: 0.4848 - val_accuracy: 0.7707 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.7556Epoch 28/40: loss=0.5028, accuracy=0.7554, val_loss=0.4660, val_accuracy=0.7790\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5028 - accuracy: 0.7554 - val_loss: 0.4660 - val_accuracy: 0.7790 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7508Epoch 29/40: loss=0.5135, accuracy=0.7508, val_loss=0.4959, val_accuracy=0.7632\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5135 - accuracy: 0.7508 - val_loss: 0.4959 - val_accuracy: 0.7632 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7546Epoch 30/40: loss=0.5017, accuracy=0.7550, val_loss=0.4646, val_accuracy=0.7740\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5017 - accuracy: 0.7550 - val_loss: 0.4646 - val_accuracy: 0.7740 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5113 - accuracy: 0.7469Epoch 31/40: loss=0.5107, accuracy=0.7471, val_loss=0.4944, val_accuracy=0.7690\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5107 - accuracy: 0.7471 - val_loss: 0.4944 - val_accuracy: 0.7690 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.7560Epoch 32/40: loss=0.5012, accuracy=0.7560, val_loss=0.4302, val_accuracy=0.7988\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5012 - accuracy: 0.7560 - val_loss: 0.4302 - val_accuracy: 0.7988 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7525Epoch 33/40: loss=0.5017, accuracy=0.7529, val_loss=0.4823, val_accuracy=0.7657\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5017 - accuracy: 0.7529 - val_loss: 0.4823 - val_accuracy: 0.7657 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.7537Epoch 34/40: loss=0.4978, accuracy=0.7537, val_loss=0.4525, val_accuracy=0.7930\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4978 - accuracy: 0.7537 - val_loss: 0.4525 - val_accuracy: 0.7930 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4940 - accuracy: 0.7596Epoch 35/40: loss=0.4946, accuracy=0.7589, val_loss=0.4656, val_accuracy=0.7781\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.4946 - accuracy: 0.7589 - val_loss: 0.4656 - val_accuracy: 0.7781 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4933 - accuracy: 0.7554Epoch 36/40: loss=0.4939, accuracy=0.7552, val_loss=0.4567, val_accuracy=0.7939\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.4939 - accuracy: 0.7552 - val_loss: 0.4567 - val_accuracy: 0.7939 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7624\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 37/40: loss=0.5005, accuracy=0.7624, val_loss=0.4404, val_accuracy=0.8137\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5005 - accuracy: 0.7624 - val_loss: 0.4404 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.7695Epoch 38/40: loss=0.4946, accuracy=0.7695, val_loss=0.4649, val_accuracy=0.7947\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4946 - accuracy: 0.7695 - val_loss: 0.4649 - val_accuracy: 0.7947 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.7664Epoch 39/40: loss=0.4850, accuracy=0.7663, val_loss=0.4549, val_accuracy=0.7964\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.4850 - accuracy: 0.7663 - val_loss: 0.4549 - val_accuracy: 0.7964 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.7647Epoch 40/40: loss=0.4865, accuracy=0.7647, val_loss=0.4423, val_accuracy=0.8013\n",
      "604/604 [==============================] - 8s 14ms/step - loss: 0.4865 - accuracy: 0.7647 - val_loss: 0.4423 - val_accuracy: 0.8013 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.8137417435646057\n",
      "Model with validation accuracy 0.8137417435646057 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 4/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.6, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1066 - accuracy: 0.5222Epoch 1/40: loss=1.1061, accuracy=0.5226, val_loss=0.7813, val_accuracy=0.5099\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 1.1061 - accuracy: 0.5226 - val_loss: 0.7813 - val_accuracy: 0.5099 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.5399Epoch 2/40: loss=0.8578, accuracy=0.5399, val_loss=0.7401, val_accuracy=0.5886\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8578 - accuracy: 0.5399 - val_loss: 0.7401 - val_accuracy: 0.5886 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8237 - accuracy: 0.5482Epoch 3/40: loss=0.8237, accuracy=0.5482, val_loss=0.7208, val_accuracy=0.5952\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8237 - accuracy: 0.5482 - val_loss: 0.7208 - val_accuracy: 0.5952 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7687 - accuracy: 0.5814Epoch 4/40: loss=0.7680, accuracy=0.5817, val_loss=0.8629, val_accuracy=0.4702\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7680 - accuracy: 0.5817 - val_loss: 0.8629 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7805 - accuracy: 0.5973Epoch 5/40: loss=0.7805, accuracy=0.5973, val_loss=0.8855, val_accuracy=0.6151\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7805 - accuracy: 0.5973 - val_loss: 0.8855 - val_accuracy: 0.6151 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7731 - accuracy: 0.5966Epoch 6/40: loss=0.7734, accuracy=0.5962, val_loss=0.8585, val_accuracy=0.5331\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7734 - accuracy: 0.5962 - val_loss: 0.8585 - val_accuracy: 0.5331 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.6126Epoch 7/40: loss=0.7375, accuracy=0.6126, val_loss=0.9715, val_accuracy=0.4768\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7375 - accuracy: 0.6126 - val_loss: 0.9715 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7453 - accuracy: 0.5955\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.7458, accuracy=0.5958, val_loss=0.9652, val_accuracy=0.6093\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7458 - accuracy: 0.5958 - val_loss: 0.9652 - val_accuracy: 0.6093 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.6148Epoch 9/40: loss=0.6904, accuracy=0.6144, val_loss=0.7411, val_accuracy=0.5853\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6904 - accuracy: 0.6144 - val_loss: 0.7411 - val_accuracy: 0.5853 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.6569Epoch 10/40: loss=0.6457, accuracy=0.6575, val_loss=0.6145, val_accuracy=0.6498\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6457 - accuracy: 0.6575 - val_loss: 0.6145 - val_accuracy: 0.6498 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.6642Epoch 11/40: loss=0.6311, accuracy=0.6647, val_loss=0.7313, val_accuracy=0.5737\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6311 - accuracy: 0.6647 - val_loss: 0.7313 - val_accuracy: 0.5737 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.6863Epoch 12/40: loss=0.6031, accuracy=0.6865, val_loss=0.5701, val_accuracy=0.7210\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6031 - accuracy: 0.6865 - val_loss: 0.5701 - val_accuracy: 0.7210 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5951 - accuracy: 0.6922Epoch 13/40: loss=0.5945, accuracy=0.6927, val_loss=1.1003, val_accuracy=0.5571\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5945 - accuracy: 0.6927 - val_loss: 1.1003 - val_accuracy: 0.5571 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5810 - accuracy: 0.7092Epoch 14/40: loss=0.5809, accuracy=0.7094, val_loss=0.8360, val_accuracy=0.5248\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5809 - accuracy: 0.7094 - val_loss: 0.8360 - val_accuracy: 0.5248 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.6997Epoch 15/40: loss=0.5897, accuracy=0.6989, val_loss=0.6377, val_accuracy=0.6291\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5897 - accuracy: 0.6989 - val_loss: 0.6377 - val_accuracy: 0.6291 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5826 - accuracy: 0.7027Epoch 16/40: loss=0.5825, accuracy=0.7030, val_loss=0.4832, val_accuracy=0.7550\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5825 - accuracy: 0.7030 - val_loss: 0.4832 - val_accuracy: 0.7550 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7074Epoch 17/40: loss=0.5836, accuracy=0.7074, val_loss=0.6000, val_accuracy=0.6714\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5836 - accuracy: 0.7074 - val_loss: 0.6000 - val_accuracy: 0.6714 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7170Epoch 18/40: loss=0.5635, accuracy=0.7173, val_loss=0.9228, val_accuracy=0.5935\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5635 - accuracy: 0.7173 - val_loss: 0.9228 - val_accuracy: 0.5935 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5661 - accuracy: 0.7183Epoch 19/40: loss=0.5660, accuracy=0.7183, val_loss=0.6671, val_accuracy=0.6134\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5660 - accuracy: 0.7183 - val_loss: 0.6671 - val_accuracy: 0.6134 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5585 - accuracy: 0.7180Epoch 20/40: loss=0.5583, accuracy=0.7183, val_loss=0.6949, val_accuracy=0.6399\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5583 - accuracy: 0.7183 - val_loss: 0.6949 - val_accuracy: 0.6399 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.7183\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 21/40: loss=0.5710, accuracy=0.7181, val_loss=0.5082, val_accuracy=0.7334\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5710 - accuracy: 0.7181 - val_loss: 0.5082 - val_accuracy: 0.7334 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5358 - accuracy: 0.7286Epoch 22/40: loss=0.5361, accuracy=0.7285, val_loss=0.5382, val_accuracy=0.7210\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5361 - accuracy: 0.7285 - val_loss: 0.5382 - val_accuracy: 0.7210 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5211 - accuracy: 0.7408Epoch 23/40: loss=0.5211, accuracy=0.7409, val_loss=0.5651, val_accuracy=0.7020\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5211 - accuracy: 0.7409 - val_loss: 0.5651 - val_accuracy: 0.7020 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.7421Epoch 24/40: loss=0.5251, accuracy=0.7430, val_loss=0.6154, val_accuracy=0.6780\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5251 - accuracy: 0.7430 - val_loss: 0.6154 - val_accuracy: 0.6780 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.7488Epoch 25/40: loss=0.5233, accuracy=0.7488, val_loss=0.6238, val_accuracy=0.6689\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5233 - accuracy: 0.7488 - val_loss: 0.6238 - val_accuracy: 0.6689 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.5179 - accuracy: 0.7592Epoch 26/40: loss=0.5172, accuracy=0.7593, val_loss=0.4477, val_accuracy=0.7798\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5172 - accuracy: 0.7593 - val_loss: 0.4477 - val_accuracy: 0.7798 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.7556Epoch 27/40: loss=0.5083, accuracy=0.7554, val_loss=0.5066, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5083 - accuracy: 0.7554 - val_loss: 0.5066 - val_accuracy: 0.7599 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.7546Epoch 28/40: loss=0.5058, accuracy=0.7541, val_loss=0.4455, val_accuracy=0.7748\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5058 - accuracy: 0.7541 - val_loss: 0.4455 - val_accuracy: 0.7748 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5128 - accuracy: 0.7479Epoch 29/40: loss=0.5126, accuracy=0.7479, val_loss=0.4361, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5126 - accuracy: 0.7479 - val_loss: 0.4361 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.7421Epoch 30/40: loss=0.5102, accuracy=0.7421, val_loss=0.4938, val_accuracy=0.7500\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5102 - accuracy: 0.7421 - val_loss: 0.4938 - val_accuracy: 0.7500 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5044 - accuracy: 0.7525Epoch 31/40: loss=0.5049, accuracy=0.7521, val_loss=0.4680, val_accuracy=0.7682\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5049 - accuracy: 0.7521 - val_loss: 0.4680 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4942 - accuracy: 0.7542Epoch 32/40: loss=0.4947, accuracy=0.7539, val_loss=0.5852, val_accuracy=0.7127\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4947 - accuracy: 0.7539 - val_loss: 0.5852 - val_accuracy: 0.7127 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.7677Epoch 33/40: loss=0.4828, accuracy=0.7672, val_loss=0.4644, val_accuracy=0.7740\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4828 - accuracy: 0.7672 - val_loss: 0.4644 - val_accuracy: 0.7740 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7601\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 34/40: loss=0.5005, accuracy=0.7601, val_loss=0.4738, val_accuracy=0.7657\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5005 - accuracy: 0.7601 - val_loss: 0.4738 - val_accuracy: 0.7657 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4822 - accuracy: 0.7664Epoch 35/40: loss=0.4821, accuracy=0.7663, val_loss=0.4669, val_accuracy=0.7674\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4821 - accuracy: 0.7663 - val_loss: 0.4669 - val_accuracy: 0.7674 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4893 - accuracy: 0.7602Epoch 36/40: loss=0.4896, accuracy=0.7599, val_loss=0.4639, val_accuracy=0.7649\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4896 - accuracy: 0.7599 - val_loss: 0.4639 - val_accuracy: 0.7649 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4907 - accuracy: 0.7672Epoch 37/40: loss=0.4903, accuracy=0.7674, val_loss=0.4530, val_accuracy=0.7674\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.4530 - val_accuracy: 0.7674 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4855 - accuracy: 0.7726Epoch 38/40: loss=0.4859, accuracy=0.7724, val_loss=0.4642, val_accuracy=0.7690\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4859 - accuracy: 0.7724 - val_loss: 0.4642 - val_accuracy: 0.7690 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.7684\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.4813, accuracy=0.7680, val_loss=0.4431, val_accuracy=0.7765\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4813 - accuracy: 0.7680 - val_loss: 0.4431 - val_accuracy: 0.7765 - lr: 8.0000e-06\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.7855960130691528\n",
      "\n",
      "Refined Training Combination 5/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0815 - accuracy: 0.5176Epoch 1/40: loss=1.0819, accuracy=0.5176, val_loss=0.8128, val_accuracy=0.5066\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 1.0819 - accuracy: 0.5176 - val_loss: 0.8128 - val_accuracy: 0.5066 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8607 - accuracy: 0.5323Epoch 2/40: loss=0.8607, accuracy=0.5323, val_loss=1.0587, val_accuracy=0.5646\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8607 - accuracy: 0.5323 - val_loss: 1.0587 - val_accuracy: 0.5646 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8188 - accuracy: 0.5519Epoch 3/40: loss=0.8179, accuracy=0.5526, val_loss=0.9296, val_accuracy=0.5778\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8179 - accuracy: 0.5526 - val_loss: 0.9296 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.8204 - accuracy: 0.5392Epoch 4/40: loss=0.8193, accuracy=0.5395, val_loss=0.8365, val_accuracy=0.4710\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8193 - accuracy: 0.5395 - val_loss: 0.8365 - val_accuracy: 0.4710 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7994 - accuracy: 0.5686Epoch 5/40: loss=0.7982, accuracy=0.5689, val_loss=0.8271, val_accuracy=0.5315\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7982 - accuracy: 0.5689 - val_loss: 0.8271 - val_accuracy: 0.5315 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7831 - accuracy: 0.5826Epoch 6/40: loss=0.7839, accuracy=0.5815, val_loss=0.7873, val_accuracy=0.4371\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7839 - accuracy: 0.5815 - val_loss: 0.7873 - val_accuracy: 0.4371 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.5882Epoch 7/40: loss=0.7777, accuracy=0.5880, val_loss=0.8846, val_accuracy=0.4139\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7777 - accuracy: 0.5880 - val_loss: 0.8846 - val_accuracy: 0.4139 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8014 - accuracy: 0.5564Epoch 8/40: loss=0.8025, accuracy=0.5561, val_loss=0.9440, val_accuracy=0.5969\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8025 - accuracy: 0.5561 - val_loss: 0.9440 - val_accuracy: 0.5969 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8082 - accuracy: 0.5558Epoch 9/40: loss=0.8079, accuracy=0.5559, val_loss=0.8169, val_accuracy=0.4785\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8079 - accuracy: 0.5559 - val_loss: 0.8169 - val_accuracy: 0.4785 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8043 - accuracy: 0.5383Epoch 10/40: loss=0.8043, accuracy=0.5383, val_loss=0.6778, val_accuracy=0.5952\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8043 - accuracy: 0.5383 - val_loss: 0.6778 - val_accuracy: 0.5952 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.5219Epoch 11/40: loss=0.8338, accuracy=0.5219, val_loss=0.8358, val_accuracy=0.4975\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8338 - accuracy: 0.5219 - val_loss: 0.8358 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8354 - accuracy: 0.5091Epoch 12/40: loss=0.8354, accuracy=0.5091, val_loss=0.8131, val_accuracy=0.5745\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8354 - accuracy: 0.5091 - val_loss: 0.8131 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8146 - accuracy: 0.5021Epoch 13/40: loss=0.8146, accuracy=0.5021, val_loss=0.6901, val_accuracy=0.4975\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8146 - accuracy: 0.5021 - val_loss: 0.6901 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8379 - accuracy: 0.5014Epoch 14/40: loss=0.8379, accuracy=0.5014, val_loss=0.6725, val_accuracy=0.6035\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8379 - accuracy: 0.5014 - val_loss: 0.6725 - val_accuracy: 0.6035 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8364 - accuracy: 0.5054Epoch 15/40: loss=0.8370, accuracy=0.5046, val_loss=0.6789, val_accuracy=0.5894\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8370 - accuracy: 0.5046 - val_loss: 0.6789 - val_accuracy: 0.5894 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8085 - accuracy: 0.4979Epoch 16/40: loss=0.8097, accuracy=0.4971, val_loss=0.6948, val_accuracy=0.5993\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8097 - accuracy: 0.4971 - val_loss: 0.6948 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8189 - accuracy: 0.4988Epoch 17/40: loss=0.8191, accuracy=0.4990, val_loss=1.0147, val_accuracy=0.3957\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8191 - accuracy: 0.4990 - val_loss: 1.0147 - val_accuracy: 0.3957 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8162 - accuracy: 0.5044Epoch 18/40: loss=0.8161, accuracy=0.5046, val_loss=0.8260, val_accuracy=0.5546\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8161 - accuracy: 0.5046 - val_loss: 0.8260 - val_accuracy: 0.5546 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8156 - accuracy: 0.5027\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 19/40: loss=0.8166, accuracy=0.5021, val_loss=0.7097, val_accuracy=0.4313\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8166 - accuracy: 0.5021 - val_loss: 0.7097 - val_accuracy: 0.4313 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7401 - accuracy: 0.5155Epoch 20/40: loss=0.7401, accuracy=0.5155, val_loss=0.7083, val_accuracy=0.3998\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7401 - accuracy: 0.5155 - val_loss: 0.7083 - val_accuracy: 0.3998 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7360 - accuracy: 0.5035Epoch 21/40: loss=0.7361, accuracy=0.5037, val_loss=0.6960, val_accuracy=0.5530\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7361 - accuracy: 0.5037 - val_loss: 0.6960 - val_accuracy: 0.5530 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7372 - accuracy: 0.4952Epoch 22/40: loss=0.7366, accuracy=0.4957, val_loss=0.7088, val_accuracy=0.4892\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7366 - accuracy: 0.4957 - val_loss: 0.7088 - val_accuracy: 0.4892 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7366 - accuracy: 0.4956Epoch 23/40: loss=0.7366, accuracy=0.4957, val_loss=0.7155, val_accuracy=0.4512\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7366 - accuracy: 0.4957 - val_loss: 0.7155 - val_accuracy: 0.4512 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7325 - accuracy: 0.5124\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.7325, accuracy=0.5126, val_loss=0.6944, val_accuracy=0.5439\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7325 - accuracy: 0.5126 - val_loss: 0.6944 - val_accuracy: 0.5439 - lr: 2.0000e-04\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.6034768223762512\n",
      "\n",
      "Refined Training Combination 6/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0543 - accuracy: 0.5257Epoch 1/40: loss=1.0543, accuracy=0.5257, val_loss=0.9461, val_accuracy=0.4354\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0543 - accuracy: 0.5257 - val_loss: 0.9461 - val_accuracy: 0.4354 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8447 - accuracy: 0.5292Epoch 2/40: loss=0.8445, accuracy=0.5290, val_loss=0.6970, val_accuracy=0.5695\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8445 - accuracy: 0.5290 - val_loss: 0.6970 - val_accuracy: 0.5695 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7873 - accuracy: 0.5339Epoch 3/40: loss=0.7873, accuracy=0.5339, val_loss=0.7107, val_accuracy=0.5919\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7873 - accuracy: 0.5339 - val_loss: 0.7107 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7392 - accuracy: 0.5772Epoch 4/40: loss=0.7391, accuracy=0.5768, val_loss=0.6336, val_accuracy=0.6540\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7391 - accuracy: 0.5768 - val_loss: 0.6336 - val_accuracy: 0.6540 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7100 - accuracy: 0.6022Epoch 5/40: loss=0.7100, accuracy=0.6018, val_loss=0.6950, val_accuracy=0.6093\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7100 - accuracy: 0.6018 - val_loss: 0.6950 - val_accuracy: 0.6093 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.6105Epoch 6/40: loss=0.7099, accuracy=0.6105, val_loss=0.6880, val_accuracy=0.5430\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7099 - accuracy: 0.6105 - val_loss: 0.6880 - val_accuracy: 0.5430 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.6348Epoch 7/40: loss=0.6798, accuracy=0.6349, val_loss=0.6383, val_accuracy=0.6416\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6798 - accuracy: 0.6349 - val_loss: 0.6383 - val_accuracy: 0.6416 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.6329Epoch 8/40: loss=0.6816, accuracy=0.6325, val_loss=0.6288, val_accuracy=0.6416\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6816 - accuracy: 0.6325 - val_loss: 0.6288 - val_accuracy: 0.6416 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.6521Epoch 9/40: loss=0.6658, accuracy=0.6521, val_loss=1.0702, val_accuracy=0.5083\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6658 - accuracy: 0.6521 - val_loss: 1.0702 - val_accuracy: 0.5083 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.6625Epoch 10/40: loss=0.6513, accuracy=0.6627, val_loss=1.2323, val_accuracy=0.4040\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6513 - accuracy: 0.6627 - val_loss: 1.2323 - val_accuracy: 0.4040 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6697 - accuracy: 0.6508Epoch 11/40: loss=0.6695, accuracy=0.6517, val_loss=0.8341, val_accuracy=0.6043\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6695 - accuracy: 0.6517 - val_loss: 0.8341 - val_accuracy: 0.6043 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.6702Epoch 12/40: loss=0.6316, accuracy=0.6701, val_loss=0.5952, val_accuracy=0.6871\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6316 - accuracy: 0.6701 - val_loss: 0.5952 - val_accuracy: 0.6871 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.6579Epoch 13/40: loss=0.6657, accuracy=0.6579, val_loss=0.6131, val_accuracy=0.6565\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6657 - accuracy: 0.6579 - val_loss: 0.6131 - val_accuracy: 0.6565 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.6574Epoch 14/40: loss=0.6509, accuracy=0.6577, val_loss=0.9704, val_accuracy=0.4561\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6509 - accuracy: 0.6577 - val_loss: 0.9704 - val_accuracy: 0.4561 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.6745Epoch 15/40: loss=0.6341, accuracy=0.6745, val_loss=0.7082, val_accuracy=0.5579\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6341 - accuracy: 0.6745 - val_loss: 0.7082 - val_accuracy: 0.5579 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.6480Epoch 16/40: loss=0.6654, accuracy=0.6480, val_loss=0.6927, val_accuracy=0.5687\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6654 - accuracy: 0.6480 - val_loss: 0.6927 - val_accuracy: 0.5687 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.6749\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/40: loss=0.6342, accuracy=0.6749, val_loss=0.6622, val_accuracy=0.6209\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6342 - accuracy: 0.6749 - val_loss: 0.6622 - val_accuracy: 0.6209 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5883 - accuracy: 0.7077Epoch 18/40: loss=0.5880, accuracy=0.7080, val_loss=0.6565, val_accuracy=0.6498\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5880 - accuracy: 0.7080 - val_loss: 0.6565 - val_accuracy: 0.6498 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5591 - accuracy: 0.7272Epoch 19/40: loss=0.5590, accuracy=0.7274, val_loss=0.8708, val_accuracy=0.5389\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5590 - accuracy: 0.7274 - val_loss: 0.8708 - val_accuracy: 0.5389 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.7250Epoch 20/40: loss=0.5530, accuracy=0.7250, val_loss=0.5946, val_accuracy=0.6796\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5530 - accuracy: 0.7250 - val_loss: 0.5946 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5571 - accuracy: 0.7170Epoch 21/40: loss=0.5567, accuracy=0.7173, val_loss=0.5224, val_accuracy=0.7583\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5567 - accuracy: 0.7173 - val_loss: 0.5224 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.7332Epoch 22/40: loss=0.5525, accuracy=0.7332, val_loss=0.4806, val_accuracy=0.7583\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5525 - accuracy: 0.7332 - val_loss: 0.4806 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.7332Epoch 23/40: loss=0.5433, accuracy=0.7332, val_loss=0.4609, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5433 - accuracy: 0.7332 - val_loss: 0.4609 - val_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7370Epoch 24/40: loss=0.5540, accuracy=0.7370, val_loss=0.4770, val_accuracy=0.7666\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5540 - accuracy: 0.7370 - val_loss: 0.4770 - val_accuracy: 0.7666 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5473 - accuracy: 0.7235Epoch 25/40: loss=0.5468, accuracy=0.7239, val_loss=0.7259, val_accuracy=0.5969\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5468 - accuracy: 0.7239 - val_loss: 0.7259 - val_accuracy: 0.5969 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.7461Epoch 26/40: loss=0.5317, accuracy=0.7461, val_loss=0.6296, val_accuracy=0.6714\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5317 - accuracy: 0.7461 - val_loss: 0.6296 - val_accuracy: 0.6714 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5369 - accuracy: 0.7324Epoch 27/40: loss=0.5375, accuracy=0.7320, val_loss=0.6122, val_accuracy=0.6598\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5375 - accuracy: 0.7320 - val_loss: 0.6122 - val_accuracy: 0.6598 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.7369\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 28/40: loss=0.5346, accuracy=0.7368, val_loss=0.5134, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5346 - accuracy: 0.7368 - val_loss: 0.5134 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.7481Epoch 29/40: loss=0.5200, accuracy=0.7486, val_loss=0.5055, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5200 - accuracy: 0.7486 - val_loss: 0.5055 - val_accuracy: 0.7384 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5136 - accuracy: 0.7456Epoch 30/40: loss=0.5135, accuracy=0.7461, val_loss=0.4987, val_accuracy=0.7508\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5135 - accuracy: 0.7461 - val_loss: 0.4987 - val_accuracy: 0.7508 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7399Epoch 31/40: loss=0.5215, accuracy=0.7399, val_loss=0.4880, val_accuracy=0.7467\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5215 - accuracy: 0.7399 - val_loss: 0.4880 - val_accuracy: 0.7467 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5040 - accuracy: 0.7492Epoch 32/40: loss=0.5042, accuracy=0.7492, val_loss=0.4522, val_accuracy=0.7914\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5042 - accuracy: 0.7492 - val_loss: 0.4522 - val_accuracy: 0.7914 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5085 - accuracy: 0.7485Epoch 33/40: loss=0.5089, accuracy=0.7486, val_loss=0.4972, val_accuracy=0.7368\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5089 - accuracy: 0.7486 - val_loss: 0.4972 - val_accuracy: 0.7368 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.7620Epoch 34/40: loss=0.5006, accuracy=0.7618, val_loss=0.4625, val_accuracy=0.7699\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5006 - accuracy: 0.7618 - val_loss: 0.4625 - val_accuracy: 0.7699 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.7510Epoch 35/40: loss=0.5117, accuracy=0.7512, val_loss=0.4715, val_accuracy=0.7790\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5117 - accuracy: 0.7512 - val_loss: 0.4715 - val_accuracy: 0.7790 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7572Epoch 36/40: loss=0.4948, accuracy=0.7572, val_loss=0.4596, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4948 - accuracy: 0.7572 - val_loss: 0.4596 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5052 - accuracy: 0.7600\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 37/40: loss=0.5061, accuracy=0.7595, val_loss=0.4631, val_accuracy=0.7740\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5061 - accuracy: 0.7595 - val_loss: 0.4631 - val_accuracy: 0.7740 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.7657Epoch 38/40: loss=0.4982, accuracy=0.7657, val_loss=0.4626, val_accuracy=0.7773\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4982 - accuracy: 0.7657 - val_loss: 0.4626 - val_accuracy: 0.7773 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.7618Epoch 39/40: loss=0.4944, accuracy=0.7618, val_loss=0.4680, val_accuracy=0.7699\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4944 - accuracy: 0.7618 - val_loss: 0.4680 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.7521Epoch 40/40: loss=0.5048, accuracy=0.7521, val_loss=0.4636, val_accuracy=0.7724\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5048 - accuracy: 0.7521 - val_loss: 0.4636 - val_accuracy: 0.7724 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.7913907170295715\n",
      "\n",
      "Refined Training Combination 7/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.4, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0816 - accuracy: 0.5116Epoch 1/40: loss=1.0804, accuracy=0.5116, val_loss=0.8273, val_accuracy=0.5853\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0804 - accuracy: 0.5116 - val_loss: 0.8273 - val_accuracy: 0.5853 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8381 - accuracy: 0.5373Epoch 2/40: loss=0.8381, accuracy=0.5373, val_loss=0.8953, val_accuracy=0.5215\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8381 - accuracy: 0.5373 - val_loss: 0.8953 - val_accuracy: 0.5215 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7279 - accuracy: 0.6061Epoch 3/40: loss=0.7279, accuracy=0.6060, val_loss=0.7453, val_accuracy=0.5762\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7279 - accuracy: 0.6060 - val_loss: 0.7453 - val_accuracy: 0.5762 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.6258Epoch 4/40: loss=0.6887, accuracy=0.6258, val_loss=0.7476, val_accuracy=0.6283\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6887 - accuracy: 0.6258 - val_loss: 0.7476 - val_accuracy: 0.6283 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6689 - accuracy: 0.6431Epoch 5/40: loss=0.6688, accuracy=0.6430, val_loss=0.6806, val_accuracy=0.5993\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6688 - accuracy: 0.6430 - val_loss: 0.6806 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6409 - accuracy: 0.6682Epoch 6/40: loss=0.6406, accuracy=0.6683, val_loss=1.6328, val_accuracy=0.4065\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6406 - accuracy: 0.6683 - val_loss: 1.6328 - val_accuracy: 0.4065 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6529 - accuracy: 0.6633Epoch 7/40: loss=0.6527, accuracy=0.6637, val_loss=0.5765, val_accuracy=0.7119\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6527 - accuracy: 0.6637 - val_loss: 0.5765 - val_accuracy: 0.7119 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.6795Epoch 8/40: loss=0.6340, accuracy=0.6796, val_loss=0.7166, val_accuracy=0.4810\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6340 - accuracy: 0.6796 - val_loss: 0.7166 - val_accuracy: 0.4810 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6373 - accuracy: 0.6757Epoch 9/40: loss=0.6367, accuracy=0.6757, val_loss=0.6346, val_accuracy=0.6714\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6367 - accuracy: 0.6757 - val_loss: 0.6346 - val_accuracy: 0.6714 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.6581Epoch 10/40: loss=0.6535, accuracy=0.6581, val_loss=0.6857, val_accuracy=0.5613\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6535 - accuracy: 0.6581 - val_loss: 0.6857 - val_accuracy: 0.5613 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6396 - accuracy: 0.6804Epoch 11/40: loss=0.6398, accuracy=0.6805, val_loss=0.5688, val_accuracy=0.6962\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6398 - accuracy: 0.6805 - val_loss: 0.5688 - val_accuracy: 0.6962 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6251 - accuracy: 0.6915Epoch 12/40: loss=0.6246, accuracy=0.6918, val_loss=0.9295, val_accuracy=0.4909\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6246 - accuracy: 0.6918 - val_loss: 0.9295 - val_accuracy: 0.4909 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6345 - accuracy: 0.6814Epoch 13/40: loss=0.6346, accuracy=0.6813, val_loss=1.3324, val_accuracy=0.4520\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6346 - accuracy: 0.6813 - val_loss: 1.3324 - val_accuracy: 0.4520 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.6623Epoch 14/40: loss=0.6536, accuracy=0.6627, val_loss=0.5402, val_accuracy=0.7227\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6536 - accuracy: 0.6627 - val_loss: 0.5402 - val_accuracy: 0.7227 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6867Epoch 15/40: loss=0.6259, accuracy=0.6867, val_loss=0.9308, val_accuracy=0.5265\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6259 - accuracy: 0.6867 - val_loss: 0.9308 - val_accuracy: 0.5265 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6537 - accuracy: 0.6640Epoch 16/40: loss=0.6536, accuracy=0.6643, val_loss=0.7232, val_accuracy=0.5232\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6536 - accuracy: 0.6643 - val_loss: 0.7232 - val_accuracy: 0.5232 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.6834Epoch 17/40: loss=0.6266, accuracy=0.6834, val_loss=0.7831, val_accuracy=0.6763\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6266 - accuracy: 0.6834 - val_loss: 0.7831 - val_accuracy: 0.6763 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.6456Epoch 18/40: loss=0.6703, accuracy=0.6451, val_loss=0.6494, val_accuracy=0.6002\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6703 - accuracy: 0.6451 - val_loss: 0.6494 - val_accuracy: 0.6002 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.6391\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 19/40: loss=0.6928, accuracy=0.6393, val_loss=0.6769, val_accuracy=0.6043\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6928 - accuracy: 0.6393 - val_loss: 0.6769 - val_accuracy: 0.6043 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.6818Epoch 20/40: loss=0.6121, accuracy=0.6827, val_loss=0.6772, val_accuracy=0.5919\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6121 - accuracy: 0.6827 - val_loss: 0.6772 - val_accuracy: 0.5919 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.7005Epoch 21/40: loss=0.5902, accuracy=0.7003, val_loss=0.5924, val_accuracy=0.6995\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5902 - accuracy: 0.7003 - val_loss: 0.5924 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7146Epoch 22/40: loss=0.5689, accuracy=0.7144, val_loss=0.5778, val_accuracy=0.6912\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5689 - accuracy: 0.7144 - val_loss: 0.5778 - val_accuracy: 0.6912 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5564 - accuracy: 0.7204Epoch 23/40: loss=0.5564, accuracy=0.7206, val_loss=0.5041, val_accuracy=0.7748\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5564 - accuracy: 0.7206 - val_loss: 0.5041 - val_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5560 - accuracy: 0.7274Epoch 24/40: loss=0.5560, accuracy=0.7274, val_loss=0.5119, val_accuracy=0.7674\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5560 - accuracy: 0.7274 - val_loss: 0.5119 - val_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7301Epoch 25/40: loss=0.5513, accuracy=0.7299, val_loss=0.5318, val_accuracy=0.7243\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5513 - accuracy: 0.7299 - val_loss: 0.5318 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5471 - accuracy: 0.7261Epoch 26/40: loss=0.5465, accuracy=0.7264, val_loss=0.4743, val_accuracy=0.7798\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5465 - accuracy: 0.7264 - val_loss: 0.4743 - val_accuracy: 0.7798 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.7432Epoch 27/40: loss=0.5226, accuracy=0.7434, val_loss=0.5061, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5226 - accuracy: 0.7434 - val_loss: 0.5061 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5304 - accuracy: 0.7378Epoch 28/40: loss=0.5302, accuracy=0.7380, val_loss=0.6837, val_accuracy=0.6076\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5302 - accuracy: 0.7380 - val_loss: 0.6837 - val_accuracy: 0.6076 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5311 - accuracy: 0.7347Epoch 29/40: loss=0.5319, accuracy=0.7343, val_loss=0.5659, val_accuracy=0.7036\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5319 - accuracy: 0.7343 - val_loss: 0.5659 - val_accuracy: 0.7036 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7280Epoch 30/40: loss=0.5327, accuracy=0.7279, val_loss=0.4802, val_accuracy=0.7881\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5327 - accuracy: 0.7279 - val_loss: 0.4802 - val_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5257 - accuracy: 0.7442Epoch 31/40: loss=0.5258, accuracy=0.7444, val_loss=0.4466, val_accuracy=0.7972\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5258 - accuracy: 0.7444 - val_loss: 0.4466 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7504Epoch 32/40: loss=0.5185, accuracy=0.7504, val_loss=0.5815, val_accuracy=0.6854\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5185 - accuracy: 0.7504 - val_loss: 0.5815 - val_accuracy: 0.6854 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7376Epoch 33/40: loss=0.5217, accuracy=0.7376, val_loss=0.4956, val_accuracy=0.7649\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5217 - accuracy: 0.7376 - val_loss: 0.4956 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5085 - accuracy: 0.7600Epoch 34/40: loss=0.5095, accuracy=0.7599, val_loss=0.5293, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5095 - accuracy: 0.7599 - val_loss: 0.5293 - val_accuracy: 0.7384 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.7544Epoch 35/40: loss=0.5109, accuracy=0.7541, val_loss=0.5318, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5109 - accuracy: 0.7541 - val_loss: 0.5318 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.7510Epoch 36/40: loss=0.5133, accuracy=0.7502, val_loss=0.4425, val_accuracy=0.8038\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5133 - accuracy: 0.7502 - val_loss: 0.4425 - val_accuracy: 0.8038 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5135 - accuracy: 0.7521Epoch 37/40: loss=0.5142, accuracy=0.7519, val_loss=0.4673, val_accuracy=0.8055\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5142 - accuracy: 0.7519 - val_loss: 0.4673 - val_accuracy: 0.8055 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4973 - accuracy: 0.7596Epoch 38/40: loss=0.4968, accuracy=0.7599, val_loss=0.4771, val_accuracy=0.7914\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4968 - accuracy: 0.7599 - val_loss: 0.4771 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7469Epoch 39/40: loss=0.5143, accuracy=0.7469, val_loss=0.5617, val_accuracy=0.7194\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5143 - accuracy: 0.7469 - val_loss: 0.5617 - val_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.7527Epoch 40/40: loss=0.5121, accuracy=0.7531, val_loss=0.4749, val_accuracy=0.7930\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5121 - accuracy: 0.7531 - val_loss: 0.4749 - val_accuracy: 0.7930 - lr: 1.0000e-04\n",
      "Validation accuracy: 0.8054635524749756\n",
      "\n",
      "Refined Training Combination 8/50: num_residual_blocks=9, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9762 - accuracy: 0.5012Epoch 1/40: loss=0.9759, accuracy=0.5012, val_loss=0.7268, val_accuracy=0.5373\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9759 - accuracy: 0.5012 - val_loss: 0.7268 - val_accuracy: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.5081Epoch 2/40: loss=0.9305, accuracy=0.5081, val_loss=0.7173, val_accuracy=0.5522\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9305 - accuracy: 0.5081 - val_loss: 0.7173 - val_accuracy: 0.5522 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8808 - accuracy: 0.5260Epoch 3/40: loss=0.8810, accuracy=0.5259, val_loss=0.7054, val_accuracy=0.5621\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8810 - accuracy: 0.5259 - val_loss: 0.7054 - val_accuracy: 0.5621 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8719 - accuracy: 0.5235Epoch 4/40: loss=0.8714, accuracy=0.5238, val_loss=0.7353, val_accuracy=0.5497\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8714 - accuracy: 0.5238 - val_loss: 0.7353 - val_accuracy: 0.5497 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8257 - accuracy: 0.5381Epoch 5/40: loss=0.8257, accuracy=0.5381, val_loss=0.7347, val_accuracy=0.5141\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8257 - accuracy: 0.5381 - val_loss: 0.7347 - val_accuracy: 0.5141 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8305 - accuracy: 0.5182Epoch 6/40: loss=0.8305, accuracy=0.5182, val_loss=0.7039, val_accuracy=0.5571\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8305 - accuracy: 0.5182 - val_loss: 0.7039 - val_accuracy: 0.5571 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.5228Epoch 7/40: loss=0.8042, accuracy=0.5228, val_loss=0.7453, val_accuracy=0.5786\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8042 - accuracy: 0.5228 - val_loss: 0.7453 - val_accuracy: 0.5786 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7943 - accuracy: 0.5266Epoch 8/40: loss=0.7943, accuracy=0.5271, val_loss=0.7901, val_accuracy=0.4942\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7943 - accuracy: 0.5271 - val_loss: 0.7901 - val_accuracy: 0.4942 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7622 - accuracy: 0.5477Epoch 9/40: loss=0.7637, accuracy=0.5470, val_loss=0.7094, val_accuracy=0.5339\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7637 - accuracy: 0.5470 - val_loss: 0.7094 - val_accuracy: 0.5339 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.5312Epoch 10/40: loss=0.7647, accuracy=0.5312, val_loss=0.7215, val_accuracy=0.5364\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7647 - accuracy: 0.5312 - val_loss: 0.7215 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7555 - accuracy: 0.5299\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 11/40: loss=0.7553, accuracy=0.5300, val_loss=0.7093, val_accuracy=0.5290\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7553 - accuracy: 0.5300 - val_loss: 0.7093 - val_accuracy: 0.5290 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7324 - accuracy: 0.5500Epoch 12/40: loss=0.7324, accuracy=0.5499, val_loss=0.7037, val_accuracy=0.5646\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7324 - accuracy: 0.5499 - val_loss: 0.7037 - val_accuracy: 0.5646 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.5522Epoch 13/40: loss=0.7197, accuracy=0.5524, val_loss=0.6877, val_accuracy=0.5786\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7197 - accuracy: 0.5524 - val_loss: 0.6877 - val_accuracy: 0.5786 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.5668Epoch 14/40: loss=0.7080, accuracy=0.5668, val_loss=0.7004, val_accuracy=0.5654\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7080 - accuracy: 0.5668 - val_loss: 0.7004 - val_accuracy: 0.5654 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7045 - accuracy: 0.5742Epoch 15/40: loss=0.7043, accuracy=0.5743, val_loss=0.6980, val_accuracy=0.5430\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7043 - accuracy: 0.5743 - val_loss: 0.6980 - val_accuracy: 0.5430 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.5697Epoch 16/40: loss=0.7026, accuracy=0.5697, val_loss=0.7142, val_accuracy=0.5331\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7026 - accuracy: 0.5697 - val_loss: 0.7142 - val_accuracy: 0.5331 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5810Epoch 17/40: loss=0.6934, accuracy=0.5813, val_loss=0.6762, val_accuracy=0.5935\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6934 - accuracy: 0.5813 - val_loss: 0.6762 - val_accuracy: 0.5935 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6969 - accuracy: 0.5821Epoch 18/40: loss=0.6974, accuracy=0.5820, val_loss=0.6906, val_accuracy=0.5530\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6974 - accuracy: 0.5820 - val_loss: 0.6906 - val_accuracy: 0.5530 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.5929Epoch 19/40: loss=0.6856, accuracy=0.5929, val_loss=0.7060, val_accuracy=0.5671\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6856 - accuracy: 0.5929 - val_loss: 0.7060 - val_accuracy: 0.5671 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.5974Epoch 20/40: loss=0.6870, accuracy=0.5973, val_loss=0.6839, val_accuracy=0.5869\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6870 - accuracy: 0.5973 - val_loss: 0.6839 - val_accuracy: 0.5869 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6691 - accuracy: 0.6142Epoch 21/40: loss=0.6698, accuracy=0.6138, val_loss=0.7281, val_accuracy=0.5579\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6698 - accuracy: 0.6138 - val_loss: 0.7281 - val_accuracy: 0.5579 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.6184\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 22/40: loss=0.6706, accuracy=0.6184, val_loss=0.6858, val_accuracy=0.5944\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6706 - accuracy: 0.6184 - val_loss: 0.6858 - val_accuracy: 0.5944 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6658 - accuracy: 0.6136Epoch 23/40: loss=0.6647, accuracy=0.6149, val_loss=0.6753, val_accuracy=0.5935\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6647 - accuracy: 0.6149 - val_loss: 0.6753 - val_accuracy: 0.5935 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.6169Epoch 24/40: loss=0.6745, accuracy=0.6169, val_loss=0.6834, val_accuracy=0.5820\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6745 - accuracy: 0.6169 - val_loss: 0.6834 - val_accuracy: 0.5820 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.6047Epoch 25/40: loss=0.6716, accuracy=0.6043, val_loss=0.6790, val_accuracy=0.5894\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6716 - accuracy: 0.6043 - val_loss: 0.6790 - val_accuracy: 0.5894 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.6157Epoch 26/40: loss=0.6554, accuracy=0.6157, val_loss=0.6688, val_accuracy=0.6043\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6554 - accuracy: 0.6157 - val_loss: 0.6688 - val_accuracy: 0.6043 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.6233Epoch 27/40: loss=0.6588, accuracy=0.6231, val_loss=0.6721, val_accuracy=0.6010\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6588 - accuracy: 0.6231 - val_loss: 0.6721 - val_accuracy: 0.6010 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.6167Epoch 28/40: loss=0.6688, accuracy=0.6161, val_loss=0.6720, val_accuracy=0.6035\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6688 - accuracy: 0.6161 - val_loss: 0.6720 - val_accuracy: 0.6035 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6653 - accuracy: 0.6134Epoch 29/40: loss=0.6653, accuracy=0.6134, val_loss=0.6743, val_accuracy=0.6126\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6653 - accuracy: 0.6134 - val_loss: 0.6743 - val_accuracy: 0.6126 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.6215Epoch 30/40: loss=0.6580, accuracy=0.6223, val_loss=0.6685, val_accuracy=0.6225\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6580 - accuracy: 0.6223 - val_loss: 0.6685 - val_accuracy: 0.6225 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6654 - accuracy: 0.6119Epoch 31/40: loss=0.6653, accuracy=0.6122, val_loss=0.6721, val_accuracy=0.6060\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6653 - accuracy: 0.6122 - val_loss: 0.6721 - val_accuracy: 0.6060 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6547 - accuracy: 0.6327Epoch 32/40: loss=0.6552, accuracy=0.6325, val_loss=0.6786, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6552 - accuracy: 0.6325 - val_loss: 0.6786 - val_accuracy: 0.5977 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6580 - accuracy: 0.6246Epoch 33/40: loss=0.6578, accuracy=0.6248, val_loss=0.6670, val_accuracy=0.6184\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6578 - accuracy: 0.6248 - val_loss: 0.6670 - val_accuracy: 0.6184 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.6271Epoch 34/40: loss=0.6560, accuracy=0.6271, val_loss=0.6771, val_accuracy=0.6043\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6560 - accuracy: 0.6271 - val_loss: 0.6771 - val_accuracy: 0.6043 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.6356Epoch 35/40: loss=0.6462, accuracy=0.6349, val_loss=0.6743, val_accuracy=0.6126\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6462 - accuracy: 0.6349 - val_loss: 0.6743 - val_accuracy: 0.6126 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6462 - accuracy: 0.6432Epoch 36/40: loss=0.6462, accuracy=0.6432, val_loss=0.6708, val_accuracy=0.6159\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6462 - accuracy: 0.6432 - val_loss: 0.6708 - val_accuracy: 0.6159 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6463 - accuracy: 0.6393Epoch 37/40: loss=0.6456, accuracy=0.6397, val_loss=0.6636, val_accuracy=0.6291\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6456 - accuracy: 0.6397 - val_loss: 0.6636 - val_accuracy: 0.6291 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.6360Epoch 38/40: loss=0.6515, accuracy=0.6358, val_loss=0.6615, val_accuracy=0.6325\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6515 - accuracy: 0.6358 - val_loss: 0.6615 - val_accuracy: 0.6325 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.6411Epoch 39/40: loss=0.6487, accuracy=0.6411, val_loss=0.6610, val_accuracy=0.6209\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6487 - accuracy: 0.6411 - val_loss: 0.6610 - val_accuracy: 0.6209 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.6353Epoch 40/40: loss=0.6391, accuracy=0.6353, val_loss=0.6718, val_accuracy=0.6035\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6391 - accuracy: 0.6353 - val_loss: 0.6718 - val_accuracy: 0.6035 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.6324503421783447\n",
      "\n",
      "Refined Training Combination 9/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.5306Epoch 1/40: loss=1.0544, accuracy=0.5306, val_loss=0.8853, val_accuracy=0.5331\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0544 - accuracy: 0.5306 - val_loss: 0.8853 - val_accuracy: 0.5331 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8512 - accuracy: 0.5379Epoch 2/40: loss=0.8512, accuracy=0.5379, val_loss=0.7292, val_accuracy=0.5588\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8512 - accuracy: 0.5379 - val_loss: 0.7292 - val_accuracy: 0.5588 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7536 - accuracy: 0.5704Epoch 3/40: loss=0.7532, accuracy=0.5704, val_loss=0.9178, val_accuracy=0.4652\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7532 - accuracy: 0.5704 - val_loss: 0.9178 - val_accuracy: 0.4652 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7282 - accuracy: 0.5889Epoch 4/40: loss=0.7282, accuracy=0.5892, val_loss=0.8770, val_accuracy=0.4868\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7282 - accuracy: 0.5892 - val_loss: 0.8770 - val_accuracy: 0.4868 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6892 - accuracy: 0.6275Epoch 5/40: loss=0.6894, accuracy=0.6273, val_loss=0.6264, val_accuracy=0.6300\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6894 - accuracy: 0.6273 - val_loss: 0.6264 - val_accuracy: 0.6300 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6742 - accuracy: 0.6375Epoch 6/40: loss=0.6735, accuracy=0.6378, val_loss=0.6616, val_accuracy=0.6043\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6735 - accuracy: 0.6378 - val_loss: 0.6616 - val_accuracy: 0.6043 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6644 - accuracy: 0.6544Epoch 7/40: loss=0.6641, accuracy=0.6548, val_loss=0.7275, val_accuracy=0.5695\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6641 - accuracy: 0.6548 - val_loss: 0.7275 - val_accuracy: 0.5695 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6585 - accuracy: 0.6645Epoch 8/40: loss=0.6583, accuracy=0.6649, val_loss=0.7170, val_accuracy=0.5364\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6583 - accuracy: 0.6649 - val_loss: 0.7170 - val_accuracy: 0.5364 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.6412Epoch 9/40: loss=0.6773, accuracy=0.6405, val_loss=0.6139, val_accuracy=0.6738\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6773 - accuracy: 0.6405 - val_loss: 0.6139 - val_accuracy: 0.6738 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6581Epoch 10/40: loss=0.6536, accuracy=0.6581, val_loss=0.6139, val_accuracy=0.6788\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6536 - accuracy: 0.6581 - val_loss: 0.6139 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.6785Epoch 11/40: loss=0.6419, accuracy=0.6772, val_loss=0.8802, val_accuracy=0.4934\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6419 - accuracy: 0.6772 - val_loss: 0.8802 - val_accuracy: 0.4934 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6411 - accuracy: 0.6764Epoch 12/40: loss=0.6407, accuracy=0.6761, val_loss=0.5649, val_accuracy=0.7111\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6407 - accuracy: 0.6761 - val_loss: 0.5649 - val_accuracy: 0.7111 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.6538Epoch 13/40: loss=0.6529, accuracy=0.6542, val_loss=0.6341, val_accuracy=0.6772\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6529 - accuracy: 0.6542 - val_loss: 0.6341 - val_accuracy: 0.6772 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.6541Epoch 14/40: loss=0.6518, accuracy=0.6540, val_loss=0.5833, val_accuracy=0.7326\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6518 - accuracy: 0.6540 - val_loss: 0.5833 - val_accuracy: 0.7326 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.6692Epoch 15/40: loss=0.6384, accuracy=0.6691, val_loss=0.5447, val_accuracy=0.7144\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6384 - accuracy: 0.6691 - val_loss: 0.5447 - val_accuracy: 0.7144 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7152 - accuracy: 0.6059Epoch 16/40: loss=0.7151, accuracy=0.6058, val_loss=1.0360, val_accuracy=0.5166\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7151 - accuracy: 0.6058 - val_loss: 1.0360 - val_accuracy: 0.5166 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6900 - accuracy: 0.6294Epoch 17/40: loss=0.6901, accuracy=0.6289, val_loss=0.6555, val_accuracy=0.6151\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6901 - accuracy: 0.6289 - val_loss: 0.6555 - val_accuracy: 0.6151 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.6478Epoch 18/40: loss=0.6585, accuracy=0.6478, val_loss=0.8035, val_accuracy=0.5066\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6585 - accuracy: 0.6478 - val_loss: 0.8035 - val_accuracy: 0.5066 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.6731Epoch 19/40: loss=0.6415, accuracy=0.6726, val_loss=0.7327, val_accuracy=0.5066\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6415 - accuracy: 0.6726 - val_loss: 0.7327 - val_accuracy: 0.5066 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6467 - accuracy: 0.6532\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 20/40: loss=0.6471, accuracy=0.6534, val_loss=0.7324, val_accuracy=0.6829\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6471 - accuracy: 0.6534 - val_loss: 0.7324 - val_accuracy: 0.6829 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5952 - accuracy: 0.6907Epoch 21/40: loss=0.5944, accuracy=0.6910, val_loss=0.5509, val_accuracy=0.6788\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5944 - accuracy: 0.6910 - val_loss: 0.5509 - val_accuracy: 0.6788 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5739 - accuracy: 0.7085Epoch 22/40: loss=0.5739, accuracy=0.7084, val_loss=0.5118, val_accuracy=0.7690\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5739 - accuracy: 0.7084 - val_loss: 0.5118 - val_accuracy: 0.7690 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.7185Epoch 23/40: loss=0.5593, accuracy=0.7185, val_loss=0.7576, val_accuracy=0.5596\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5593 - accuracy: 0.7185 - val_loss: 0.7576 - val_accuracy: 0.5596 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7316Epoch 24/40: loss=0.5499, accuracy=0.7316, val_loss=0.5131, val_accuracy=0.7541\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5499 - accuracy: 0.7316 - val_loss: 0.5131 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7235Epoch 25/40: loss=0.5528, accuracy=0.7237, val_loss=0.5671, val_accuracy=0.6896\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5528 - accuracy: 0.7237 - val_loss: 0.5671 - val_accuracy: 0.6896 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.7299Epoch 26/40: loss=0.5491, accuracy=0.7299, val_loss=0.5579, val_accuracy=0.7086\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5491 - accuracy: 0.7299 - val_loss: 0.5579 - val_accuracy: 0.7086 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.7425\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 27/40: loss=0.5404, accuracy=0.7423, val_loss=0.5912, val_accuracy=0.6647\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5404 - accuracy: 0.7423 - val_loss: 0.5912 - val_accuracy: 0.6647 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5282 - accuracy: 0.7408Epoch 28/40: loss=0.5279, accuracy=0.7411, val_loss=0.5577, val_accuracy=0.6945\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5279 - accuracy: 0.7411 - val_loss: 0.5577 - val_accuracy: 0.6945 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7330Epoch 29/40: loss=0.5340, accuracy=0.7332, val_loss=0.5714, val_accuracy=0.6838\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5340 - accuracy: 0.7332 - val_loss: 0.5714 - val_accuracy: 0.6838 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5246 - accuracy: 0.7485Epoch 30/40: loss=0.5245, accuracy=0.7486, val_loss=0.5543, val_accuracy=0.6970\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5245 - accuracy: 0.7486 - val_loss: 0.5543 - val_accuracy: 0.6970 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.7463Epoch 31/40: loss=0.5247, accuracy=0.7459, val_loss=0.5377, val_accuracy=0.7177\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5247 - accuracy: 0.7459 - val_loss: 0.5377 - val_accuracy: 0.7177 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.7427\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.5247, accuracy=0.7432, val_loss=0.5320, val_accuracy=0.7425\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5247 - accuracy: 0.7432 - val_loss: 0.5320 - val_accuracy: 0.7425 - lr: 2.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.7690397500991821\n",
      "\n",
      "Refined Training Combination 10/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.5220Epoch 1/40: loss=0.9270, accuracy=0.5217, val_loss=0.8227, val_accuracy=0.5149\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 0.9270 - accuracy: 0.5217 - val_loss: 0.8227 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8977 - accuracy: 0.5367Epoch 2/40: loss=0.8971, accuracy=0.5370, val_loss=0.8338, val_accuracy=0.5886\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8971 - accuracy: 0.5370 - val_loss: 0.8338 - val_accuracy: 0.5886 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8758 - accuracy: 0.5242Epoch 3/40: loss=0.8758, accuracy=0.5242, val_loss=0.7365, val_accuracy=0.4992\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8758 - accuracy: 0.5242 - val_loss: 0.7365 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8576 - accuracy: 0.5264Epoch 4/40: loss=0.8583, accuracy=0.5261, val_loss=0.7363, val_accuracy=0.5745\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8583 - accuracy: 0.5261 - val_loss: 0.7363 - val_accuracy: 0.5745 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8429 - accuracy: 0.5329Epoch 5/40: loss=0.8429, accuracy=0.5329, val_loss=0.7031, val_accuracy=0.5513\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8429 - accuracy: 0.5329 - val_loss: 0.7031 - val_accuracy: 0.5513 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8079 - accuracy: 0.5437Epoch 6/40: loss=0.8082, accuracy=0.5433, val_loss=0.7155, val_accuracy=0.5505\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8082 - accuracy: 0.5433 - val_loss: 0.7155 - val_accuracy: 0.5505 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7779 - accuracy: 0.5531Epoch 7/40: loss=0.7777, accuracy=0.5532, val_loss=0.7530, val_accuracy=0.5033\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7777 - accuracy: 0.5532 - val_loss: 0.7530 - val_accuracy: 0.5033 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7847 - accuracy: 0.5418Epoch 8/40: loss=0.7847, accuracy=0.5418, val_loss=0.7352, val_accuracy=0.5637\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7847 - accuracy: 0.5418 - val_loss: 0.7352 - val_accuracy: 0.5637 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7747 - accuracy: 0.5406Epoch 9/40: loss=0.7740, accuracy=0.5412, val_loss=0.6900, val_accuracy=0.5836\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7740 - accuracy: 0.5412 - val_loss: 0.6900 - val_accuracy: 0.5836 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7547 - accuracy: 0.5451Epoch 10/40: loss=0.7541, accuracy=0.5453, val_loss=0.7233, val_accuracy=0.5406\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7541 - accuracy: 0.5453 - val_loss: 0.7233 - val_accuracy: 0.5406 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7439 - accuracy: 0.5510Epoch 11/40: loss=0.7436, accuracy=0.5511, val_loss=0.7904, val_accuracy=0.4661\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7436 - accuracy: 0.5511 - val_loss: 0.7904 - val_accuracy: 0.4661 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.5803Epoch 12/40: loss=0.7201, accuracy=0.5803, val_loss=0.6986, val_accuracy=0.5737\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7201 - accuracy: 0.5803 - val_loss: 0.6986 - val_accuracy: 0.5737 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6995 - accuracy: 0.5889Epoch 13/40: loss=0.6998, accuracy=0.5886, val_loss=0.6867, val_accuracy=0.5546\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6998 - accuracy: 0.5886 - val_loss: 0.6867 - val_accuracy: 0.5546 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6897 - accuracy: 0.6107Epoch 14/40: loss=0.6894, accuracy=0.6107, val_loss=0.6446, val_accuracy=0.6308\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6894 - accuracy: 0.6107 - val_loss: 0.6446 - val_accuracy: 0.6308 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.6240Epoch 15/40: loss=0.6737, accuracy=0.6238, val_loss=0.6234, val_accuracy=0.6631\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6737 - accuracy: 0.6238 - val_loss: 0.6234 - val_accuracy: 0.6631 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.6488Epoch 16/40: loss=0.6494, accuracy=0.6492, val_loss=0.5879, val_accuracy=0.6796\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6494 - accuracy: 0.6492 - val_loss: 0.5879 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.6513Epoch 17/40: loss=0.6405, accuracy=0.6513, val_loss=0.5963, val_accuracy=0.6705\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6405 - accuracy: 0.6513 - val_loss: 0.5963 - val_accuracy: 0.6705 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.6534Epoch 18/40: loss=0.6342, accuracy=0.6529, val_loss=0.6078, val_accuracy=0.6805\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6342 - accuracy: 0.6529 - val_loss: 0.6078 - val_accuracy: 0.6805 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.6668Epoch 19/40: loss=0.6194, accuracy=0.6664, val_loss=0.5844, val_accuracy=0.6887\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6194 - accuracy: 0.6664 - val_loss: 0.5844 - val_accuracy: 0.6887 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.6931Epoch 20/40: loss=0.6028, accuracy=0.6937, val_loss=0.6888, val_accuracy=0.6250\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6028 - accuracy: 0.6937 - val_loss: 0.6888 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.6874Epoch 21/40: loss=0.5956, accuracy=0.6879, val_loss=0.7797, val_accuracy=0.5033\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5956 - accuracy: 0.6879 - val_loss: 0.7797 - val_accuracy: 0.5033 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5978 - accuracy: 0.6901Epoch 22/40: loss=0.5976, accuracy=0.6902, val_loss=0.5473, val_accuracy=0.7210\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5976 - accuracy: 0.6902 - val_loss: 0.5473 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.6937Epoch 23/40: loss=0.5915, accuracy=0.6937, val_loss=0.5984, val_accuracy=0.6838\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5915 - accuracy: 0.6937 - val_loss: 0.5984 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7049Epoch 24/40: loss=0.5750, accuracy=0.7049, val_loss=0.6807, val_accuracy=0.6175\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5750 - accuracy: 0.7049 - val_loss: 0.6807 - val_accuracy: 0.6175 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5683 - accuracy: 0.7108Epoch 25/40: loss=0.5685, accuracy=0.7105, val_loss=0.5395, val_accuracy=0.7368\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5685 - accuracy: 0.7105 - val_loss: 0.5395 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5840 - accuracy: 0.6920Epoch 26/40: loss=0.5845, accuracy=0.6914, val_loss=0.6351, val_accuracy=0.6573\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5845 - accuracy: 0.6914 - val_loss: 0.6351 - val_accuracy: 0.6573 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.7020Epoch 27/40: loss=0.5759, accuracy=0.7022, val_loss=0.5387, val_accuracy=0.7359\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5759 - accuracy: 0.7022 - val_loss: 0.5387 - val_accuracy: 0.7359 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.7101Epoch 28/40: loss=0.5646, accuracy=0.7101, val_loss=0.4987, val_accuracy=0.7583\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5646 - accuracy: 0.7101 - val_loss: 0.4987 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5569 - accuracy: 0.7204Epoch 29/40: loss=0.5577, accuracy=0.7198, val_loss=0.4896, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5577 - accuracy: 0.7198 - val_loss: 0.4896 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5595 - accuracy: 0.7218Epoch 30/40: loss=0.5590, accuracy=0.7221, val_loss=0.5760, val_accuracy=0.6904\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5590 - accuracy: 0.7221 - val_loss: 0.5760 - val_accuracy: 0.6904 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5622 - accuracy: 0.7112Epoch 31/40: loss=0.5630, accuracy=0.7105, val_loss=0.5361, val_accuracy=0.7144\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5630 - accuracy: 0.7105 - val_loss: 0.5361 - val_accuracy: 0.7144 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5558 - accuracy: 0.7119Epoch 32/40: loss=0.5554, accuracy=0.7121, val_loss=0.5311, val_accuracy=0.7434\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5554 - accuracy: 0.7121 - val_loss: 0.5311 - val_accuracy: 0.7434 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7235Epoch 33/40: loss=0.5470, accuracy=0.7235, val_loss=0.5193, val_accuracy=0.7392\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5470 - accuracy: 0.7235 - val_loss: 0.5193 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.7268Epoch 34/40: loss=0.5401, accuracy=0.7272, val_loss=0.4653, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5401 - accuracy: 0.7272 - val_loss: 0.4653 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.7284Epoch 35/40: loss=0.5479, accuracy=0.7293, val_loss=0.5402, val_accuracy=0.7103\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5479 - accuracy: 0.7293 - val_loss: 0.5402 - val_accuracy: 0.7103 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.7217Epoch 36/40: loss=0.5452, accuracy=0.7221, val_loss=0.5033, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5452 - accuracy: 0.7221 - val_loss: 0.5033 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.7195Epoch 37/40: loss=0.5547, accuracy=0.7202, val_loss=0.5118, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5547 - accuracy: 0.7202 - val_loss: 0.5118 - val_accuracy: 0.7732 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7245Epoch 38/40: loss=0.5423, accuracy=0.7250, val_loss=0.4831, val_accuracy=0.7856\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5423 - accuracy: 0.7250 - val_loss: 0.4831 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7289\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 39/40: loss=0.5379, accuracy=0.7287, val_loss=0.5541, val_accuracy=0.7194\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5379 - accuracy: 0.7287 - val_loss: 0.5541 - val_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.7430Epoch 40/40: loss=0.5178, accuracy=0.7430, val_loss=0.4600, val_accuracy=0.7757\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5178 - accuracy: 0.7430 - val_loss: 0.4600 - val_accuracy: 0.7757 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.7855960130691528\n",
      "\n",
      "Refined Training Combination 11/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.5, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1031 - accuracy: 0.5187Epoch 1/40: loss=1.1021, accuracy=0.5184, val_loss=0.7310, val_accuracy=0.5679\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.1021 - accuracy: 0.5184 - val_loss: 0.7310 - val_accuracy: 0.5679 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8522 - accuracy: 0.5400Epoch 2/40: loss=0.8524, accuracy=0.5397, val_loss=0.8186, val_accuracy=0.5571\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8524 - accuracy: 0.5397 - val_loss: 0.8186 - val_accuracy: 0.5571 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7567 - accuracy: 0.5795Epoch 3/40: loss=0.7568, accuracy=0.5793, val_loss=0.8345, val_accuracy=0.6002\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7568 - accuracy: 0.5793 - val_loss: 0.8345 - val_accuracy: 0.6002 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.6161Epoch 4/40: loss=0.7104, accuracy=0.6161, val_loss=0.9042, val_accuracy=0.5265\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7104 - accuracy: 0.6161 - val_loss: 0.9042 - val_accuracy: 0.5265 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6770 - accuracy: 0.6317Epoch 5/40: loss=0.6771, accuracy=0.6314, val_loss=0.6340, val_accuracy=0.6854\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6771 - accuracy: 0.6314 - val_loss: 0.6340 - val_accuracy: 0.6854 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.6337Epoch 6/40: loss=0.6743, accuracy=0.6337, val_loss=0.7323, val_accuracy=0.5911\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6743 - accuracy: 0.6337 - val_loss: 0.7323 - val_accuracy: 0.5911 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.6562Epoch 7/40: loss=0.6604, accuracy=0.6562, val_loss=0.6372, val_accuracy=0.6490\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6604 - accuracy: 0.6562 - val_loss: 0.6372 - val_accuracy: 0.6490 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.6428Epoch 8/40: loss=0.6832, accuracy=0.6428, val_loss=0.6437, val_accuracy=0.6540\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6832 - accuracy: 0.6428 - val_loss: 0.6437 - val_accuracy: 0.6540 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.6774Epoch 9/40: loss=0.6309, accuracy=0.6769, val_loss=0.6586, val_accuracy=0.6531\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6309 - accuracy: 0.6769 - val_loss: 0.6586 - val_accuracy: 0.6531 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6192 - accuracy: 0.6854\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/40: loss=0.6205, accuracy=0.6846, val_loss=0.8888, val_accuracy=0.4818\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6205 - accuracy: 0.6846 - val_loss: 0.8888 - val_accuracy: 0.4818 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.7020Epoch 11/40: loss=0.5815, accuracy=0.7020, val_loss=0.5679, val_accuracy=0.7061\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5815 - accuracy: 0.7020 - val_loss: 0.5679 - val_accuracy: 0.7061 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5548 - accuracy: 0.7292Epoch 12/40: loss=0.5545, accuracy=0.7293, val_loss=0.5708, val_accuracy=0.7070\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5545 - accuracy: 0.7293 - val_loss: 0.5708 - val_accuracy: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7332Epoch 13/40: loss=0.5382, accuracy=0.7324, val_loss=0.5507, val_accuracy=0.7094\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5382 - accuracy: 0.7324 - val_loss: 0.5507 - val_accuracy: 0.7094 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.7292Epoch 14/40: loss=0.5490, accuracy=0.7289, val_loss=0.4564, val_accuracy=0.7914\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5490 - accuracy: 0.7289 - val_loss: 0.4564 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7342Epoch 15/40: loss=0.5375, accuracy=0.7345, val_loss=0.6029, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5375 - accuracy: 0.7345 - val_loss: 0.6029 - val_accuracy: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5229 - accuracy: 0.7438Epoch 16/40: loss=0.5232, accuracy=0.7436, val_loss=0.5256, val_accuracy=0.7285\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5232 - accuracy: 0.7436 - val_loss: 0.5256 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7475Epoch 17/40: loss=0.5312, accuracy=0.7475, val_loss=0.5357, val_accuracy=0.7293\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5312 - accuracy: 0.7475 - val_loss: 0.5357 - val_accuracy: 0.7293 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5267 - accuracy: 0.7404Epoch 18/40: loss=0.5260, accuracy=0.7409, val_loss=0.4860, val_accuracy=0.7525\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5260 - accuracy: 0.7409 - val_loss: 0.4860 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5231 - accuracy: 0.7375\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.5230, accuracy=0.7378, val_loss=0.4765, val_accuracy=0.7848\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5230 - accuracy: 0.7378 - val_loss: 0.4765 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.7475Epoch 20/40: loss=0.5089, accuracy=0.7475, val_loss=0.4501, val_accuracy=0.8030\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5089 - accuracy: 0.7475 - val_loss: 0.4501 - val_accuracy: 0.8030 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.7569Epoch 21/40: loss=0.4918, accuracy=0.7568, val_loss=0.4740, val_accuracy=0.7781\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4918 - accuracy: 0.7568 - val_loss: 0.4740 - val_accuracy: 0.7781 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.7672Epoch 22/40: loss=0.4957, accuracy=0.7666, val_loss=0.4571, val_accuracy=0.7906\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4957 - accuracy: 0.7666 - val_loss: 0.4571 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7614Epoch 23/40: loss=0.4991, accuracy=0.7612, val_loss=0.4502, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4991 - accuracy: 0.7612 - val_loss: 0.4502 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.7652Epoch 24/40: loss=0.4849, accuracy=0.7653, val_loss=0.4824, val_accuracy=0.7632\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4849 - accuracy: 0.7653 - val_loss: 0.4824 - val_accuracy: 0.7632 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.7765\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 25/40: loss=0.4718, accuracy=0.7763, val_loss=0.5215, val_accuracy=0.7467\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4718 - accuracy: 0.7763 - val_loss: 0.5215 - val_accuracy: 0.7467 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.7652Epoch 26/40: loss=0.4894, accuracy=0.7653, val_loss=0.4604, val_accuracy=0.7873\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4894 - accuracy: 0.7653 - val_loss: 0.4604 - val_accuracy: 0.7873 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.7614Epoch 27/40: loss=0.4881, accuracy=0.7614, val_loss=0.4587, val_accuracy=0.7897\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4881 - accuracy: 0.7614 - val_loss: 0.4587 - val_accuracy: 0.7897 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.7705Epoch 28/40: loss=0.4734, accuracy=0.7709, val_loss=0.4523, val_accuracy=0.7922\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4734 - accuracy: 0.7709 - val_loss: 0.4523 - val_accuracy: 0.7922 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7734Epoch 29/40: loss=0.4795, accuracy=0.7734, val_loss=0.4507, val_accuracy=0.7906\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4795 - accuracy: 0.7734 - val_loss: 0.4507 - val_accuracy: 0.7906 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.7728\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 30/40: loss=0.4865, accuracy=0.7728, val_loss=0.4518, val_accuracy=0.7873\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4865 - accuracy: 0.7728 - val_loss: 0.4518 - val_accuracy: 0.7873 - lr: 4.0000e-06\n",
      "Epoch 30: early stopping\n",
      "Validation accuracy: 0.8029801249504089\n",
      "\n",
      "Refined Training Combination 12/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0687 - accuracy: 0.5071Epoch 1/40: loss=1.0678, accuracy=0.5079, val_loss=0.7809, val_accuracy=0.5207\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0678 - accuracy: 0.5079 - val_loss: 0.7809 - val_accuracy: 0.5207 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.5319Epoch 2/40: loss=0.8508, accuracy=0.5319, val_loss=0.8356, val_accuracy=0.4793\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8508 - accuracy: 0.5319 - val_loss: 0.8356 - val_accuracy: 0.4793 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.5498Epoch 3/40: loss=0.7908, accuracy=0.5497, val_loss=0.6719, val_accuracy=0.5919\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7908 - accuracy: 0.5497 - val_loss: 0.6719 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7518 - accuracy: 0.5629Epoch 4/40: loss=0.7513, accuracy=0.5633, val_loss=0.6761, val_accuracy=0.6151\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7513 - accuracy: 0.5633 - val_loss: 0.6761 - val_accuracy: 0.6151 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7269 - accuracy: 0.5997Epoch 5/40: loss=0.7271, accuracy=0.5995, val_loss=0.6377, val_accuracy=0.6308\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7271 - accuracy: 0.5995 - val_loss: 0.6377 - val_accuracy: 0.6308 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.6314Epoch 6/40: loss=0.6828, accuracy=0.6312, val_loss=0.7911, val_accuracy=0.5000\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6828 - accuracy: 0.6312 - val_loss: 0.7911 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.6593Epoch 7/40: loss=0.6588, accuracy=0.6598, val_loss=0.6320, val_accuracy=0.6565\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6588 - accuracy: 0.6598 - val_loss: 0.6320 - val_accuracy: 0.6565 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.6530Epoch 8/40: loss=0.6571, accuracy=0.6527, val_loss=0.7825, val_accuracy=0.5430\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6571 - accuracy: 0.6527 - val_loss: 0.7825 - val_accuracy: 0.5430 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.6736Epoch 9/40: loss=0.6382, accuracy=0.6736, val_loss=0.6102, val_accuracy=0.6945\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6382 - accuracy: 0.6736 - val_loss: 0.6102 - val_accuracy: 0.6945 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6416 - accuracy: 0.6649Epoch 10/40: loss=0.6415, accuracy=0.6647, val_loss=0.7752, val_accuracy=0.4652\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6415 - accuracy: 0.6647 - val_loss: 0.7752 - val_accuracy: 0.4652 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6451 - accuracy: 0.6668Epoch 11/40: loss=0.6452, accuracy=0.6668, val_loss=0.7152, val_accuracy=0.5480\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6452 - accuracy: 0.6668 - val_loss: 0.7152 - val_accuracy: 0.5480 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.6726Epoch 12/40: loss=0.6334, accuracy=0.6726, val_loss=1.6032, val_accuracy=0.4230\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6334 - accuracy: 0.6726 - val_loss: 1.6032 - val_accuracy: 0.4230 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.6637Epoch 13/40: loss=0.6533, accuracy=0.6637, val_loss=0.9540, val_accuracy=0.4379\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6533 - accuracy: 0.6637 - val_loss: 0.9540 - val_accuracy: 0.4379 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.6515\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/40: loss=0.6593, accuracy=0.6521, val_loss=0.9136, val_accuracy=0.4677\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6593 - accuracy: 0.6521 - val_loss: 0.9136 - val_accuracy: 0.4677 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.6854Epoch 15/40: loss=0.5963, accuracy=0.6854, val_loss=0.5838, val_accuracy=0.6937\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5963 - accuracy: 0.6854 - val_loss: 0.5838 - val_accuracy: 0.6937 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5717 - accuracy: 0.7156Epoch 16/40: loss=0.5719, accuracy=0.7154, val_loss=0.4911, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5719 - accuracy: 0.7154 - val_loss: 0.4911 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7073Epoch 17/40: loss=0.5706, accuracy=0.7070, val_loss=0.5744, val_accuracy=0.6987\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5706 - accuracy: 0.7070 - val_loss: 0.5744 - val_accuracy: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.7213Epoch 18/40: loss=0.5616, accuracy=0.7212, val_loss=0.6470, val_accuracy=0.6556\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5616 - accuracy: 0.7212 - val_loss: 0.6470 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7239Epoch 19/40: loss=0.5602, accuracy=0.7239, val_loss=0.6494, val_accuracy=0.6498\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5602 - accuracy: 0.7239 - val_loss: 0.6494 - val_accuracy: 0.6498 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.7303Epoch 20/40: loss=0.5558, accuracy=0.7305, val_loss=0.7511, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5558 - accuracy: 0.7305 - val_loss: 0.7511 - val_accuracy: 0.5579 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7255\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 21/40: loss=0.5499, accuracy=0.7250, val_loss=0.5274, val_accuracy=0.7450\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5499 - accuracy: 0.7250 - val_loss: 0.5274 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.7305Epoch 22/40: loss=0.5403, accuracy=0.7308, val_loss=0.5018, val_accuracy=0.7657\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5403 - accuracy: 0.7308 - val_loss: 0.5018 - val_accuracy: 0.7657 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7382Epoch 23/40: loss=0.5323, accuracy=0.7380, val_loss=0.5177, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5323 - accuracy: 0.7380 - val_loss: 0.5177 - val_accuracy: 0.7384 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5239 - accuracy: 0.7525Epoch 24/40: loss=0.5246, accuracy=0.7521, val_loss=0.4847, val_accuracy=0.7815\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5246 - accuracy: 0.7521 - val_loss: 0.4847 - val_accuracy: 0.7815 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.7423Epoch 25/40: loss=0.5331, accuracy=0.7423, val_loss=0.5346, val_accuracy=0.7293\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5331 - accuracy: 0.7423 - val_loss: 0.5346 - val_accuracy: 0.7293 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5190 - accuracy: 0.7417Epoch 26/40: loss=0.5187, accuracy=0.7419, val_loss=0.4973, val_accuracy=0.7715\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.4973 - val_accuracy: 0.7715 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5260 - accuracy: 0.7448Epoch 27/40: loss=0.5260, accuracy=0.7448, val_loss=0.4974, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5260 - accuracy: 0.7448 - val_loss: 0.4974 - val_accuracy: 0.7839 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.7481Epoch 28/40: loss=0.5221, accuracy=0.7481, val_loss=0.5026, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5221 - accuracy: 0.7481 - val_loss: 0.5026 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.7419\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 29/40: loss=0.5229, accuracy=0.7417, val_loss=0.4915, val_accuracy=0.7848\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5229 - accuracy: 0.7417 - val_loss: 0.4915 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.7570Epoch 30/40: loss=0.5131, accuracy=0.7570, val_loss=0.4959, val_accuracy=0.7773\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5131 - accuracy: 0.7570 - val_loss: 0.4959 - val_accuracy: 0.7773 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5124 - accuracy: 0.7446Epoch 31/40: loss=0.5131, accuracy=0.7446, val_loss=0.4831, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5131 - accuracy: 0.7446 - val_loss: 0.4831 - val_accuracy: 0.7831 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.7494Epoch 32/40: loss=0.5140, accuracy=0.7498, val_loss=0.4951, val_accuracy=0.7657\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5140 - accuracy: 0.7498 - val_loss: 0.4951 - val_accuracy: 0.7657 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5267 - accuracy: 0.7405Epoch 33/40: loss=0.5274, accuracy=0.7405, val_loss=0.5035, val_accuracy=0.7699\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5274 - accuracy: 0.7405 - val_loss: 0.5035 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7425Epoch 34/40: loss=0.5219, accuracy=0.7428, val_loss=0.4907, val_accuracy=0.7765\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5219 - accuracy: 0.7428 - val_loss: 0.4907 - val_accuracy: 0.7765 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.7405Epoch 35/40: loss=0.5247, accuracy=0.7405, val_loss=0.4921, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5247 - accuracy: 0.7405 - val_loss: 0.4921 - val_accuracy: 0.7740 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.7521\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Epoch 36/40: loss=0.5110, accuracy=0.7521, val_loss=0.4969, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5110 - accuracy: 0.7521 - val_loss: 0.4969 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5205 - accuracy: 0.7419Epoch 37/40: loss=0.5198, accuracy=0.7423, val_loss=0.4899, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5198 - accuracy: 0.7423 - val_loss: 0.4899 - val_accuracy: 0.7732 - lr: 8.0000e-07\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.7504Epoch 38/40: loss=0.5232, accuracy=0.7504, val_loss=0.4921, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5232 - accuracy: 0.7504 - val_loss: 0.4921 - val_accuracy: 0.7732 - lr: 8.0000e-07\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.7531Epoch 39/40: loss=0.5144, accuracy=0.7531, val_loss=0.4986, val_accuracy=0.7724\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5144 - accuracy: 0.7531 - val_loss: 0.4986 - val_accuracy: 0.7724 - lr: 8.0000e-07\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5222 - accuracy: 0.7444Epoch 40/40: loss=0.5223, accuracy=0.7444, val_loss=0.4976, val_accuracy=0.7732\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5223 - accuracy: 0.7444 - val_loss: 0.4976 - val_accuracy: 0.7732 - lr: 8.0000e-07\n",
      "Validation accuracy: 0.7847682237625122\n",
      "\n",
      "Refined Training Combination 13/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.4, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0517 - accuracy: 0.5210Epoch 1/40: loss=1.0508, accuracy=0.5211, val_loss=0.8045, val_accuracy=0.5132\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0508 - accuracy: 0.5211 - val_loss: 0.8045 - val_accuracy: 0.5132 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8445 - accuracy: 0.5453Epoch 2/40: loss=0.8445, accuracy=0.5453, val_loss=0.8367, val_accuracy=0.4652\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8445 - accuracy: 0.5453 - val_loss: 0.8367 - val_accuracy: 0.4652 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.5702Epoch 3/40: loss=0.7660, accuracy=0.5702, val_loss=0.9118, val_accuracy=0.4727\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7660 - accuracy: 0.5702 - val_loss: 0.9118 - val_accuracy: 0.4727 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.6044Epoch 4/40: loss=0.7197, accuracy=0.6043, val_loss=0.6601, val_accuracy=0.6399\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7197 - accuracy: 0.6043 - val_loss: 0.6601 - val_accuracy: 0.6399 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6993 - accuracy: 0.6161Epoch 5/40: loss=0.6992, accuracy=0.6161, val_loss=0.7857, val_accuracy=0.5579\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6992 - accuracy: 0.6161 - val_loss: 0.7857 - val_accuracy: 0.5579 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.6577Epoch 6/40: loss=0.6588, accuracy=0.6577, val_loss=0.5707, val_accuracy=0.7285\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6588 - accuracy: 0.6577 - val_loss: 0.5707 - val_accuracy: 0.7285 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.6774Epoch 7/40: loss=0.6238, accuracy=0.6774, val_loss=0.6032, val_accuracy=0.6548\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6238 - accuracy: 0.6774 - val_loss: 0.6032 - val_accuracy: 0.6548 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.6588Epoch 8/40: loss=0.6515, accuracy=0.6594, val_loss=0.7365, val_accuracy=0.6233\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6515 - accuracy: 0.6594 - val_loss: 0.7365 - val_accuracy: 0.6233 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.6625Epoch 9/40: loss=0.6577, accuracy=0.6620, val_loss=0.7534, val_accuracy=0.5389\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6577 - accuracy: 0.6620 - val_loss: 0.7534 - val_accuracy: 0.5389 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.6672Epoch 10/40: loss=0.6329, accuracy=0.6672, val_loss=1.2154, val_accuracy=0.4743\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6329 - accuracy: 0.6672 - val_loss: 1.2154 - val_accuracy: 0.4743 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6344 - accuracy: 0.6823\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/40: loss=0.6342, accuracy=0.6825, val_loss=0.7387, val_accuracy=0.5546\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6342 - accuracy: 0.6825 - val_loss: 0.7387 - val_accuracy: 0.5546 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.7173Epoch 12/40: loss=0.5740, accuracy=0.7175, val_loss=0.5956, val_accuracy=0.6631\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5740 - accuracy: 0.7175 - val_loss: 0.5956 - val_accuracy: 0.6631 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5555 - accuracy: 0.7336Epoch 13/40: loss=0.5551, accuracy=0.7341, val_loss=0.5263, val_accuracy=0.7541\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5551 - accuracy: 0.7341 - val_loss: 0.5263 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.7338Epoch 14/40: loss=0.5418, accuracy=0.7341, val_loss=0.5456, val_accuracy=0.7210\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5418 - accuracy: 0.7341 - val_loss: 0.5456 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5261 - accuracy: 0.7425Epoch 15/40: loss=0.5263, accuracy=0.7425, val_loss=0.5444, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5263 - accuracy: 0.7425 - val_loss: 0.5444 - val_accuracy: 0.7301 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.7380Epoch 16/40: loss=0.5345, accuracy=0.7380, val_loss=0.5027, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5345 - accuracy: 0.7380 - val_loss: 0.5027 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7327Epoch 17/40: loss=0.5389, accuracy=0.7324, val_loss=0.5017, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5389 - accuracy: 0.7324 - val_loss: 0.5017 - val_accuracy: 0.7384 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7378Epoch 18/40: loss=0.5259, accuracy=0.7378, val_loss=0.5227, val_accuracy=0.7376\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.5227 - val_accuracy: 0.7376 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.7440Epoch 19/40: loss=0.5165, accuracy=0.7442, val_loss=0.4670, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5165 - accuracy: 0.7442 - val_loss: 0.4670 - val_accuracy: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.7500Epoch 20/40: loss=0.5102, accuracy=0.7490, val_loss=0.4502, val_accuracy=0.7831\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5102 - accuracy: 0.7490 - val_loss: 0.4502 - val_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5049 - accuracy: 0.7521Epoch 21/40: loss=0.5045, accuracy=0.7521, val_loss=0.4751, val_accuracy=0.7682\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5045 - accuracy: 0.7521 - val_loss: 0.4751 - val_accuracy: 0.7682 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.7450Epoch 22/40: loss=0.5140, accuracy=0.7452, val_loss=0.4477, val_accuracy=0.7914\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5140 - accuracy: 0.7452 - val_loss: 0.4477 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.7548Epoch 23/40: loss=0.4949, accuracy=0.7548, val_loss=0.4548, val_accuracy=0.7616\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4949 - accuracy: 0.7548 - val_loss: 0.4548 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7525Epoch 24/40: loss=0.5022, accuracy=0.7525, val_loss=0.5661, val_accuracy=0.7119\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5022 - accuracy: 0.7525 - val_loss: 0.5661 - val_accuracy: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.7587Epoch 25/40: loss=0.4917, accuracy=0.7587, val_loss=0.4553, val_accuracy=0.7715\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4917 - accuracy: 0.7587 - val_loss: 0.4553 - val_accuracy: 0.7715 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5104 - accuracy: 0.7434Epoch 26/40: loss=0.5109, accuracy=0.7430, val_loss=0.5592, val_accuracy=0.6962\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5109 - accuracy: 0.7430 - val_loss: 0.5592 - val_accuracy: 0.6962 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.7606\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 27/40: loss=0.4958, accuracy=0.7608, val_loss=0.5649, val_accuracy=0.7144\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4958 - accuracy: 0.7608 - val_loss: 0.5649 - val_accuracy: 0.7144 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7635Epoch 28/40: loss=0.4840, accuracy=0.7632, val_loss=0.4785, val_accuracy=0.7533\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4840 - accuracy: 0.7632 - val_loss: 0.4785 - val_accuracy: 0.7533 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7790Epoch 29/40: loss=0.4665, accuracy=0.7790, val_loss=0.4619, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4665 - accuracy: 0.7790 - val_loss: 0.4619 - val_accuracy: 0.7599 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.7796Epoch 30/40: loss=0.4795, accuracy=0.7798, val_loss=0.4812, val_accuracy=0.7475\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4795 - accuracy: 0.7798 - val_loss: 0.4812 - val_accuracy: 0.7475 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4660 - accuracy: 0.7749Epoch 31/40: loss=0.4661, accuracy=0.7748, val_loss=0.4865, val_accuracy=0.7401\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4661 - accuracy: 0.7748 - val_loss: 0.4865 - val_accuracy: 0.7401 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.7692\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.4775, accuracy=0.7692, val_loss=0.4614, val_accuracy=0.7541\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.4775 - accuracy: 0.7692 - val_loss: 0.4614 - val_accuracy: 0.7541 - lr: 2.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.7913907170295715\n",
      "\n",
      "Refined Training Combination 14/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.5161Epoch 1/40: loss=1.0867, accuracy=0.5161, val_loss=0.9198, val_accuracy=0.5762\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 1.0867 - accuracy: 0.5161 - val_loss: 0.9198 - val_accuracy: 0.5762 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8328 - accuracy: 0.5325Epoch 2/40: loss=0.8328, accuracy=0.5325, val_loss=0.6986, val_accuracy=0.5654\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8328 - accuracy: 0.5325 - val_loss: 0.6986 - val_accuracy: 0.5654 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7766 - accuracy: 0.5578Epoch 3/40: loss=0.7764, accuracy=0.5575, val_loss=0.7077, val_accuracy=0.6076\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7764 - accuracy: 0.5575 - val_loss: 0.7077 - val_accuracy: 0.6076 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7040 - accuracy: 0.6018Epoch 4/40: loss=0.7037, accuracy=0.6020, val_loss=1.0061, val_accuracy=0.5141\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7037 - accuracy: 0.6020 - val_loss: 1.0061 - val_accuracy: 0.5141 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.6265Epoch 5/40: loss=0.6813, accuracy=0.6271, val_loss=0.5566, val_accuracy=0.7185\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6813 - accuracy: 0.6271 - val_loss: 0.5566 - val_accuracy: 0.7185 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6782 - accuracy: 0.6287Epoch 6/40: loss=0.6777, accuracy=0.6285, val_loss=0.8275, val_accuracy=0.6316\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6777 - accuracy: 0.6285 - val_loss: 0.8275 - val_accuracy: 0.6316 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6575 - accuracy: 0.6597Epoch 7/40: loss=0.6574, accuracy=0.6598, val_loss=0.6410, val_accuracy=0.6374\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6574 - accuracy: 0.6598 - val_loss: 0.6410 - val_accuracy: 0.6374 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.6697Epoch 8/40: loss=0.6534, accuracy=0.6699, val_loss=0.6091, val_accuracy=0.6606\n",
      "604/604 [==============================] - 8s 14ms/step - loss: 0.6534 - accuracy: 0.6699 - val_loss: 0.6091 - val_accuracy: 0.6606 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6369 - accuracy: 0.6749Epoch 9/40: loss=0.6370, accuracy=0.6751, val_loss=0.5900, val_accuracy=0.6515\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6370 - accuracy: 0.6751 - val_loss: 0.5900 - val_accuracy: 0.6515 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6402 - accuracy: 0.6694\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/40: loss=0.6398, accuracy=0.6699, val_loss=0.7382, val_accuracy=0.6382\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6398 - accuracy: 0.6699 - val_loss: 0.7382 - val_accuracy: 0.6382 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5772 - accuracy: 0.7081Epoch 11/40: loss=0.5768, accuracy=0.7084, val_loss=0.5403, val_accuracy=0.7417\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5768 - accuracy: 0.7084 - val_loss: 0.5403 - val_accuracy: 0.7417 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5571 - accuracy: 0.7255Epoch 12/40: loss=0.5572, accuracy=0.7256, val_loss=0.5338, val_accuracy=0.7492\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5572 - accuracy: 0.7256 - val_loss: 0.5338 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5669 - accuracy: 0.7166Epoch 13/40: loss=0.5671, accuracy=0.7165, val_loss=0.5797, val_accuracy=0.6598\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5671 - accuracy: 0.7165 - val_loss: 0.5797 - val_accuracy: 0.6598 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7255Epoch 14/40: loss=0.5511, accuracy=0.7250, val_loss=0.4838, val_accuracy=0.7947\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5511 - accuracy: 0.7250 - val_loss: 0.4838 - val_accuracy: 0.7947 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7280Epoch 15/40: loss=0.5455, accuracy=0.7283, val_loss=0.4659, val_accuracy=0.8005\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5455 - accuracy: 0.7283 - val_loss: 0.4659 - val_accuracy: 0.8005 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.7219Epoch 16/40: loss=0.5541, accuracy=0.7219, val_loss=0.4787, val_accuracy=0.7806\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5541 - accuracy: 0.7219 - val_loss: 0.4787 - val_accuracy: 0.7806 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5345 - accuracy: 0.7290Epoch 17/40: loss=0.5346, accuracy=0.7287, val_loss=0.4490, val_accuracy=0.7798\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5346 - accuracy: 0.7287 - val_loss: 0.4490 - val_accuracy: 0.7798 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.7394Epoch 18/40: loss=0.5320, accuracy=0.7390, val_loss=0.5515, val_accuracy=0.7194\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5320 - accuracy: 0.7390 - val_loss: 0.5515 - val_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7378Epoch 19/40: loss=0.5287, accuracy=0.7378, val_loss=0.5541, val_accuracy=0.7053\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5287 - accuracy: 0.7378 - val_loss: 0.5541 - val_accuracy: 0.7053 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5182 - accuracy: 0.7488Epoch 20/40: loss=0.5176, accuracy=0.7488, val_loss=0.4880, val_accuracy=0.7508\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5176 - accuracy: 0.7488 - val_loss: 0.4880 - val_accuracy: 0.7508 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.7473Epoch 21/40: loss=0.5189, accuracy=0.7473, val_loss=0.4525, val_accuracy=0.7724\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5189 - accuracy: 0.7473 - val_loss: 0.4525 - val_accuracy: 0.7724 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.7407\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 22/40: loss=0.5199, accuracy=0.7407, val_loss=0.5485, val_accuracy=0.7111\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5199 - accuracy: 0.7407 - val_loss: 0.5485 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.7498Epoch 23/40: loss=0.5037, accuracy=0.7496, val_loss=0.4627, val_accuracy=0.7889\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5037 - accuracy: 0.7496 - val_loss: 0.4627 - val_accuracy: 0.7889 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4967 - accuracy: 0.7622Epoch 24/40: loss=0.4967, accuracy=0.7622, val_loss=0.4421, val_accuracy=0.8030\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4967 - accuracy: 0.7622 - val_loss: 0.4421 - val_accuracy: 0.8030 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4789 - accuracy: 0.7754Epoch 25/40: loss=0.4797, accuracy=0.7750, val_loss=0.4544, val_accuracy=0.8046\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4797 - accuracy: 0.7750 - val_loss: 0.4544 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7490Epoch 26/40: loss=0.4983, accuracy=0.7496, val_loss=0.4330, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4983 - accuracy: 0.7496 - val_loss: 0.4330 - val_accuracy: 0.7997 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4872 - accuracy: 0.7682Epoch 27/40: loss=0.4868, accuracy=0.7684, val_loss=0.4339, val_accuracy=0.8121\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4868 - accuracy: 0.7684 - val_loss: 0.4339 - val_accuracy: 0.8121 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.7546Epoch 28/40: loss=0.5022, accuracy=0.7546, val_loss=0.4331, val_accuracy=0.8071\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5022 - accuracy: 0.7546 - val_loss: 0.4331 - val_accuracy: 0.8071 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.7703Epoch 29/40: loss=0.4830, accuracy=0.7703, val_loss=0.4394, val_accuracy=0.8063\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4830 - accuracy: 0.7703 - val_loss: 0.4394 - val_accuracy: 0.8063 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.7787Epoch 30/40: loss=0.4746, accuracy=0.7794, val_loss=0.4549, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4746 - accuracy: 0.7794 - val_loss: 0.4549 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4841 - accuracy: 0.7722\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 31/40: loss=0.4837, accuracy=0.7728, val_loss=0.4563, val_accuracy=0.7964\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4837 - accuracy: 0.7728 - val_loss: 0.4563 - val_accuracy: 0.7964 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7776Epoch 32/40: loss=0.4707, accuracy=0.7784, val_loss=0.4348, val_accuracy=0.8071\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4707 - accuracy: 0.7784 - val_loss: 0.4348 - val_accuracy: 0.8071 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7686Epoch 33/40: loss=0.4766, accuracy=0.7686, val_loss=0.4303, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4766 - accuracy: 0.7686 - val_loss: 0.4303 - val_accuracy: 0.8104 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7681Epoch 34/40: loss=0.4747, accuracy=0.7686, val_loss=0.4289, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4747 - accuracy: 0.7686 - val_loss: 0.4289 - val_accuracy: 0.8104 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.7639Epoch 35/40: loss=0.4884, accuracy=0.7643, val_loss=0.4289, val_accuracy=0.8096\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4884 - accuracy: 0.7643 - val_loss: 0.4289 - val_accuracy: 0.8096 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.7733Epoch 36/40: loss=0.4815, accuracy=0.7730, val_loss=0.4318, val_accuracy=0.8129\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4815 - accuracy: 0.7730 - val_loss: 0.4318 - val_accuracy: 0.8129 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4578 - accuracy: 0.7818Epoch 37/40: loss=0.4578, accuracy=0.7819, val_loss=0.4328, val_accuracy=0.8146\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4578 - accuracy: 0.7819 - val_loss: 0.4328 - val_accuracy: 0.8146 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.7690Epoch 38/40: loss=0.4794, accuracy=0.7690, val_loss=0.4313, val_accuracy=0.8195\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4794 - accuracy: 0.7690 - val_loss: 0.4313 - val_accuracy: 0.8195 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.7727Epoch 39/40: loss=0.4745, accuracy=0.7728, val_loss=0.4266, val_accuracy=0.8113\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4745 - accuracy: 0.7728 - val_loss: 0.4266 - val_accuracy: 0.8113 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.7757Epoch 40/40: loss=0.4750, accuracy=0.7752, val_loss=0.4273, val_accuracy=0.8096\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4750 - accuracy: 0.7752 - val_loss: 0.4273 - val_accuracy: 0.8096 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.8195364475250244\n",
      "Model with validation accuracy 0.8195364475250244 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 15/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.6, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1142 - accuracy: 0.5170Epoch 1/40: loss=1.1130, accuracy=0.5172, val_loss=1.0937, val_accuracy=0.4545\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 1.1130 - accuracy: 0.5172 - val_loss: 1.0937 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8676 - accuracy: 0.5293Epoch 2/40: loss=0.8695, accuracy=0.5292, val_loss=0.9389, val_accuracy=0.4661\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8695 - accuracy: 0.5292 - val_loss: 0.9389 - val_accuracy: 0.4661 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8544 - accuracy: 0.5391Epoch 3/40: loss=0.8539, accuracy=0.5385, val_loss=1.0389, val_accuracy=0.4354\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8539 - accuracy: 0.5385 - val_loss: 1.0389 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8114 - accuracy: 0.5515Epoch 4/40: loss=0.8114, accuracy=0.5515, val_loss=0.7699, val_accuracy=0.5869\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8114 - accuracy: 0.5515 - val_loss: 0.7699 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8147 - accuracy: 0.5321Epoch 5/40: loss=0.8147, accuracy=0.5321, val_loss=0.7071, val_accuracy=0.6002\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8147 - accuracy: 0.5321 - val_loss: 0.7071 - val_accuracy: 0.6002 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7613 - accuracy: 0.5743Epoch 6/40: loss=0.7625, accuracy=0.5737, val_loss=0.8703, val_accuracy=0.4512\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7625 - accuracy: 0.5737 - val_loss: 0.8703 - val_accuracy: 0.4512 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7810 - accuracy: 0.5652Epoch 7/40: loss=0.7820, accuracy=0.5650, val_loss=0.6924, val_accuracy=0.6018\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7820 - accuracy: 0.5650 - val_loss: 0.6924 - val_accuracy: 0.6018 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8096 - accuracy: 0.5393Epoch 8/40: loss=0.8107, accuracy=0.5389, val_loss=0.7144, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8107 - accuracy: 0.5389 - val_loss: 0.7144 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8199 - accuracy: 0.5327Epoch 9/40: loss=0.8199, accuracy=0.5327, val_loss=0.7354, val_accuracy=0.5091\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8199 - accuracy: 0.5327 - val_loss: 0.7354 - val_accuracy: 0.5091 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7869 - accuracy: 0.5238Epoch 10/40: loss=0.7869, accuracy=0.5238, val_loss=0.8779, val_accuracy=0.4892\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7869 - accuracy: 0.5238 - val_loss: 0.8779 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8177 - accuracy: 0.5112Epoch 11/40: loss=0.8169, accuracy=0.5120, val_loss=0.7935, val_accuracy=0.5348\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8169 - accuracy: 0.5120 - val_loss: 0.7935 - val_accuracy: 0.5348 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.4861\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.8224, accuracy=0.4861, val_loss=0.8138, val_accuracy=0.4313\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8224 - accuracy: 0.4861 - val_loss: 0.8138 - val_accuracy: 0.4313 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7493 - accuracy: 0.5075Epoch 13/40: loss=0.7493, accuracy=0.5075, val_loss=0.7038, val_accuracy=0.4917\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7493 - accuracy: 0.5075 - val_loss: 0.7038 - val_accuracy: 0.4917 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7499 - accuracy: 0.4973Epoch 14/40: loss=0.7500, accuracy=0.4967, val_loss=0.6802, val_accuracy=0.6043\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7500 - accuracy: 0.4967 - val_loss: 0.6802 - val_accuracy: 0.6043 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7283 - accuracy: 0.5182Epoch 15/40: loss=0.7284, accuracy=0.5182, val_loss=0.6945, val_accuracy=0.5116\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7284 - accuracy: 0.5182 - val_loss: 0.6945 - val_accuracy: 0.5116 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7320 - accuracy: 0.5187Epoch 16/40: loss=0.7318, accuracy=0.5188, val_loss=0.7088, val_accuracy=0.5414\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7318 - accuracy: 0.5188 - val_loss: 0.7088 - val_accuracy: 0.5414 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.5114Epoch 17/40: loss=0.7270, accuracy=0.5106, val_loss=0.6791, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7270 - accuracy: 0.5106 - val_loss: 0.6791 - val_accuracy: 0.5579 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.5087Epoch 18/40: loss=0.7245, accuracy=0.5083, val_loss=0.6715, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7245 - accuracy: 0.5083 - val_loss: 0.6715 - val_accuracy: 0.5960 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7280 - accuracy: 0.5150Epoch 19/40: loss=0.7276, accuracy=0.5151, val_loss=0.7332, val_accuracy=0.4950\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7276 - accuracy: 0.5151 - val_loss: 0.7332 - val_accuracy: 0.4950 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7180 - accuracy: 0.5354Epoch 20/40: loss=0.7183, accuracy=0.5354, val_loss=0.6668, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7183 - accuracy: 0.5354 - val_loss: 0.6668 - val_accuracy: 0.5960 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.5292Epoch 21/40: loss=0.7149, accuracy=0.5292, val_loss=0.6738, val_accuracy=0.5861\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7149 - accuracy: 0.5292 - val_loss: 0.6738 - val_accuracy: 0.5861 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7165 - accuracy: 0.5292Epoch 22/40: loss=0.7167, accuracy=0.5292, val_loss=0.6791, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7167 - accuracy: 0.5292 - val_loss: 0.6791 - val_accuracy: 0.5969 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.5588Epoch 23/40: loss=0.6965, accuracy=0.5588, val_loss=0.6799, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6965 - accuracy: 0.5588 - val_loss: 0.6799 - val_accuracy: 0.5977 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7035 - accuracy: 0.5690Epoch 24/40: loss=0.7033, accuracy=0.5689, val_loss=0.6830, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7033 - accuracy: 0.5689 - val_loss: 0.6830 - val_accuracy: 0.5579 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.6093Epoch 25/40: loss=0.6736, accuracy=0.6093, val_loss=0.6641, val_accuracy=0.6051\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6736 - accuracy: 0.6093 - val_loss: 0.6641 - val_accuracy: 0.6051 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6635 - accuracy: 0.6200Epoch 26/40: loss=0.6639, accuracy=0.6194, val_loss=0.5911, val_accuracy=0.6863\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6639 - accuracy: 0.6194 - val_loss: 0.5911 - val_accuracy: 0.6863 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6428 - accuracy: 0.6498Epoch 27/40: loss=0.6442, accuracy=0.6486, val_loss=0.6867, val_accuracy=0.5596\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6442 - accuracy: 0.6486 - val_loss: 0.6867 - val_accuracy: 0.5596 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6407 - accuracy: 0.6475Epoch 28/40: loss=0.6401, accuracy=0.6482, val_loss=0.6211, val_accuracy=0.6507\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6401 - accuracy: 0.6482 - val_loss: 0.6211 - val_accuracy: 0.6507 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6243 - accuracy: 0.6662Epoch 29/40: loss=0.6241, accuracy=0.6666, val_loss=0.8711, val_accuracy=0.5447\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6241 - accuracy: 0.6666 - val_loss: 0.8711 - val_accuracy: 0.5447 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.6629Epoch 30/40: loss=0.6189, accuracy=0.6635, val_loss=0.6593, val_accuracy=0.6026\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6189 - accuracy: 0.6635 - val_loss: 0.6593 - val_accuracy: 0.6026 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6705Epoch 31/40: loss=0.6126, accuracy=0.6705, val_loss=0.5666, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6126 - accuracy: 0.6705 - val_loss: 0.5666 - val_accuracy: 0.7020 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6162 - accuracy: 0.6774Epoch 32/40: loss=0.6160, accuracy=0.6778, val_loss=0.6079, val_accuracy=0.6556\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6160 - accuracy: 0.6778 - val_loss: 0.6079 - val_accuracy: 0.6556 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.6797Epoch 33/40: loss=0.6060, accuracy=0.6796, val_loss=0.6302, val_accuracy=0.6598\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6060 - accuracy: 0.6796 - val_loss: 0.6302 - val_accuracy: 0.6598 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6017 - accuracy: 0.6935Epoch 34/40: loss=0.6017, accuracy=0.6935, val_loss=0.6089, val_accuracy=0.6738\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6017 - accuracy: 0.6935 - val_loss: 0.6089 - val_accuracy: 0.6738 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.6964Epoch 35/40: loss=0.5974, accuracy=0.6964, val_loss=0.6255, val_accuracy=0.6490\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5974 - accuracy: 0.6964 - val_loss: 0.6255 - val_accuracy: 0.6490 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.7080\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40: loss=0.5760, accuracy=0.7086, val_loss=0.6204, val_accuracy=0.6912\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5760 - accuracy: 0.7086 - val_loss: 0.6204 - val_accuracy: 0.6912 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5696 - accuracy: 0.7114Epoch 37/40: loss=0.5697, accuracy=0.7111, val_loss=0.5545, val_accuracy=0.7293\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5697 - accuracy: 0.7111 - val_loss: 0.5545 - val_accuracy: 0.7293 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5582 - accuracy: 0.7222Epoch 38/40: loss=0.5582, accuracy=0.7223, val_loss=0.5557, val_accuracy=0.7169\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5582 - accuracy: 0.7223 - val_loss: 0.5557 - val_accuracy: 0.7169 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.7259Epoch 39/40: loss=0.5586, accuracy=0.7254, val_loss=0.5116, val_accuracy=0.7550\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5586 - accuracy: 0.7254 - val_loss: 0.5116 - val_accuracy: 0.7550 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.7250Epoch 40/40: loss=0.5534, accuracy=0.7248, val_loss=0.5242, val_accuracy=0.7508\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5534 - accuracy: 0.7248 - val_loss: 0.5242 - val_accuracy: 0.7508 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.7549669146537781\n",
      "\n",
      "Refined Training Combination 16/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1272 - accuracy: 0.5264Epoch 1/40: loss=1.1250, accuracy=0.5273, val_loss=1.3171, val_accuracy=0.3916\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 1.1250 - accuracy: 0.5273 - val_loss: 1.3171 - val_accuracy: 0.3916 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8183 - accuracy: 0.5664Epoch 2/40: loss=0.8179, accuracy=0.5660, val_loss=0.7188, val_accuracy=0.5861\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8179 - accuracy: 0.5660 - val_loss: 0.7188 - val_accuracy: 0.5861 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.5792Epoch 3/40: loss=0.8041, accuracy=0.5795, val_loss=0.7189, val_accuracy=0.5654\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8041 - accuracy: 0.5795 - val_loss: 0.7189 - val_accuracy: 0.5654 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7980 - accuracy: 0.5606Epoch 4/40: loss=0.7994, accuracy=0.5604, val_loss=0.8531, val_accuracy=0.5588\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7994 - accuracy: 0.5604 - val_loss: 0.8531 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7851 - accuracy: 0.5808Epoch 5/40: loss=0.7845, accuracy=0.5815, val_loss=0.6525, val_accuracy=0.7061\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7845 - accuracy: 0.5815 - val_loss: 0.6525 - val_accuracy: 0.7061 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7479 - accuracy: 0.6150Epoch 6/40: loss=0.7481, accuracy=0.6147, val_loss=0.6180, val_accuracy=0.6805\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7481 - accuracy: 0.6147 - val_loss: 0.6180 - val_accuracy: 0.6805 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7109 - accuracy: 0.6327Epoch 7/40: loss=0.7123, accuracy=0.6322, val_loss=0.6520, val_accuracy=0.6175\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7123 - accuracy: 0.6322 - val_loss: 0.6520 - val_accuracy: 0.6175 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8010 - accuracy: 0.5431Epoch 8/40: loss=0.8014, accuracy=0.5424, val_loss=0.6866, val_accuracy=0.5969\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8014 - accuracy: 0.5424 - val_loss: 0.6866 - val_accuracy: 0.5969 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7162 - accuracy: 0.6011Epoch 9/40: loss=0.7167, accuracy=0.6006, val_loss=0.7138, val_accuracy=0.5704\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7167 - accuracy: 0.6006 - val_loss: 0.7138 - val_accuracy: 0.5704 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7681 - accuracy: 0.5655Epoch 10/40: loss=0.7683, accuracy=0.5654, val_loss=0.7172, val_accuracy=0.5224\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7683 - accuracy: 0.5654 - val_loss: 0.7172 - val_accuracy: 0.5224 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.5588\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 11/40: loss=0.7596, accuracy=0.5590, val_loss=0.7641, val_accuracy=0.5786\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7596 - accuracy: 0.5590 - val_loss: 0.7641 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.6157Epoch 12/40: loss=0.6724, accuracy=0.6155, val_loss=0.6483, val_accuracy=0.6291\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6724 - accuracy: 0.6155 - val_loss: 0.6483 - val_accuracy: 0.6291 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6320 - accuracy: 0.6680Epoch 13/40: loss=0.6337, accuracy=0.6668, val_loss=0.6060, val_accuracy=0.6391\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6337 - accuracy: 0.6668 - val_loss: 0.6060 - val_accuracy: 0.6391 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.6790Epoch 14/40: loss=0.6146, accuracy=0.6790, val_loss=0.5944, val_accuracy=0.6689\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6146 - accuracy: 0.6790 - val_loss: 0.5944 - val_accuracy: 0.6689 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5986 - accuracy: 0.7021Epoch 15/40: loss=0.5993, accuracy=0.7016, val_loss=0.8988, val_accuracy=0.4826\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5993 - accuracy: 0.7016 - val_loss: 0.8988 - val_accuracy: 0.4826 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.6894Epoch 16/40: loss=0.6039, accuracy=0.6889, val_loss=0.5783, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6039 - accuracy: 0.6889 - val_loss: 0.5783 - val_accuracy: 0.7020 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.6962Epoch 17/40: loss=0.5979, accuracy=0.6962, val_loss=0.5045, val_accuracy=0.7525\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5979 - accuracy: 0.6962 - val_loss: 0.5045 - val_accuracy: 0.7525 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5923 - accuracy: 0.7013Epoch 18/40: loss=0.5924, accuracy=0.7012, val_loss=0.6454, val_accuracy=0.6465\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5924 - accuracy: 0.7012 - val_loss: 0.6454 - val_accuracy: 0.6465 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.6970Epoch 19/40: loss=0.5888, accuracy=0.6970, val_loss=0.6965, val_accuracy=0.6275\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5888 - accuracy: 0.6970 - val_loss: 0.6965 - val_accuracy: 0.6275 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.6904Epoch 20/40: loss=0.5973, accuracy=0.6908, val_loss=0.5254, val_accuracy=0.7442\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5973 - accuracy: 0.6908 - val_loss: 0.5254 - val_accuracy: 0.7442 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.7187Epoch 21/40: loss=0.5769, accuracy=0.7185, val_loss=0.5245, val_accuracy=0.7185\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5769 - accuracy: 0.7185 - val_loss: 0.5245 - val_accuracy: 0.7185 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5764 - accuracy: 0.7081\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 22/40: loss=0.5756, accuracy=0.7086, val_loss=0.8539, val_accuracy=0.5737\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5756 - accuracy: 0.7086 - val_loss: 0.8539 - val_accuracy: 0.5737 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7274Epoch 23/40: loss=0.5531, accuracy=0.7274, val_loss=0.5224, val_accuracy=0.7541\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5531 - accuracy: 0.7274 - val_loss: 0.5224 - val_accuracy: 0.7541 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7314Epoch 24/40: loss=0.5422, accuracy=0.7314, val_loss=0.5663, val_accuracy=0.6978\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5422 - accuracy: 0.7314 - val_loss: 0.5663 - val_accuracy: 0.6978 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7282Epoch 25/40: loss=0.5429, accuracy=0.7279, val_loss=0.5235, val_accuracy=0.7334\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5429 - accuracy: 0.7279 - val_loss: 0.5235 - val_accuracy: 0.7334 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.7351Epoch 26/40: loss=0.5322, accuracy=0.7351, val_loss=0.5157, val_accuracy=0.7558\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5322 - accuracy: 0.7351 - val_loss: 0.5157 - val_accuracy: 0.7558 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7407\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5352, accuracy=0.7409, val_loss=0.5124, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5352 - accuracy: 0.7409 - val_loss: 0.5124 - val_accuracy: 0.7450 - lr: 4.0000e-05\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7557947039604187\n",
      "\n",
      "Refined Training Combination 17/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.5, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0708 - accuracy: 0.5197Epoch 1/40: loss=1.0708, accuracy=0.5197, val_loss=0.7857, val_accuracy=0.5273\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0708 - accuracy: 0.5197 - val_loss: 0.7857 - val_accuracy: 0.5273 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8349 - accuracy: 0.5496Epoch 2/40: loss=0.8342, accuracy=0.5499, val_loss=0.7661, val_accuracy=0.6051\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8342 - accuracy: 0.5499 - val_loss: 0.7661 - val_accuracy: 0.6051 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.5847Epoch 3/40: loss=0.7450, accuracy=0.5842, val_loss=0.6940, val_accuracy=0.5927\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7450 - accuracy: 0.5842 - val_loss: 0.6940 - val_accuracy: 0.5927 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7080 - accuracy: 0.6200Epoch 4/40: loss=0.7080, accuracy=0.6202, val_loss=1.2916, val_accuracy=0.5447\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7080 - accuracy: 0.6202 - val_loss: 1.2916 - val_accuracy: 0.5447 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.6275Epoch 5/40: loss=0.6881, accuracy=0.6262, val_loss=0.6538, val_accuracy=0.6068\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6881 - accuracy: 0.6262 - val_loss: 0.6538 - val_accuracy: 0.6068 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.6298Epoch 6/40: loss=0.6864, accuracy=0.6298, val_loss=0.7305, val_accuracy=0.5199\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6864 - accuracy: 0.6298 - val_loss: 0.7305 - val_accuracy: 0.5199 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6432 - accuracy: 0.6633Epoch 7/40: loss=0.6432, accuracy=0.6635, val_loss=0.7033, val_accuracy=0.5919\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6432 - accuracy: 0.6635 - val_loss: 0.7033 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.6691Epoch 8/40: loss=0.6405, accuracy=0.6691, val_loss=0.5645, val_accuracy=0.6921\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6405 - accuracy: 0.6691 - val_loss: 0.5645 - val_accuracy: 0.6921 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6468 - accuracy: 0.6704Epoch 9/40: loss=0.6468, accuracy=0.6701, val_loss=0.7714, val_accuracy=0.6010\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6468 - accuracy: 0.6701 - val_loss: 0.7714 - val_accuracy: 0.6010 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6624Epoch 10/40: loss=0.6540, accuracy=0.6627, val_loss=0.9414, val_accuracy=0.4776\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6540 - accuracy: 0.6627 - val_loss: 0.9414 - val_accuracy: 0.4776 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.6638Epoch 11/40: loss=0.6633, accuracy=0.6637, val_loss=0.8680, val_accuracy=0.5116\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6633 - accuracy: 0.6637 - val_loss: 0.8680 - val_accuracy: 0.5116 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6383 - accuracy: 0.6735Epoch 12/40: loss=0.6395, accuracy=0.6730, val_loss=0.6040, val_accuracy=0.6805\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6395 - accuracy: 0.6730 - val_loss: 0.6040 - val_accuracy: 0.6805 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.6812\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/40: loss=0.6290, accuracy=0.6813, val_loss=0.5689, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6290 - accuracy: 0.6813 - val_loss: 0.5689 - val_accuracy: 0.7020 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5694 - accuracy: 0.7107Epoch 14/40: loss=0.5689, accuracy=0.7111, val_loss=0.5535, val_accuracy=0.6755\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5689 - accuracy: 0.7111 - val_loss: 0.5535 - val_accuracy: 0.6755 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7384Epoch 15/40: loss=0.5412, accuracy=0.7384, val_loss=0.5765, val_accuracy=0.6970\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5412 - accuracy: 0.7384 - val_loss: 0.5765 - val_accuracy: 0.6970 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7293Epoch 16/40: loss=0.5534, accuracy=0.7293, val_loss=0.5134, val_accuracy=0.7475\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5534 - accuracy: 0.7293 - val_loss: 0.5134 - val_accuracy: 0.7475 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7446Epoch 17/40: loss=0.5338, accuracy=0.7448, val_loss=0.5980, val_accuracy=0.7152\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5338 - accuracy: 0.7448 - val_loss: 0.5980 - val_accuracy: 0.7152 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.7471Epoch 18/40: loss=0.5280, accuracy=0.7467, val_loss=0.4765, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5280 - accuracy: 0.7467 - val_loss: 0.4765 - val_accuracy: 0.7690 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.7450Epoch 19/40: loss=0.5249, accuracy=0.7450, val_loss=0.4422, val_accuracy=0.8096\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5249 - accuracy: 0.7450 - val_loss: 0.4422 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.7500Epoch 20/40: loss=0.5160, accuracy=0.7502, val_loss=0.4105, val_accuracy=0.8286\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5160 - accuracy: 0.7502 - val_loss: 0.4105 - val_accuracy: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.7637Epoch 21/40: loss=0.5043, accuracy=0.7637, val_loss=0.4609, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5043 - accuracy: 0.7637 - val_loss: 0.4609 - val_accuracy: 0.7906 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.7504Epoch 22/40: loss=0.5162, accuracy=0.7502, val_loss=0.4607, val_accuracy=0.7848\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5162 - accuracy: 0.7502 - val_loss: 0.4607 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5111 - accuracy: 0.7550Epoch 23/40: loss=0.5114, accuracy=0.7550, val_loss=0.4255, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5114 - accuracy: 0.7550 - val_loss: 0.4255 - val_accuracy: 0.7964 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.7639Epoch 24/40: loss=0.4900, accuracy=0.7639, val_loss=0.4330, val_accuracy=0.7997\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4900 - accuracy: 0.7639 - val_loss: 0.4330 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.7620\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 25/40: loss=0.5016, accuracy=0.7618, val_loss=0.4502, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5016 - accuracy: 0.7618 - val_loss: 0.4502 - val_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4764 - accuracy: 0.7762Epoch 26/40: loss=0.4784, accuracy=0.7746, val_loss=0.4009, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4784 - accuracy: 0.7746 - val_loss: 0.4009 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.7696Epoch 27/40: loss=0.4855, accuracy=0.7699, val_loss=0.3972, val_accuracy=0.8311\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4855 - accuracy: 0.7699 - val_loss: 0.3972 - val_accuracy: 0.8311 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.7775Epoch 28/40: loss=0.4746, accuracy=0.7771, val_loss=0.4077, val_accuracy=0.8228\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4746 - accuracy: 0.7771 - val_loss: 0.4077 - val_accuracy: 0.8228 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.7744Epoch 29/40: loss=0.4714, accuracy=0.7744, val_loss=0.3979, val_accuracy=0.8320\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4714 - accuracy: 0.7744 - val_loss: 0.3979 - val_accuracy: 0.8320 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4567 - accuracy: 0.7878Epoch 30/40: loss=0.4565, accuracy=0.7875, val_loss=0.3944, val_accuracy=0.8369\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4565 - accuracy: 0.7875 - val_loss: 0.3944 - val_accuracy: 0.8369 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4543 - accuracy: 0.7856Epoch 31/40: loss=0.4547, accuracy=0.7854, val_loss=0.3840, val_accuracy=0.8295\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4547 - accuracy: 0.7854 - val_loss: 0.3840 - val_accuracy: 0.8295 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.7814Epoch 32/40: loss=0.4598, accuracy=0.7810, val_loss=0.4057, val_accuracy=0.8270\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4598 - accuracy: 0.7810 - val_loss: 0.4057 - val_accuracy: 0.8270 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.7871Epoch 33/40: loss=0.4633, accuracy=0.7875, val_loss=0.3954, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4633 - accuracy: 0.7875 - val_loss: 0.3954 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7847Epoch 34/40: loss=0.4573, accuracy=0.7854, val_loss=0.3793, val_accuracy=0.8253\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4573 - accuracy: 0.7854 - val_loss: 0.3793 - val_accuracy: 0.8253 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.7845Epoch 35/40: loss=0.4615, accuracy=0.7844, val_loss=0.3659, val_accuracy=0.8435\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4615 - accuracy: 0.7844 - val_loss: 0.3659 - val_accuracy: 0.8435 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.7846Epoch 36/40: loss=0.4514, accuracy=0.7848, val_loss=0.3972, val_accuracy=0.8179\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4514 - accuracy: 0.7848 - val_loss: 0.3972 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.7877Epoch 37/40: loss=0.4501, accuracy=0.7875, val_loss=0.3689, val_accuracy=0.8543\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4501 - accuracy: 0.7875 - val_loss: 0.3689 - val_accuracy: 0.8543 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7872Epoch 38/40: loss=0.4575, accuracy=0.7875, val_loss=0.3818, val_accuracy=0.8485\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4575 - accuracy: 0.7875 - val_loss: 0.3818 - val_accuracy: 0.8485 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7913Epoch 39/40: loss=0.4375, accuracy=0.7918, val_loss=0.3575, val_accuracy=0.8551\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4375 - accuracy: 0.7918 - val_loss: 0.3575 - val_accuracy: 0.8551 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7928Epoch 40/40: loss=0.4386, accuracy=0.7928, val_loss=0.3749, val_accuracy=0.8609\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4386 - accuracy: 0.7928 - val_loss: 0.3749 - val_accuracy: 0.8609 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.860927164554596\n",
      "Model with validation accuracy 0.860927164554596 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 18/50: num_residual_blocks=7, dropout_rate=0.4, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9248 - accuracy: 0.5309Epoch 1/40: loss=0.9244, accuracy=0.5310, val_loss=0.7706, val_accuracy=0.5927\n",
      "604/604 [==============================] - 14s 18ms/step - loss: 0.9244 - accuracy: 0.5310 - val_loss: 0.7706 - val_accuracy: 0.5927 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9037 - accuracy: 0.5233Epoch 2/40: loss=0.9046, accuracy=0.5232, val_loss=0.7734, val_accuracy=0.5257\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9046 - accuracy: 0.5232 - val_loss: 0.7734 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8827 - accuracy: 0.5377Epoch 3/40: loss=0.8830, accuracy=0.5377, val_loss=0.7256, val_accuracy=0.5762\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8830 - accuracy: 0.5377 - val_loss: 0.7256 - val_accuracy: 0.5762 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8475 - accuracy: 0.5373Epoch 4/40: loss=0.8481, accuracy=0.5373, val_loss=0.7883, val_accuracy=0.5017\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8481 - accuracy: 0.5373 - val_loss: 0.7883 - val_accuracy: 0.5017 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.5315Epoch 5/40: loss=0.8415, accuracy=0.5315, val_loss=0.7078, val_accuracy=0.5737\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8415 - accuracy: 0.5315 - val_loss: 0.7078 - val_accuracy: 0.5737 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.5486Epoch 6/40: loss=0.8020, accuracy=0.5486, val_loss=0.6845, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8020 - accuracy: 0.5486 - val_loss: 0.6845 - val_accuracy: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7771 - accuracy: 0.5748Epoch 7/40: loss=0.7776, accuracy=0.5747, val_loss=0.7355, val_accuracy=0.6101\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7776 - accuracy: 0.5747 - val_loss: 0.7355 - val_accuracy: 0.6101 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.5710Epoch 8/40: loss=0.7589, accuracy=0.5710, val_loss=0.7455, val_accuracy=0.5091\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7589 - accuracy: 0.5710 - val_loss: 0.7455 - val_accuracy: 0.5091 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7555 - accuracy: 0.5643Epoch 9/40: loss=0.7555, accuracy=0.5639, val_loss=0.7334, val_accuracy=0.5364\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7555 - accuracy: 0.5639 - val_loss: 0.7334 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.5902Epoch 10/40: loss=0.7232, accuracy=0.5902, val_loss=0.7071, val_accuracy=0.5894\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7232 - accuracy: 0.5902 - val_loss: 0.7071 - val_accuracy: 0.5894 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.6208Epoch 11/40: loss=0.6961, accuracy=0.6209, val_loss=0.6569, val_accuracy=0.6308\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6961 - accuracy: 0.6209 - val_loss: 0.6569 - val_accuracy: 0.6308 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.6142Epoch 12/40: loss=0.6970, accuracy=0.6142, val_loss=0.7051, val_accuracy=0.5820\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6970 - accuracy: 0.6142 - val_loss: 0.7051 - val_accuracy: 0.5820 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.6271Epoch 13/40: loss=0.6735, accuracy=0.6260, val_loss=0.6697, val_accuracy=0.6142\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6735 - accuracy: 0.6260 - val_loss: 0.6697 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.6426Epoch 14/40: loss=0.6477, accuracy=0.6430, val_loss=0.5889, val_accuracy=0.6896\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6477 - accuracy: 0.6430 - val_loss: 0.5889 - val_accuracy: 0.6896 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.6498Epoch 15/40: loss=0.6431, accuracy=0.6498, val_loss=0.5643, val_accuracy=0.7094\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6431 - accuracy: 0.6498 - val_loss: 0.5643 - val_accuracy: 0.7094 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6245 - accuracy: 0.6696Epoch 16/40: loss=0.6247, accuracy=0.6695, val_loss=0.6437, val_accuracy=0.6523\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6247 - accuracy: 0.6695 - val_loss: 0.6437 - val_accuracy: 0.6523 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.6676Epoch 17/40: loss=0.6179, accuracy=0.6676, val_loss=0.5919, val_accuracy=0.6780\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6179 - accuracy: 0.6676 - val_loss: 0.5919 - val_accuracy: 0.6780 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.6643Epoch 18/40: loss=0.6213, accuracy=0.6643, val_loss=0.6373, val_accuracy=0.6639\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6213 - accuracy: 0.6643 - val_loss: 0.6373 - val_accuracy: 0.6639 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6028 - accuracy: 0.6881Epoch 19/40: loss=0.6017, accuracy=0.6889, val_loss=0.7460, val_accuracy=0.5720\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6017 - accuracy: 0.6889 - val_loss: 0.7460 - val_accuracy: 0.5720 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.6983Epoch 20/40: loss=0.5902, accuracy=0.6983, val_loss=0.5393, val_accuracy=0.7417\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5902 - accuracy: 0.6983 - val_loss: 0.5393 - val_accuracy: 0.7417 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5738 - accuracy: 0.6989Epoch 21/40: loss=0.5733, accuracy=0.6989, val_loss=0.5489, val_accuracy=0.7376\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5733 - accuracy: 0.6989 - val_loss: 0.5489 - val_accuracy: 0.7376 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.7184Epoch 22/40: loss=0.5742, accuracy=0.7183, val_loss=0.5218, val_accuracy=0.7500\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5742 - accuracy: 0.7183 - val_loss: 0.5218 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5707 - accuracy: 0.7072Epoch 23/40: loss=0.5704, accuracy=0.7078, val_loss=0.5578, val_accuracy=0.7152\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5704 - accuracy: 0.7078 - val_loss: 0.5578 - val_accuracy: 0.7152 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5832 - accuracy: 0.6980Epoch 24/40: loss=0.5835, accuracy=0.6978, val_loss=0.6080, val_accuracy=0.6714\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5835 - accuracy: 0.6978 - val_loss: 0.6080 - val_accuracy: 0.6714 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5696 - accuracy: 0.7106Epoch 25/40: loss=0.5705, accuracy=0.7103, val_loss=0.6224, val_accuracy=0.6565\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5705 - accuracy: 0.7103 - val_loss: 0.6224 - val_accuracy: 0.6565 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7148Epoch 26/40: loss=0.5616, accuracy=0.7148, val_loss=0.5464, val_accuracy=0.7219\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5616 - accuracy: 0.7148 - val_loss: 0.5464 - val_accuracy: 0.7219 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7210\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 27/40: loss=0.5601, accuracy=0.7210, val_loss=0.5439, val_accuracy=0.7276\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5601 - accuracy: 0.7210 - val_loss: 0.5439 - val_accuracy: 0.7276 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.7272Epoch 28/40: loss=0.5441, accuracy=0.7272, val_loss=0.5244, val_accuracy=0.7442\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5441 - accuracy: 0.7272 - val_loss: 0.5244 - val_accuracy: 0.7442 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.7277Epoch 29/40: loss=0.5394, accuracy=0.7274, val_loss=0.5132, val_accuracy=0.7566\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5394 - accuracy: 0.7274 - val_loss: 0.5132 - val_accuracy: 0.7566 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.7324Epoch 30/40: loss=0.5345, accuracy=0.7328, val_loss=0.4986, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5345 - accuracy: 0.7328 - val_loss: 0.4986 - val_accuracy: 0.7641 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.7374Epoch 31/40: loss=0.5253, accuracy=0.7374, val_loss=0.5452, val_accuracy=0.7185\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5253 - accuracy: 0.7374 - val_loss: 0.5452 - val_accuracy: 0.7185 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.7415Epoch 32/40: loss=0.5232, accuracy=0.7411, val_loss=0.5074, val_accuracy=0.7434\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5232 - accuracy: 0.7411 - val_loss: 0.5074 - val_accuracy: 0.7434 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5245 - accuracy: 0.7409Epoch 33/40: loss=0.5246, accuracy=0.7411, val_loss=0.5193, val_accuracy=0.7624\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5246 - accuracy: 0.7411 - val_loss: 0.5193 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7367Epoch 34/40: loss=0.5259, accuracy=0.7374, val_loss=0.5264, val_accuracy=0.7442\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5259 - accuracy: 0.7374 - val_loss: 0.5264 - val_accuracy: 0.7442 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.7465\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 35/40: loss=0.5162, accuracy=0.7465, val_loss=0.5571, val_accuracy=0.7119\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5162 - accuracy: 0.7465 - val_loss: 0.5571 - val_accuracy: 0.7119 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5185 - accuracy: 0.7394Epoch 36/40: loss=0.5184, accuracy=0.7394, val_loss=0.5005, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5184 - accuracy: 0.7394 - val_loss: 0.5005 - val_accuracy: 0.7599 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7458Epoch 37/40: loss=0.5137, accuracy=0.7459, val_loss=0.5267, val_accuracy=0.7285\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5137 - accuracy: 0.7459 - val_loss: 0.5267 - val_accuracy: 0.7285 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.7423Epoch 38/40: loss=0.5114, accuracy=0.7430, val_loss=0.5034, val_accuracy=0.7525\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5114 - accuracy: 0.7430 - val_loss: 0.5034 - val_accuracy: 0.7525 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.7475Epoch 39/40: loss=0.5112, accuracy=0.7477, val_loss=0.5001, val_accuracy=0.7616\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5112 - accuracy: 0.7477 - val_loss: 0.5001 - val_accuracy: 0.7616 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7467\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40/40: loss=0.5080, accuracy=0.7467, val_loss=0.5063, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5080 - accuracy: 0.7467 - val_loss: 0.5063 - val_accuracy: 0.7483 - lr: 4.0000e-06\n",
      "Epoch 40: early stopping\n",
      "Validation accuracy: 0.764072835445404\n",
      "\n",
      "Refined Training Combination 19/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.4, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0901 - accuracy: 0.5069Epoch 1/40: loss=1.0892, accuracy=0.5068, val_loss=0.8486, val_accuracy=0.5687\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 1.0892 - accuracy: 0.5068 - val_loss: 0.8486 - val_accuracy: 0.5687 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8552 - accuracy: 0.5373Epoch 2/40: loss=0.8553, accuracy=0.5375, val_loss=0.8839, val_accuracy=0.5786\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8553 - accuracy: 0.5375 - val_loss: 0.8839 - val_accuracy: 0.5786 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7812 - accuracy: 0.5481Epoch 3/40: loss=0.7811, accuracy=0.5482, val_loss=0.7450, val_accuracy=0.5356\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7811 - accuracy: 0.5482 - val_loss: 0.7450 - val_accuracy: 0.5356 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7410 - accuracy: 0.5633Epoch 4/40: loss=0.7411, accuracy=0.5625, val_loss=0.6597, val_accuracy=0.6316\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7411 - accuracy: 0.5625 - val_loss: 0.6597 - val_accuracy: 0.6316 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7166 - accuracy: 0.5888Epoch 5/40: loss=0.7168, accuracy=0.5886, val_loss=0.6541, val_accuracy=0.6267\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7168 - accuracy: 0.5886 - val_loss: 0.6541 - val_accuracy: 0.6267 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7111 - accuracy: 0.6016Epoch 6/40: loss=0.7110, accuracy=0.6014, val_loss=0.6802, val_accuracy=0.5820\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7110 - accuracy: 0.6014 - val_loss: 0.6802 - val_accuracy: 0.5820 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.6151Epoch 7/40: loss=0.6958, accuracy=0.6151, val_loss=0.9035, val_accuracy=0.4321\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6958 - accuracy: 0.6151 - val_loss: 0.9035 - val_accuracy: 0.4321 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7060 - accuracy: 0.6124Epoch 8/40: loss=0.7064, accuracy=0.6120, val_loss=0.6344, val_accuracy=0.6548\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7064 - accuracy: 0.6120 - val_loss: 0.6344 - val_accuracy: 0.6548 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7030 - accuracy: 0.6078Epoch 9/40: loss=0.7026, accuracy=0.6080, val_loss=0.6219, val_accuracy=0.6647\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7026 - accuracy: 0.6080 - val_loss: 0.6219 - val_accuracy: 0.6647 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.6353Epoch 10/40: loss=0.6839, accuracy=0.6353, val_loss=0.7823, val_accuracy=0.4884\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6839 - accuracy: 0.6353 - val_loss: 0.7823 - val_accuracy: 0.4884 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.6484Epoch 11/40: loss=0.6608, accuracy=0.6484, val_loss=0.7911, val_accuracy=0.5373\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6608 - accuracy: 0.6484 - val_loss: 0.7911 - val_accuracy: 0.5373 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.6339Epoch 12/40: loss=0.6993, accuracy=0.6339, val_loss=0.6922, val_accuracy=0.5637\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6993 - accuracy: 0.6339 - val_loss: 0.6922 - val_accuracy: 0.5637 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.6213Epoch 13/40: loss=0.6912, accuracy=0.6213, val_loss=1.0127, val_accuracy=0.5017\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6912 - accuracy: 0.6213 - val_loss: 1.0127 - val_accuracy: 0.5017 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6606 - accuracy: 0.6404\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/40: loss=0.6619, accuracy=0.6401, val_loss=0.7722, val_accuracy=0.5613\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6619 - accuracy: 0.6401 - val_loss: 0.7722 - val_accuracy: 0.5613 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6063 - accuracy: 0.6829Epoch 15/40: loss=0.6059, accuracy=0.6834, val_loss=0.6215, val_accuracy=0.6656\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6059 - accuracy: 0.6834 - val_loss: 0.6215 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5957 - accuracy: 0.6888Epoch 16/40: loss=0.5953, accuracy=0.6892, val_loss=0.5964, val_accuracy=0.7202\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5953 - accuracy: 0.6892 - val_loss: 0.5964 - val_accuracy: 0.7202 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5780 - accuracy: 0.7059Epoch 17/40: loss=0.5778, accuracy=0.7059, val_loss=0.5050, val_accuracy=0.7492\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5778 - accuracy: 0.7059 - val_loss: 0.5050 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5744 - accuracy: 0.7119Epoch 18/40: loss=0.5740, accuracy=0.7123, val_loss=0.6062, val_accuracy=0.6854\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5740 - accuracy: 0.7123 - val_loss: 0.6062 - val_accuracy: 0.6854 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5647 - accuracy: 0.7149Epoch 19/40: loss=0.5641, accuracy=0.7152, val_loss=0.5968, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5641 - accuracy: 0.7152 - val_loss: 0.5968 - val_accuracy: 0.7020 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.7268Epoch 20/40: loss=0.5576, accuracy=0.7268, val_loss=0.5413, val_accuracy=0.7359\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5576 - accuracy: 0.7268 - val_loss: 0.5413 - val_accuracy: 0.7359 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7285Epoch 21/40: loss=0.5522, accuracy=0.7285, val_loss=0.6602, val_accuracy=0.6556\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5522 - accuracy: 0.7285 - val_loss: 0.6602 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.7357\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 22/40: loss=0.5470, accuracy=0.7353, val_loss=0.5478, val_accuracy=0.7425\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5470 - accuracy: 0.7353 - val_loss: 0.5478 - val_accuracy: 0.7425 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.7434Epoch 23/40: loss=0.5383, accuracy=0.7430, val_loss=0.5127, val_accuracy=0.7591\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5383 - accuracy: 0.7430 - val_loss: 0.5127 - val_accuracy: 0.7591 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5294 - accuracy: 0.7436Epoch 24/40: loss=0.5297, accuracy=0.7436, val_loss=0.5059, val_accuracy=0.7624\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5297 - accuracy: 0.7436 - val_loss: 0.5059 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.7355Epoch 25/40: loss=0.5292, accuracy=0.7355, val_loss=0.5457, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5292 - accuracy: 0.7355 - val_loss: 0.5457 - val_accuracy: 0.7384 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.7381Epoch 26/40: loss=0.5333, accuracy=0.7382, val_loss=0.5272, val_accuracy=0.7434\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5333 - accuracy: 0.7382 - val_loss: 0.5272 - val_accuracy: 0.7434 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7417\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5344, accuracy=0.7417, val_loss=0.5138, val_accuracy=0.7566\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5344 - accuracy: 0.7417 - val_loss: 0.5138 - val_accuracy: 0.7566 - lr: 2.0000e-05\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.762417197227478\n",
      "\n",
      "Refined Training Combination 20/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1084 - accuracy: 0.5255Epoch 1/40: loss=1.1073, accuracy=0.5255, val_loss=0.7379, val_accuracy=0.5414\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 1.1073 - accuracy: 0.5255 - val_loss: 0.7379 - val_accuracy: 0.5414 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.5487Epoch 2/40: loss=0.8362, accuracy=0.5484, val_loss=0.7149, val_accuracy=0.5447\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8362 - accuracy: 0.5484 - val_loss: 0.7149 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8054 - accuracy: 0.5674Epoch 3/40: loss=0.8047, accuracy=0.5681, val_loss=0.8843, val_accuracy=0.4354\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8047 - accuracy: 0.5681 - val_loss: 0.8843 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.5886Epoch 4/40: loss=0.8002, accuracy=0.5894, val_loss=0.9032, val_accuracy=0.5877\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.8002 - accuracy: 0.5894 - val_loss: 0.9032 - val_accuracy: 0.5877 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.6131Epoch 5/40: loss=0.7282, accuracy=0.6142, val_loss=0.7797, val_accuracy=0.5637\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7282 - accuracy: 0.6142 - val_loss: 0.7797 - val_accuracy: 0.5637 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7405 - accuracy: 0.5962Epoch 6/40: loss=0.7405, accuracy=0.5962, val_loss=0.9678, val_accuracy=0.5058\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7405 - accuracy: 0.5962 - val_loss: 0.9678 - val_accuracy: 0.5058 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7396 - accuracy: 0.6051\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/40: loss=0.7408, accuracy=0.6045, val_loss=0.7273, val_accuracy=0.5389\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7408 - accuracy: 0.6045 - val_loss: 0.7273 - val_accuracy: 0.5389 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6300 - accuracy: 0.6586Epoch 8/40: loss=0.6300, accuracy=0.6585, val_loss=0.6215, val_accuracy=0.6531\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6300 - accuracy: 0.6585 - val_loss: 0.6215 - val_accuracy: 0.6531 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.6924Epoch 9/40: loss=0.5982, accuracy=0.6927, val_loss=0.8458, val_accuracy=0.5182\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5982 - accuracy: 0.6927 - val_loss: 0.8458 - val_accuracy: 0.5182 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6027 - accuracy: 0.6830Epoch 10/40: loss=0.6021, accuracy=0.6834, val_loss=0.6874, val_accuracy=0.6382\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6021 - accuracy: 0.6834 - val_loss: 0.6874 - val_accuracy: 0.6382 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.7043Epoch 11/40: loss=0.5887, accuracy=0.7043, val_loss=0.4802, val_accuracy=0.7690\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5887 - accuracy: 0.7043 - val_loss: 0.4802 - val_accuracy: 0.7690 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5735 - accuracy: 0.7086Epoch 12/40: loss=0.5726, accuracy=0.7090, val_loss=0.5802, val_accuracy=0.7541\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5726 - accuracy: 0.7090 - val_loss: 0.5802 - val_accuracy: 0.7541 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5886 - accuracy: 0.7015Epoch 13/40: loss=0.5878, accuracy=0.7020, val_loss=0.5866, val_accuracy=0.6772\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5878 - accuracy: 0.7020 - val_loss: 0.5866 - val_accuracy: 0.6772 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.7114Epoch 14/40: loss=0.5798, accuracy=0.7115, val_loss=0.5766, val_accuracy=0.6705\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5798 - accuracy: 0.7115 - val_loss: 0.5766 - val_accuracy: 0.6705 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5698 - accuracy: 0.7133Epoch 15/40: loss=0.5702, accuracy=0.7132, val_loss=0.7635, val_accuracy=0.6184\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5702 - accuracy: 0.7132 - val_loss: 0.7635 - val_accuracy: 0.6184 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5697 - accuracy: 0.7132\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 16/40: loss=0.5714, accuracy=0.7127, val_loss=0.8518, val_accuracy=0.5679\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5714 - accuracy: 0.7127 - val_loss: 0.8518 - val_accuracy: 0.5679 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7276Epoch 17/40: loss=0.5471, accuracy=0.7276, val_loss=0.5058, val_accuracy=0.7310\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5471 - accuracy: 0.7276 - val_loss: 0.5058 - val_accuracy: 0.7310 - lr: 4.0000e-05\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.7398Epoch 18/40: loss=0.5303, accuracy=0.7399, val_loss=0.5457, val_accuracy=0.6962\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5303 - accuracy: 0.7399 - val_loss: 0.5457 - val_accuracy: 0.6962 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7460Epoch 19/40: loss=0.5229, accuracy=0.7459, val_loss=0.5730, val_accuracy=0.6954\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5229 - accuracy: 0.7459 - val_loss: 0.5730 - val_accuracy: 0.6954 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7469Epoch 20/40: loss=0.5215, accuracy=0.7469, val_loss=0.4869, val_accuracy=0.7566\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5215 - accuracy: 0.7469 - val_loss: 0.4869 - val_accuracy: 0.7566 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.7554\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.5144, accuracy=0.7552, val_loss=0.5585, val_accuracy=0.6821\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5144 - accuracy: 0.7552 - val_loss: 0.5585 - val_accuracy: 0.6821 - lr: 4.0000e-05\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.7690397500991821\n",
      "\n",
      "Refined Training Combination 21/50: num_residual_blocks=7, dropout_rate=0.4, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9166 - accuracy: 0.5331Epoch 1/40: loss=0.9166, accuracy=0.5331, val_loss=0.7280, val_accuracy=0.5786\n",
      "604/604 [==============================] - 11s 15ms/step - loss: 0.9166 - accuracy: 0.5331 - val_loss: 0.7280 - val_accuracy: 0.5786 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8752 - accuracy: 0.5393Epoch 2/40: loss=0.8752, accuracy=0.5393, val_loss=0.7538, val_accuracy=0.5546\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.8752 - accuracy: 0.5393 - val_loss: 0.7538 - val_accuracy: 0.5546 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8451 - accuracy: 0.5527Epoch 3/40: loss=0.8446, accuracy=0.5528, val_loss=0.7478, val_accuracy=0.5869\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8446 - accuracy: 0.5528 - val_loss: 0.7478 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8368 - accuracy: 0.5464Epoch 4/40: loss=0.8368, accuracy=0.5464, val_loss=0.7754, val_accuracy=0.5116\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8368 - accuracy: 0.5464 - val_loss: 0.7754 - val_accuracy: 0.5116 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8032 - accuracy: 0.5532Epoch 5/40: loss=0.8032, accuracy=0.5532, val_loss=0.6921, val_accuracy=0.5985\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8032 - accuracy: 0.5532 - val_loss: 0.6921 - val_accuracy: 0.5985 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7918 - accuracy: 0.5560Epoch 6/40: loss=0.7919, accuracy=0.5559, val_loss=0.7060, val_accuracy=0.5662\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7919 - accuracy: 0.5559 - val_loss: 0.7060 - val_accuracy: 0.5662 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7716 - accuracy: 0.5588Epoch 7/40: loss=0.7716, accuracy=0.5586, val_loss=0.6951, val_accuracy=0.6026\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7716 - accuracy: 0.5586 - val_loss: 0.6951 - val_accuracy: 0.6026 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7491 - accuracy: 0.5734Epoch 8/40: loss=0.7483, accuracy=0.5737, val_loss=0.6631, val_accuracy=0.6159\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7483 - accuracy: 0.5737 - val_loss: 0.6631 - val_accuracy: 0.6159 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7190 - accuracy: 0.5993Epoch 9/40: loss=0.7191, accuracy=0.5995, val_loss=0.6907, val_accuracy=0.6002\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7191 - accuracy: 0.5995 - val_loss: 0.6907 - val_accuracy: 0.6002 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.6049Epoch 10/40: loss=0.7131, accuracy=0.6049, val_loss=0.6809, val_accuracy=0.5902\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.7131 - accuracy: 0.6049 - val_loss: 0.6809 - val_accuracy: 0.5902 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6846 - accuracy: 0.6217Epoch 11/40: loss=0.6845, accuracy=0.6219, val_loss=0.6857, val_accuracy=0.5877\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6845 - accuracy: 0.6219 - val_loss: 0.6857 - val_accuracy: 0.5877 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.6553Epoch 12/40: loss=0.6476, accuracy=0.6552, val_loss=0.6323, val_accuracy=0.6540\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6476 - accuracy: 0.6552 - val_loss: 0.6323 - val_accuracy: 0.6540 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.6615Epoch 13/40: loss=0.6377, accuracy=0.6616, val_loss=0.6960, val_accuracy=0.6250\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6377 - accuracy: 0.6616 - val_loss: 0.6960 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.6766Epoch 14/40: loss=0.6212, accuracy=0.6763, val_loss=0.5762, val_accuracy=0.6954\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6212 - accuracy: 0.6763 - val_loss: 0.5762 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.6784Epoch 15/40: loss=0.6155, accuracy=0.6784, val_loss=0.5808, val_accuracy=0.6978\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6155 - accuracy: 0.6784 - val_loss: 0.5808 - val_accuracy: 0.6978 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.6837Epoch 16/40: loss=0.6103, accuracy=0.6829, val_loss=0.5911, val_accuracy=0.6954\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6103 - accuracy: 0.6829 - val_loss: 0.5911 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.6927Epoch 17/40: loss=0.5927, accuracy=0.6927, val_loss=0.5855, val_accuracy=0.6937\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5927 - accuracy: 0.6927 - val_loss: 0.5855 - val_accuracy: 0.6937 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.7050Epoch 18/40: loss=0.5777, accuracy=0.7047, val_loss=0.6241, val_accuracy=0.6349\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5777 - accuracy: 0.7047 - val_loss: 0.6241 - val_accuracy: 0.6349 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.7063Epoch 19/40: loss=0.5789, accuracy=0.7063, val_loss=0.5333, val_accuracy=0.7334\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5789 - accuracy: 0.7063 - val_loss: 0.5333 - val_accuracy: 0.7334 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.7167Epoch 20/40: loss=0.5663, accuracy=0.7159, val_loss=0.5882, val_accuracy=0.6838\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5663 - accuracy: 0.7159 - val_loss: 0.5882 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.7132Epoch 21/40: loss=0.5701, accuracy=0.7132, val_loss=0.5919, val_accuracy=0.6978\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5701 - accuracy: 0.7132 - val_loss: 0.5919 - val_accuracy: 0.6978 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7130Epoch 22/40: loss=0.5658, accuracy=0.7136, val_loss=0.5832, val_accuracy=0.6995\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5658 - accuracy: 0.7136 - val_loss: 0.5832 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.7139Epoch 23/40: loss=0.5607, accuracy=0.7138, val_loss=0.5316, val_accuracy=0.7467\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5607 - accuracy: 0.7138 - val_loss: 0.5316 - val_accuracy: 0.7467 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5468 - accuracy: 0.7301Epoch 24/40: loss=0.5463, accuracy=0.7305, val_loss=0.4938, val_accuracy=0.7666\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5463 - accuracy: 0.7305 - val_loss: 0.4938 - val_accuracy: 0.7666 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.7309Epoch 25/40: loss=0.5370, accuracy=0.7303, val_loss=0.6018, val_accuracy=0.6680\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5370 - accuracy: 0.7303 - val_loss: 0.6018 - val_accuracy: 0.6680 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7375Epoch 26/40: loss=0.5385, accuracy=0.7376, val_loss=0.5139, val_accuracy=0.7624\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5385 - accuracy: 0.7376 - val_loss: 0.5139 - val_accuracy: 0.7624 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.7343Epoch 27/40: loss=0.5349, accuracy=0.7343, val_loss=0.5292, val_accuracy=0.7194\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5349 - accuracy: 0.7343 - val_loss: 0.5292 - val_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7421Epoch 28/40: loss=0.5230, accuracy=0.7421, val_loss=0.5205, val_accuracy=0.7492\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5230 - accuracy: 0.7421 - val_loss: 0.5205 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.7448\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 29/40: loss=0.5246, accuracy=0.7446, val_loss=0.5222, val_accuracy=0.7351\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5246 - accuracy: 0.7446 - val_loss: 0.5222 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7514Epoch 30/40: loss=0.5123, accuracy=0.7514, val_loss=0.4698, val_accuracy=0.7831\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5123 - accuracy: 0.7514 - val_loss: 0.4698 - val_accuracy: 0.7831 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5060 - accuracy: 0.7564Epoch 31/40: loss=0.5057, accuracy=0.7566, val_loss=0.4664, val_accuracy=0.7823\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5057 - accuracy: 0.7566 - val_loss: 0.4664 - val_accuracy: 0.7823 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.7525Epoch 32/40: loss=0.5054, accuracy=0.7519, val_loss=0.4901, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5054 - accuracy: 0.7519 - val_loss: 0.4901 - val_accuracy: 0.7707 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 4s - loss: 0.4876 - accuracy: 0.7591 Epoch 33/40: loss=0.4874, accuracy=0.7595, val_loss=0.4602, val_accuracy=0.7831\n",
      "604/604 [==============================] - 2702s 4s/step - loss: 0.4874 - accuracy: 0.7595 - val_loss: 0.4602 - val_accuracy: 0.7831 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.7753Epoch 34/40: loss=0.4757, accuracy=0.7748, val_loss=0.4580, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4757 - accuracy: 0.7748 - val_loss: 0.4580 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.7674Epoch 35/40: loss=0.4922, accuracy=0.7680, val_loss=0.4575, val_accuracy=0.7798\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4922 - accuracy: 0.7680 - val_loss: 0.4575 - val_accuracy: 0.7798 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.7668Epoch 36/40: loss=0.4916, accuracy=0.7668, val_loss=0.4778, val_accuracy=0.7641\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4916 - accuracy: 0.7668 - val_loss: 0.4778 - val_accuracy: 0.7641 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.7663Epoch 37/40: loss=0.4830, accuracy=0.7663, val_loss=0.4493, val_accuracy=0.7914\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4830 - accuracy: 0.7663 - val_loss: 0.4493 - val_accuracy: 0.7914 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4875 - accuracy: 0.7714Epoch 38/40: loss=0.4868, accuracy=0.7717, val_loss=0.4457, val_accuracy=0.7823\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4868 - accuracy: 0.7717 - val_loss: 0.4457 - val_accuracy: 0.7823 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7718Epoch 39/40: loss=0.4789, accuracy=0.7721, val_loss=0.4496, val_accuracy=0.7939\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4789 - accuracy: 0.7721 - val_loss: 0.4496 - val_accuracy: 0.7939 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.7736Epoch 40/40: loss=0.4724, accuracy=0.7736, val_loss=0.4303, val_accuracy=0.8088\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4724 - accuracy: 0.7736 - val_loss: 0.4303 - val_accuracy: 0.8088 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8087748289108276\n",
      "\n",
      "Refined Training Combination 22/50: num_residual_blocks=7, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0968 - accuracy: 0.5309Epoch 1/40: loss=1.0984, accuracy=0.5306, val_loss=0.9420, val_accuracy=0.5894\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0984 - accuracy: 0.5306 - val_loss: 0.9420 - val_accuracy: 0.5894 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8661 - accuracy: 0.5542Epoch 2/40: loss=0.8659, accuracy=0.5538, val_loss=0.7084, val_accuracy=0.5828\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8659 - accuracy: 0.5538 - val_loss: 0.7084 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7987 - accuracy: 0.5909Epoch 3/40: loss=0.8005, accuracy=0.5904, val_loss=0.6763, val_accuracy=0.6341\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8005 - accuracy: 0.5904 - val_loss: 0.6763 - val_accuracy: 0.6341 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7899 - accuracy: 0.5946Epoch 4/40: loss=0.7885, accuracy=0.5950, val_loss=0.7870, val_accuracy=0.6440\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7885 - accuracy: 0.5950 - val_loss: 0.7870 - val_accuracy: 0.6440 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.6308Epoch 5/40: loss=0.7311, accuracy=0.6308, val_loss=0.9094, val_accuracy=0.5894\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7311 - accuracy: 0.6308 - val_loss: 0.9094 - val_accuracy: 0.5894 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7270 - accuracy: 0.6260Epoch 6/40: loss=0.7272, accuracy=0.6254, val_loss=0.6756, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7272 - accuracy: 0.6254 - val_loss: 0.6756 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7081 - accuracy: 0.6529Epoch 7/40: loss=0.7071, accuracy=0.6538, val_loss=0.9064, val_accuracy=0.4156\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7071 - accuracy: 0.6538 - val_loss: 0.9064 - val_accuracy: 0.4156 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.6469Epoch 8/40: loss=0.7009, accuracy=0.6469, val_loss=0.7648, val_accuracy=0.6945\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7009 - accuracy: 0.6469 - val_loss: 0.7648 - val_accuracy: 0.6945 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.6527Epoch 9/40: loss=0.7257, accuracy=0.6527, val_loss=0.6019, val_accuracy=0.7053\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7257 - accuracy: 0.6527 - val_loss: 0.6019 - val_accuracy: 0.7053 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.6118Epoch 10/40: loss=0.7462, accuracy=0.6118, val_loss=1.0534, val_accuracy=0.4892\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7462 - accuracy: 0.6118 - val_loss: 1.0534 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7424 - accuracy: 0.6215Epoch 11/40: loss=0.7415, accuracy=0.6219, val_loss=1.0446, val_accuracy=0.5381\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7415 - accuracy: 0.6219 - val_loss: 1.0446 - val_accuracy: 0.5381 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7162 - accuracy: 0.6360Epoch 12/40: loss=0.7154, accuracy=0.6360, val_loss=0.9322, val_accuracy=0.6407\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7154 - accuracy: 0.6360 - val_loss: 0.9322 - val_accuracy: 0.6407 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7425 - accuracy: 0.6015Epoch 13/40: loss=0.7421, accuracy=0.6020, val_loss=0.6771, val_accuracy=0.6192\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7421 - accuracy: 0.6020 - val_loss: 0.6771 - val_accuracy: 0.6192 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7585 - accuracy: 0.6024Epoch 14/40: loss=0.7578, accuracy=0.6029, val_loss=0.5744, val_accuracy=0.7086\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7578 - accuracy: 0.6029 - val_loss: 0.5744 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7181 - accuracy: 0.6154Epoch 15/40: loss=0.7170, accuracy=0.6161, val_loss=1.1006, val_accuracy=0.4048\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7170 - accuracy: 0.6161 - val_loss: 1.1006 - val_accuracy: 0.4048 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.6227Epoch 16/40: loss=0.7333, accuracy=0.6227, val_loss=1.0022, val_accuracy=0.4089\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7333 - accuracy: 0.6227 - val_loss: 1.0022 - val_accuracy: 0.4089 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7202 - accuracy: 0.6213Epoch 17/40: loss=0.7207, accuracy=0.6211, val_loss=0.8286, val_accuracy=0.4147\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7207 - accuracy: 0.6211 - val_loss: 0.8286 - val_accuracy: 0.4147 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.6586Epoch 18/40: loss=0.6769, accuracy=0.6585, val_loss=0.5352, val_accuracy=0.7384\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6769 - accuracy: 0.6585 - val_loss: 0.5352 - val_accuracy: 0.7384 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7134 - accuracy: 0.6190Epoch 19/40: loss=0.7136, accuracy=0.6190, val_loss=0.7904, val_accuracy=0.4570\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7136 - accuracy: 0.6190 - val_loss: 0.7904 - val_accuracy: 0.4570 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7582 - accuracy: 0.5718Epoch 20/40: loss=0.7572, accuracy=0.5728, val_loss=0.8045, val_accuracy=0.4338\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7572 - accuracy: 0.5728 - val_loss: 0.8045 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7809 - accuracy: 0.5501Epoch 21/40: loss=0.7809, accuracy=0.5501, val_loss=0.8116, val_accuracy=0.5671\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7809 - accuracy: 0.5501 - val_loss: 0.8116 - val_accuracy: 0.5671 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7830 - accuracy: 0.5545Epoch 22/40: loss=0.7819, accuracy=0.5553, val_loss=0.8391, val_accuracy=0.6109\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7819 - accuracy: 0.5553 - val_loss: 0.8391 - val_accuracy: 0.6109 - lr: 0.0010\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7195 - accuracy: 0.6103\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 23/40: loss=0.7193, accuracy=0.6105, val_loss=0.7038, val_accuracy=0.6151\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7193 - accuracy: 0.6105 - val_loss: 0.7038 - val_accuracy: 0.6151 - lr: 0.0010\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6422 - accuracy: 0.6647Epoch 24/40: loss=0.6415, accuracy=0.6649, val_loss=0.5575, val_accuracy=0.7169\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6415 - accuracy: 0.6649 - val_loss: 0.5575 - val_accuracy: 0.7169 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.6900Epoch 25/40: loss=0.6069, accuracy=0.6900, val_loss=0.5200, val_accuracy=0.7401\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6069 - accuracy: 0.6900 - val_loss: 0.5200 - val_accuracy: 0.7401 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6089 - accuracy: 0.6859Epoch 26/40: loss=0.6085, accuracy=0.6863, val_loss=0.5011, val_accuracy=0.7608\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6085 - accuracy: 0.6863 - val_loss: 0.5011 - val_accuracy: 0.7608 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5972 - accuracy: 0.6909Epoch 27/40: loss=0.5972, accuracy=0.6910, val_loss=0.5470, val_accuracy=0.7401\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5972 - accuracy: 0.6910 - val_loss: 0.5470 - val_accuracy: 0.7401 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5706 - accuracy: 0.7200Epoch 28/40: loss=0.5702, accuracy=0.7200, val_loss=0.4982, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5702 - accuracy: 0.7200 - val_loss: 0.4982 - val_accuracy: 0.7624 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5689 - accuracy: 0.7151Epoch 29/40: loss=0.5692, accuracy=0.7152, val_loss=0.5296, val_accuracy=0.7674\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5692 - accuracy: 0.7152 - val_loss: 0.5296 - val_accuracy: 0.7674 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.7222Epoch 30/40: loss=0.5592, accuracy=0.7223, val_loss=0.5358, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5592 - accuracy: 0.7223 - val_loss: 0.5358 - val_accuracy: 0.7450 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5548 - accuracy: 0.7260Epoch 31/40: loss=0.5553, accuracy=0.7258, val_loss=0.4749, val_accuracy=0.7757\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5553 - accuracy: 0.7258 - val_loss: 0.4749 - val_accuracy: 0.7757 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5493 - accuracy: 0.7356Epoch 32/40: loss=0.5504, accuracy=0.7351, val_loss=0.5005, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5504 - accuracy: 0.7351 - val_loss: 0.5005 - val_accuracy: 0.7641 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7328Epoch 33/40: loss=0.5423, accuracy=0.7328, val_loss=0.4868, val_accuracy=0.7748\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5423 - accuracy: 0.7328 - val_loss: 0.4868 - val_accuracy: 0.7748 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.7363Epoch 34/40: loss=0.5401, accuracy=0.7365, val_loss=0.6511, val_accuracy=0.6573\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5401 - accuracy: 0.7365 - val_loss: 0.6511 - val_accuracy: 0.6573 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5519 - accuracy: 0.7263Epoch 35/40: loss=0.5515, accuracy=0.7268, val_loss=0.4812, val_accuracy=0.7715\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5515 - accuracy: 0.7268 - val_loss: 0.4812 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.7332\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40: loss=0.5335, accuracy=0.7332, val_loss=0.4862, val_accuracy=0.7715\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5335 - accuracy: 0.7332 - val_loss: 0.4862 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.7477Epoch 37/40: loss=0.5113, accuracy=0.7477, val_loss=0.4987, val_accuracy=0.7682\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.4987 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7368Epoch 38/40: loss=0.5298, accuracy=0.7368, val_loss=0.5178, val_accuracy=0.7550\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5298 - accuracy: 0.7368 - val_loss: 0.5178 - val_accuracy: 0.7550 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.7386Epoch 39/40: loss=0.5306, accuracy=0.7386, val_loss=0.5073, val_accuracy=0.7533\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5306 - accuracy: 0.7386 - val_loss: 0.5073 - val_accuracy: 0.7533 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.7589Epoch 40/40: loss=0.5091, accuracy=0.7589, val_loss=0.4937, val_accuracy=0.7806\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5091 - accuracy: 0.7589 - val_loss: 0.4937 - val_accuracy: 0.7806 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.7806291580200195\n",
      "\n",
      "Refined Training Combination 23/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.6, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1152 - accuracy: 0.5360Epoch 1/40: loss=1.1142, accuracy=0.5354, val_loss=0.7286, val_accuracy=0.6374\n",
      "604/604 [==============================] - 12s 18ms/step - loss: 1.1142 - accuracy: 0.5354 - val_loss: 0.7286 - val_accuracy: 0.6374 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8565 - accuracy: 0.5535Epoch 2/40: loss=0.8571, accuracy=0.5532, val_loss=0.8225, val_accuracy=0.5298\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8571 - accuracy: 0.5532 - val_loss: 0.8225 - val_accuracy: 0.5298 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7935 - accuracy: 0.5954Epoch 3/40: loss=0.7935, accuracy=0.5954, val_loss=0.7270, val_accuracy=0.5637\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7935 - accuracy: 0.5954 - val_loss: 0.7270 - val_accuracy: 0.5637 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7767 - accuracy: 0.5981Epoch 4/40: loss=0.7766, accuracy=0.5981, val_loss=0.7713, val_accuracy=0.4404\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7766 - accuracy: 0.5981 - val_loss: 0.7713 - val_accuracy: 0.4404 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7461 - accuracy: 0.6250Epoch 5/40: loss=0.7455, accuracy=0.6254, val_loss=0.6260, val_accuracy=0.6755\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7455 - accuracy: 0.6254 - val_loss: 0.6260 - val_accuracy: 0.6755 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7366 - accuracy: 0.6273Epoch 6/40: loss=0.7370, accuracy=0.6269, val_loss=0.7100, val_accuracy=0.5853\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7370 - accuracy: 0.6269 - val_loss: 0.7100 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7469 - accuracy: 0.6294Epoch 7/40: loss=0.7475, accuracy=0.6289, val_loss=0.7525, val_accuracy=0.5091\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7475 - accuracy: 0.6289 - val_loss: 0.7525 - val_accuracy: 0.5091 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7135 - accuracy: 0.6412Epoch 8/40: loss=0.7137, accuracy=0.6409, val_loss=0.8365, val_accuracy=0.4545\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7137 - accuracy: 0.6409 - val_loss: 0.8365 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.6161Epoch 9/40: loss=0.7625, accuracy=0.6161, val_loss=1.3758, val_accuracy=0.5621\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7625 - accuracy: 0.6161 - val_loss: 1.3758 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7533 - accuracy: 0.6126\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.7534, accuracy=0.6128, val_loss=1.0477, val_accuracy=0.4545\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7534 - accuracy: 0.6128 - val_loss: 1.0477 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.6778Epoch 11/40: loss=0.6395, accuracy=0.6778, val_loss=0.5103, val_accuracy=0.7533\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6395 - accuracy: 0.6778 - val_loss: 0.5103 - val_accuracy: 0.7533 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6063 - accuracy: 0.6953Epoch 12/40: loss=0.6064, accuracy=0.6954, val_loss=0.6950, val_accuracy=0.6382\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6064 - accuracy: 0.6954 - val_loss: 0.6950 - val_accuracy: 0.6382 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5936 - accuracy: 0.7082Epoch 13/40: loss=0.5935, accuracy=0.7082, val_loss=0.6085, val_accuracy=0.6929\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5935 - accuracy: 0.7082 - val_loss: 0.6085 - val_accuracy: 0.6929 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.7121Epoch 14/40: loss=0.5871, accuracy=0.7121, val_loss=0.5964, val_accuracy=0.6846\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5871 - accuracy: 0.7121 - val_loss: 0.5964 - val_accuracy: 0.6846 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.7150Epoch 15/40: loss=0.5698, accuracy=0.7152, val_loss=0.6282, val_accuracy=0.6614\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5698 - accuracy: 0.7152 - val_loss: 0.6282 - val_accuracy: 0.6614 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5632 - accuracy: 0.7214\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 16/40: loss=0.5630, accuracy=0.7214, val_loss=0.7441, val_accuracy=0.5671\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5630 - accuracy: 0.7214 - val_loss: 0.7441 - val_accuracy: 0.5671 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7268Epoch 17/40: loss=0.5499, accuracy=0.7268, val_loss=0.5792, val_accuracy=0.6887\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5499 - accuracy: 0.7268 - val_loss: 0.5792 - val_accuracy: 0.6887 - lr: 4.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5541 - accuracy: 0.7272Epoch 18/40: loss=0.5539, accuracy=0.7270, val_loss=0.5589, val_accuracy=0.7061\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5539 - accuracy: 0.7270 - val_loss: 0.5589 - val_accuracy: 0.7061 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.7384Epoch 19/40: loss=0.5335, accuracy=0.7382, val_loss=0.5470, val_accuracy=0.7318\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5335 - accuracy: 0.7382 - val_loss: 0.5470 - val_accuracy: 0.7318 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7347Epoch 20/40: loss=0.5350, accuracy=0.7347, val_loss=0.5583, val_accuracy=0.7219\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5350 - accuracy: 0.7347 - val_loss: 0.5583 - val_accuracy: 0.7219 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7461Epoch 21/40: loss=0.5269, accuracy=0.7461, val_loss=0.4822, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5269 - accuracy: 0.7461 - val_loss: 0.4822 - val_accuracy: 0.7790 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5254 - accuracy: 0.7477Epoch 22/40: loss=0.5256, accuracy=0.7477, val_loss=0.4943, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5256 - accuracy: 0.7477 - val_loss: 0.4943 - val_accuracy: 0.7831 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.7409Epoch 23/40: loss=0.5301, accuracy=0.7411, val_loss=0.5107, val_accuracy=0.7376\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5301 - accuracy: 0.7411 - val_loss: 0.5107 - val_accuracy: 0.7376 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7427Epoch 24/40: loss=0.5305, accuracy=0.7419, val_loss=0.4716, val_accuracy=0.7930\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5305 - accuracy: 0.7419 - val_loss: 0.4716 - val_accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7303Epoch 25/40: loss=0.5337, accuracy=0.7305, val_loss=0.4948, val_accuracy=0.7566\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5337 - accuracy: 0.7305 - val_loss: 0.4948 - val_accuracy: 0.7566 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.7452Epoch 26/40: loss=0.5148, accuracy=0.7450, val_loss=0.5240, val_accuracy=0.7293\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5148 - accuracy: 0.7450 - val_loss: 0.5240 - val_accuracy: 0.7293 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5101 - accuracy: 0.7399Epoch 27/40: loss=0.5101, accuracy=0.7399, val_loss=0.4641, val_accuracy=0.7930\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5101 - accuracy: 0.7399 - val_loss: 0.4641 - val_accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7529Epoch 28/40: loss=0.5042, accuracy=0.7529, val_loss=0.4819, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5042 - accuracy: 0.7529 - val_loss: 0.4819 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.7458Epoch 29/40: loss=0.5134, accuracy=0.7454, val_loss=0.4540, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5134 - accuracy: 0.7454 - val_loss: 0.4540 - val_accuracy: 0.8071 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5064 - accuracy: 0.7515Epoch 30/40: loss=0.5065, accuracy=0.7514, val_loss=0.5155, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5065 - accuracy: 0.7514 - val_loss: 0.5155 - val_accuracy: 0.7301 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7519Epoch 31/40: loss=0.5134, accuracy=0.7519, val_loss=0.4689, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5134 - accuracy: 0.7519 - val_loss: 0.4689 - val_accuracy: 0.7980 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7498Epoch 32/40: loss=0.5061, accuracy=0.7498, val_loss=0.5186, val_accuracy=0.7310\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5061 - accuracy: 0.7498 - val_loss: 0.5186 - val_accuracy: 0.7310 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.7544Epoch 33/40: loss=0.5121, accuracy=0.7546, val_loss=0.4957, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5121 - accuracy: 0.7546 - val_loss: 0.4957 - val_accuracy: 0.7873 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.7550\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 34/40: loss=0.5027, accuracy=0.7548, val_loss=0.4643, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5027 - accuracy: 0.7548 - val_loss: 0.4643 - val_accuracy: 0.7748 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4889 - accuracy: 0.7641Epoch 35/40: loss=0.4897, accuracy=0.7639, val_loss=0.4599, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.4599 - val_accuracy: 0.7897 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.7597Epoch 36/40: loss=0.4960, accuracy=0.7597, val_loss=0.4687, val_accuracy=0.7781\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4960 - accuracy: 0.7597 - val_loss: 0.4687 - val_accuracy: 0.7781 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7666Epoch 37/40: loss=0.4899, accuracy=0.7666, val_loss=0.4630, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4899 - accuracy: 0.7666 - val_loss: 0.4630 - val_accuracy: 0.7839 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.7664Epoch 38/40: loss=0.4907, accuracy=0.7659, val_loss=0.4512, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4907 - accuracy: 0.7659 - val_loss: 0.4512 - val_accuracy: 0.7914 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4927 - accuracy: 0.7612Epoch 39/40: loss=0.4926, accuracy=0.7612, val_loss=0.4622, val_accuracy=0.7889\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4926 - accuracy: 0.7612 - val_loss: 0.4622 - val_accuracy: 0.7889 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.7610Epoch 40/40: loss=0.4971, accuracy=0.7606, val_loss=0.4633, val_accuracy=0.7848\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4971 - accuracy: 0.7606 - val_loss: 0.4633 - val_accuracy: 0.7848 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.8071191906929016\n",
      "\n",
      "Refined Training Combination 24/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0764 - accuracy: 0.5242Epoch 1/40: loss=1.0764, accuracy=0.5242, val_loss=1.3089, val_accuracy=0.4553\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 1.0764 - accuracy: 0.5242 - val_loss: 1.3089 - val_accuracy: 0.4553 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8533 - accuracy: 0.5391Epoch 2/40: loss=0.8531, accuracy=0.5387, val_loss=0.7381, val_accuracy=0.5935\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8531 - accuracy: 0.5387 - val_loss: 0.7381 - val_accuracy: 0.5935 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.5544Epoch 3/40: loss=0.7820, accuracy=0.5544, val_loss=0.7076, val_accuracy=0.5795\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7820 - accuracy: 0.5544 - val_loss: 0.7076 - val_accuracy: 0.5795 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.5857Epoch 4/40: loss=0.7296, accuracy=0.5859, val_loss=0.7067, val_accuracy=0.5704\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7296 - accuracy: 0.5859 - val_loss: 0.7067 - val_accuracy: 0.5704 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.6082Epoch 5/40: loss=0.7158, accuracy=0.6080, val_loss=0.6845, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7158 - accuracy: 0.6080 - val_loss: 0.6845 - val_accuracy: 0.5969 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7137 - accuracy: 0.6134Epoch 6/40: loss=0.7153, accuracy=0.6130, val_loss=0.7427, val_accuracy=0.6184\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7153 - accuracy: 0.6130 - val_loss: 0.7427 - val_accuracy: 0.6184 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.6242Epoch 7/40: loss=0.6857, accuracy=0.6242, val_loss=0.6406, val_accuracy=0.6308\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6857 - accuracy: 0.6242 - val_loss: 0.6406 - val_accuracy: 0.6308 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.6649Epoch 8/40: loss=0.6459, accuracy=0.6649, val_loss=0.9693, val_accuracy=0.4089\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6459 - accuracy: 0.6649 - val_loss: 0.9693 - val_accuracy: 0.4089 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6409 - accuracy: 0.6718Epoch 9/40: loss=0.6411, accuracy=0.6716, val_loss=0.8715, val_accuracy=0.4801\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6411 - accuracy: 0.6716 - val_loss: 0.8715 - val_accuracy: 0.4801 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6429 - accuracy: 0.6680Epoch 10/40: loss=0.6430, accuracy=0.6678, val_loss=0.6961, val_accuracy=0.6887\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6430 - accuracy: 0.6678 - val_loss: 0.6961 - val_accuracy: 0.6887 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6666Epoch 11/40: loss=0.6416, accuracy=0.6666, val_loss=1.6975, val_accuracy=0.4810\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6416 - accuracy: 0.6666 - val_loss: 1.6975 - val_accuracy: 0.4810 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.6670\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/40: loss=0.6513, accuracy=0.6674, val_loss=1.2663, val_accuracy=0.5000\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6513 - accuracy: 0.6674 - val_loss: 1.2663 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5934 - accuracy: 0.6928Epoch 13/40: loss=0.5932, accuracy=0.6929, val_loss=0.5099, val_accuracy=0.7616\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5932 - accuracy: 0.6929 - val_loss: 0.5099 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7166Epoch 14/40: loss=0.5588, accuracy=0.7163, val_loss=0.4711, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5588 - accuracy: 0.7163 - val_loss: 0.4711 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.7345Epoch 15/40: loss=0.5421, accuracy=0.7345, val_loss=0.4549, val_accuracy=0.7765\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5421 - accuracy: 0.7345 - val_loss: 0.4549 - val_accuracy: 0.7765 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.7316Epoch 16/40: loss=0.5418, accuracy=0.7316, val_loss=0.5356, val_accuracy=0.7318\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5418 - accuracy: 0.7316 - val_loss: 0.5356 - val_accuracy: 0.7318 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7272Epoch 17/40: loss=0.5455, accuracy=0.7272, val_loss=0.6032, val_accuracy=0.6689\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5455 - accuracy: 0.7272 - val_loss: 0.6032 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.7330Epoch 18/40: loss=0.5415, accuracy=0.7332, val_loss=0.5127, val_accuracy=0.7417\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5415 - accuracy: 0.7332 - val_loss: 0.5127 - val_accuracy: 0.7417 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.5154 - accuracy: 0.7508Epoch 19/40: loss=0.5159, accuracy=0.7510, val_loss=0.4523, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5159 - accuracy: 0.7510 - val_loss: 0.4523 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.7421Epoch 20/40: loss=0.5242, accuracy=0.7419, val_loss=0.6299, val_accuracy=0.6548\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5242 - accuracy: 0.7419 - val_loss: 0.6299 - val_accuracy: 0.6548 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.7403Epoch 21/40: loss=0.5235, accuracy=0.7401, val_loss=0.4293, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5235 - accuracy: 0.7401 - val_loss: 0.4293 - val_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.7504Epoch 22/40: loss=0.5136, accuracy=0.7502, val_loss=0.4716, val_accuracy=0.7616\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5136 - accuracy: 0.7502 - val_loss: 0.4716 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.7479Epoch 23/40: loss=0.5100, accuracy=0.7479, val_loss=0.4594, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5100 - accuracy: 0.7479 - val_loss: 0.4594 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.7512Epoch 24/40: loss=0.5120, accuracy=0.7517, val_loss=0.4475, val_accuracy=0.8055\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5120 - accuracy: 0.7517 - val_loss: 0.4475 - val_accuracy: 0.8055 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.7535Epoch 25/40: loss=0.5176, accuracy=0.7525, val_loss=0.4894, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5176 - accuracy: 0.7525 - val_loss: 0.4894 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.7583\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 26/40: loss=0.5026, accuracy=0.7585, val_loss=0.4326, val_accuracy=0.7972\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5026 - accuracy: 0.7585 - val_loss: 0.4326 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.7635Epoch 27/40: loss=0.4858, accuracy=0.7635, val_loss=0.4243, val_accuracy=0.8046\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4858 - accuracy: 0.7635 - val_loss: 0.4243 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.7706Epoch 28/40: loss=0.4838, accuracy=0.7713, val_loss=0.4339, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4838 - accuracy: 0.7713 - val_loss: 0.4339 - val_accuracy: 0.7790 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.7633Epoch 29/40: loss=0.4896, accuracy=0.7628, val_loss=0.4317, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4896 - accuracy: 0.7628 - val_loss: 0.4317 - val_accuracy: 0.8071 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.7686Epoch 30/40: loss=0.4792, accuracy=0.7686, val_loss=0.4362, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4792 - accuracy: 0.7686 - val_loss: 0.4362 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.7789Epoch 31/40: loss=0.4657, accuracy=0.7784, val_loss=0.4323, val_accuracy=0.8204\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4657 - accuracy: 0.7784 - val_loss: 0.4323 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7726Epoch 32/40: loss=0.4681, accuracy=0.7726, val_loss=0.4216, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4216 - val_accuracy: 0.8121 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4802 - accuracy: 0.7687Epoch 33/40: loss=0.4799, accuracy=0.7690, val_loss=0.4194, val_accuracy=0.8046\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4799 - accuracy: 0.7690 - val_loss: 0.4194 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.7752Epoch 34/40: loss=0.4719, accuracy=0.7752, val_loss=0.4310, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4719 - accuracy: 0.7752 - val_loss: 0.4310 - val_accuracy: 0.8079 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.7738Epoch 35/40: loss=0.4733, accuracy=0.7738, val_loss=0.4154, val_accuracy=0.8038\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4733 - accuracy: 0.7738 - val_loss: 0.4154 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.7699Epoch 36/40: loss=0.4734, accuracy=0.7695, val_loss=0.4270, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4734 - accuracy: 0.7695 - val_loss: 0.4270 - val_accuracy: 0.8071 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.7758Epoch 37/40: loss=0.4687, accuracy=0.7757, val_loss=0.4219, val_accuracy=0.8104\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4687 - accuracy: 0.7757 - val_loss: 0.4219 - val_accuracy: 0.8104 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.7639Epoch 38/40: loss=0.4717, accuracy=0.7641, val_loss=0.4105, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4717 - accuracy: 0.7641 - val_loss: 0.4105 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.7807Epoch 39/40: loss=0.4673, accuracy=0.7812, val_loss=0.4287, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4287 - val_accuracy: 0.8030 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7732Epoch 40/40: loss=0.4686, accuracy=0.7732, val_loss=0.4276, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4686 - accuracy: 0.7732 - val_loss: 0.4276 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.820364236831665\n",
      "\n",
      "Refined Training Combination 25/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.6, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1225 - accuracy: 0.5322Epoch 1/40: loss=1.1206, accuracy=0.5325, val_loss=0.7790, val_accuracy=0.5199\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.1206 - accuracy: 0.5325 - val_loss: 0.7790 - val_accuracy: 0.5199 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8470 - accuracy: 0.5575Epoch 2/40: loss=0.8470, accuracy=0.5575, val_loss=1.1921, val_accuracy=0.4354\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8470 - accuracy: 0.5575 - val_loss: 1.1921 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8021 - accuracy: 0.5846Epoch 3/40: loss=0.8021, accuracy=0.5846, val_loss=0.8011, val_accuracy=0.5265\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8021 - accuracy: 0.5846 - val_loss: 0.8011 - val_accuracy: 0.5265 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7719 - accuracy: 0.6044Epoch 4/40: loss=0.7728, accuracy=0.6045, val_loss=0.7293, val_accuracy=0.5844\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7728 - accuracy: 0.6045 - val_loss: 0.7293 - val_accuracy: 0.5844 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.6093Epoch 5/40: loss=0.7512, accuracy=0.6093, val_loss=1.1369, val_accuracy=0.6068\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7512 - accuracy: 0.6093 - val_loss: 1.1369 - val_accuracy: 0.6068 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7562 - accuracy: 0.6068Epoch 6/40: loss=0.7562, accuracy=0.6068, val_loss=0.8643, val_accuracy=0.5811\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7562 - accuracy: 0.6068 - val_loss: 0.8643 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7138 - accuracy: 0.6250Epoch 7/40: loss=0.7142, accuracy=0.6248, val_loss=0.6576, val_accuracy=0.6424\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7142 - accuracy: 0.6248 - val_loss: 0.6576 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.6060Epoch 8/40: loss=0.7245, accuracy=0.6060, val_loss=0.7700, val_accuracy=0.5977\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7245 - accuracy: 0.6060 - val_loss: 0.7700 - val_accuracy: 0.5977 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7931 - accuracy: 0.5638Epoch 9/40: loss=0.7930, accuracy=0.5637, val_loss=0.7438, val_accuracy=0.4901\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7930 - accuracy: 0.5637 - val_loss: 0.7438 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7988 - accuracy: 0.5449Epoch 10/40: loss=0.7986, accuracy=0.5453, val_loss=0.6764, val_accuracy=0.5828\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7986 - accuracy: 0.5453 - val_loss: 0.6764 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.5019Epoch 11/40: loss=0.8265, accuracy=0.5023, val_loss=0.7250, val_accuracy=0.5381\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8265 - accuracy: 0.5023 - val_loss: 0.7250 - val_accuracy: 0.5381 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7825 - accuracy: 0.5151\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.7825, accuracy=0.5151, val_loss=0.7438, val_accuracy=0.5298\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7825 - accuracy: 0.5151 - val_loss: 0.7438 - val_accuracy: 0.5298 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.5230Epoch 13/40: loss=0.7246, accuracy=0.5230, val_loss=0.6748, val_accuracy=0.5538\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7246 - accuracy: 0.5230 - val_loss: 0.6748 - val_accuracy: 0.5538 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7073 - accuracy: 0.5647Epoch 14/40: loss=0.7072, accuracy=0.5646, val_loss=0.7021, val_accuracy=0.4843\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7072 - accuracy: 0.5646 - val_loss: 0.7021 - val_accuracy: 0.4843 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.5538Epoch 15/40: loss=0.7082, accuracy=0.5538, val_loss=0.6382, val_accuracy=0.6407\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7082 - accuracy: 0.5538 - val_loss: 0.6382 - val_accuracy: 0.6407 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.6033Epoch 16/40: loss=0.6829, accuracy=0.6033, val_loss=0.6654, val_accuracy=0.6217\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6829 - accuracy: 0.6033 - val_loss: 0.6654 - val_accuracy: 0.6217 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6739 - accuracy: 0.6138Epoch 17/40: loss=0.6744, accuracy=0.6134, val_loss=0.6554, val_accuracy=0.6118\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6744 - accuracy: 0.6134 - val_loss: 0.6554 - val_accuracy: 0.6118 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.6448Epoch 18/40: loss=0.6509, accuracy=0.6451, val_loss=0.6198, val_accuracy=0.6614\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6509 - accuracy: 0.6451 - val_loss: 0.6198 - val_accuracy: 0.6614 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.6751Epoch 19/40: loss=0.6172, accuracy=0.6751, val_loss=0.7033, val_accuracy=0.6267\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6172 - accuracy: 0.6751 - val_loss: 0.7033 - val_accuracy: 0.6267 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6800Epoch 20/40: loss=0.6139, accuracy=0.6800, val_loss=0.5309, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6139 - accuracy: 0.6800 - val_loss: 0.5309 - val_accuracy: 0.7450 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6143 - accuracy: 0.6752Epoch 21/40: loss=0.6150, accuracy=0.6745, val_loss=0.6232, val_accuracy=0.6308\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6150 - accuracy: 0.6745 - val_loss: 0.6232 - val_accuracy: 0.6308 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5899 - accuracy: 0.7036Epoch 22/40: loss=0.5899, accuracy=0.7036, val_loss=0.5139, val_accuracy=0.7591\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5899 - accuracy: 0.7036 - val_loss: 0.5139 - val_accuracy: 0.7591 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5888 - accuracy: 0.6989Epoch 23/40: loss=0.5898, accuracy=0.6981, val_loss=0.6176, val_accuracy=0.6647\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5898 - accuracy: 0.6981 - val_loss: 0.6176 - val_accuracy: 0.6647 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5867 - accuracy: 0.6928Epoch 24/40: loss=0.5866, accuracy=0.6927, val_loss=0.7462, val_accuracy=0.5546\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5866 - accuracy: 0.6927 - val_loss: 0.7462 - val_accuracy: 0.5546 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.7094Epoch 25/40: loss=0.5702, accuracy=0.7094, val_loss=0.6211, val_accuracy=0.6432\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5702 - accuracy: 0.7094 - val_loss: 0.6211 - val_accuracy: 0.6432 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.7251Epoch 26/40: loss=0.5551, accuracy=0.7245, val_loss=0.5178, val_accuracy=0.7252\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5551 - accuracy: 0.7245 - val_loss: 0.5178 - val_accuracy: 0.7252 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.7251\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 27/40: loss=0.5513, accuracy=0.7252, val_loss=0.6340, val_accuracy=0.6838\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5513 - accuracy: 0.7252 - val_loss: 0.6340 - val_accuracy: 0.6838 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7359Epoch 28/40: loss=0.5341, accuracy=0.7361, val_loss=0.4746, val_accuracy=0.7715\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5341 - accuracy: 0.7361 - val_loss: 0.4746 - val_accuracy: 0.7715 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.7461Epoch 29/40: loss=0.5237, accuracy=0.7461, val_loss=0.5074, val_accuracy=0.7425\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5237 - accuracy: 0.7461 - val_loss: 0.5074 - val_accuracy: 0.7425 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.7402Epoch 30/40: loss=0.5272, accuracy=0.7403, val_loss=0.4722, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5272 - accuracy: 0.7403 - val_loss: 0.4722 - val_accuracy: 0.7839 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5258 - accuracy: 0.7423Epoch 31/40: loss=0.5254, accuracy=0.7421, val_loss=0.4620, val_accuracy=0.7930\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5254 - accuracy: 0.7421 - val_loss: 0.4620 - val_accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7494Epoch 32/40: loss=0.5258, accuracy=0.7494, val_loss=0.4971, val_accuracy=0.7666\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5258 - accuracy: 0.7494 - val_loss: 0.4971 - val_accuracy: 0.7666 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.7427Epoch 33/40: loss=0.5267, accuracy=0.7428, val_loss=0.4801, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5267 - accuracy: 0.7428 - val_loss: 0.4801 - val_accuracy: 0.7781 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.7465Epoch 34/40: loss=0.5158, accuracy=0.7465, val_loss=0.4947, val_accuracy=0.7558\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5158 - accuracy: 0.7465 - val_loss: 0.4947 - val_accuracy: 0.7558 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.7446Epoch 35/40: loss=0.5192, accuracy=0.7448, val_loss=0.4874, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5192 - accuracy: 0.7448 - val_loss: 0.4874 - val_accuracy: 0.7732 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7434\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 36/40: loss=0.5123, accuracy=0.7434, val_loss=0.4957, val_accuracy=0.7566\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5123 - accuracy: 0.7434 - val_loss: 0.4957 - val_accuracy: 0.7566 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5198 - accuracy: 0.7405Epoch 37/40: loss=0.5200, accuracy=0.7405, val_loss=0.4915, val_accuracy=0.7666\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5200 - accuracy: 0.7405 - val_loss: 0.4915 - val_accuracy: 0.7666 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.7481Epoch 38/40: loss=0.5118, accuracy=0.7481, val_loss=0.4780, val_accuracy=0.7930\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5118 - accuracy: 0.7481 - val_loss: 0.4780 - val_accuracy: 0.7930 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.7475Epoch 39/40: loss=0.5115, accuracy=0.7467, val_loss=0.4760, val_accuracy=0.7947\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5115 - accuracy: 0.7467 - val_loss: 0.4760 - val_accuracy: 0.7947 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.7572Epoch 40/40: loss=0.4981, accuracy=0.7572, val_loss=0.4605, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4981 - accuracy: 0.7572 - val_loss: 0.4605 - val_accuracy: 0.7955 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.7955297827720642\n",
      "\n",
      "Refined Training Combination 26/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.6, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9562 - accuracy: 0.5147Epoch 1/40: loss=0.9562, accuracy=0.5147, val_loss=0.7522, val_accuracy=0.5406\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9562 - accuracy: 0.5147 - val_loss: 0.7522 - val_accuracy: 0.5406 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9107 - accuracy: 0.5189Epoch 2/40: loss=0.9099, accuracy=0.5188, val_loss=0.6866, val_accuracy=0.5969\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.9099 - accuracy: 0.5188 - val_loss: 0.6866 - val_accuracy: 0.5969 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.5296Epoch 3/40: loss=0.8732, accuracy=0.5296, val_loss=0.7170, val_accuracy=0.5720\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8732 - accuracy: 0.5296 - val_loss: 0.7170 - val_accuracy: 0.5720 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8596 - accuracy: 0.5267Epoch 4/40: loss=0.8597, accuracy=0.5267, val_loss=0.6619, val_accuracy=0.6002\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8597 - accuracy: 0.5267 - val_loss: 0.6619 - val_accuracy: 0.6002 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8260 - accuracy: 0.5435Epoch 5/40: loss=0.8263, accuracy=0.5435, val_loss=0.7321, val_accuracy=0.5588\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.8263 - accuracy: 0.5435 - val_loss: 0.7321 - val_accuracy: 0.5588 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.5604Epoch 6/40: loss=0.7933, accuracy=0.5604, val_loss=0.7882, val_accuracy=0.5497\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7933 - accuracy: 0.5604 - val_loss: 0.7882 - val_accuracy: 0.5497 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7773 - accuracy: 0.5618Epoch 7/40: loss=0.7776, accuracy=0.5619, val_loss=0.7903, val_accuracy=0.5157\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7776 - accuracy: 0.5619 - val_loss: 0.7903 - val_accuracy: 0.5157 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7558 - accuracy: 0.5658Epoch 8/40: loss=0.7559, accuracy=0.5660, val_loss=0.7158, val_accuracy=0.5753\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7559 - accuracy: 0.5660 - val_loss: 0.7158 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.7356 - accuracy: 0.5829Epoch 9/40: loss=0.7359, accuracy=0.5830, val_loss=0.6166, val_accuracy=0.6722\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7359 - accuracy: 0.5830 - val_loss: 0.6166 - val_accuracy: 0.6722 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6994 - accuracy: 0.6098Epoch 10/40: loss=0.6994, accuracy=0.6101, val_loss=0.6823, val_accuracy=0.6291\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6994 - accuracy: 0.6101 - val_loss: 0.6823 - val_accuracy: 0.6291 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.6327Epoch 11/40: loss=0.6776, accuracy=0.6327, val_loss=0.6350, val_accuracy=0.6738\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6776 - accuracy: 0.6327 - val_loss: 0.6350 - val_accuracy: 0.6738 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.6358Epoch 12/40: loss=0.6536, accuracy=0.6353, val_loss=0.5974, val_accuracy=0.6821\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6536 - accuracy: 0.6353 - val_loss: 0.5974 - val_accuracy: 0.6821 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6353 - accuracy: 0.6630Epoch 13/40: loss=0.6353, accuracy=0.6629, val_loss=0.6282, val_accuracy=0.6449\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6353 - accuracy: 0.6629 - val_loss: 0.6282 - val_accuracy: 0.6449 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6082 - accuracy: 0.6850Epoch 14/40: loss=0.6083, accuracy=0.6848, val_loss=0.5617, val_accuracy=0.7045\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6083 - accuracy: 0.6848 - val_loss: 0.5617 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5927 - accuracy: 0.7006Epoch 15/40: loss=0.5924, accuracy=0.7005, val_loss=0.5824, val_accuracy=0.6871\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5924 - accuracy: 0.7005 - val_loss: 0.5824 - val_accuracy: 0.6871 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.6925Epoch 16/40: loss=0.5977, accuracy=0.6923, val_loss=0.5638, val_accuracy=0.6978\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5977 - accuracy: 0.6923 - val_loss: 0.5638 - val_accuracy: 0.6978 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.7038Epoch 17/40: loss=0.5819, accuracy=0.7036, val_loss=0.5048, val_accuracy=0.7459\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5819 - accuracy: 0.7036 - val_loss: 0.5048 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.7018Epoch 18/40: loss=0.5770, accuracy=0.7018, val_loss=0.5288, val_accuracy=0.7368\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5770 - accuracy: 0.7018 - val_loss: 0.5288 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7117Epoch 19/40: loss=0.5632, accuracy=0.7117, val_loss=0.4803, val_accuracy=0.7583\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5632 - accuracy: 0.7117 - val_loss: 0.4803 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5566 - accuracy: 0.7228Epoch 20/40: loss=0.5561, accuracy=0.7231, val_loss=0.6115, val_accuracy=0.6921\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5561 - accuracy: 0.7231 - val_loss: 0.6115 - val_accuracy: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.7249Epoch 21/40: loss=0.5509, accuracy=0.7250, val_loss=0.5275, val_accuracy=0.7483\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5509 - accuracy: 0.7250 - val_loss: 0.5275 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7274Epoch 22/40: loss=0.5374, accuracy=0.7274, val_loss=0.5868, val_accuracy=0.7119\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5374 - accuracy: 0.7274 - val_loss: 0.5868 - val_accuracy: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.7310Epoch 23/40: loss=0.5334, accuracy=0.7310, val_loss=0.4801, val_accuracy=0.7616\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5334 - accuracy: 0.7310 - val_loss: 0.4801 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.7330Epoch 24/40: loss=0.5363, accuracy=0.7330, val_loss=0.4358, val_accuracy=0.7972\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5363 - accuracy: 0.7330 - val_loss: 0.4358 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.7382Epoch 25/40: loss=0.5300, accuracy=0.7386, val_loss=0.5105, val_accuracy=0.7459\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5300 - accuracy: 0.7386 - val_loss: 0.5105 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5201 - accuracy: 0.7444Epoch 26/40: loss=0.5197, accuracy=0.7450, val_loss=0.4378, val_accuracy=0.7939\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5197 - accuracy: 0.7450 - val_loss: 0.4378 - val_accuracy: 0.7939 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7401Epoch 27/40: loss=0.5230, accuracy=0.7401, val_loss=0.5817, val_accuracy=0.7020\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5230 - accuracy: 0.7401 - val_loss: 0.5817 - val_accuracy: 0.7020 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.7496Epoch 28/40: loss=0.5133, accuracy=0.7496, val_loss=0.4910, val_accuracy=0.7632\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5133 - accuracy: 0.7496 - val_loss: 0.4910 - val_accuracy: 0.7632 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5117 - accuracy: 0.7446\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 29/40: loss=0.5121, accuracy=0.7446, val_loss=0.4444, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.5121 - accuracy: 0.7446 - val_loss: 0.4444 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.7653Epoch 30/40: loss=0.4921, accuracy=0.7655, val_loss=0.4349, val_accuracy=0.7947\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4921 - accuracy: 0.7655 - val_loss: 0.4349 - val_accuracy: 0.7947 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7641Epoch 31/40: loss=0.4796, accuracy=0.7641, val_loss=0.4228, val_accuracy=0.7964\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4796 - accuracy: 0.7641 - val_loss: 0.4228 - val_accuracy: 0.7964 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.7793Epoch 32/40: loss=0.4642, accuracy=0.7792, val_loss=0.4374, val_accuracy=0.8038\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4642 - accuracy: 0.7792 - val_loss: 0.4374 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.7726Epoch 33/40: loss=0.4738, accuracy=0.7726, val_loss=0.4079, val_accuracy=0.8137\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.4079 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.7672Epoch 34/40: loss=0.4684, accuracy=0.7672, val_loss=0.4073, val_accuracy=0.8187\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4684 - accuracy: 0.7672 - val_loss: 0.4073 - val_accuracy: 0.8187 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.7785Epoch 35/40: loss=0.4622, accuracy=0.7788, val_loss=0.4003, val_accuracy=0.8228\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4622 - accuracy: 0.7788 - val_loss: 0.4003 - val_accuracy: 0.8228 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.7836Epoch 36/40: loss=0.4595, accuracy=0.7833, val_loss=0.4189, val_accuracy=0.8055\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4595 - accuracy: 0.7833 - val_loss: 0.4189 - val_accuracy: 0.8055 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4575 - accuracy: 0.7820Epoch 37/40: loss=0.4581, accuracy=0.7812, val_loss=0.4019, val_accuracy=0.8212\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4019 - val_accuracy: 0.8212 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.7784Epoch 38/40: loss=0.4671, accuracy=0.7784, val_loss=0.4400, val_accuracy=0.7881\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4671 - accuracy: 0.7784 - val_loss: 0.4400 - val_accuracy: 0.7881 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.7858Epoch 39/40: loss=0.4461, accuracy=0.7858, val_loss=0.4080, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4461 - accuracy: 0.7858 - val_loss: 0.4080 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4380 - accuracy: 0.8008\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 40/40: loss=0.4378, accuracy=0.8009, val_loss=0.4064, val_accuracy=0.8113\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4378 - accuracy: 0.8009 - val_loss: 0.4064 - val_accuracy: 0.8113 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8228476643562317\n",
      "\n",
      "Refined Training Combination 27/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.6, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.4983Epoch 1/40: loss=1.0908, accuracy=0.4983, val_loss=0.8002, val_accuracy=0.5414\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 1.0908 - accuracy: 0.4983 - val_loss: 0.8002 - val_accuracy: 0.5414 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8503 - accuracy: 0.5265Epoch 2/40: loss=0.8503, accuracy=0.5265, val_loss=0.8088, val_accuracy=0.4843\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8503 - accuracy: 0.5265 - val_loss: 0.8088 - val_accuracy: 0.4843 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7901 - accuracy: 0.5277Epoch 3/40: loss=0.7901, accuracy=0.5277, val_loss=1.0247, val_accuracy=0.4652\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7901 - accuracy: 0.5277 - val_loss: 1.0247 - val_accuracy: 0.4652 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7561 - accuracy: 0.5417Epoch 4/40: loss=0.7564, accuracy=0.5416, val_loss=0.7807, val_accuracy=0.4487\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7564 - accuracy: 0.5416 - val_loss: 0.7807 - val_accuracy: 0.4487 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7828 - accuracy: 0.5073Epoch 5/40: loss=0.7831, accuracy=0.5072, val_loss=0.9202, val_accuracy=0.4214\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7831 - accuracy: 0.5072 - val_loss: 0.9202 - val_accuracy: 0.4214 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7325 - accuracy: 0.5733Epoch 6/40: loss=0.7325, accuracy=0.5733, val_loss=0.6525, val_accuracy=0.6159\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7325 - accuracy: 0.5733 - val_loss: 0.6525 - val_accuracy: 0.6159 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7018 - accuracy: 0.6036Epoch 7/40: loss=0.7014, accuracy=0.6039, val_loss=0.9109, val_accuracy=0.5257\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7014 - accuracy: 0.6039 - val_loss: 0.9109 - val_accuracy: 0.5257 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6867 - accuracy: 0.6292Epoch 8/40: loss=0.6860, accuracy=0.6296, val_loss=0.6455, val_accuracy=0.6209\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6860 - accuracy: 0.6296 - val_loss: 0.6455 - val_accuracy: 0.6209 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.6298Epoch 9/40: loss=0.6924, accuracy=0.6298, val_loss=0.6872, val_accuracy=0.5728\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6924 - accuracy: 0.6298 - val_loss: 0.6872 - val_accuracy: 0.5728 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7031 - accuracy: 0.6206Epoch 10/40: loss=0.7031, accuracy=0.6209, val_loss=0.6327, val_accuracy=0.6366\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7031 - accuracy: 0.6209 - val_loss: 0.6327 - val_accuracy: 0.6366 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.6292Epoch 11/40: loss=0.6738, accuracy=0.6293, val_loss=0.7018, val_accuracy=0.6258\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6738 - accuracy: 0.6293 - val_loss: 0.7018 - val_accuracy: 0.6258 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.6441Epoch 12/40: loss=0.6737, accuracy=0.6438, val_loss=0.8201, val_accuracy=0.5298\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6737 - accuracy: 0.6438 - val_loss: 0.8201 - val_accuracy: 0.5298 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6900 - accuracy: 0.6300Epoch 13/40: loss=0.6897, accuracy=0.6298, val_loss=0.7155, val_accuracy=0.6432\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6897 - accuracy: 0.6298 - val_loss: 0.7155 - val_accuracy: 0.6432 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.6099Epoch 14/40: loss=0.6999, accuracy=0.6099, val_loss=0.6373, val_accuracy=0.6556\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6999 - accuracy: 0.6099 - val_loss: 0.6373 - val_accuracy: 0.6556 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6874 - accuracy: 0.6343Epoch 15/40: loss=0.6874, accuracy=0.6343, val_loss=0.6108, val_accuracy=0.6896\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6874 - accuracy: 0.6343 - val_loss: 0.6108 - val_accuracy: 0.6896 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 1s - loss: 0.6940 - accuracy: 0.6157Epoch 16/40: loss=0.6937, accuracy=0.6161, val_loss=0.5746, val_accuracy=0.7177\n",
      "604/604 [==============================] - 708s 1s/step - loss: 0.6937 - accuracy: 0.6161 - val_loss: 0.5746 - val_accuracy: 0.7177 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.6379Epoch 17/40: loss=0.6714, accuracy=0.6380, val_loss=0.5911, val_accuracy=0.7003\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6714 - accuracy: 0.6380 - val_loss: 0.5911 - val_accuracy: 0.7003 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.6250Epoch 18/40: loss=0.6901, accuracy=0.6250, val_loss=0.6476, val_accuracy=0.6275\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6901 - accuracy: 0.6250 - val_loss: 0.6476 - val_accuracy: 0.6275 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.6107Epoch 19/40: loss=0.6974, accuracy=0.6107, val_loss=0.7270, val_accuracy=0.5298\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6974 - accuracy: 0.6107 - val_loss: 0.7270 - val_accuracy: 0.5298 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.6240Epoch 20/40: loss=0.6824, accuracy=0.6238, val_loss=0.8066, val_accuracy=0.5604\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6824 - accuracy: 0.6238 - val_loss: 0.8066 - val_accuracy: 0.5604 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.6296\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 21/40: loss=0.6822, accuracy=0.6298, val_loss=0.9419, val_accuracy=0.6060\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6822 - accuracy: 0.6298 - val_loss: 0.9419 - val_accuracy: 0.6060 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.6825Epoch 22/40: loss=0.6122, accuracy=0.6825, val_loss=0.6474, val_accuracy=0.6060\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6122 - accuracy: 0.6825 - val_loss: 0.6474 - val_accuracy: 0.6060 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.6927Epoch 23/40: loss=0.6011, accuracy=0.6931, val_loss=0.5930, val_accuracy=0.6829\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6011 - accuracy: 0.6931 - val_loss: 0.5930 - val_accuracy: 0.6829 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5806 - accuracy: 0.7000Epoch 24/40: loss=0.5802, accuracy=0.7003, val_loss=0.5931, val_accuracy=0.6954\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5802 - accuracy: 0.7003 - val_loss: 0.5931 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7137Epoch 25/40: loss=0.5674, accuracy=0.7142, val_loss=0.5588, val_accuracy=0.7285\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5674 - accuracy: 0.7142 - val_loss: 0.5588 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.7237Epoch 26/40: loss=0.5611, accuracy=0.7237, val_loss=0.6210, val_accuracy=0.6664\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5611 - accuracy: 0.7237 - val_loss: 0.6210 - val_accuracy: 0.6664 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5643 - accuracy: 0.7182Epoch 27/40: loss=0.5642, accuracy=0.7179, val_loss=0.6804, val_accuracy=0.6076\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5642 - accuracy: 0.7179 - val_loss: 0.6804 - val_accuracy: 0.6076 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7176Epoch 28/40: loss=0.5581, accuracy=0.7179, val_loss=0.5832, val_accuracy=0.6912\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5581 - accuracy: 0.7179 - val_loss: 0.5832 - val_accuracy: 0.6912 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5567 - accuracy: 0.7146Epoch 29/40: loss=0.5569, accuracy=0.7146, val_loss=0.6226, val_accuracy=0.6772\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5569 - accuracy: 0.7146 - val_loss: 0.6226 - val_accuracy: 0.6772 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5471 - accuracy: 0.7276\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 30/40: loss=0.5468, accuracy=0.7279, val_loss=0.5785, val_accuracy=0.6929\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5468 - accuracy: 0.7279 - val_loss: 0.5785 - val_accuracy: 0.6929 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.7384Epoch 31/40: loss=0.5373, accuracy=0.7384, val_loss=0.5558, val_accuracy=0.7152\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5373 - accuracy: 0.7384 - val_loss: 0.5558 - val_accuracy: 0.7152 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.7440Epoch 32/40: loss=0.5304, accuracy=0.7440, val_loss=0.5662, val_accuracy=0.6921\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5304 - accuracy: 0.7440 - val_loss: 0.5662 - val_accuracy: 0.6921 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7285Epoch 33/40: loss=0.5507, accuracy=0.7285, val_loss=0.6152, val_accuracy=0.6697\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5507 - accuracy: 0.7285 - val_loss: 0.6152 - val_accuracy: 0.6697 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.7386Epoch 34/40: loss=0.5336, accuracy=0.7378, val_loss=0.5657, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5336 - accuracy: 0.7378 - val_loss: 0.5657 - val_accuracy: 0.7012 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.7394Epoch 35/40: loss=0.5325, accuracy=0.7388, val_loss=0.5857, val_accuracy=0.6846\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5325 - accuracy: 0.7388 - val_loss: 0.5857 - val_accuracy: 0.6846 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.7473\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 36/40: loss=0.5294, accuracy=0.7473, val_loss=0.5955, val_accuracy=0.6871\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5294 - accuracy: 0.7473 - val_loss: 0.5955 - val_accuracy: 0.6871 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.7376Epoch 37/40: loss=0.5405, accuracy=0.7374, val_loss=0.5637, val_accuracy=0.6987\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5405 - accuracy: 0.7374 - val_loss: 0.5637 - val_accuracy: 0.6987 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.7479Epoch 38/40: loss=0.5227, accuracy=0.7479, val_loss=0.5737, val_accuracy=0.6887\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5227 - accuracy: 0.7479 - val_loss: 0.5737 - val_accuracy: 0.6887 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.7473Epoch 39/40: loss=0.5205, accuracy=0.7477, val_loss=0.5666, val_accuracy=0.7094\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5205 - accuracy: 0.7477 - val_loss: 0.5666 - val_accuracy: 0.7094 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.7461Epoch 40/40: loss=0.5195, accuracy=0.7463, val_loss=0.5695, val_accuracy=0.7003\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5195 - accuracy: 0.7463 - val_loss: 0.5695 - val_accuracy: 0.7003 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.7284768223762512\n",
      "\n",
      "Refined Training Combination 28/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.6, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1360 - accuracy: 0.5146Epoch 1/40: loss=1.1337, accuracy=0.5149, val_loss=0.7473, val_accuracy=0.6051\n",
      "604/604 [==============================] - 14s 18ms/step - loss: 1.1337 - accuracy: 0.5149 - val_loss: 0.7473 - val_accuracy: 0.6051 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8492 - accuracy: 0.5160Epoch 2/40: loss=0.8486, accuracy=0.5159, val_loss=0.8199, val_accuracy=0.5066\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8486 - accuracy: 0.5159 - val_loss: 0.8199 - val_accuracy: 0.5066 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8580 - accuracy: 0.5156Epoch 3/40: loss=0.8576, accuracy=0.5157, val_loss=0.8585, val_accuracy=0.5969\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8576 - accuracy: 0.5157 - val_loss: 0.8585 - val_accuracy: 0.5969 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.5592Epoch 4/40: loss=0.7752, accuracy=0.5592, val_loss=0.9079, val_accuracy=0.5877\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7752 - accuracy: 0.5592 - val_loss: 0.9079 - val_accuracy: 0.5877 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7634 - accuracy: 0.5840Epoch 5/40: loss=0.7636, accuracy=0.5840, val_loss=0.8387, val_accuracy=0.6118\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7636 - accuracy: 0.5840 - val_loss: 0.8387 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7526 - accuracy: 0.5984Epoch 6/40: loss=0.7521, accuracy=0.5987, val_loss=0.7366, val_accuracy=0.4826\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7521 - accuracy: 0.5987 - val_loss: 0.7366 - val_accuracy: 0.4826 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8225 - accuracy: 0.5450Epoch 7/40: loss=0.8225, accuracy=0.5449, val_loss=0.8309, val_accuracy=0.5190\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8225 - accuracy: 0.5449 - val_loss: 0.8309 - val_accuracy: 0.5190 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8267 - accuracy: 0.5384Epoch 8/40: loss=0.8264, accuracy=0.5383, val_loss=0.6550, val_accuracy=0.6101\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8264 - accuracy: 0.5383 - val_loss: 0.6550 - val_accuracy: 0.6101 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.5726Epoch 9/40: loss=0.7679, accuracy=0.5726, val_loss=0.7770, val_accuracy=0.5381\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7679 - accuracy: 0.5726 - val_loss: 0.7770 - val_accuracy: 0.5381 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8643 - accuracy: 0.5027Epoch 10/40: loss=0.8636, accuracy=0.5029, val_loss=0.7044, val_accuracy=0.4752\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8636 - accuracy: 0.5029 - val_loss: 0.7044 - val_accuracy: 0.4752 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.4915Epoch 11/40: loss=0.8321, accuracy=0.4915, val_loss=0.6869, val_accuracy=0.5803\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8321 - accuracy: 0.4915 - val_loss: 0.6869 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7890 - accuracy: 0.5139Epoch 12/40: loss=0.7890, accuracy=0.5139, val_loss=0.7674, val_accuracy=0.4089\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7890 - accuracy: 0.5139 - val_loss: 0.7674 - val_accuracy: 0.4089 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7807 - accuracy: 0.5102\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40: loss=0.7804, accuracy=0.5103, val_loss=0.7308, val_accuracy=0.5447\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7804 - accuracy: 0.5103 - val_loss: 0.7308 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7385 - accuracy: 0.5068Epoch 14/40: loss=0.7385, accuracy=0.5068, val_loss=0.6802, val_accuracy=0.5811\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7385 - accuracy: 0.5068 - val_loss: 0.6802 - val_accuracy: 0.5811 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7455 - accuracy: 0.4898Epoch 15/40: loss=0.7452, accuracy=0.4901, val_loss=0.6800, val_accuracy=0.5712\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7452 - accuracy: 0.4901 - val_loss: 0.6800 - val_accuracy: 0.5712 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7355 - accuracy: 0.5066Epoch 16/40: loss=0.7356, accuracy=0.5066, val_loss=0.6855, val_accuracy=0.5522\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7356 - accuracy: 0.5066 - val_loss: 0.6855 - val_accuracy: 0.5522 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.5116Epoch 17/40: loss=0.7282, accuracy=0.5116, val_loss=0.6883, val_accuracy=0.5306\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7282 - accuracy: 0.5116 - val_loss: 0.6883 - val_accuracy: 0.5306 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7298 - accuracy: 0.5015\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 18/40: loss=0.7296, accuracy=0.5014, val_loss=0.6737, val_accuracy=0.5704\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7296 - accuracy: 0.5014 - val_loss: 0.6737 - val_accuracy: 0.5704 - lr: 2.0000e-04\n",
      "Epoch 18: early stopping\n",
      "Validation accuracy: 0.6117549538612366\n",
      "\n",
      "Refined Training Combination 29/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.6, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9498 - accuracy: 0.5112Epoch 1/40: loss=0.9498, accuracy=0.5112, val_loss=0.8563, val_accuracy=0.5240\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 0.9498 - accuracy: 0.5112 - val_loss: 0.8563 - val_accuracy: 0.5240 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.5091Epoch 2/40: loss=0.9264, accuracy=0.5091, val_loss=0.7344, val_accuracy=0.5356\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9264 - accuracy: 0.5091 - val_loss: 0.7344 - val_accuracy: 0.5356 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8779 - accuracy: 0.5100Epoch 3/40: loss=0.8780, accuracy=0.5097, val_loss=0.7816, val_accuracy=0.5232\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8780 - accuracy: 0.5097 - val_loss: 0.7816 - val_accuracy: 0.5232 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8596 - accuracy: 0.5193Epoch 4/40: loss=0.8587, accuracy=0.5195, val_loss=0.7149, val_accuracy=0.5753\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8587 - accuracy: 0.5195 - val_loss: 0.7149 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8183 - accuracy: 0.5388Epoch 5/40: loss=0.8172, accuracy=0.5393, val_loss=0.7553, val_accuracy=0.5373\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8172 - accuracy: 0.5393 - val_loss: 0.7553 - val_accuracy: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8271 - accuracy: 0.5305Epoch 6/40: loss=0.8279, accuracy=0.5296, val_loss=0.6707, val_accuracy=0.6118\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8279 - accuracy: 0.5296 - val_loss: 0.6707 - val_accuracy: 0.6118 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7885 - accuracy: 0.5417Epoch 7/40: loss=0.7881, accuracy=0.5418, val_loss=0.7356, val_accuracy=0.5728\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7881 - accuracy: 0.5418 - val_loss: 0.7356 - val_accuracy: 0.5728 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7899 - accuracy: 0.5295Epoch 8/40: loss=0.7890, accuracy=0.5306, val_loss=0.7649, val_accuracy=0.5215\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7890 - accuracy: 0.5306 - val_loss: 0.7649 - val_accuracy: 0.5215 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7669 - accuracy: 0.5475Epoch 9/40: loss=0.7667, accuracy=0.5478, val_loss=0.6892, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7667 - accuracy: 0.5478 - val_loss: 0.6892 - val_accuracy: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.5627Epoch 10/40: loss=0.7482, accuracy=0.5627, val_loss=0.6515, val_accuracy=0.6167\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7482 - accuracy: 0.5627 - val_loss: 0.6515 - val_accuracy: 0.6167 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.5420Epoch 11/40: loss=0.7574, accuracy=0.5420, val_loss=0.6763, val_accuracy=0.6076\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7574 - accuracy: 0.5420 - val_loss: 0.6763 - val_accuracy: 0.6076 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7290 - accuracy: 0.5698Epoch 12/40: loss=0.7289, accuracy=0.5702, val_loss=0.6619, val_accuracy=0.5944\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7289 - accuracy: 0.5702 - val_loss: 0.6619 - val_accuracy: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7184 - accuracy: 0.5688Epoch 13/40: loss=0.7187, accuracy=0.5687, val_loss=0.6424, val_accuracy=0.6341\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7187 - accuracy: 0.5687 - val_loss: 0.6424 - val_accuracy: 0.6341 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5976Epoch 14/40: loss=0.6931, accuracy=0.5977, val_loss=0.6658, val_accuracy=0.6366\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6931 - accuracy: 0.5977 - val_loss: 0.6658 - val_accuracy: 0.6366 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.5973Epoch 15/40: loss=0.6979, accuracy=0.5973, val_loss=0.7517, val_accuracy=0.5373\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6979 - accuracy: 0.5973 - val_loss: 0.7517 - val_accuracy: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6819 - accuracy: 0.6103Epoch 16/40: loss=0.6817, accuracy=0.6105, val_loss=0.6588, val_accuracy=0.6283\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6817 - accuracy: 0.6105 - val_loss: 0.6588 - val_accuracy: 0.6283 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.6341Epoch 17/40: loss=0.6578, accuracy=0.6347, val_loss=0.5791, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6578 - accuracy: 0.6347 - val_loss: 0.5791 - val_accuracy: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.6547Epoch 18/40: loss=0.6381, accuracy=0.6552, val_loss=0.8240, val_accuracy=0.5861\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6381 - accuracy: 0.6552 - val_loss: 0.8240 - val_accuracy: 0.5861 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6333 - accuracy: 0.6586Epoch 19/40: loss=0.6331, accuracy=0.6589, val_loss=0.7200, val_accuracy=0.5836\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6331 - accuracy: 0.6589 - val_loss: 0.7200 - val_accuracy: 0.5836 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.6509Epoch 20/40: loss=0.6423, accuracy=0.6509, val_loss=0.5858, val_accuracy=0.6929\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6423 - accuracy: 0.6509 - val_loss: 0.5858 - val_accuracy: 0.6929 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6195 - accuracy: 0.6694Epoch 21/40: loss=0.6195, accuracy=0.6695, val_loss=0.6140, val_accuracy=0.6763\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6195 - accuracy: 0.6695 - val_loss: 0.6140 - val_accuracy: 0.6763 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.6774\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 22/40: loss=0.6058, accuracy=0.6774, val_loss=0.5874, val_accuracy=0.6995\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6058 - accuracy: 0.6774 - val_loss: 0.5874 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5882 - accuracy: 0.6917Epoch 23/40: loss=0.5885, accuracy=0.6916, val_loss=0.6084, val_accuracy=0.6672\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5885 - accuracy: 0.6916 - val_loss: 0.6084 - val_accuracy: 0.6672 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5853 - accuracy: 0.6968Epoch 24/40: loss=0.5844, accuracy=0.6978, val_loss=0.6161, val_accuracy=0.6490\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5844 - accuracy: 0.6978 - val_loss: 0.6161 - val_accuracy: 0.6490 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.6908Epoch 25/40: loss=0.5810, accuracy=0.6914, val_loss=0.6251, val_accuracy=0.6722\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5810 - accuracy: 0.6914 - val_loss: 0.6251 - val_accuracy: 0.6722 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5766 - accuracy: 0.7003Epoch 26/40: loss=0.5762, accuracy=0.7005, val_loss=0.6198, val_accuracy=0.6838\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5762 - accuracy: 0.7005 - val_loss: 0.6198 - val_accuracy: 0.6838 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5581 - accuracy: 0.7093\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5581, accuracy=0.7090, val_loss=0.6115, val_accuracy=0.6763\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5581 - accuracy: 0.7090 - val_loss: 0.6115 - val_accuracy: 0.6763 - lr: 2.0000e-05\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.6995033025741577\n",
      "\n",
      "Refined Training Combination 30/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.6, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9433 - accuracy: 0.5106Epoch 1/40: loss=0.9435, accuracy=0.5101, val_loss=0.7416, val_accuracy=0.5339\n",
      "604/604 [==============================] - 14s 18ms/step - loss: 0.9435 - accuracy: 0.5101 - val_loss: 0.7416 - val_accuracy: 0.5339 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9004 - accuracy: 0.5175Epoch 2/40: loss=0.9000, accuracy=0.5178, val_loss=0.7287, val_accuracy=0.5844\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9000 - accuracy: 0.5178 - val_loss: 0.7287 - val_accuracy: 0.5844 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.5141Epoch 3/40: loss=0.8913, accuracy=0.5141, val_loss=0.7594, val_accuracy=0.5563\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8913 - accuracy: 0.5141 - val_loss: 0.7594 - val_accuracy: 0.5563 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8582 - accuracy: 0.5239Epoch 4/40: loss=0.8574, accuracy=0.5242, val_loss=0.7188, val_accuracy=0.5613\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8574 - accuracy: 0.5242 - val_loss: 0.7188 - val_accuracy: 0.5613 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8334 - accuracy: 0.5182Epoch 5/40: loss=0.8333, accuracy=0.5182, val_loss=0.7149, val_accuracy=0.5571\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8333 - accuracy: 0.5182 - val_loss: 0.7149 - val_accuracy: 0.5571 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8241 - accuracy: 0.5079Epoch 6/40: loss=0.8236, accuracy=0.5083, val_loss=0.7947, val_accuracy=0.4421\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8236 - accuracy: 0.5083 - val_loss: 0.7947 - val_accuracy: 0.4421 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8138 - accuracy: 0.5064Epoch 7/40: loss=0.8138, accuracy=0.5068, val_loss=0.7402, val_accuracy=0.5778\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8138 - accuracy: 0.5068 - val_loss: 0.7402 - val_accuracy: 0.5778 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7952 - accuracy: 0.5178Epoch 8/40: loss=0.7952, accuracy=0.5178, val_loss=0.7078, val_accuracy=0.5737\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7952 - accuracy: 0.5178 - val_loss: 0.7078 - val_accuracy: 0.5737 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7716 - accuracy: 0.5389Epoch 9/40: loss=0.7716, accuracy=0.5389, val_loss=0.7253, val_accuracy=0.5472\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7716 - accuracy: 0.5389 - val_loss: 0.7253 - val_accuracy: 0.5472 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7628 - accuracy: 0.5345Epoch 10/40: loss=0.7632, accuracy=0.5344, val_loss=0.6907, val_accuracy=0.5786\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7632 - accuracy: 0.5344 - val_loss: 0.6907 - val_accuracy: 0.5786 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7643 - accuracy: 0.5295Epoch 11/40: loss=0.7641, accuracy=0.5292, val_loss=0.7165, val_accuracy=0.5364\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7641 - accuracy: 0.5292 - val_loss: 0.7165 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.5507Epoch 12/40: loss=0.7369, accuracy=0.5507, val_loss=0.6917, val_accuracy=0.5944\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7369 - accuracy: 0.5507 - val_loss: 0.6917 - val_accuracy: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7411 - accuracy: 0.5446Epoch 13/40: loss=0.7414, accuracy=0.5443, val_loss=0.7451, val_accuracy=0.5182\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7414 - accuracy: 0.5443 - val_loss: 0.7451 - val_accuracy: 0.5182 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7229 - accuracy: 0.5673Epoch 14/40: loss=0.7223, accuracy=0.5677, val_loss=0.6780, val_accuracy=0.5803\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7223 - accuracy: 0.5677 - val_loss: 0.6780 - val_accuracy: 0.5803 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7049 - accuracy: 0.5693Epoch 15/40: loss=0.7049, accuracy=0.5693, val_loss=0.6848, val_accuracy=0.5886\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7049 - accuracy: 0.5693 - val_loss: 0.6848 - val_accuracy: 0.5886 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.6061Epoch 16/40: loss=0.6778, accuracy=0.6062, val_loss=0.6858, val_accuracy=0.5902\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6778 - accuracy: 0.6062 - val_loss: 0.6858 - val_accuracy: 0.5902 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6758 - accuracy: 0.6100Epoch 17/40: loss=0.6754, accuracy=0.6101, val_loss=0.6333, val_accuracy=0.6482\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6754 - accuracy: 0.6101 - val_loss: 0.6333 - val_accuracy: 0.6482 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.6310Epoch 18/40: loss=0.6573, accuracy=0.6310, val_loss=0.6984, val_accuracy=0.5969\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6573 - accuracy: 0.6310 - val_loss: 0.6984 - val_accuracy: 0.5969 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6294 - accuracy: 0.6648Epoch 19/40: loss=0.6295, accuracy=0.6649, val_loss=0.5757, val_accuracy=0.6904\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6295 - accuracy: 0.6649 - val_loss: 0.5757 - val_accuracy: 0.6904 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6302 - accuracy: 0.6591Epoch 20/40: loss=0.6299, accuracy=0.6594, val_loss=0.6465, val_accuracy=0.6474\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6299 - accuracy: 0.6594 - val_loss: 0.6465 - val_accuracy: 0.6474 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.6687Epoch 21/40: loss=0.6152, accuracy=0.6687, val_loss=0.8233, val_accuracy=0.5199\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6152 - accuracy: 0.6687 - val_loss: 0.8233 - val_accuracy: 0.5199 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.6768Epoch 22/40: loss=0.6190, accuracy=0.6769, val_loss=0.6282, val_accuracy=0.6515\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6190 - accuracy: 0.6769 - val_loss: 0.6282 - val_accuracy: 0.6515 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.6805Epoch 23/40: loss=0.6054, accuracy=0.6805, val_loss=0.5890, val_accuracy=0.6995\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6054 - accuracy: 0.6805 - val_loss: 0.5890 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.6741\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 24/40: loss=0.6146, accuracy=0.6743, val_loss=0.6729, val_accuracy=0.6242\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6146 - accuracy: 0.6743 - val_loss: 0.6729 - val_accuracy: 0.6242 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5951 - accuracy: 0.6915Epoch 25/40: loss=0.5951, accuracy=0.6916, val_loss=0.5825, val_accuracy=0.6912\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5951 - accuracy: 0.6916 - val_loss: 0.5825 - val_accuracy: 0.6912 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5848 - accuracy: 0.6921Epoch 26/40: loss=0.5850, accuracy=0.6921, val_loss=0.5718, val_accuracy=0.7053\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5850 - accuracy: 0.6921 - val_loss: 0.5718 - val_accuracy: 0.7053 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5843 - accuracy: 0.6921Epoch 27/40: loss=0.5849, accuracy=0.6918, val_loss=0.5496, val_accuracy=0.7119\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5849 - accuracy: 0.6918 - val_loss: 0.5496 - val_accuracy: 0.7119 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7041Epoch 28/40: loss=0.5677, accuracy=0.7049, val_loss=0.5881, val_accuracy=0.6821\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5677 - accuracy: 0.7049 - val_loss: 0.5881 - val_accuracy: 0.6821 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7063Epoch 29/40: loss=0.5704, accuracy=0.7063, val_loss=0.5723, val_accuracy=0.7185\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5704 - accuracy: 0.7063 - val_loss: 0.5723 - val_accuracy: 0.7185 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.7193Epoch 30/40: loss=0.5606, accuracy=0.7196, val_loss=0.5354, val_accuracy=0.7384\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5606 - accuracy: 0.7196 - val_loss: 0.5354 - val_accuracy: 0.7384 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.7161Epoch 31/40: loss=0.5622, accuracy=0.7161, val_loss=0.5256, val_accuracy=0.7376\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5622 - accuracy: 0.7161 - val_loss: 0.5256 - val_accuracy: 0.7376 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5636 - accuracy: 0.7110Epoch 32/40: loss=0.5638, accuracy=0.7111, val_loss=0.5484, val_accuracy=0.7276\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5638 - accuracy: 0.7111 - val_loss: 0.5484 - val_accuracy: 0.7276 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.7257Epoch 33/40: loss=0.5562, accuracy=0.7258, val_loss=0.5314, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5562 - accuracy: 0.7258 - val_loss: 0.5314 - val_accuracy: 0.7442 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5527 - accuracy: 0.7214Epoch 34/40: loss=0.5523, accuracy=0.7216, val_loss=0.5546, val_accuracy=0.7210\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5523 - accuracy: 0.7216 - val_loss: 0.5546 - val_accuracy: 0.7210 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.7285Epoch 35/40: loss=0.5483, accuracy=0.7285, val_loss=0.5479, val_accuracy=0.7194\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5483 - accuracy: 0.7285 - val_loss: 0.5479 - val_accuracy: 0.7194 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7224\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 36/40: loss=0.5504, accuracy=0.7225, val_loss=0.5497, val_accuracy=0.7185\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5504 - accuracy: 0.7225 - val_loss: 0.5497 - val_accuracy: 0.7185 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.7261Epoch 37/40: loss=0.5420, accuracy=0.7260, val_loss=0.5308, val_accuracy=0.7401\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5420 - accuracy: 0.7260 - val_loss: 0.5308 - val_accuracy: 0.7401 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.7321Epoch 38/40: loss=0.5374, accuracy=0.7322, val_loss=0.5260, val_accuracy=0.7384\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5374 - accuracy: 0.7322 - val_loss: 0.5260 - val_accuracy: 0.7384 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7237Epoch 39/40: loss=0.5509, accuracy=0.7237, val_loss=0.5242, val_accuracy=0.7417\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5509 - accuracy: 0.7237 - val_loss: 0.5242 - val_accuracy: 0.7417 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7290Epoch 40/40: loss=0.5425, accuracy=0.7287, val_loss=0.5193, val_accuracy=0.7467\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5425 - accuracy: 0.7287 - val_loss: 0.5193 - val_accuracy: 0.7467 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.746688723564148\n",
      "\n",
      "Refined Training Combination 31/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.5, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9527 - accuracy: 0.5154Epoch 1/40: loss=0.9524, accuracy=0.5153, val_loss=0.7629, val_accuracy=0.5803\n",
      "604/604 [==============================] - 18s 24ms/step - loss: 0.9524 - accuracy: 0.5153 - val_loss: 0.7629 - val_accuracy: 0.5803 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9195 - accuracy: 0.5187Epoch 2/40: loss=0.9195, accuracy=0.5190, val_loss=0.7414, val_accuracy=0.5298\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9195 - accuracy: 0.5190 - val_loss: 0.7414 - val_accuracy: 0.5298 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8822 - accuracy: 0.5230Epoch 3/40: loss=0.8819, accuracy=0.5230, val_loss=0.7198, val_accuracy=0.5795\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8819 - accuracy: 0.5230 - val_loss: 0.7198 - val_accuracy: 0.5795 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8523 - accuracy: 0.5262Epoch 4/40: loss=0.8520, accuracy=0.5255, val_loss=0.7087, val_accuracy=0.5621\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8520 - accuracy: 0.5255 - val_loss: 0.7087 - val_accuracy: 0.5621 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.5462Epoch 5/40: loss=0.8180, accuracy=0.5462, val_loss=0.7117, val_accuracy=0.5894\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.8180 - accuracy: 0.5462 - val_loss: 0.7117 - val_accuracy: 0.5894 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8124 - accuracy: 0.5290Epoch 6/40: loss=0.8124, accuracy=0.5290, val_loss=0.7120, val_accuracy=0.5397\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8124 - accuracy: 0.5290 - val_loss: 0.7120 - val_accuracy: 0.5397 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8032 - accuracy: 0.5348Epoch 7/40: loss=0.8032, accuracy=0.5348, val_loss=0.7404, val_accuracy=0.5257\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8032 - accuracy: 0.5348 - val_loss: 0.7404 - val_accuracy: 0.5257 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7636 - accuracy: 0.5600Epoch 8/40: loss=0.7636, accuracy=0.5600, val_loss=0.6722, val_accuracy=0.5853\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7636 - accuracy: 0.5600 - val_loss: 0.6722 - val_accuracy: 0.5853 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7535 - accuracy: 0.5592Epoch 9/40: loss=0.7551, accuracy=0.5582, val_loss=0.6562, val_accuracy=0.6134\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7551 - accuracy: 0.5582 - val_loss: 0.6562 - val_accuracy: 0.6134 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7605 - accuracy: 0.5408Epoch 10/40: loss=0.7602, accuracy=0.5410, val_loss=0.6842, val_accuracy=0.5613\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7602 - accuracy: 0.5410 - val_loss: 0.6842 - val_accuracy: 0.5613 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7366 - accuracy: 0.5549Epoch 11/40: loss=0.7366, accuracy=0.5548, val_loss=0.6560, val_accuracy=0.6209\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7366 - accuracy: 0.5548 - val_loss: 0.6560 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7148 - accuracy: 0.5777Epoch 12/40: loss=0.7145, accuracy=0.5776, val_loss=0.6609, val_accuracy=0.6142\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7145 - accuracy: 0.5776 - val_loss: 0.6609 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.6010Epoch 13/40: loss=0.6918, accuracy=0.6010, val_loss=0.6564, val_accuracy=0.6407\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6918 - accuracy: 0.6010 - val_loss: 0.6564 - val_accuracy: 0.6407 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.6120Epoch 14/40: loss=0.6818, accuracy=0.6120, val_loss=0.6159, val_accuracy=0.6656\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6818 - accuracy: 0.6120 - val_loss: 0.6159 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.6337Epoch 15/40: loss=0.6548, accuracy=0.6331, val_loss=0.6334, val_accuracy=0.6325\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6548 - accuracy: 0.6331 - val_loss: 0.6334 - val_accuracy: 0.6325 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6600 - accuracy: 0.6329Epoch 16/40: loss=0.6608, accuracy=0.6320, val_loss=0.6294, val_accuracy=0.6614\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6608 - accuracy: 0.6320 - val_loss: 0.6294 - val_accuracy: 0.6614 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6446 - accuracy: 0.6374Epoch 17/40: loss=0.6444, accuracy=0.6376, val_loss=0.5742, val_accuracy=0.7078\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6444 - accuracy: 0.6376 - val_loss: 0.5742 - val_accuracy: 0.7078 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6209 - accuracy: 0.6636Epoch 18/40: loss=0.6212, accuracy=0.6633, val_loss=0.5911, val_accuracy=0.6772\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6212 - accuracy: 0.6633 - val_loss: 0.5911 - val_accuracy: 0.6772 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.6780Epoch 19/40: loss=0.6054, accuracy=0.6780, val_loss=0.6074, val_accuracy=0.6689\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6054 - accuracy: 0.6780 - val_loss: 0.6074 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6047 - accuracy: 0.6847Epoch 20/40: loss=0.6047, accuracy=0.6844, val_loss=0.7140, val_accuracy=0.5803\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6047 - accuracy: 0.6844 - val_loss: 0.7140 - val_accuracy: 0.5803 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.6784Epoch 21/40: loss=0.6022, accuracy=0.6784, val_loss=0.5713, val_accuracy=0.6945\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6022 - accuracy: 0.6784 - val_loss: 0.5713 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.6819Epoch 22/40: loss=0.5909, accuracy=0.6819, val_loss=0.5618, val_accuracy=0.7012\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5909 - accuracy: 0.6819 - val_loss: 0.5618 - val_accuracy: 0.7012 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5871 - accuracy: 0.6953Epoch 23/40: loss=0.5870, accuracy=0.6952, val_loss=0.5129, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5870 - accuracy: 0.6952 - val_loss: 0.5129 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.6939Epoch 24/40: loss=0.5824, accuracy=0.6939, val_loss=0.5348, val_accuracy=0.7409\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5824 - accuracy: 0.6939 - val_loss: 0.5348 - val_accuracy: 0.7409 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.6893Epoch 25/40: loss=0.5873, accuracy=0.6898, val_loss=0.5163, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5873 - accuracy: 0.6898 - val_loss: 0.5163 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7086Epoch 26/40: loss=0.5676, accuracy=0.7086, val_loss=0.5129, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5676 - accuracy: 0.7086 - val_loss: 0.5129 - val_accuracy: 0.7318 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5699 - accuracy: 0.7032Epoch 27/40: loss=0.5703, accuracy=0.7028, val_loss=0.5107, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5703 - accuracy: 0.7028 - val_loss: 0.5107 - val_accuracy: 0.7682 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.7127Epoch 28/40: loss=0.5657, accuracy=0.7127, val_loss=0.4975, val_accuracy=0.7500\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5657 - accuracy: 0.7127 - val_loss: 0.4975 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5678 - accuracy: 0.7061Epoch 29/40: loss=0.5682, accuracy=0.7059, val_loss=0.5186, val_accuracy=0.7467\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5682 - accuracy: 0.7059 - val_loss: 0.5186 - val_accuracy: 0.7467 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7332Epoch 30/40: loss=0.5536, accuracy=0.7330, val_loss=0.5153, val_accuracy=0.7616\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5536 - accuracy: 0.7330 - val_loss: 0.5153 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.7228Epoch 31/40: loss=0.5506, accuracy=0.7239, val_loss=0.5195, val_accuracy=0.7459\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5506 - accuracy: 0.7239 - val_loss: 0.5195 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5482 - accuracy: 0.7344Epoch 32/40: loss=0.5482, accuracy=0.7345, val_loss=0.5256, val_accuracy=0.7409\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5482 - accuracy: 0.7345 - val_loss: 0.5256 - val_accuracy: 0.7409 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.7193\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 33/40: loss=0.5564, accuracy=0.7194, val_loss=0.5785, val_accuracy=0.7136\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5564 - accuracy: 0.7194 - val_loss: 0.5785 - val_accuracy: 0.7136 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.7413Epoch 34/40: loss=0.5336, accuracy=0.7417, val_loss=0.5123, val_accuracy=0.7558\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5336 - accuracy: 0.7417 - val_loss: 0.5123 - val_accuracy: 0.7558 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7337Epoch 35/40: loss=0.5308, accuracy=0.7337, val_loss=0.4801, val_accuracy=0.7864\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5308 - accuracy: 0.7337 - val_loss: 0.4801 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5258 - accuracy: 0.7427Epoch 36/40: loss=0.5258, accuracy=0.7423, val_loss=0.4803, val_accuracy=0.7806\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5258 - accuracy: 0.7423 - val_loss: 0.4803 - val_accuracy: 0.7806 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.7384Epoch 37/40: loss=0.5224, accuracy=0.7388, val_loss=0.4659, val_accuracy=0.7798\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5224 - accuracy: 0.7388 - val_loss: 0.4659 - val_accuracy: 0.7798 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.7459Epoch 38/40: loss=0.5145, accuracy=0.7459, val_loss=0.4703, val_accuracy=0.7748\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5145 - accuracy: 0.7459 - val_loss: 0.4703 - val_accuracy: 0.7748 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.7494Epoch 39/40: loss=0.5171, accuracy=0.7488, val_loss=0.4715, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5171 - accuracy: 0.7488 - val_loss: 0.4715 - val_accuracy: 0.7889 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.7425Epoch 40/40: loss=0.5163, accuracy=0.7423, val_loss=0.4692, val_accuracy=0.7856\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5163 - accuracy: 0.7423 - val_loss: 0.4692 - val_accuracy: 0.7856 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.7889072895050049\n",
      "\n",
      "Refined Training Combination 32/50: num_residual_blocks=7, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.5, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1255 - accuracy: 0.5320Epoch 1/40: loss=1.1247, accuracy=0.5325, val_loss=0.8212, val_accuracy=0.5513\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 1.1247 - accuracy: 0.5325 - val_loss: 0.8212 - val_accuracy: 0.5513 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8598 - accuracy: 0.5437Epoch 2/40: loss=0.8599, accuracy=0.5437, val_loss=0.7291, val_accuracy=0.6035\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8599 - accuracy: 0.5437 - val_loss: 0.7291 - val_accuracy: 0.6035 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8041 - accuracy: 0.5813Epoch 3/40: loss=0.8041, accuracy=0.5813, val_loss=0.7678, val_accuracy=0.5853\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8041 - accuracy: 0.5813 - val_loss: 0.7678 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7613 - accuracy: 0.5988Epoch 4/40: loss=0.7612, accuracy=0.5987, val_loss=0.7852, val_accuracy=0.5505\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7612 - accuracy: 0.5987 - val_loss: 0.7852 - val_accuracy: 0.5505 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.6246Epoch 5/40: loss=0.7403, accuracy=0.6248, val_loss=0.5981, val_accuracy=0.7127\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7403 - accuracy: 0.6248 - val_loss: 0.5981 - val_accuracy: 0.7127 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.6180Epoch 6/40: loss=0.7386, accuracy=0.6184, val_loss=1.7890, val_accuracy=0.4520\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7386 - accuracy: 0.6184 - val_loss: 1.7890 - val_accuracy: 0.4520 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7771 - accuracy: 0.5984Epoch 7/40: loss=0.7769, accuracy=0.5981, val_loss=0.9440, val_accuracy=0.4776\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7769 - accuracy: 0.5981 - val_loss: 0.9440 - val_accuracy: 0.4776 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.6103Epoch 8/40: loss=0.7418, accuracy=0.6103, val_loss=1.6756, val_accuracy=0.4238\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7418 - accuracy: 0.6103 - val_loss: 1.6756 - val_accuracy: 0.4238 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.6430Epoch 9/40: loss=0.6951, accuracy=0.6430, val_loss=0.8836, val_accuracy=0.6151\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6951 - accuracy: 0.6430 - val_loss: 0.8836 - val_accuracy: 0.6151 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6855 - accuracy: 0.6567Epoch 10/40: loss=0.6857, accuracy=0.6571, val_loss=0.5782, val_accuracy=0.7169\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6857 - accuracy: 0.6571 - val_loss: 0.5782 - val_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.6602Epoch 11/40: loss=0.6736, accuracy=0.6602, val_loss=0.6844, val_accuracy=0.6060\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6736 - accuracy: 0.6602 - val_loss: 0.6844 - val_accuracy: 0.6060 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.6356Epoch 12/40: loss=0.7147, accuracy=0.6356, val_loss=0.7105, val_accuracy=0.6159\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7147 - accuracy: 0.6356 - val_loss: 0.7105 - val_accuracy: 0.6159 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.6625Epoch 13/40: loss=0.6772, accuracy=0.6625, val_loss=0.5753, val_accuracy=0.7152\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6772 - accuracy: 0.6625 - val_loss: 0.5753 - val_accuracy: 0.7152 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.6582Epoch 14/40: loss=0.6704, accuracy=0.6585, val_loss=1.0049, val_accuracy=0.6325\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6704 - accuracy: 0.6585 - val_loss: 1.0049 - val_accuracy: 0.6325 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.6567Epoch 15/40: loss=0.6892, accuracy=0.6567, val_loss=0.6084, val_accuracy=0.6639\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6892 - accuracy: 0.6567 - val_loss: 0.6084 - val_accuracy: 0.6639 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.6643Epoch 16/40: loss=0.6675, accuracy=0.6643, val_loss=0.9239, val_accuracy=0.6656\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6675 - accuracy: 0.6643 - val_loss: 0.9239 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6625 - accuracy: 0.6743Epoch 17/40: loss=0.6618, accuracy=0.6749, val_loss=0.5219, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6618 - accuracy: 0.6749 - val_loss: 0.5219 - val_accuracy: 0.7442 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6488 - accuracy: 0.6886Epoch 18/40: loss=0.6489, accuracy=0.6881, val_loss=0.9066, val_accuracy=0.6134\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6489 - accuracy: 0.6881 - val_loss: 0.9066 - val_accuracy: 0.6134 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6507 - accuracy: 0.6805Epoch 19/40: loss=0.6506, accuracy=0.6809, val_loss=0.5324, val_accuracy=0.7517\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6506 - accuracy: 0.6809 - val_loss: 0.5324 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.6870Epoch 20/40: loss=0.6490, accuracy=0.6873, val_loss=0.6853, val_accuracy=0.6316\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6490 - accuracy: 0.6873 - val_loss: 0.6853 - val_accuracy: 0.6316 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6358 - accuracy: 0.6965Epoch 21/40: loss=0.6354, accuracy=0.6966, val_loss=0.8415, val_accuracy=0.5472\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6354 - accuracy: 0.6966 - val_loss: 0.8415 - val_accuracy: 0.5472 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6448 - accuracy: 0.6929\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 22/40: loss=0.6445, accuracy=0.6933, val_loss=0.6021, val_accuracy=0.6407\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6445 - accuracy: 0.6933 - val_loss: 0.6021 - val_accuracy: 0.6407 - lr: 0.0010\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7123Epoch 23/40: loss=0.5970, accuracy=0.7123, val_loss=0.4770, val_accuracy=0.7773\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5970 - accuracy: 0.7123 - val_loss: 0.4770 - val_accuracy: 0.7773 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.7330Epoch 24/40: loss=0.5629, accuracy=0.7330, val_loss=0.4488, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5629 - accuracy: 0.7330 - val_loss: 0.4488 - val_accuracy: 0.7906 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5493 - accuracy: 0.7327Epoch 25/40: loss=0.5498, accuracy=0.7326, val_loss=0.4769, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5498 - accuracy: 0.7326 - val_loss: 0.4769 - val_accuracy: 0.7848 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.7477Epoch 26/40: loss=0.5367, accuracy=0.7479, val_loss=0.4528, val_accuracy=0.8030\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5367 - accuracy: 0.7479 - val_loss: 0.4528 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5211 - accuracy: 0.7506Epoch 27/40: loss=0.5215, accuracy=0.7504, val_loss=0.4469, val_accuracy=0.8055\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5215 - accuracy: 0.7504 - val_loss: 0.4469 - val_accuracy: 0.8055 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.7552Epoch 28/40: loss=0.5326, accuracy=0.7556, val_loss=0.4493, val_accuracy=0.7947\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5326 - accuracy: 0.7556 - val_loss: 0.4493 - val_accuracy: 0.7947 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.7657Epoch 29/40: loss=0.4998, accuracy=0.7657, val_loss=0.4946, val_accuracy=0.7475\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4998 - accuracy: 0.7657 - val_loss: 0.4946 - val_accuracy: 0.7475 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.7641Epoch 30/40: loss=0.4978, accuracy=0.7641, val_loss=0.4192, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4978 - accuracy: 0.7641 - val_loss: 0.4192 - val_accuracy: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4930 - accuracy: 0.7687Epoch 31/40: loss=0.4931, accuracy=0.7686, val_loss=0.3889, val_accuracy=0.8245\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4931 - accuracy: 0.7686 - val_loss: 0.3889 - val_accuracy: 0.8245 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.7784Epoch 32/40: loss=0.4809, accuracy=0.7784, val_loss=0.4425, val_accuracy=0.7964\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4809 - accuracy: 0.7784 - val_loss: 0.4425 - val_accuracy: 0.7964 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.7780Epoch 33/40: loss=0.4892, accuracy=0.7777, val_loss=0.4537, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4892 - accuracy: 0.7777 - val_loss: 0.4537 - val_accuracy: 0.7881 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.7746Epoch 34/40: loss=0.4823, accuracy=0.7746, val_loss=0.4639, val_accuracy=0.7831\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4823 - accuracy: 0.7746 - val_loss: 0.4639 - val_accuracy: 0.7831 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.7825Epoch 35/40: loss=0.4687, accuracy=0.7825, val_loss=0.4420, val_accuracy=0.7930\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4687 - accuracy: 0.7825 - val_loss: 0.4420 - val_accuracy: 0.7930 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.7817\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40: loss=0.4693, accuracy=0.7812, val_loss=0.4842, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4693 - accuracy: 0.7812 - val_loss: 0.4842 - val_accuracy: 0.7740 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.7861Epoch 37/40: loss=0.4615, accuracy=0.7864, val_loss=0.3909, val_accuracy=0.8303\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4615 - accuracy: 0.7864 - val_loss: 0.3909 - val_accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.7930Epoch 38/40: loss=0.4523, accuracy=0.7933, val_loss=0.4105, val_accuracy=0.8179\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4523 - accuracy: 0.7933 - val_loss: 0.4105 - val_accuracy: 0.8179 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.7844Epoch 39/40: loss=0.4606, accuracy=0.7846, val_loss=0.3965, val_accuracy=0.8253\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4606 - accuracy: 0.7846 - val_loss: 0.3965 - val_accuracy: 0.8253 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.7880Epoch 40/40: loss=0.4537, accuracy=0.7883, val_loss=0.4114, val_accuracy=0.8129\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4537 - accuracy: 0.7883 - val_loss: 0.4114 - val_accuracy: 0.8129 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.8302980065345764\n",
      "\n",
      "Refined Training Combination 33/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.4, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1070 - accuracy: 0.5257Epoch 1/40: loss=1.1070, accuracy=0.5257, val_loss=0.8157, val_accuracy=0.5836\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.1070 - accuracy: 0.5257 - val_loss: 0.8157 - val_accuracy: 0.5836 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.5435Epoch 2/40: loss=0.8454, accuracy=0.5435, val_loss=0.6619, val_accuracy=0.6300\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.8454 - accuracy: 0.5435 - val_loss: 0.6619 - val_accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8340 - accuracy: 0.5625Epoch 3/40: loss=0.8340, accuracy=0.5625, val_loss=0.6841, val_accuracy=0.5853\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8340 - accuracy: 0.5625 - val_loss: 0.6841 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7936 - accuracy: 0.5889Epoch 4/40: loss=0.7933, accuracy=0.5890, val_loss=0.7311, val_accuracy=0.6200\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7933 - accuracy: 0.5890 - val_loss: 0.7311 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7588 - accuracy: 0.5968Epoch 5/40: loss=0.7589, accuracy=0.5964, val_loss=0.7816, val_accuracy=0.4338\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7589 - accuracy: 0.5964 - val_loss: 0.7816 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7749 - accuracy: 0.5953Epoch 6/40: loss=0.7730, accuracy=0.5966, val_loss=0.6540, val_accuracy=0.6507\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7730 - accuracy: 0.5966 - val_loss: 0.6540 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7359 - accuracy: 0.6262Epoch 7/40: loss=0.7352, accuracy=0.6264, val_loss=0.7013, val_accuracy=0.6482\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7352 - accuracy: 0.6264 - val_loss: 0.7013 - val_accuracy: 0.6482 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.6358Epoch 8/40: loss=0.7201, accuracy=0.6358, val_loss=1.6749, val_accuracy=0.6076\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7201 - accuracy: 0.6358 - val_loss: 1.6749 - val_accuracy: 0.6076 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.6370Epoch 9/40: loss=0.7308, accuracy=0.6370, val_loss=1.4972, val_accuracy=0.4189\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7308 - accuracy: 0.6370 - val_loss: 1.4972 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7150 - accuracy: 0.6483Epoch 10/40: loss=0.7145, accuracy=0.6480, val_loss=0.7586, val_accuracy=0.5869\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7145 - accuracy: 0.6480 - val_loss: 0.7586 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7169 - accuracy: 0.6379Epoch 11/40: loss=0.7167, accuracy=0.6380, val_loss=0.6313, val_accuracy=0.6060\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7167 - accuracy: 0.6380 - val_loss: 0.6313 - val_accuracy: 0.6060 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7246 - accuracy: 0.6348Epoch 12/40: loss=0.7237, accuracy=0.6353, val_loss=0.5408, val_accuracy=0.7310\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7237 - accuracy: 0.6353 - val_loss: 0.5408 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7198 - accuracy: 0.6437Epoch 13/40: loss=0.7200, accuracy=0.6434, val_loss=0.6170, val_accuracy=0.6515\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7200 - accuracy: 0.6434 - val_loss: 0.6170 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7909 - accuracy: 0.5716Epoch 14/40: loss=0.7913, accuracy=0.5718, val_loss=0.6730, val_accuracy=0.6242\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7913 - accuracy: 0.5718 - val_loss: 0.6730 - val_accuracy: 0.6242 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7277 - accuracy: 0.6287Epoch 15/40: loss=0.7279, accuracy=0.6287, val_loss=1.6677, val_accuracy=0.4023\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7279 - accuracy: 0.6287 - val_loss: 1.6677 - val_accuracy: 0.4023 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7163 - accuracy: 0.6393Epoch 16/40: loss=0.7163, accuracy=0.6393, val_loss=0.7128, val_accuracy=0.6209\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7163 - accuracy: 0.6393 - val_loss: 0.7128 - val_accuracy: 0.6209 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.6327\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 17/40: loss=0.7232, accuracy=0.6327, val_loss=0.5684, val_accuracy=0.7376\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7232 - accuracy: 0.6327 - val_loss: 0.5684 - val_accuracy: 0.7376 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6368 - accuracy: 0.6885Epoch 18/40: loss=0.6370, accuracy=0.6887, val_loss=0.6191, val_accuracy=0.6747\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6370 - accuracy: 0.6887 - val_loss: 0.6191 - val_accuracy: 0.6747 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.6916Epoch 19/40: loss=0.6237, accuracy=0.6916, val_loss=0.5494, val_accuracy=0.7492\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6237 - accuracy: 0.6916 - val_loss: 0.5494 - val_accuracy: 0.7492 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.7120Epoch 20/40: loss=0.5920, accuracy=0.7125, val_loss=0.5684, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5920 - accuracy: 0.7125 - val_loss: 0.5684 - val_accuracy: 0.7210 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5870 - accuracy: 0.7150Epoch 21/40: loss=0.5868, accuracy=0.7150, val_loss=0.5905, val_accuracy=0.6755\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5868 - accuracy: 0.7150 - val_loss: 0.5905 - val_accuracy: 0.6755 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.6995Epoch 22/40: loss=0.5938, accuracy=0.6995, val_loss=0.5313, val_accuracy=0.7492\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5938 - accuracy: 0.6995 - val_loss: 0.5313 - val_accuracy: 0.7492 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7282Epoch 23/40: loss=0.5570, accuracy=0.7283, val_loss=0.4920, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5570 - accuracy: 0.7283 - val_loss: 0.4920 - val_accuracy: 0.7856 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5511 - accuracy: 0.7272Epoch 24/40: loss=0.5511, accuracy=0.7272, val_loss=0.5134, val_accuracy=0.7541\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5511 - accuracy: 0.7272 - val_loss: 0.5134 - val_accuracy: 0.7541 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5502 - accuracy: 0.7274Epoch 25/40: loss=0.5502, accuracy=0.7270, val_loss=0.4839, val_accuracy=0.7715\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5502 - accuracy: 0.7270 - val_loss: 0.4839 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5460 - accuracy: 0.7303Epoch 26/40: loss=0.5457, accuracy=0.7305, val_loss=0.4518, val_accuracy=0.7930\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5457 - accuracy: 0.7305 - val_loss: 0.4518 - val_accuracy: 0.7930 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7378Epoch 27/40: loss=0.5276, accuracy=0.7378, val_loss=0.4726, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5276 - accuracy: 0.7378 - val_loss: 0.4726 - val_accuracy: 0.7575 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7380Epoch 28/40: loss=0.5408, accuracy=0.7380, val_loss=0.5750, val_accuracy=0.7061\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5408 - accuracy: 0.7380 - val_loss: 0.5750 - val_accuracy: 0.7061 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7456Epoch 29/40: loss=0.5319, accuracy=0.7459, val_loss=0.4991, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5319 - accuracy: 0.7459 - val_loss: 0.4991 - val_accuracy: 0.7740 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5294 - accuracy: 0.7450Epoch 30/40: loss=0.5298, accuracy=0.7448, val_loss=0.4866, val_accuracy=0.7674\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5298 - accuracy: 0.7448 - val_loss: 0.4866 - val_accuracy: 0.7674 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.7413\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 31/40: loss=0.5325, accuracy=0.7413, val_loss=0.5275, val_accuracy=0.7475\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5325 - accuracy: 0.7413 - val_loss: 0.5275 - val_accuracy: 0.7475 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.7581Epoch 32/40: loss=0.5106, accuracy=0.7577, val_loss=0.4863, val_accuracy=0.7732\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5106 - accuracy: 0.7577 - val_loss: 0.4863 - val_accuracy: 0.7732 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.7477Epoch 33/40: loss=0.5145, accuracy=0.7477, val_loss=0.4737, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5145 - accuracy: 0.7477 - val_loss: 0.4737 - val_accuracy: 0.7964 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.7490Epoch 34/40: loss=0.5155, accuracy=0.7490, val_loss=0.4875, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5155 - accuracy: 0.7490 - val_loss: 0.4875 - val_accuracy: 0.7649 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.7541Epoch 35/40: loss=0.5089, accuracy=0.7543, val_loss=0.4927, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5089 - accuracy: 0.7543 - val_loss: 0.4927 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5158 - accuracy: 0.7504\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36/40: loss=0.5154, accuracy=0.7506, val_loss=0.4738, val_accuracy=0.7897\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5154 - accuracy: 0.7506 - val_loss: 0.4738 - val_accuracy: 0.7897 - lr: 4.0000e-05\n",
      "Epoch 36: early stopping\n",
      "Validation accuracy: 0.7963576316833496\n",
      "\n",
      "Refined Training Combination 34/50: num_residual_blocks=9, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.6, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9553 - accuracy: 0.5123Epoch 1/40: loss=0.9558, accuracy=0.5116, val_loss=0.7543, val_accuracy=0.5695\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 0.9558 - accuracy: 0.5116 - val_loss: 0.7543 - val_accuracy: 0.5695 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9040 - accuracy: 0.5218Epoch 2/40: loss=0.9033, accuracy=0.5221, val_loss=0.8360, val_accuracy=0.5099\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9033 - accuracy: 0.5221 - val_loss: 0.8360 - val_accuracy: 0.5099 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8722 - accuracy: 0.5289Epoch 3/40: loss=0.8717, accuracy=0.5292, val_loss=0.7123, val_accuracy=0.5588\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8717 - accuracy: 0.5292 - val_loss: 0.7123 - val_accuracy: 0.5588 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8669 - accuracy: 0.5235Epoch 4/40: loss=0.8677, accuracy=0.5230, val_loss=0.7658, val_accuracy=0.4975\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8677 - accuracy: 0.5230 - val_loss: 0.7658 - val_accuracy: 0.4975 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8388 - accuracy: 0.5380Epoch 5/40: loss=0.8390, accuracy=0.5377, val_loss=0.7370, val_accuracy=0.5058\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8390 - accuracy: 0.5377 - val_loss: 0.7370 - val_accuracy: 0.5058 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8232 - accuracy: 0.5233Epoch 6/40: loss=0.8239, accuracy=0.5226, val_loss=0.6996, val_accuracy=0.5828\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8239 - accuracy: 0.5226 - val_loss: 0.6996 - val_accuracy: 0.5828 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7898 - accuracy: 0.5516Epoch 7/40: loss=0.7899, accuracy=0.5515, val_loss=0.8199, val_accuracy=0.4768\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7899 - accuracy: 0.5515 - val_loss: 0.8199 - val_accuracy: 0.4768 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7708 - accuracy: 0.5524Epoch 8/40: loss=0.7713, accuracy=0.5524, val_loss=0.7304, val_accuracy=0.5323\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7713 - accuracy: 0.5524 - val_loss: 0.7304 - val_accuracy: 0.5323 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7611 - accuracy: 0.5621Epoch 9/40: loss=0.7603, accuracy=0.5623, val_loss=0.8030, val_accuracy=0.5066\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7603 - accuracy: 0.5623 - val_loss: 0.8030 - val_accuracy: 0.5066 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7334 - accuracy: 0.5729Epoch 10/40: loss=0.7338, accuracy=0.5726, val_loss=0.6525, val_accuracy=0.6275\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7338 - accuracy: 0.5726 - val_loss: 0.6525 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7315 - accuracy: 0.5766Epoch 11/40: loss=0.7313, accuracy=0.5766, val_loss=0.6967, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7313 - accuracy: 0.5766 - val_loss: 0.6967 - val_accuracy: 0.5993 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.5726Epoch 12/40: loss=0.7215, accuracy=0.5726, val_loss=0.6343, val_accuracy=0.6449\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7215 - accuracy: 0.5726 - val_loss: 0.6343 - val_accuracy: 0.6449 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.6003Epoch 13/40: loss=0.7000, accuracy=0.6006, val_loss=0.6134, val_accuracy=0.6680\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7000 - accuracy: 0.6006 - val_loss: 0.6134 - val_accuracy: 0.6680 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.6057Epoch 14/40: loss=0.6830, accuracy=0.6060, val_loss=0.7017, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6830 - accuracy: 0.6060 - val_loss: 0.7017 - val_accuracy: 0.5985 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.6043Epoch 15/40: loss=0.6820, accuracy=0.6043, val_loss=0.6451, val_accuracy=0.6316\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6820 - accuracy: 0.6043 - val_loss: 0.6451 - val_accuracy: 0.6316 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6504 - accuracy: 0.6426Epoch 16/40: loss=0.6511, accuracy=0.6422, val_loss=0.5842, val_accuracy=0.6796\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6511 - accuracy: 0.6422 - val_loss: 0.5842 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.6483Epoch 17/40: loss=0.6341, accuracy=0.6484, val_loss=0.6739, val_accuracy=0.5977\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6341 - accuracy: 0.6484 - val_loss: 0.6739 - val_accuracy: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.6660Epoch 18/40: loss=0.6165, accuracy=0.6662, val_loss=0.6161, val_accuracy=0.6863\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6165 - accuracy: 0.6662 - val_loss: 0.6161 - val_accuracy: 0.6863 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.6786Epoch 19/40: loss=0.6085, accuracy=0.6786, val_loss=0.5800, val_accuracy=0.6945\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6085 - accuracy: 0.6786 - val_loss: 0.5800 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6090 - accuracy: 0.6825Epoch 20/40: loss=0.6094, accuracy=0.6821, val_loss=0.5765, val_accuracy=0.7111\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6094 - accuracy: 0.6821 - val_loss: 0.5765 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6755Epoch 21/40: loss=0.6116, accuracy=0.6755, val_loss=0.6492, val_accuracy=0.6126\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6116 - accuracy: 0.6755 - val_loss: 0.6492 - val_accuracy: 0.6126 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5924 - accuracy: 0.6973Epoch 22/40: loss=0.5917, accuracy=0.6978, val_loss=0.6499, val_accuracy=0.6391\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5917 - accuracy: 0.6978 - val_loss: 0.6499 - val_accuracy: 0.6391 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.7022Epoch 23/40: loss=0.5778, accuracy=0.7022, val_loss=0.5281, val_accuracy=0.7434\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5778 - accuracy: 0.7022 - val_loss: 0.5281 - val_accuracy: 0.7434 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.7059Epoch 24/40: loss=0.5783, accuracy=0.7059, val_loss=0.5834, val_accuracy=0.7103\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5783 - accuracy: 0.7059 - val_loss: 0.5834 - val_accuracy: 0.7103 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5770 - accuracy: 0.7011Epoch 25/40: loss=0.5765, accuracy=0.7016, val_loss=0.6640, val_accuracy=0.6258\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5765 - accuracy: 0.7016 - val_loss: 0.6640 - val_accuracy: 0.6258 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7136Epoch 26/40: loss=0.5632, accuracy=0.7136, val_loss=0.7160, val_accuracy=0.6200\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5632 - accuracy: 0.7136 - val_loss: 0.7160 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7179Epoch 27/40: loss=0.5587, accuracy=0.7179, val_loss=0.5374, val_accuracy=0.7351\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5587 - accuracy: 0.7179 - val_loss: 0.5374 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7298Epoch 28/40: loss=0.5497, accuracy=0.7289, val_loss=0.4897, val_accuracy=0.7715\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5497 - accuracy: 0.7289 - val_loss: 0.4897 - val_accuracy: 0.7715 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.7229Epoch 29/40: loss=0.5578, accuracy=0.7229, val_loss=0.5338, val_accuracy=0.7276\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5578 - accuracy: 0.7229 - val_loss: 0.5338 - val_accuracy: 0.7276 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7403Epoch 30/40: loss=0.5372, accuracy=0.7403, val_loss=0.4861, val_accuracy=0.7748\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5372 - accuracy: 0.7403 - val_loss: 0.4861 - val_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.7262Epoch 31/40: loss=0.5409, accuracy=0.7260, val_loss=0.5422, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5409 - accuracy: 0.7260 - val_loss: 0.5422 - val_accuracy: 0.7219 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5522 - accuracy: 0.7236Epoch 32/40: loss=0.5520, accuracy=0.7233, val_loss=0.6013, val_accuracy=0.6747\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5520 - accuracy: 0.7233 - val_loss: 0.6013 - val_accuracy: 0.6747 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7386Epoch 33/40: loss=0.5284, accuracy=0.7390, val_loss=0.4772, val_accuracy=0.7401\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5284 - accuracy: 0.7390 - val_loss: 0.4772 - val_accuracy: 0.7401 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.7332Epoch 34/40: loss=0.5268, accuracy=0.7339, val_loss=0.4734, val_accuracy=0.7831\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5268 - accuracy: 0.7339 - val_loss: 0.4734 - val_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.7436Epoch 35/40: loss=0.5198, accuracy=0.7432, val_loss=0.4930, val_accuracy=0.7823\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5198 - accuracy: 0.7432 - val_loss: 0.4930 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.7438Epoch 36/40: loss=0.5188, accuracy=0.7436, val_loss=0.5090, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5188 - accuracy: 0.7436 - val_loss: 0.5090 - val_accuracy: 0.7765 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5165 - accuracy: 0.7556Epoch 37/40: loss=0.5171, accuracy=0.7554, val_loss=0.4693, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5171 - accuracy: 0.7554 - val_loss: 0.4693 - val_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7527Epoch 38/40: loss=0.5187, accuracy=0.7529, val_loss=0.5051, val_accuracy=0.7450\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5187 - accuracy: 0.7529 - val_loss: 0.5051 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.7454Epoch 39/40: loss=0.5160, accuracy=0.7457, val_loss=0.5351, val_accuracy=0.7293\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5160 - accuracy: 0.7457 - val_loss: 0.5351 - val_accuracy: 0.7293 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5086 - accuracy: 0.7504Epoch 40/40: loss=0.5094, accuracy=0.7498, val_loss=0.5530, val_accuracy=0.6805\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5094 - accuracy: 0.7498 - val_loss: 0.5530 - val_accuracy: 0.6805 - lr: 1.0000e-04\n",
      "Validation accuracy: 0.7831125855445862\n",
      "\n",
      "Refined Training Combination 35/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.5, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0719 - accuracy: 0.5075Epoch 1/40: loss=1.0717, accuracy=0.5075, val_loss=1.0425, val_accuracy=0.4661\n",
      "604/604 [==============================] - 15s 19ms/step - loss: 1.0717 - accuracy: 0.5075 - val_loss: 1.0425 - val_accuracy: 0.4661 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8438 - accuracy: 0.5292Epoch 2/40: loss=0.8435, accuracy=0.5296, val_loss=0.8561, val_accuracy=0.4967\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8435 - accuracy: 0.5296 - val_loss: 0.8561 - val_accuracy: 0.4967 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7654 - accuracy: 0.5680Epoch 3/40: loss=0.7659, accuracy=0.5675, val_loss=0.7429, val_accuracy=0.6184\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7659 - accuracy: 0.5675 - val_loss: 0.7429 - val_accuracy: 0.6184 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.5915Epoch 4/40: loss=0.7339, accuracy=0.5915, val_loss=0.6899, val_accuracy=0.6093\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7339 - accuracy: 0.5915 - val_loss: 0.6899 - val_accuracy: 0.6093 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7089 - accuracy: 0.6013Epoch 5/40: loss=0.7090, accuracy=0.6014, val_loss=1.2235, val_accuracy=0.4545\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7090 - accuracy: 0.6014 - val_loss: 1.2235 - val_accuracy: 0.4545 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6673 - accuracy: 0.6491Epoch 6/40: loss=0.6673, accuracy=0.6490, val_loss=0.7081, val_accuracy=0.5927\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6673 - accuracy: 0.6490 - val_loss: 0.7081 - val_accuracy: 0.5927 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6534Epoch 7/40: loss=0.6536, accuracy=0.6534, val_loss=0.9351, val_accuracy=0.5025\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6536 - accuracy: 0.6534 - val_loss: 0.9351 - val_accuracy: 0.5025 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.6633Epoch 8/40: loss=0.6448, accuracy=0.6633, val_loss=0.8311, val_accuracy=0.5919\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6448 - accuracy: 0.6633 - val_loss: 0.8311 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.6617Epoch 9/40: loss=0.6561, accuracy=0.6616, val_loss=0.6007, val_accuracy=0.6747\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6561 - accuracy: 0.6616 - val_loss: 0.6007 - val_accuracy: 0.6747 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.6718Epoch 10/40: loss=0.6388, accuracy=0.6718, val_loss=0.5330, val_accuracy=0.7442\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6388 - accuracy: 0.6718 - val_loss: 0.5330 - val_accuracy: 0.7442 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.6757Epoch 11/40: loss=0.6435, accuracy=0.6757, val_loss=0.6119, val_accuracy=0.6647\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6435 - accuracy: 0.6757 - val_loss: 0.6119 - val_accuracy: 0.6647 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.6610Epoch 12/40: loss=0.6523, accuracy=0.6612, val_loss=1.9364, val_accuracy=0.4114\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6523 - accuracy: 0.6612 - val_loss: 1.9364 - val_accuracy: 0.4114 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6447 - accuracy: 0.6727Epoch 13/40: loss=0.6445, accuracy=0.6728, val_loss=0.8358, val_accuracy=0.5695\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6445 - accuracy: 0.6728 - val_loss: 0.8358 - val_accuracy: 0.5695 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6669 - accuracy: 0.6603Epoch 14/40: loss=0.6662, accuracy=0.6610, val_loss=0.7795, val_accuracy=0.6175\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6662 - accuracy: 0.6610 - val_loss: 0.7795 - val_accuracy: 0.6175 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6289 - accuracy: 0.6788\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/40: loss=0.6295, accuracy=0.6784, val_loss=0.5628, val_accuracy=0.7086\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6295 - accuracy: 0.6784 - val_loss: 0.5628 - val_accuracy: 0.7086 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.7135Epoch 16/40: loss=0.5612, accuracy=0.7132, val_loss=0.4976, val_accuracy=0.7566\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5612 - accuracy: 0.7132 - val_loss: 0.4976 - val_accuracy: 0.7566 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.7200Epoch 17/40: loss=0.5545, accuracy=0.7200, val_loss=0.5968, val_accuracy=0.6945\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5545 - accuracy: 0.7200 - val_loss: 0.5968 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.7243Epoch 18/40: loss=0.5440, accuracy=0.7243, val_loss=0.5402, val_accuracy=0.7243\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5440 - accuracy: 0.7243 - val_loss: 0.5402 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.7373Epoch 19/40: loss=0.5292, accuracy=0.7368, val_loss=0.4688, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5292 - accuracy: 0.7368 - val_loss: 0.4688 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.7374Epoch 20/40: loss=0.5330, accuracy=0.7374, val_loss=0.4336, val_accuracy=0.7980\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5330 - accuracy: 0.7374 - val_loss: 0.4336 - val_accuracy: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.7397Epoch 21/40: loss=0.5302, accuracy=0.7397, val_loss=0.4388, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5302 - accuracy: 0.7397 - val_loss: 0.4388 - val_accuracy: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5202 - accuracy: 0.7452Epoch 22/40: loss=0.5198, accuracy=0.7450, val_loss=0.4538, val_accuracy=0.8113\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5198 - accuracy: 0.7450 - val_loss: 0.4538 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5041 - accuracy: 0.7529Epoch 23/40: loss=0.5041, accuracy=0.7525, val_loss=0.4943, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5041 - accuracy: 0.7525 - val_loss: 0.4943 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5156 - accuracy: 0.7459Epoch 24/40: loss=0.5158, accuracy=0.7459, val_loss=0.4372, val_accuracy=0.7997\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5158 - accuracy: 0.7459 - val_loss: 0.4372 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7558\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 25/40: loss=0.4995, accuracy=0.7560, val_loss=0.6674, val_accuracy=0.6209\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4995 - accuracy: 0.7560 - val_loss: 0.6674 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.7614Epoch 26/40: loss=0.4831, accuracy=0.7616, val_loss=0.4308, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4831 - accuracy: 0.7616 - val_loss: 0.4308 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.7676Epoch 27/40: loss=0.4866, accuracy=0.7676, val_loss=0.4322, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4866 - accuracy: 0.7676 - val_loss: 0.4322 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.7591Epoch 28/40: loss=0.4888, accuracy=0.7587, val_loss=0.4316, val_accuracy=0.8063\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4888 - accuracy: 0.7587 - val_loss: 0.4316 - val_accuracy: 0.8063 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.7676Epoch 29/40: loss=0.4816, accuracy=0.7682, val_loss=0.4313, val_accuracy=0.8055\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4816 - accuracy: 0.7682 - val_loss: 0.4313 - val_accuracy: 0.8055 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7645Epoch 30/40: loss=0.4836, accuracy=0.7647, val_loss=0.4442, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4836 - accuracy: 0.7647 - val_loss: 0.4442 - val_accuracy: 0.7914 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.7732Epoch 31/40: loss=0.4815, accuracy=0.7732, val_loss=0.4045, val_accuracy=0.8278\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4815 - accuracy: 0.7732 - val_loss: 0.4045 - val_accuracy: 0.8278 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.7680Epoch 32/40: loss=0.4859, accuracy=0.7682, val_loss=0.4352, val_accuracy=0.7955\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4859 - accuracy: 0.7682 - val_loss: 0.4352 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.7721Epoch 33/40: loss=0.4739, accuracy=0.7721, val_loss=0.4276, val_accuracy=0.8022\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4739 - accuracy: 0.7721 - val_loss: 0.4276 - val_accuracy: 0.8022 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.7777Epoch 34/40: loss=0.4701, accuracy=0.7769, val_loss=0.4048, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4701 - accuracy: 0.7769 - val_loss: 0.4048 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.7815Epoch 35/40: loss=0.4619, accuracy=0.7815, val_loss=0.4034, val_accuracy=0.8162\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4619 - accuracy: 0.7815 - val_loss: 0.4034 - val_accuracy: 0.8162 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7780Epoch 36/40: loss=0.4681, accuracy=0.7781, val_loss=0.3914, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4681 - accuracy: 0.7781 - val_loss: 0.3914 - val_accuracy: 0.8336 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4655 - accuracy: 0.7805Epoch 37/40: loss=0.4658, accuracy=0.7802, val_loss=0.4214, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4658 - accuracy: 0.7802 - val_loss: 0.4214 - val_accuracy: 0.8212 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.7819Epoch 38/40: loss=0.4689, accuracy=0.7819, val_loss=0.4111, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4689 - accuracy: 0.7819 - val_loss: 0.4111 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.7769Epoch 39/40: loss=0.4675, accuracy=0.7769, val_loss=0.4045, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4675 - accuracy: 0.7769 - val_loss: 0.4045 - val_accuracy: 0.8237 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4560 - accuracy: 0.7819Epoch 40/40: loss=0.4560, accuracy=0.7819, val_loss=0.3932, val_accuracy=0.8245\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4560 - accuracy: 0.7819 - val_loss: 0.3932 - val_accuracy: 0.8245 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8336092829704285\n",
      "\n",
      "Refined Training Combination 36/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9714 - accuracy: 0.5193Epoch 1/40: loss=0.9709, accuracy=0.5197, val_loss=0.7891, val_accuracy=0.5331\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.9709 - accuracy: 0.5197 - val_loss: 0.7891 - val_accuracy: 0.5331 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8867 - accuracy: 0.5488Epoch 2/40: loss=0.8867, accuracy=0.5488, val_loss=0.8791, val_accuracy=0.4727\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8867 - accuracy: 0.5488 - val_loss: 0.8791 - val_accuracy: 0.4727 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8638 - accuracy: 0.5451Epoch 3/40: loss=0.8655, accuracy=0.5445, val_loss=0.6915, val_accuracy=0.6010\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8655 - accuracy: 0.5445 - val_loss: 0.6915 - val_accuracy: 0.6010 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8451 - accuracy: 0.5489Epoch 4/40: loss=0.8456, accuracy=0.5486, val_loss=0.7142, val_accuracy=0.6084\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8456 - accuracy: 0.5486 - val_loss: 0.7142 - val_accuracy: 0.6084 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.5534Epoch 5/40: loss=0.8288, accuracy=0.5534, val_loss=0.6869, val_accuracy=0.6142\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8288 - accuracy: 0.5534 - val_loss: 0.6869 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7659 - accuracy: 0.5770Epoch 6/40: loss=0.7659, accuracy=0.5770, val_loss=0.8152, val_accuracy=0.5050\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7659 - accuracy: 0.5770 - val_loss: 0.8152 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7789 - accuracy: 0.5757Epoch 7/40: loss=0.7789, accuracy=0.5757, val_loss=0.7440, val_accuracy=0.5869\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7789 - accuracy: 0.5757 - val_loss: 0.7440 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7705 - accuracy: 0.5755Epoch 8/40: loss=0.7703, accuracy=0.5757, val_loss=0.6607, val_accuracy=0.6424\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7703 - accuracy: 0.5757 - val_loss: 0.6607 - val_accuracy: 0.6424 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7318 - accuracy: 0.5906Epoch 9/40: loss=0.7323, accuracy=0.5904, val_loss=0.6750, val_accuracy=0.6060\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7323 - accuracy: 0.5904 - val_loss: 0.6750 - val_accuracy: 0.6060 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7287 - accuracy: 0.5917Epoch 10/40: loss=0.7287, accuracy=0.5917, val_loss=0.7354, val_accuracy=0.5886\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7287 - accuracy: 0.5917 - val_loss: 0.7354 - val_accuracy: 0.5886 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.6163Epoch 11/40: loss=0.6881, accuracy=0.6165, val_loss=0.7962, val_accuracy=0.5315\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6881 - accuracy: 0.6165 - val_loss: 0.7962 - val_accuracy: 0.5315 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.6018Epoch 12/40: loss=0.6958, accuracy=0.6018, val_loss=0.9189, val_accuracy=0.4445\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6958 - accuracy: 0.6018 - val_loss: 0.9189 - val_accuracy: 0.4445 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.6381\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 13/40: loss=0.6587, accuracy=0.6380, val_loss=0.7358, val_accuracy=0.5770\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6587 - accuracy: 0.6380 - val_loss: 0.7358 - val_accuracy: 0.5770 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6342 - accuracy: 0.6571Epoch 14/40: loss=0.6341, accuracy=0.6571, val_loss=0.6767, val_accuracy=0.6151\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6341 - accuracy: 0.6571 - val_loss: 0.6767 - val_accuracy: 0.6151 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6156 - accuracy: 0.6647Epoch 15/40: loss=0.6149, accuracy=0.6654, val_loss=0.5933, val_accuracy=0.6738\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6149 - accuracy: 0.6654 - val_loss: 0.5933 - val_accuracy: 0.6738 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6162 - accuracy: 0.6673Epoch 16/40: loss=0.6159, accuracy=0.6676, val_loss=0.5962, val_accuracy=0.6871\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6159 - accuracy: 0.6676 - val_loss: 0.5962 - val_accuracy: 0.6871 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.6837Epoch 17/40: loss=0.5926, accuracy=0.6842, val_loss=0.5817, val_accuracy=0.7036\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5926 - accuracy: 0.6842 - val_loss: 0.5817 - val_accuracy: 0.7036 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6046 - accuracy: 0.6742Epoch 18/40: loss=0.6050, accuracy=0.6736, val_loss=0.5904, val_accuracy=0.6821\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6050 - accuracy: 0.6736 - val_loss: 0.5904 - val_accuracy: 0.6821 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.6834Epoch 19/40: loss=0.5926, accuracy=0.6834, val_loss=0.6037, val_accuracy=0.6838\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5926 - accuracy: 0.6834 - val_loss: 0.6037 - val_accuracy: 0.6838 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 0.6994Epoch 20/40: loss=0.5831, accuracy=0.6993, val_loss=0.5850, val_accuracy=0.6937\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5831 - accuracy: 0.6993 - val_loss: 0.5850 - val_accuracy: 0.6937 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.6954Epoch 21/40: loss=0.5866, accuracy=0.6954, val_loss=0.5861, val_accuracy=0.6904\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5866 - accuracy: 0.6954 - val_loss: 0.5861 - val_accuracy: 0.6904 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.6950Epoch 22/40: loss=0.5800, accuracy=0.6950, val_loss=0.5192, val_accuracy=0.7409\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5800 - accuracy: 0.6950 - val_loss: 0.5192 - val_accuracy: 0.7409 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7041Epoch 23/40: loss=0.5792, accuracy=0.7041, val_loss=0.5284, val_accuracy=0.7260\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5792 - accuracy: 0.7041 - val_loss: 0.5284 - val_accuracy: 0.7260 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7016Epoch 24/40: loss=0.5750, accuracy=0.7016, val_loss=0.5995, val_accuracy=0.6829\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5750 - accuracy: 0.7016 - val_loss: 0.5995 - val_accuracy: 0.6829 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5688 - accuracy: 0.7087Epoch 25/40: loss=0.5679, accuracy=0.7094, val_loss=0.5659, val_accuracy=0.7078\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5679 - accuracy: 0.7094 - val_loss: 0.5659 - val_accuracy: 0.7078 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5751 - accuracy: 0.7079Epoch 26/40: loss=0.5758, accuracy=0.7076, val_loss=0.5889, val_accuracy=0.6680\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5758 - accuracy: 0.7076 - val_loss: 0.5889 - val_accuracy: 0.6680 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.7063\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 27/40: loss=0.5596, accuracy=0.7063, val_loss=0.5714, val_accuracy=0.6954\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5596 - accuracy: 0.7063 - val_loss: 0.5714 - val_accuracy: 0.6954 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7152Epoch 28/40: loss=0.5543, accuracy=0.7152, val_loss=0.5788, val_accuracy=0.6937\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5543 - accuracy: 0.7152 - val_loss: 0.5788 - val_accuracy: 0.6937 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.7126Epoch 29/40: loss=0.5539, accuracy=0.7127, val_loss=0.5640, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5539 - accuracy: 0.7127 - val_loss: 0.5640 - val_accuracy: 0.7020 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5528 - accuracy: 0.7172Epoch 30/40: loss=0.5527, accuracy=0.7175, val_loss=0.5725, val_accuracy=0.6970\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5527 - accuracy: 0.7175 - val_loss: 0.5725 - val_accuracy: 0.6970 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7182Epoch 31/40: loss=0.5583, accuracy=0.7181, val_loss=0.5656, val_accuracy=0.7045\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5583 - accuracy: 0.7181 - val_loss: 0.5656 - val_accuracy: 0.7045 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7179\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.5566, accuracy=0.7179, val_loss=0.5620, val_accuracy=0.7094\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5566 - accuracy: 0.7179 - val_loss: 0.5620 - val_accuracy: 0.7094 - lr: 4.0000e-06\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.7408940196037292\n",
      "\n",
      "Refined Training Combination 37/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1252 - accuracy: 0.5201Epoch 1/40: loss=1.1249, accuracy=0.5201, val_loss=0.8586, val_accuracy=0.4578\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 1.1249 - accuracy: 0.5201 - val_loss: 0.8586 - val_accuracy: 0.4578 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8867 - accuracy: 0.5310Epoch 2/40: loss=0.8867, accuracy=0.5310, val_loss=1.0214, val_accuracy=0.4073\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8867 - accuracy: 0.5310 - val_loss: 1.0214 - val_accuracy: 0.4073 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8134 - accuracy: 0.5720Epoch 3/40: loss=0.8132, accuracy=0.5728, val_loss=1.1243, val_accuracy=0.4967\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8132 - accuracy: 0.5728 - val_loss: 1.1243 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7578 - accuracy: 0.6076Epoch 4/40: loss=0.7578, accuracy=0.6076, val_loss=0.7897, val_accuracy=0.5488\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7578 - accuracy: 0.6076 - val_loss: 0.7897 - val_accuracy: 0.5488 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.6045Epoch 5/40: loss=0.7538, accuracy=0.6045, val_loss=0.8866, val_accuracy=0.6233\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7538 - accuracy: 0.6045 - val_loss: 0.8866 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7752 - accuracy: 0.5864Epoch 6/40: loss=0.7751, accuracy=0.5867, val_loss=0.8103, val_accuracy=0.5397\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7751 - accuracy: 0.5867 - val_loss: 0.8103 - val_accuracy: 0.5397 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7595 - accuracy: 0.5883Epoch 7/40: loss=0.7594, accuracy=0.5880, val_loss=0.7620, val_accuracy=0.6018\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7594 - accuracy: 0.5880 - val_loss: 0.7620 - val_accuracy: 0.6018 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7430 - accuracy: 0.6119Epoch 8/40: loss=0.7440, accuracy=0.6113, val_loss=0.9202, val_accuracy=0.4040\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7440 - accuracy: 0.6113 - val_loss: 0.9202 - val_accuracy: 0.4040 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8122 - accuracy: 0.5381Epoch 9/40: loss=0.8120, accuracy=0.5381, val_loss=0.9132, val_accuracy=0.4669\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8120 - accuracy: 0.5381 - val_loss: 0.9132 - val_accuracy: 0.4669 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8101 - accuracy: 0.5454Epoch 10/40: loss=0.8106, accuracy=0.5451, val_loss=0.7475, val_accuracy=0.4917\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8106 - accuracy: 0.5451 - val_loss: 0.7475 - val_accuracy: 0.4917 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8060 - accuracy: 0.5289Epoch 11/40: loss=0.8064, accuracy=0.5284, val_loss=0.7525, val_accuracy=0.4288\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.8064 - accuracy: 0.5284 - val_loss: 0.7525 - val_accuracy: 0.4288 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8045 - accuracy: 0.5046Epoch 12/40: loss=0.8047, accuracy=0.5048, val_loss=0.7771, val_accuracy=0.4437\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8047 - accuracy: 0.5048 - val_loss: 0.7771 - val_accuracy: 0.4437 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7897 - accuracy: 0.5044Epoch 13/40: loss=0.7895, accuracy=0.5048, val_loss=0.6873, val_accuracy=0.5232\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7895 - accuracy: 0.5048 - val_loss: 0.6873 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7976 - accuracy: 0.4906Epoch 14/40: loss=0.7970, accuracy=0.4911, val_loss=0.7690, val_accuracy=0.4801\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7970 - accuracy: 0.4911 - val_loss: 0.7690 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8066 - accuracy: 0.4735Epoch 15/40: loss=0.8066, accuracy=0.4735, val_loss=0.7604, val_accuracy=0.5281\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8066 - accuracy: 0.4735 - val_loss: 0.7604 - val_accuracy: 0.5281 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8198 - accuracy: 0.5118Epoch 16/40: loss=0.8201, accuracy=0.5112, val_loss=0.7552, val_accuracy=0.5182\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8201 - accuracy: 0.5112 - val_loss: 0.7552 - val_accuracy: 0.5182 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8017 - accuracy: 0.5052Epoch 17/40: loss=0.8017, accuracy=0.5052, val_loss=0.7316, val_accuracy=0.5695\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8017 - accuracy: 0.5052 - val_loss: 0.7316 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7996 - accuracy: 0.5008\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/40: loss=0.7998, accuracy=0.5000, val_loss=0.9102, val_accuracy=0.4909\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7998 - accuracy: 0.5000 - val_loss: 0.9102 - val_accuracy: 0.4909 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.5021Epoch 19/40: loss=0.7447, accuracy=0.5019, val_loss=0.6882, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7447 - accuracy: 0.5019 - val_loss: 0.6882 - val_accuracy: 0.5977 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.4981Epoch 20/40: loss=0.7357, accuracy=0.4981, val_loss=0.6919, val_accuracy=0.5555\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7357 - accuracy: 0.4981 - val_loss: 0.6919 - val_accuracy: 0.5555 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7317 - accuracy: 0.4938Epoch 21/40: loss=0.7317, accuracy=0.4936, val_loss=0.6990, val_accuracy=0.5281\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7317 - accuracy: 0.4936 - val_loss: 0.6990 - val_accuracy: 0.5281 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7331 - accuracy: 0.4946Epoch 22/40: loss=0.7334, accuracy=0.4946, val_loss=0.7223, val_accuracy=0.5373\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7334 - accuracy: 0.4946 - val_loss: 0.7223 - val_accuracy: 0.5373 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7261 - accuracy: 0.4983\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 23/40: loss=0.7267, accuracy=0.4971, val_loss=0.6896, val_accuracy=0.5621\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7267 - accuracy: 0.4971 - val_loss: 0.6896 - val_accuracy: 0.5621 - lr: 2.0000e-04\n",
      "Epoch 23: early stopping\n",
      "Validation accuracy: 0.623344361782074\n",
      "\n",
      "Refined Training Combination 38/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0933 - accuracy: 0.5154Epoch 1/40: loss=1.0930, accuracy=0.5149, val_loss=0.8690, val_accuracy=0.4710\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 1.0930 - accuracy: 0.5149 - val_loss: 0.8690 - val_accuracy: 0.4710 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8391 - accuracy: 0.5469Epoch 2/40: loss=0.8385, accuracy=0.5472, val_loss=0.7868, val_accuracy=0.5712\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8385 - accuracy: 0.5472 - val_loss: 0.7868 - val_accuracy: 0.5712 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7384 - accuracy: 0.5926Epoch 3/40: loss=0.7377, accuracy=0.5931, val_loss=1.1684, val_accuracy=0.4851\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7377 - accuracy: 0.5931 - val_loss: 1.1684 - val_accuracy: 0.4851 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6987 - accuracy: 0.6238Epoch 4/40: loss=0.6989, accuracy=0.6236, val_loss=0.6570, val_accuracy=0.6267\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6989 - accuracy: 0.6236 - val_loss: 0.6570 - val_accuracy: 0.6267 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.6395Epoch 5/40: loss=0.6880, accuracy=0.6397, val_loss=0.7981, val_accuracy=0.5430\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6880 - accuracy: 0.6397 - val_loss: 0.7981 - val_accuracy: 0.5430 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6556 - accuracy: 0.6640Epoch 6/40: loss=0.6551, accuracy=0.6641, val_loss=0.6912, val_accuracy=0.5828\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6551 - accuracy: 0.6641 - val_loss: 0.6912 - val_accuracy: 0.5828 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.6989Epoch 7/40: loss=0.6102, accuracy=0.6989, val_loss=0.6069, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6102 - accuracy: 0.6989 - val_loss: 0.6069 - val_accuracy: 0.6879 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5834 - accuracy: 0.7086Epoch 8/40: loss=0.5834, accuracy=0.7086, val_loss=0.5795, val_accuracy=0.6788\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5834 - accuracy: 0.7086 - val_loss: 0.5795 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5869 - accuracy: 0.7163Epoch 9/40: loss=0.5878, accuracy=0.7154, val_loss=0.6793, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5878 - accuracy: 0.7154 - val_loss: 0.6793 - val_accuracy: 0.5960 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.7130Epoch 10/40: loss=0.5947, accuracy=0.7130, val_loss=0.6045, val_accuracy=0.7061\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5947 - accuracy: 0.7130 - val_loss: 0.6045 - val_accuracy: 0.7061 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5852 - accuracy: 0.7125Epoch 11/40: loss=0.5851, accuracy=0.7127, val_loss=1.0642, val_accuracy=0.4429\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5851 - accuracy: 0.7127 - val_loss: 1.0642 - val_accuracy: 0.4429 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.7098Epoch 12/40: loss=0.5936, accuracy=0.7096, val_loss=0.7342, val_accuracy=0.6358\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5936 - accuracy: 0.7096 - val_loss: 0.7342 - val_accuracy: 0.6358 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5855 - accuracy: 0.7173Epoch 13/40: loss=0.5858, accuracy=0.7167, val_loss=0.5770, val_accuracy=0.6714\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5858 - accuracy: 0.7167 - val_loss: 0.5770 - val_accuracy: 0.6714 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6142 - accuracy: 0.7046Epoch 14/40: loss=0.6149, accuracy=0.7043, val_loss=0.5221, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6149 - accuracy: 0.7043 - val_loss: 0.5221 - val_accuracy: 0.7599 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6147 - accuracy: 0.6972Epoch 15/40: loss=0.6142, accuracy=0.6972, val_loss=0.6720, val_accuracy=0.6267\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6142 - accuracy: 0.6972 - val_loss: 0.6720 - val_accuracy: 0.6267 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.6957Epoch 16/40: loss=0.6124, accuracy=0.6958, val_loss=0.8425, val_accuracy=0.5389\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6124 - accuracy: 0.6958 - val_loss: 0.8425 - val_accuracy: 0.5389 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5863 - accuracy: 0.7236Epoch 17/40: loss=0.5868, accuracy=0.7229, val_loss=0.6346, val_accuracy=0.6382\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5868 - accuracy: 0.7229 - val_loss: 0.6346 - val_accuracy: 0.6382 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.7043Epoch 18/40: loss=0.6073, accuracy=0.7043, val_loss=0.6108, val_accuracy=0.6772\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6073 - accuracy: 0.7043 - val_loss: 0.6108 - val_accuracy: 0.6772 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.6952\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 19/40: loss=0.6127, accuracy=0.6950, val_loss=1.0924, val_accuracy=0.4321\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6127 - accuracy: 0.6950 - val_loss: 1.0924 - val_accuracy: 0.4321 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5705 - accuracy: 0.7176Epoch 20/40: loss=0.5698, accuracy=0.7183, val_loss=0.4661, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5698 - accuracy: 0.7183 - val_loss: 0.4661 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.7600Epoch 21/40: loss=0.5124, accuracy=0.7601, val_loss=0.4306, val_accuracy=0.7972\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5124 - accuracy: 0.7601 - val_loss: 0.4306 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.7774Epoch 22/40: loss=0.4737, accuracy=0.7773, val_loss=0.3824, val_accuracy=0.8435\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4737 - accuracy: 0.7773 - val_loss: 0.3824 - val_accuracy: 0.8435 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7972Epoch 23/40: loss=0.4563, accuracy=0.7972, val_loss=0.3645, val_accuracy=0.8502\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4563 - accuracy: 0.7972 - val_loss: 0.3645 - val_accuracy: 0.8502 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8185Epoch 24/40: loss=0.4130, accuracy=0.8185, val_loss=0.3560, val_accuracy=0.8419\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4130 - accuracy: 0.8185 - val_loss: 0.3560 - val_accuracy: 0.8419 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.8307Epoch 25/40: loss=0.3986, accuracy=0.8307, val_loss=0.3075, val_accuracy=0.8758\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3986 - accuracy: 0.8307 - val_loss: 0.3075 - val_accuracy: 0.8758 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3452 - accuracy: 0.8511Epoch 26/40: loss=0.3445, accuracy=0.8514, val_loss=0.2672, val_accuracy=0.8907\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.3445 - accuracy: 0.8514 - val_loss: 0.2672 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8625Epoch 27/40: loss=0.3265, accuracy=0.8624, val_loss=0.3057, val_accuracy=0.8651\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3265 - accuracy: 0.8624 - val_loss: 0.3057 - val_accuracy: 0.8651 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8636Epoch 28/40: loss=0.3193, accuracy=0.8636, val_loss=0.2820, val_accuracy=0.8659\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3193 - accuracy: 0.8636 - val_loss: 0.2820 - val_accuracy: 0.8659 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2895 - accuracy: 0.8835Epoch 29/40: loss=0.2916, accuracy=0.8833, val_loss=0.2968, val_accuracy=0.8882\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2916 - accuracy: 0.8833 - val_loss: 0.2968 - val_accuracy: 0.8882 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.8872Epoch 30/40: loss=0.2761, accuracy=0.8872, val_loss=0.2740, val_accuracy=0.8767\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2761 - accuracy: 0.8872 - val_loss: 0.2740 - val_accuracy: 0.8767 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2578 - accuracy: 0.8964\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 31/40: loss=0.2582, accuracy=0.8963, val_loss=0.4062, val_accuracy=0.8154\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.2582 - accuracy: 0.8963 - val_loss: 0.4062 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9227Epoch 32/40: loss=0.2082, accuracy=0.9228, val_loss=0.0870, val_accuracy=0.9801\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2082 - accuracy: 0.9228 - val_loss: 0.0870 - val_accuracy: 0.9801 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9319Epoch 33/40: loss=0.1714, accuracy=0.9321, val_loss=0.0789, val_accuracy=0.9818\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.1714 - accuracy: 0.9321 - val_loss: 0.0789 - val_accuracy: 0.9818 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9345Epoch 34/40: loss=0.1831, accuracy=0.9346, val_loss=0.0655, val_accuracy=0.9892\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.1831 - accuracy: 0.9346 - val_loss: 0.0655 - val_accuracy: 0.9892 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9361Epoch 35/40: loss=0.1736, accuracy=0.9361, val_loss=0.0524, val_accuracy=0.9909\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.1736 - accuracy: 0.9361 - val_loss: 0.0524 - val_accuracy: 0.9909 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9427Epoch 36/40: loss=0.1628, accuracy=0.9423, val_loss=0.0547, val_accuracy=0.9892\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.1628 - accuracy: 0.9423 - val_loss: 0.0547 - val_accuracy: 0.9892 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9517Epoch 37/40: loss=0.1357, accuracy=0.9518, val_loss=0.0400, val_accuracy=0.9925\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 0.0400 - val_accuracy: 0.9925 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9570Epoch 38/40: loss=0.1287, accuracy=0.9567, val_loss=0.0357, val_accuracy=0.9950\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.1287 - accuracy: 0.9567 - val_loss: 0.0357 - val_accuracy: 0.9950 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9460Epoch 39/40: loss=0.1482, accuracy=0.9460, val_loss=0.0376, val_accuracy=0.9909\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.1482 - accuracy: 0.9460 - val_loss: 0.0376 - val_accuracy: 0.9909 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9529Epoch 40/40: loss=0.1334, accuracy=0.9530, val_loss=0.0505, val_accuracy=0.9876\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.1334 - accuracy: 0.9530 - val_loss: 0.0505 - val_accuracy: 0.9876 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.9950330853462219\n",
      "Model with validation accuracy 0.9950330853462219 saved to best_refined_model.h5\n",
      "\n",
      "Refined Training Combination 39/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1145 - accuracy: 0.4990Epoch 1/40: loss=1.1138, accuracy=0.4990, val_loss=0.8104, val_accuracy=0.5364\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.1138 - accuracy: 0.4990 - val_loss: 0.8104 - val_accuracy: 0.5364 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.5251Epoch 2/40: loss=0.8476, accuracy=0.5248, val_loss=0.8373, val_accuracy=0.5546\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8476 - accuracy: 0.5248 - val_loss: 0.8373 - val_accuracy: 0.5546 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8051 - accuracy: 0.5357Epoch 3/40: loss=0.8050, accuracy=0.5354, val_loss=0.7086, val_accuracy=0.5869\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8050 - accuracy: 0.5354 - val_loss: 0.7086 - val_accuracy: 0.5869 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7703 - accuracy: 0.5448Epoch 4/40: loss=0.7702, accuracy=0.5449, val_loss=0.7344, val_accuracy=0.5596\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7702 - accuracy: 0.5449 - val_loss: 0.7344 - val_accuracy: 0.5596 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7205 - accuracy: 0.5827Epoch 5/40: loss=0.7202, accuracy=0.5828, val_loss=0.9418, val_accuracy=0.5778\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7202 - accuracy: 0.5828 - val_loss: 0.9418 - val_accuracy: 0.5778 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7017 - accuracy: 0.6146Epoch 6/40: loss=0.7013, accuracy=0.6149, val_loss=0.6258, val_accuracy=0.6507\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7013 - accuracy: 0.6149 - val_loss: 0.6258 - val_accuracy: 0.6507 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.6441Epoch 7/40: loss=0.6681, accuracy=0.6432, val_loss=0.7143, val_accuracy=0.4156\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6681 - accuracy: 0.6432 - val_loss: 0.7143 - val_accuracy: 0.4156 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6792 - accuracy: 0.6215Epoch 8/40: loss=0.6791, accuracy=0.6211, val_loss=0.6797, val_accuracy=0.5753\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6791 - accuracy: 0.6211 - val_loss: 0.6797 - val_accuracy: 0.5753 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6760 - accuracy: 0.6358Epoch 9/40: loss=0.6755, accuracy=0.6360, val_loss=0.7195, val_accuracy=0.6523\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6755 - accuracy: 0.6360 - val_loss: 0.7195 - val_accuracy: 0.6523 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.6395Epoch 10/40: loss=0.6769, accuracy=0.6391, val_loss=0.7127, val_accuracy=0.5753\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6769 - accuracy: 0.6391 - val_loss: 0.7127 - val_accuracy: 0.5753 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.6362\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/40: loss=0.6801, accuracy=0.6362, val_loss=0.7281, val_accuracy=0.5704\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6801 - accuracy: 0.6362 - val_loss: 0.7281 - val_accuracy: 0.5704 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.6807Epoch 12/40: loss=0.6108, accuracy=0.6807, val_loss=0.7171, val_accuracy=0.5836\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6108 - accuracy: 0.6807 - val_loss: 0.7171 - val_accuracy: 0.5836 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.7028Epoch 13/40: loss=0.5899, accuracy=0.7022, val_loss=0.6046, val_accuracy=0.6738\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5899 - accuracy: 0.7022 - val_loss: 0.6046 - val_accuracy: 0.6738 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.7087Epoch 14/40: loss=0.5806, accuracy=0.7088, val_loss=0.5105, val_accuracy=0.7649\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5806 - accuracy: 0.7088 - val_loss: 0.5105 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5812 - accuracy: 0.7029Epoch 15/40: loss=0.5814, accuracy=0.7028, val_loss=0.6486, val_accuracy=0.6374\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5814 - accuracy: 0.7028 - val_loss: 0.6486 - val_accuracy: 0.6374 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.6927Epoch 16/40: loss=0.5933, accuracy=0.6927, val_loss=0.6848, val_accuracy=0.6118\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5933 - accuracy: 0.6927 - val_loss: 0.6848 - val_accuracy: 0.6118 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7099Epoch 17/40: loss=0.5672, accuracy=0.7099, val_loss=0.6293, val_accuracy=0.6416\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5672 - accuracy: 0.7099 - val_loss: 0.6293 - val_accuracy: 0.6416 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.7130Epoch 18/40: loss=0.5643, accuracy=0.7130, val_loss=0.6442, val_accuracy=0.6647\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5643 - accuracy: 0.7130 - val_loss: 0.6442 - val_accuracy: 0.6647 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5638 - accuracy: 0.7114\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.5637, accuracy=0.7117, val_loss=0.8453, val_accuracy=0.5596\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5637 - accuracy: 0.7117 - val_loss: 0.8453 - val_accuracy: 0.5596 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7173Epoch 20/40: loss=0.5502, accuracy=0.7173, val_loss=0.5525, val_accuracy=0.7103\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5502 - accuracy: 0.7173 - val_loss: 0.5525 - val_accuracy: 0.7103 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.7357Epoch 21/40: loss=0.5323, accuracy=0.7357, val_loss=0.5859, val_accuracy=0.6896\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5323 - accuracy: 0.7357 - val_loss: 0.5859 - val_accuracy: 0.6896 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7365Epoch 22/40: loss=0.5318, accuracy=0.7365, val_loss=0.5873, val_accuracy=0.7053\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5318 - accuracy: 0.7365 - val_loss: 0.5873 - val_accuracy: 0.7053 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5299 - accuracy: 0.7382Epoch 23/40: loss=0.5301, accuracy=0.7382, val_loss=0.5442, val_accuracy=0.7301\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5301 - accuracy: 0.7382 - val_loss: 0.5442 - val_accuracy: 0.7301 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.7378\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.5286, accuracy=0.7378, val_loss=0.5123, val_accuracy=0.7409\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5286 - accuracy: 0.7378 - val_loss: 0.5123 - val_accuracy: 0.7409 - lr: 2.0000e-05\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.7649006843566895\n",
      "\n",
      "Refined Training Combination 40/50: num_residual_blocks=9, dropout_rate=0.45, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.5, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0981 - accuracy: 0.5176Epoch 1/40: loss=1.0978, accuracy=0.5176, val_loss=1.1202, val_accuracy=0.4901\n",
      "604/604 [==============================] - 16s 22ms/step - loss: 1.0978 - accuracy: 0.5176 - val_loss: 1.1202 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8767 - accuracy: 0.5240Epoch 2/40: loss=0.8768, accuracy=0.5240, val_loss=0.7394, val_accuracy=0.6118\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8768 - accuracy: 0.5240 - val_loss: 0.7394 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8196 - accuracy: 0.5541Epoch 3/40: loss=0.8196, accuracy=0.5536, val_loss=0.6571, val_accuracy=0.6225\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8196 - accuracy: 0.5536 - val_loss: 0.6571 - val_accuracy: 0.6225 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8136 - accuracy: 0.5638Epoch 4/40: loss=0.8139, accuracy=0.5633, val_loss=0.8242, val_accuracy=0.5621\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8139 - accuracy: 0.5633 - val_loss: 0.8242 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8009 - accuracy: 0.5705Epoch 5/40: loss=0.8008, accuracy=0.5704, val_loss=0.7533, val_accuracy=0.4776\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8008 - accuracy: 0.5704 - val_loss: 0.7533 - val_accuracy: 0.4776 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7870 - accuracy: 0.5529Epoch 6/40: loss=0.7867, accuracy=0.5530, val_loss=0.6789, val_accuracy=0.6076\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7867 - accuracy: 0.5530 - val_loss: 0.6789 - val_accuracy: 0.6076 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7538 - accuracy: 0.5857Epoch 7/40: loss=0.7537, accuracy=0.5861, val_loss=0.6943, val_accuracy=0.6159\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7537 - accuracy: 0.5861 - val_loss: 0.6943 - val_accuracy: 0.6159 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7640 - accuracy: 0.5983\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.7641, accuracy=0.5983, val_loss=0.8161, val_accuracy=0.5778\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7641 - accuracy: 0.5983 - val_loss: 0.8161 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.6047Epoch 9/40: loss=0.7071, accuracy=0.6047, val_loss=0.6284, val_accuracy=0.6465\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7071 - accuracy: 0.6047 - val_loss: 0.6284 - val_accuracy: 0.6465 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.6533Epoch 10/40: loss=0.6545, accuracy=0.6531, val_loss=0.5817, val_accuracy=0.7003\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6545 - accuracy: 0.6531 - val_loss: 0.5817 - val_accuracy: 0.7003 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.6798Epoch 11/40: loss=0.6287, accuracy=0.6798, val_loss=0.9484, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6287 - accuracy: 0.6798 - val_loss: 0.9484 - val_accuracy: 0.5985 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.6839Epoch 12/40: loss=0.6065, accuracy=0.6842, val_loss=0.5920, val_accuracy=0.7028\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6065 - accuracy: 0.6842 - val_loss: 0.5920 - val_accuracy: 0.7028 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.7014Epoch 13/40: loss=0.5915, accuracy=0.7016, val_loss=0.5537, val_accuracy=0.7136\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5915 - accuracy: 0.7016 - val_loss: 0.5537 - val_accuracy: 0.7136 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5960 - accuracy: 0.7018Epoch 14/40: loss=0.5960, accuracy=0.7020, val_loss=0.5050, val_accuracy=0.7434\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5960 - accuracy: 0.7020 - val_loss: 0.5050 - val_accuracy: 0.7434 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.7181Epoch 15/40: loss=0.5614, accuracy=0.7181, val_loss=0.5033, val_accuracy=0.7624\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5614 - accuracy: 0.7181 - val_loss: 0.5033 - val_accuracy: 0.7624 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.7224Epoch 16/40: loss=0.5541, accuracy=0.7229, val_loss=0.5043, val_accuracy=0.7591\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5541 - accuracy: 0.7229 - val_loss: 0.5043 - val_accuracy: 0.7591 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5465 - accuracy: 0.7299Epoch 17/40: loss=0.5460, accuracy=0.7301, val_loss=0.5573, val_accuracy=0.7293\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5460 - accuracy: 0.7301 - val_loss: 0.5573 - val_accuracy: 0.7293 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7463Epoch 18/40: loss=0.5288, accuracy=0.7463, val_loss=0.5103, val_accuracy=0.7533\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5288 - accuracy: 0.7463 - val_loss: 0.5103 - val_accuracy: 0.7533 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.7471Epoch 19/40: loss=0.5241, accuracy=0.7471, val_loss=0.5280, val_accuracy=0.7517\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5241 - accuracy: 0.7471 - val_loss: 0.5280 - val_accuracy: 0.7517 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.7473\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 20/40: loss=0.5210, accuracy=0.7475, val_loss=0.9151, val_accuracy=0.6267\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5210 - accuracy: 0.7475 - val_loss: 0.9151 - val_accuracy: 0.6267 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5047 - accuracy: 0.7568Epoch 21/40: loss=0.5049, accuracy=0.7568, val_loss=0.4180, val_accuracy=0.8005\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5049 - accuracy: 0.7568 - val_loss: 0.4180 - val_accuracy: 0.8005 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.7753Epoch 22/40: loss=0.4805, accuracy=0.7755, val_loss=0.4693, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4805 - accuracy: 0.7755 - val_loss: 0.4693 - val_accuracy: 0.7773 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.7888Epoch 23/40: loss=0.4615, accuracy=0.7885, val_loss=0.4274, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4615 - accuracy: 0.7885 - val_loss: 0.4274 - val_accuracy: 0.8129 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.7850Epoch 24/40: loss=0.4617, accuracy=0.7854, val_loss=0.4128, val_accuracy=0.8071\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4617 - accuracy: 0.7854 - val_loss: 0.4128 - val_accuracy: 0.8071 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.7899Epoch 25/40: loss=0.4453, accuracy=0.7899, val_loss=0.4224, val_accuracy=0.8154\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4224 - val_accuracy: 0.8154 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.7986Epoch 26/40: loss=0.4437, accuracy=0.7986, val_loss=0.4082, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4437 - accuracy: 0.7986 - val_loss: 0.4082 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.7982Epoch 27/40: loss=0.4440, accuracy=0.7978, val_loss=0.3947, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4440 - accuracy: 0.7978 - val_loss: 0.3947 - val_accuracy: 0.8204 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8077Epoch 28/40: loss=0.4366, accuracy=0.8077, val_loss=0.4100, val_accuracy=0.8171\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4366 - accuracy: 0.8077 - val_loss: 0.4100 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.8027Epoch 29/40: loss=0.4278, accuracy=0.8026, val_loss=0.4006, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4278 - accuracy: 0.8026 - val_loss: 0.4006 - val_accuracy: 0.8063 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.8115Epoch 30/40: loss=0.4141, accuracy=0.8115, val_loss=0.3967, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4141 - accuracy: 0.8115 - val_loss: 0.3967 - val_accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8088Epoch 31/40: loss=0.4229, accuracy=0.8088, val_loss=0.3665, val_accuracy=0.8369\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4229 - accuracy: 0.8088 - val_loss: 0.3665 - val_accuracy: 0.8369 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.8132Epoch 32/40: loss=0.4137, accuracy=0.8131, val_loss=0.4223, val_accuracy=0.7964\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4137 - accuracy: 0.8131 - val_loss: 0.4223 - val_accuracy: 0.7964 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.8070Epoch 33/40: loss=0.4221, accuracy=0.8067, val_loss=0.3628, val_accuracy=0.8344\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4221 - accuracy: 0.8067 - val_loss: 0.3628 - val_accuracy: 0.8344 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8179Epoch 34/40: loss=0.4049, accuracy=0.8181, val_loss=0.3429, val_accuracy=0.8469\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4049 - accuracy: 0.8181 - val_loss: 0.3429 - val_accuracy: 0.8469 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8202Epoch 35/40: loss=0.3916, accuracy=0.8202, val_loss=0.3689, val_accuracy=0.8435\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3916 - accuracy: 0.8202 - val_loss: 0.3689 - val_accuracy: 0.8435 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8271Epoch 36/40: loss=0.3848, accuracy=0.8272, val_loss=0.4027, val_accuracy=0.8228\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3848 - accuracy: 0.8272 - val_loss: 0.4027 - val_accuracy: 0.8228 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3999 - accuracy: 0.8163Epoch 37/40: loss=0.3995, accuracy=0.8164, val_loss=0.4008, val_accuracy=0.8212\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3995 - accuracy: 0.8164 - val_loss: 0.4008 - val_accuracy: 0.8212 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8279Epoch 38/40: loss=0.3893, accuracy=0.8276, val_loss=0.3392, val_accuracy=0.8535\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3893 - accuracy: 0.8276 - val_loss: 0.3392 - val_accuracy: 0.8535 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8340Epoch 39/40: loss=0.3792, accuracy=0.8334, val_loss=0.3464, val_accuracy=0.8584\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3792 - accuracy: 0.8334 - val_loss: 0.3464 - val_accuracy: 0.8584 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8267Epoch 40/40: loss=0.3809, accuracy=0.8270, val_loss=0.4297, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3809 - accuracy: 0.8270 - val_loss: 0.4297 - val_accuracy: 0.7839 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.8584437370300293\n",
      "\n",
      "Refined Training Combination 41/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1136 - accuracy: 0.5075Epoch 1/40: loss=1.1136, accuracy=0.5075, val_loss=0.7484, val_accuracy=0.4950\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 1.1136 - accuracy: 0.5075 - val_loss: 0.7484 - val_accuracy: 0.4950 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8443 - accuracy: 0.5321Epoch 2/40: loss=0.8443, accuracy=0.5321, val_loss=0.9254, val_accuracy=0.5786\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8443 - accuracy: 0.5321 - val_loss: 0.9254 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8415 - accuracy: 0.5305Epoch 3/40: loss=0.8422, accuracy=0.5302, val_loss=0.9489, val_accuracy=0.4661\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8422 - accuracy: 0.5302 - val_loss: 0.9489 - val_accuracy: 0.4661 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8331 - accuracy: 0.5253Epoch 4/40: loss=0.8331, accuracy=0.5252, val_loss=0.6834, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8331 - accuracy: 0.5252 - val_loss: 0.6834 - val_accuracy: 0.5579 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8097 - accuracy: 0.5550Epoch 5/40: loss=0.8097, accuracy=0.5550, val_loss=0.7123, val_accuracy=0.6060\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8097 - accuracy: 0.5550 - val_loss: 0.7123 - val_accuracy: 0.6060 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7708 - accuracy: 0.5772Epoch 6/40: loss=0.7715, accuracy=0.5766, val_loss=1.1454, val_accuracy=0.4305\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7715 - accuracy: 0.5766 - val_loss: 1.1454 - val_accuracy: 0.4305 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8109 - accuracy: 0.5162Epoch 7/40: loss=0.8105, accuracy=0.5159, val_loss=0.8843, val_accuracy=0.4503\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.8105 - accuracy: 0.5159 - val_loss: 0.8843 - val_accuracy: 0.4503 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7877 - accuracy: 0.5037Epoch 8/40: loss=0.7880, accuracy=0.5035, val_loss=0.8263, val_accuracy=0.3998\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7880 - accuracy: 0.5035 - val_loss: 0.8263 - val_accuracy: 0.3998 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.5197\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/40: loss=0.8014, accuracy=0.5197, val_loss=0.6949, val_accuracy=0.5166\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8014 - accuracy: 0.5197 - val_loss: 0.6949 - val_accuracy: 0.5166 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.5135Epoch 10/40: loss=0.7368, accuracy=0.5135, val_loss=0.6750, val_accuracy=0.5886\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7368 - accuracy: 0.5135 - val_loss: 0.6750 - val_accuracy: 0.5886 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7161 - accuracy: 0.5448Epoch 11/40: loss=0.7161, accuracy=0.5449, val_loss=0.6822, val_accuracy=0.5621\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7161 - accuracy: 0.5449 - val_loss: 0.6822 - val_accuracy: 0.5621 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.5631Epoch 12/40: loss=0.7055, accuracy=0.5631, val_loss=0.7361, val_accuracy=0.4644\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7055 - accuracy: 0.5631 - val_loss: 0.7361 - val_accuracy: 0.4644 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6986 - accuracy: 0.5869Epoch 13/40: loss=0.6992, accuracy=0.5865, val_loss=0.6606, val_accuracy=0.6184\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6992 - accuracy: 0.5865 - val_loss: 0.6606 - val_accuracy: 0.6184 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.5982Epoch 14/40: loss=0.6829, accuracy=0.5981, val_loss=0.8368, val_accuracy=0.4371\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6829 - accuracy: 0.5981 - val_loss: 0.8368 - val_accuracy: 0.4371 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.6376Epoch 15/40: loss=0.6541, accuracy=0.6374, val_loss=0.7416, val_accuracy=0.4983\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6541 - accuracy: 0.6374 - val_loss: 0.7416 - val_accuracy: 0.4983 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6407 - accuracy: 0.6424Epoch 16/40: loss=0.6408, accuracy=0.6422, val_loss=0.5606, val_accuracy=0.7094\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6408 - accuracy: 0.6422 - val_loss: 0.5606 - val_accuracy: 0.7094 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6252 - accuracy: 0.6607Epoch 17/40: loss=0.6250, accuracy=0.6606, val_loss=0.6305, val_accuracy=0.6829\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6250 - accuracy: 0.6606 - val_loss: 0.6305 - val_accuracy: 0.6829 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6343 - accuracy: 0.6543Epoch 18/40: loss=0.6345, accuracy=0.6542, val_loss=0.7686, val_accuracy=0.5306\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6345 - accuracy: 0.6542 - val_loss: 0.7686 - val_accuracy: 0.5306 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.6842Epoch 19/40: loss=0.6132, accuracy=0.6838, val_loss=1.0354, val_accuracy=0.4263\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6132 - accuracy: 0.6838 - val_loss: 1.0354 - val_accuracy: 0.4263 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5988 - accuracy: 0.6872Epoch 20/40: loss=0.5993, accuracy=0.6867, val_loss=0.5340, val_accuracy=0.7483\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5993 - accuracy: 0.6867 - val_loss: 0.5340 - val_accuracy: 0.7483 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5937 - accuracy: 0.6896Epoch 21/40: loss=0.5929, accuracy=0.6900, val_loss=0.6960, val_accuracy=0.6184\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5929 - accuracy: 0.6900 - val_loss: 0.6960 - val_accuracy: 0.6184 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5861 - accuracy: 0.6952Epoch 22/40: loss=0.5861, accuracy=0.6952, val_loss=0.7272, val_accuracy=0.6283\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5861 - accuracy: 0.6952 - val_loss: 0.7272 - val_accuracy: 0.6283 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5893 - accuracy: 0.6927Epoch 23/40: loss=0.5890, accuracy=0.6931, val_loss=0.8089, val_accuracy=0.5008\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5890 - accuracy: 0.6931 - val_loss: 0.8089 - val_accuracy: 0.5008 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6048 - accuracy: 0.6871Epoch 24/40: loss=0.6057, accuracy=0.6871, val_loss=0.5388, val_accuracy=0.7318\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6057 - accuracy: 0.6871 - val_loss: 0.5388 - val_accuracy: 0.7318 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.6860\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/40: loss=0.5939, accuracy=0.6867, val_loss=0.5498, val_accuracy=0.7061\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5939 - accuracy: 0.6867 - val_loss: 0.5498 - val_accuracy: 0.7061 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5644 - accuracy: 0.7123Epoch 26/40: loss=0.5647, accuracy=0.7121, val_loss=0.5470, val_accuracy=0.7136\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5647 - accuracy: 0.7121 - val_loss: 0.5470 - val_accuracy: 0.7136 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5600 - accuracy: 0.7175Epoch 27/40: loss=0.5600, accuracy=0.7173, val_loss=0.5308, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5600 - accuracy: 0.7173 - val_loss: 0.5308 - val_accuracy: 0.7459 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5542 - accuracy: 0.7150Epoch 28/40: loss=0.5539, accuracy=0.7152, val_loss=0.5399, val_accuracy=0.7243\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5539 - accuracy: 0.7152 - val_loss: 0.5399 - val_accuracy: 0.7243 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7303Epoch 29/40: loss=0.5467, accuracy=0.7303, val_loss=0.5451, val_accuracy=0.7243\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5467 - accuracy: 0.7303 - val_loss: 0.5451 - val_accuracy: 0.7243 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7276Epoch 30/40: loss=0.5424, accuracy=0.7276, val_loss=0.5882, val_accuracy=0.7028\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5424 - accuracy: 0.7276 - val_loss: 0.5882 - val_accuracy: 0.7028 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.7278Epoch 31/40: loss=0.5420, accuracy=0.7276, val_loss=0.5381, val_accuracy=0.7417\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5420 - accuracy: 0.7276 - val_loss: 0.5381 - val_accuracy: 0.7417 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5507 - accuracy: 0.7288Epoch 32/40: loss=0.5512, accuracy=0.7281, val_loss=0.4918, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5512 - accuracy: 0.7281 - val_loss: 0.4918 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5477 - accuracy: 0.7248Epoch 33/40: loss=0.5482, accuracy=0.7245, val_loss=0.5329, val_accuracy=0.7434\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5482 - accuracy: 0.7245 - val_loss: 0.5329 - val_accuracy: 0.7434 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.7255Epoch 34/40: loss=0.5406, accuracy=0.7260, val_loss=0.5089, val_accuracy=0.7632\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5406 - accuracy: 0.7260 - val_loss: 0.5089 - val_accuracy: 0.7632 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.7409Epoch 35/40: loss=0.5310, accuracy=0.7409, val_loss=0.4752, val_accuracy=0.7790\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5310 - accuracy: 0.7409 - val_loss: 0.4752 - val_accuracy: 0.7790 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.7457Epoch 36/40: loss=0.5292, accuracy=0.7457, val_loss=0.5799, val_accuracy=0.7103\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5292 - accuracy: 0.7457 - val_loss: 0.5799 - val_accuracy: 0.7103 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.7386Epoch 37/40: loss=0.5369, accuracy=0.7386, val_loss=0.5226, val_accuracy=0.7425\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5369 - accuracy: 0.7386 - val_loss: 0.5226 - val_accuracy: 0.7425 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.7457Epoch 38/40: loss=0.5273, accuracy=0.7457, val_loss=0.4955, val_accuracy=0.7674\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5273 - accuracy: 0.7457 - val_loss: 0.4955 - val_accuracy: 0.7674 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7332Epoch 39/40: loss=0.5380, accuracy=0.7332, val_loss=0.5272, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5380 - accuracy: 0.7332 - val_loss: 0.5272 - val_accuracy: 0.7442 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.7430\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 40/40: loss=0.5280, accuracy=0.7428, val_loss=0.5087, val_accuracy=0.7533\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5280 - accuracy: 0.7428 - val_loss: 0.5087 - val_accuracy: 0.7533 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.7789735198020935\n",
      "\n",
      "Refined Training Combination 42/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1479 - accuracy: 0.5100Epoch 1/40: loss=1.1472, accuracy=0.5101, val_loss=0.9175, val_accuracy=0.4495\n",
      "604/604 [==============================] - 14s 18ms/step - loss: 1.1472 - accuracy: 0.5101 - val_loss: 0.9175 - val_accuracy: 0.4495 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8361 - accuracy: 0.5317Epoch 2/40: loss=0.8360, accuracy=0.5315, val_loss=0.7738, val_accuracy=0.4859\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8360 - accuracy: 0.5315 - val_loss: 0.7738 - val_accuracy: 0.4859 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8539 - accuracy: 0.5296Epoch 3/40: loss=0.8543, accuracy=0.5292, val_loss=0.8205, val_accuracy=0.5464\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8543 - accuracy: 0.5292 - val_loss: 0.8205 - val_accuracy: 0.5464 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8208 - accuracy: 0.5512Epoch 4/40: loss=0.8204, accuracy=0.5513, val_loss=0.7323, val_accuracy=0.5472\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8204 - accuracy: 0.5513 - val_loss: 0.7323 - val_accuracy: 0.5472 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7816 - accuracy: 0.5614Epoch 5/40: loss=0.7815, accuracy=0.5613, val_loss=0.8344, val_accuracy=0.4487\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7815 - accuracy: 0.5613 - val_loss: 0.8344 - val_accuracy: 0.4487 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.5540Epoch 6/40: loss=0.8080, accuracy=0.5540, val_loss=0.9301, val_accuracy=0.4959\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8080 - accuracy: 0.5540 - val_loss: 0.9301 - val_accuracy: 0.4959 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.5691Epoch 7/40: loss=0.7743, accuracy=0.5691, val_loss=0.6940, val_accuracy=0.6200\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7743 - accuracy: 0.5691 - val_loss: 0.6940 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7734 - accuracy: 0.5731Epoch 8/40: loss=0.7737, accuracy=0.5735, val_loss=2.2178, val_accuracy=0.4114\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7737 - accuracy: 0.5735 - val_loss: 2.2178 - val_accuracy: 0.4114 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8233 - accuracy: 0.5101Epoch 9/40: loss=0.8233, accuracy=0.5101, val_loss=0.9716, val_accuracy=0.3841\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8233 - accuracy: 0.5101 - val_loss: 0.9716 - val_accuracy: 0.3841 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7985 - accuracy: 0.5131Epoch 10/40: loss=0.7988, accuracy=0.5124, val_loss=0.8195, val_accuracy=0.4048\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7988 - accuracy: 0.5124 - val_loss: 0.8195 - val_accuracy: 0.4048 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8212 - accuracy: 0.4990Epoch 11/40: loss=0.8219, accuracy=0.4988, val_loss=1.0808, val_accuracy=0.4065\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8219 - accuracy: 0.4988 - val_loss: 1.0808 - val_accuracy: 0.4065 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8277 - accuracy: 0.5035\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.8277, accuracy=0.5035, val_loss=1.1038, val_accuracy=0.3684\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8277 - accuracy: 0.5035 - val_loss: 1.1038 - val_accuracy: 0.3684 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.5041Epoch 13/40: loss=0.7538, accuracy=0.5041, val_loss=0.7092, val_accuracy=0.5066\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7538 - accuracy: 0.5041 - val_loss: 0.7092 - val_accuracy: 0.5066 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.5274Epoch 14/40: loss=0.7317, accuracy=0.5277, val_loss=0.7784, val_accuracy=0.4247\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7317 - accuracy: 0.5277 - val_loss: 0.7784 - val_accuracy: 0.4247 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.5197Epoch 15/40: loss=0.7295, accuracy=0.5199, val_loss=0.7063, val_accuracy=0.5455\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7295 - accuracy: 0.5199 - val_loss: 0.7063 - val_accuracy: 0.5455 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.5118Epoch 16/40: loss=0.7291, accuracy=0.5118, val_loss=0.7052, val_accuracy=0.4892\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7291 - accuracy: 0.5118 - val_loss: 0.7052 - val_accuracy: 0.4892 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7178 - accuracy: 0.5362Epoch 17/40: loss=0.7178, accuracy=0.5362, val_loss=0.6894, val_accuracy=0.5149\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7178 - accuracy: 0.5362 - val_loss: 0.6894 - val_accuracy: 0.5149 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7135 - accuracy: 0.5436Epoch 18/40: loss=0.7136, accuracy=0.5439, val_loss=0.7430, val_accuracy=0.5099\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7136 - accuracy: 0.5439 - val_loss: 0.7430 - val_accuracy: 0.5099 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7109 - accuracy: 0.5408Epoch 19/40: loss=0.7108, accuracy=0.5410, val_loss=0.7083, val_accuracy=0.5190\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7108 - accuracy: 0.5410 - val_loss: 0.7083 - val_accuracy: 0.5190 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.5913Epoch 20/40: loss=0.6843, accuracy=0.5913, val_loss=0.7407, val_accuracy=0.5157\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6843 - accuracy: 0.5913 - val_loss: 0.7407 - val_accuracy: 0.5157 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6810 - accuracy: 0.5890Epoch 21/40: loss=0.6809, accuracy=0.5890, val_loss=0.6498, val_accuracy=0.6258\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6809 - accuracy: 0.5890 - val_loss: 0.6498 - val_accuracy: 0.6258 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6674 - accuracy: 0.6113Epoch 22/40: loss=0.6675, accuracy=0.6109, val_loss=0.8423, val_accuracy=0.4040\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6675 - accuracy: 0.6109 - val_loss: 0.8423 - val_accuracy: 0.4040 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.6449Epoch 23/40: loss=0.6370, accuracy=0.6449, val_loss=0.7259, val_accuracy=0.6283\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6370 - accuracy: 0.6449 - val_loss: 0.7259 - val_accuracy: 0.6283 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6163 - accuracy: 0.6667Epoch 24/40: loss=0.6169, accuracy=0.6662, val_loss=0.7426, val_accuracy=0.5778\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6169 - accuracy: 0.6662 - val_loss: 0.7426 - val_accuracy: 0.5778 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.6788Epoch 25/40: loss=0.6115, accuracy=0.6788, val_loss=0.7780, val_accuracy=0.4859\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6115 - accuracy: 0.6788 - val_loss: 0.7780 - val_accuracy: 0.4859 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.6883\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 26/40: loss=0.6107, accuracy=0.6883, val_loss=1.0730, val_accuracy=0.4603\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6107 - accuracy: 0.6883 - val_loss: 1.0730 - val_accuracy: 0.4603 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5860 - accuracy: 0.6949Epoch 27/40: loss=0.5855, accuracy=0.6954, val_loss=0.7015, val_accuracy=0.6109\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5855 - accuracy: 0.6954 - val_loss: 0.7015 - val_accuracy: 0.6109 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7067Epoch 28/40: loss=0.5727, accuracy=0.7065, val_loss=0.7632, val_accuracy=0.5629\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5727 - accuracy: 0.7065 - val_loss: 0.7632 - val_accuracy: 0.5629 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5815 - accuracy: 0.7073Epoch 29/40: loss=0.5810, accuracy=0.7078, val_loss=0.6413, val_accuracy=0.6233\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5810 - accuracy: 0.7078 - val_loss: 0.6413 - val_accuracy: 0.6233 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.7087Epoch 30/40: loss=0.5674, accuracy=0.7088, val_loss=0.6576, val_accuracy=0.6399\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5674 - accuracy: 0.7088 - val_loss: 0.6576 - val_accuracy: 0.6399 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7179Epoch 31/40: loss=0.5637, accuracy=0.7179, val_loss=0.6758, val_accuracy=0.6175\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5637 - accuracy: 0.7179 - val_loss: 0.6758 - val_accuracy: 0.6175 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.7166Epoch 32/40: loss=0.5556, accuracy=0.7163, val_loss=0.7172, val_accuracy=0.6051\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5556 - accuracy: 0.7163 - val_loss: 0.7172 - val_accuracy: 0.6051 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.7159Epoch 33/40: loss=0.5618, accuracy=0.7159, val_loss=0.5968, val_accuracy=0.7012\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5618 - accuracy: 0.7159 - val_loss: 0.5968 - val_accuracy: 0.7012 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7212Epoch 34/40: loss=0.5574, accuracy=0.7210, val_loss=0.6260, val_accuracy=0.6565\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5574 - accuracy: 0.7210 - val_loss: 0.6260 - val_accuracy: 0.6565 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5561 - accuracy: 0.7151Epoch 35/40: loss=0.5562, accuracy=0.7148, val_loss=0.6286, val_accuracy=0.6432\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5562 - accuracy: 0.7148 - val_loss: 0.6286 - val_accuracy: 0.6432 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5529 - accuracy: 0.7251Epoch 36/40: loss=0.5535, accuracy=0.7243, val_loss=0.6681, val_accuracy=0.6101\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5535 - accuracy: 0.7243 - val_loss: 0.6681 - val_accuracy: 0.6101 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.7131Epoch 37/40: loss=0.5594, accuracy=0.7132, val_loss=0.6055, val_accuracy=0.6730\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5594 - accuracy: 0.7132 - val_loss: 0.6055 - val_accuracy: 0.6730 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.7195\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 38/40: loss=0.5537, accuracy=0.7198, val_loss=0.6270, val_accuracy=0.6854\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5537 - accuracy: 0.7198 - val_loss: 0.6270 - val_accuracy: 0.6854 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7276Epoch 39/40: loss=0.5527, accuracy=0.7276, val_loss=0.6017, val_accuracy=0.6912\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5527 - accuracy: 0.7276 - val_loss: 0.6017 - val_accuracy: 0.6912 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.7205Epoch 40/40: loss=0.5548, accuracy=0.7200, val_loss=0.6117, val_accuracy=0.6796\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5548 - accuracy: 0.7200 - val_loss: 0.6117 - val_accuracy: 0.6796 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.7011589407920837\n",
      "\n",
      "Refined Training Combination 43/50: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.6, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1043 - accuracy: 0.5325Epoch 1/40: loss=1.1048, accuracy=0.5327, val_loss=1.6575, val_accuracy=0.5935\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 1.1048 - accuracy: 0.5327 - val_loss: 1.6575 - val_accuracy: 0.5935 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.5410Epoch 2/40: loss=0.8383, accuracy=0.5410, val_loss=0.8652, val_accuracy=0.5050\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8383 - accuracy: 0.5410 - val_loss: 0.8652 - val_accuracy: 0.5050 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8142 - accuracy: 0.5588Epoch 3/40: loss=0.8153, accuracy=0.5579, val_loss=0.8718, val_accuracy=0.4743\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8153 - accuracy: 0.5579 - val_loss: 0.8718 - val_accuracy: 0.4743 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8533 - accuracy: 0.5382Epoch 4/40: loss=0.8540, accuracy=0.5383, val_loss=1.9059, val_accuracy=0.4106\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8540 - accuracy: 0.5383 - val_loss: 1.9059 - val_accuracy: 0.4106 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8238 - accuracy: 0.5370Epoch 5/40: loss=0.8238, accuracy=0.5364, val_loss=0.7013, val_accuracy=0.6026\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8238 - accuracy: 0.5364 - val_loss: 0.7013 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8084 - accuracy: 0.5237Epoch 6/40: loss=0.8089, accuracy=0.5232, val_loss=0.7438, val_accuracy=0.5207\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8089 - accuracy: 0.5232 - val_loss: 0.7438 - val_accuracy: 0.5207 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8388 - accuracy: 0.5463Epoch 7/40: loss=0.8385, accuracy=0.5462, val_loss=0.8140, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8385 - accuracy: 0.5462 - val_loss: 0.8140 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.5221Epoch 8/40: loss=0.7884, accuracy=0.5221, val_loss=1.0429, val_accuracy=0.6093\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7884 - accuracy: 0.5221 - val_loss: 1.0429 - val_accuracy: 0.6093 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8242 - accuracy: 0.5019Epoch 9/40: loss=0.8239, accuracy=0.5021, val_loss=0.8874, val_accuracy=0.4205\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8239 - accuracy: 0.5021 - val_loss: 0.8874 - val_accuracy: 0.4205 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8197 - accuracy: 0.5033Epoch 10/40: loss=0.8197, accuracy=0.5033, val_loss=0.6954, val_accuracy=0.5455\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8197 - accuracy: 0.5033 - val_loss: 0.6954 - val_accuracy: 0.5455 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8203 - accuracy: 0.5050Epoch 11/40: loss=0.8200, accuracy=0.5050, val_loss=0.7351, val_accuracy=0.4238\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8200 - accuracy: 0.5050 - val_loss: 0.7351 - val_accuracy: 0.4238 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8037 - accuracy: 0.5017Epoch 12/40: loss=0.8037, accuracy=0.5017, val_loss=0.8075, val_accuracy=0.4346\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8037 - accuracy: 0.5017 - val_loss: 0.8075 - val_accuracy: 0.4346 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7955 - accuracy: 0.5052Epoch 13/40: loss=0.7946, accuracy=0.5056, val_loss=0.7402, val_accuracy=0.5861\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7946 - accuracy: 0.5056 - val_loss: 0.7402 - val_accuracy: 0.5861 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.4915Epoch 14/40: loss=0.8022, accuracy=0.4911, val_loss=0.7085, val_accuracy=0.4023\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8022 - accuracy: 0.4911 - val_loss: 0.7085 - val_accuracy: 0.4023 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7972 - accuracy: 0.5062\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/40: loss=0.7984, accuracy=0.5060, val_loss=0.9837, val_accuracy=0.4801\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7984 - accuracy: 0.5060 - val_loss: 0.9837 - val_accuracy: 0.4801 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.4861Epoch 16/40: loss=0.7525, accuracy=0.4861, val_loss=0.6856, val_accuracy=0.5969\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7525 - accuracy: 0.4861 - val_loss: 0.6856 - val_accuracy: 0.5969 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7336 - accuracy: 0.5010Epoch 17/40: loss=0.7337, accuracy=0.5006, val_loss=0.7068, val_accuracy=0.5141\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7337 - accuracy: 0.5006 - val_loss: 0.7068 - val_accuracy: 0.5141 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7292 - accuracy: 0.5108Epoch 18/40: loss=0.7285, accuracy=0.5116, val_loss=0.6941, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7285 - accuracy: 0.5116 - val_loss: 0.6941 - val_accuracy: 0.5579 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7330 - accuracy: 0.5137Epoch 19/40: loss=0.7326, accuracy=0.5143, val_loss=0.7367, val_accuracy=0.5041\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7326 - accuracy: 0.5143 - val_loss: 0.7367 - val_accuracy: 0.5041 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.4919Epoch 20/40: loss=0.7305, accuracy=0.4919, val_loss=0.7079, val_accuracy=0.5132\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7305 - accuracy: 0.4919 - val_loss: 0.7079 - val_accuracy: 0.5132 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7269 - accuracy: 0.4992\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 21/40: loss=0.7268, accuracy=0.4996, val_loss=0.7057, val_accuracy=0.5124\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7268 - accuracy: 0.4996 - val_loss: 0.7057 - val_accuracy: 0.5124 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.5118Epoch 22/40: loss=0.7131, accuracy=0.5118, val_loss=0.6967, val_accuracy=0.4685\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7131 - accuracy: 0.5118 - val_loss: 0.6967 - val_accuracy: 0.4685 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7154 - accuracy: 0.5058Epoch 23/40: loss=0.7152, accuracy=0.5058, val_loss=0.6951, val_accuracy=0.4677\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7152 - accuracy: 0.5058 - val_loss: 0.6951 - val_accuracy: 0.4677 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7089 - accuracy: 0.5125Epoch 24/40: loss=0.7088, accuracy=0.5128, val_loss=0.7013, val_accuracy=0.4760\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7088 - accuracy: 0.5128 - val_loss: 0.7013 - val_accuracy: 0.4760 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.5033Epoch 25/40: loss=0.7081, accuracy=0.5033, val_loss=0.6927, val_accuracy=0.5877\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7081 - accuracy: 0.5033 - val_loss: 0.6927 - val_accuracy: 0.5877 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7080 - accuracy: 0.5116\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 26/40: loss=0.7080, accuracy=0.5116, val_loss=0.6920, val_accuracy=0.5389\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7080 - accuracy: 0.5116 - val_loss: 0.6920 - val_accuracy: 0.5389 - lr: 4.0000e-05\n",
      "Epoch 26: early stopping\n",
      "Validation accuracy: 0.6092715263366699\n",
      "\n",
      "Refined Training Combination 44/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.5, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0999 - accuracy: 0.5106Epoch 1/40: loss=1.0999, accuracy=0.5106, val_loss=0.8464, val_accuracy=0.4843\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 1.0999 - accuracy: 0.5106 - val_loss: 0.8464 - val_accuracy: 0.4843 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8510 - accuracy: 0.5324Epoch 2/40: loss=0.8504, accuracy=0.5325, val_loss=0.7863, val_accuracy=0.4735\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8504 - accuracy: 0.5325 - val_loss: 0.7863 - val_accuracy: 0.4735 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7891 - accuracy: 0.5413Epoch 3/40: loss=0.7891, accuracy=0.5414, val_loss=0.9699, val_accuracy=0.4288\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7891 - accuracy: 0.5414 - val_loss: 0.9699 - val_accuracy: 0.4288 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7432 - accuracy: 0.5664Epoch 4/40: loss=0.7435, accuracy=0.5662, val_loss=0.6125, val_accuracy=0.6515\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7435 - accuracy: 0.5662 - val_loss: 0.6125 - val_accuracy: 0.6515 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.6391Epoch 5/40: loss=0.6813, accuracy=0.6389, val_loss=0.8127, val_accuracy=0.4983\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6813 - accuracy: 0.6389 - val_loss: 0.8127 - val_accuracy: 0.4983 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.6583Epoch 6/40: loss=0.6624, accuracy=0.6581, val_loss=0.8207, val_accuracy=0.5240\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6624 - accuracy: 0.6581 - val_loss: 0.8207 - val_accuracy: 0.5240 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.6602Epoch 7/40: loss=0.6608, accuracy=0.6600, val_loss=0.9424, val_accuracy=0.6258\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6608 - accuracy: 0.6600 - val_loss: 0.9424 - val_accuracy: 0.6258 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6630 - accuracy: 0.6540Epoch 8/40: loss=0.6630, accuracy=0.6540, val_loss=0.6714, val_accuracy=0.6167\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6630 - accuracy: 0.6540 - val_loss: 0.6714 - val_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6565 - accuracy: 0.6579Epoch 9/40: loss=0.6561, accuracy=0.6575, val_loss=0.6007, val_accuracy=0.6829\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6561 - accuracy: 0.6575 - val_loss: 0.6007 - val_accuracy: 0.6829 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.6590Epoch 10/40: loss=0.6551, accuracy=0.6587, val_loss=0.6004, val_accuracy=0.6921\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6551 - accuracy: 0.6587 - val_loss: 0.6004 - val_accuracy: 0.6921 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6642 - accuracy: 0.6621Epoch 11/40: loss=0.6646, accuracy=0.6616, val_loss=0.6384, val_accuracy=0.6366\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6646 - accuracy: 0.6616 - val_loss: 0.6384 - val_accuracy: 0.6366 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.6348Epoch 12/40: loss=0.6774, accuracy=0.6343, val_loss=0.7040, val_accuracy=0.5381\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6774 - accuracy: 0.6343 - val_loss: 0.7040 - val_accuracy: 0.5381 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.6577Epoch 13/40: loss=0.6466, accuracy=0.6577, val_loss=0.6466, val_accuracy=0.6432\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6466 - accuracy: 0.6577 - val_loss: 0.6466 - val_accuracy: 0.6432 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6550 - accuracy: 0.6526Epoch 14/40: loss=0.6551, accuracy=0.6525, val_loss=0.8662, val_accuracy=0.4048\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6551 - accuracy: 0.6525 - val_loss: 0.8662 - val_accuracy: 0.4048 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.6512\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/40: loss=0.6519, accuracy=0.6513, val_loss=0.7021, val_accuracy=0.6175\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6519 - accuracy: 0.6513 - val_loss: 0.7021 - val_accuracy: 0.6175 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.7014Epoch 16/40: loss=0.5823, accuracy=0.7014, val_loss=0.5747, val_accuracy=0.7003\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5823 - accuracy: 0.7014 - val_loss: 0.5747 - val_accuracy: 0.7003 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7228Epoch 17/40: loss=0.5576, accuracy=0.7231, val_loss=0.5967, val_accuracy=0.7127\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5576 - accuracy: 0.7231 - val_loss: 0.5967 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.7207Epoch 18/40: loss=0.5659, accuracy=0.7206, val_loss=0.5582, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5659 - accuracy: 0.7206 - val_loss: 0.5582 - val_accuracy: 0.7012 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7171Epoch 19/40: loss=0.5632, accuracy=0.7171, val_loss=0.5926, val_accuracy=0.6772\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5632 - accuracy: 0.7171 - val_loss: 0.5926 - val_accuracy: 0.6772 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.7243Epoch 20/40: loss=0.5618, accuracy=0.7243, val_loss=0.4963, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5618 - accuracy: 0.7243 - val_loss: 0.4963 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7384Epoch 21/40: loss=0.5480, accuracy=0.7384, val_loss=0.5639, val_accuracy=0.7094\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5480 - accuracy: 0.7384 - val_loss: 0.5639 - val_accuracy: 0.7094 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7203Epoch 22/40: loss=0.5537, accuracy=0.7200, val_loss=0.6342, val_accuracy=0.6523\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5537 - accuracy: 0.7200 - val_loss: 0.6342 - val_accuracy: 0.6523 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.7305Epoch 23/40: loss=0.5405, accuracy=0.7305, val_loss=0.6606, val_accuracy=0.6498\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5405 - accuracy: 0.7305 - val_loss: 0.6606 - val_accuracy: 0.6498 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7396Epoch 24/40: loss=0.5357, accuracy=0.7394, val_loss=0.5068, val_accuracy=0.7483\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5357 - accuracy: 0.7394 - val_loss: 0.5068 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5350 - accuracy: 0.7396\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 25/40: loss=0.5348, accuracy=0.7401, val_loss=0.5284, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5348 - accuracy: 0.7401 - val_loss: 0.5284 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.7512Epoch 26/40: loss=0.5163, accuracy=0.7512, val_loss=0.4729, val_accuracy=0.7881\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5163 - accuracy: 0.7512 - val_loss: 0.4729 - val_accuracy: 0.7881 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7475Epoch 27/40: loss=0.5234, accuracy=0.7473, val_loss=0.4914, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5234 - accuracy: 0.7473 - val_loss: 0.4914 - val_accuracy: 0.7690 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5198 - accuracy: 0.7517Epoch 28/40: loss=0.5206, accuracy=0.7512, val_loss=0.4666, val_accuracy=0.7864\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5206 - accuracy: 0.7512 - val_loss: 0.4666 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5178 - accuracy: 0.7515Epoch 29/40: loss=0.5176, accuracy=0.7517, val_loss=0.4873, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5176 - accuracy: 0.7517 - val_loss: 0.4873 - val_accuracy: 0.7682 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.7544Epoch 30/40: loss=0.5117, accuracy=0.7546, val_loss=0.5094, val_accuracy=0.7591\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5117 - accuracy: 0.7546 - val_loss: 0.5094 - val_accuracy: 0.7591 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.7523Epoch 31/40: loss=0.5162, accuracy=0.7529, val_loss=0.4836, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5162 - accuracy: 0.7529 - val_loss: 0.4836 - val_accuracy: 0.7690 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7430Epoch 32/40: loss=0.5193, accuracy=0.7430, val_loss=0.4894, val_accuracy=0.7674\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5193 - accuracy: 0.7430 - val_loss: 0.4894 - val_accuracy: 0.7674 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.7573\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 33/40: loss=0.5050, accuracy=0.7572, val_loss=0.4958, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5050 - accuracy: 0.7572 - val_loss: 0.4958 - val_accuracy: 0.7699 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7587Epoch 34/40: loss=0.4991, accuracy=0.7587, val_loss=0.4853, val_accuracy=0.7724\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4991 - accuracy: 0.7587 - val_loss: 0.4853 - val_accuracy: 0.7724 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7614Epoch 35/40: loss=0.4992, accuracy=0.7620, val_loss=0.4777, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4992 - accuracy: 0.7620 - val_loss: 0.4777 - val_accuracy: 0.7740 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.7575Epoch 36/40: loss=0.5083, accuracy=0.7575, val_loss=0.4786, val_accuracy=0.7781\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5083 - accuracy: 0.7575 - val_loss: 0.4786 - val_accuracy: 0.7781 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.7546Epoch 37/40: loss=0.5114, accuracy=0.7546, val_loss=0.4880, val_accuracy=0.7732\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5114 - accuracy: 0.7546 - val_loss: 0.4880 - val_accuracy: 0.7732 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.7566\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.5070, accuracy=0.7566, val_loss=0.4675, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5070 - accuracy: 0.7566 - val_loss: 0.4675 - val_accuracy: 0.7781 - lr: 4.0000e-06\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.7880794405937195\n",
      "\n",
      "Refined Training Combination 45/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.6, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.5259Epoch 1/40: loss=1.1280, accuracy=0.5265, val_loss=0.9000, val_accuracy=0.5298\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 1.1280 - accuracy: 0.5265 - val_loss: 0.9000 - val_accuracy: 0.5298 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8486 - accuracy: 0.5500Epoch 2/40: loss=0.8478, accuracy=0.5503, val_loss=0.7984, val_accuracy=0.5613\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8478 - accuracy: 0.5503 - val_loss: 0.7984 - val_accuracy: 0.5613 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8191 - accuracy: 0.5614Epoch 3/40: loss=0.8186, accuracy=0.5617, val_loss=0.8048, val_accuracy=0.6076\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8186 - accuracy: 0.5617 - val_loss: 0.8048 - val_accuracy: 0.6076 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7370 - accuracy: 0.6099Epoch 4/40: loss=0.7368, accuracy=0.6099, val_loss=0.7421, val_accuracy=0.5853\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7368 - accuracy: 0.6099 - val_loss: 0.7421 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.6254Epoch 5/40: loss=0.7204, accuracy=0.6254, val_loss=0.7368, val_accuracy=0.5166\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7204 - accuracy: 0.6254 - val_loss: 0.7368 - val_accuracy: 0.5166 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.6024Epoch 6/40: loss=0.7571, accuracy=0.6026, val_loss=1.4407, val_accuracy=0.4048\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7571 - accuracy: 0.6026 - val_loss: 1.4407 - val_accuracy: 0.4048 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.6093Epoch 7/40: loss=0.7345, accuracy=0.6093, val_loss=0.7441, val_accuracy=0.4652\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7345 - accuracy: 0.6093 - val_loss: 0.7441 - val_accuracy: 0.4652 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7022 - accuracy: 0.6277Epoch 8/40: loss=0.7017, accuracy=0.6279, val_loss=0.6563, val_accuracy=0.6639\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7017 - accuracy: 0.6279 - val_loss: 0.6563 - val_accuracy: 0.6639 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7740 - accuracy: 0.5749Epoch 9/40: loss=0.7740, accuracy=0.5749, val_loss=0.8542, val_accuracy=0.4983\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7740 - accuracy: 0.5749 - val_loss: 0.8542 - val_accuracy: 0.4983 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8423 - accuracy: 0.5112Epoch 10/40: loss=0.8424, accuracy=0.5114, val_loss=0.7308, val_accuracy=0.5091\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8424 - accuracy: 0.5114 - val_loss: 0.7308 - val_accuracy: 0.5091 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8200 - accuracy: 0.5110Epoch 11/40: loss=0.8196, accuracy=0.5112, val_loss=0.7466, val_accuracy=0.5977\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8196 - accuracy: 0.5112 - val_loss: 0.7466 - val_accuracy: 0.5977 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.5002Epoch 12/40: loss=0.8123, accuracy=0.5002, val_loss=0.6968, val_accuracy=0.5306\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8123 - accuracy: 0.5002 - val_loss: 0.6968 - val_accuracy: 0.5306 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8067 - accuracy: 0.5073\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40: loss=0.8068, accuracy=0.5068, val_loss=0.6809, val_accuracy=0.5877\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8068 - accuracy: 0.5068 - val_loss: 0.6809 - val_accuracy: 0.5877 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7408 - accuracy: 0.5103Epoch 14/40: loss=0.7408, accuracy=0.5103, val_loss=0.6812, val_accuracy=0.5522\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7408 - accuracy: 0.5103 - val_loss: 0.6812 - val_accuracy: 0.5522 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7306 - accuracy: 0.5097Epoch 15/40: loss=0.7305, accuracy=0.5097, val_loss=0.6732, val_accuracy=0.5704\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7305 - accuracy: 0.5097 - val_loss: 0.6732 - val_accuracy: 0.5704 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.5012Epoch 16/40: loss=0.7294, accuracy=0.5010, val_loss=0.7210, val_accuracy=0.4305\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7294 - accuracy: 0.5010 - val_loss: 0.7210 - val_accuracy: 0.4305 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7289 - accuracy: 0.5062Epoch 17/40: loss=0.7291, accuracy=0.5062, val_loss=0.6888, val_accuracy=0.4669\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7291 - accuracy: 0.5062 - val_loss: 0.6888 - val_accuracy: 0.4669 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7255 - accuracy: 0.5166\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 18/40: loss=0.7256, accuracy=0.5161, val_loss=0.6647, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7256 - accuracy: 0.5161 - val_loss: 0.6647 - val_accuracy: 0.5985 - lr: 2.0000e-04\n",
      "Epoch 18: early stopping\n",
      "Validation accuracy: 0.6639072895050049\n",
      "\n",
      "Refined Training Combination 46/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.4, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0739 - accuracy: 0.5258Epoch 1/40: loss=1.0735, accuracy=0.5257, val_loss=0.7323, val_accuracy=0.5927\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 1.0735 - accuracy: 0.5257 - val_loss: 0.7323 - val_accuracy: 0.5927 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8344 - accuracy: 0.5436Epoch 2/40: loss=0.8344, accuracy=0.5437, val_loss=0.7138, val_accuracy=0.5902\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8344 - accuracy: 0.5437 - val_loss: 0.7138 - val_accuracy: 0.5902 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7838 - accuracy: 0.5439Epoch 3/40: loss=0.7838, accuracy=0.5439, val_loss=0.6808, val_accuracy=0.6200\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7838 - accuracy: 0.5439 - val_loss: 0.6808 - val_accuracy: 0.6200 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7518 - accuracy: 0.5599Epoch 4/40: loss=0.7519, accuracy=0.5602, val_loss=0.7541, val_accuracy=0.5621\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7519 - accuracy: 0.5602 - val_loss: 0.7541 - val_accuracy: 0.5621 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7186 - accuracy: 0.5962Epoch 5/40: loss=0.7186, accuracy=0.5962, val_loss=0.6040, val_accuracy=0.6747\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7186 - accuracy: 0.5962 - val_loss: 0.6040 - val_accuracy: 0.6747 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.6088Epoch 6/40: loss=0.6937, accuracy=0.6082, val_loss=0.7503, val_accuracy=0.6018\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6937 - accuracy: 0.6082 - val_loss: 0.7503 - val_accuracy: 0.6018 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.6376Epoch 7/40: loss=0.6653, accuracy=0.6376, val_loss=0.7312, val_accuracy=0.5008\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6653 - accuracy: 0.6376 - val_loss: 0.7312 - val_accuracy: 0.5008 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.6422Epoch 8/40: loss=0.6724, accuracy=0.6422, val_loss=0.5703, val_accuracy=0.6912\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6724 - accuracy: 0.6422 - val_loss: 0.5703 - val_accuracy: 0.6912 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6501 - accuracy: 0.6591Epoch 9/40: loss=0.6501, accuracy=0.6591, val_loss=0.5383, val_accuracy=0.7235\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6501 - accuracy: 0.6591 - val_loss: 0.5383 - val_accuracy: 0.7235 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6507 - accuracy: 0.6682Epoch 10/40: loss=0.6504, accuracy=0.6687, val_loss=0.6668, val_accuracy=0.6772\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6504 - accuracy: 0.6687 - val_loss: 0.6668 - val_accuracy: 0.6772 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6477 - accuracy: 0.6663Epoch 11/40: loss=0.6482, accuracy=0.6658, val_loss=0.5771, val_accuracy=0.7028\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6482 - accuracy: 0.6658 - val_loss: 0.5771 - val_accuracy: 0.7028 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.6559Epoch 12/40: loss=0.6494, accuracy=0.6562, val_loss=0.8471, val_accuracy=0.6391\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6494 - accuracy: 0.6562 - val_loss: 0.8471 - val_accuracy: 0.6391 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6563 - accuracy: 0.6607Epoch 13/40: loss=0.6557, accuracy=0.6610, val_loss=0.7865, val_accuracy=0.5414\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6557 - accuracy: 0.6610 - val_loss: 0.7865 - val_accuracy: 0.5414 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.6636\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/40: loss=0.6417, accuracy=0.6643, val_loss=0.5958, val_accuracy=0.6904\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6417 - accuracy: 0.6643 - val_loss: 0.5958 - val_accuracy: 0.6904 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.7127Epoch 15/40: loss=0.5747, accuracy=0.7121, val_loss=0.6946, val_accuracy=0.5902\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5747 - accuracy: 0.7121 - val_loss: 0.6946 - val_accuracy: 0.5902 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5731 - accuracy: 0.7067Epoch 16/40: loss=0.5734, accuracy=0.7063, val_loss=0.5121, val_accuracy=0.7500\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5734 - accuracy: 0.7063 - val_loss: 0.5121 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.7204Epoch 17/40: loss=0.5579, accuracy=0.7204, val_loss=0.5726, val_accuracy=0.7070\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5579 - accuracy: 0.7204 - val_loss: 0.5726 - val_accuracy: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7177Epoch 18/40: loss=0.5606, accuracy=0.7177, val_loss=0.5585, val_accuracy=0.7194\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5606 - accuracy: 0.7177 - val_loss: 0.5585 - val_accuracy: 0.7194 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5589 - accuracy: 0.7239Epoch 19/40: loss=0.5585, accuracy=0.7239, val_loss=0.6704, val_accuracy=0.6449\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5585 - accuracy: 0.7239 - val_loss: 0.6704 - val_accuracy: 0.6449 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.7363Epoch 20/40: loss=0.5335, accuracy=0.7365, val_loss=0.4531, val_accuracy=0.7897\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5335 - accuracy: 0.7365 - val_loss: 0.4531 - val_accuracy: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5522 - accuracy: 0.7220Epoch 21/40: loss=0.5524, accuracy=0.7219, val_loss=0.4498, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5524 - accuracy: 0.7219 - val_loss: 0.4498 - val_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.7285Epoch 22/40: loss=0.5427, accuracy=0.7285, val_loss=0.4697, val_accuracy=0.7798\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5427 - accuracy: 0.7285 - val_loss: 0.4697 - val_accuracy: 0.7798 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7347Epoch 23/40: loss=0.5355, accuracy=0.7347, val_loss=0.4896, val_accuracy=0.7823\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5355 - accuracy: 0.7347 - val_loss: 0.4896 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.7322Epoch 24/40: loss=0.5366, accuracy=0.7322, val_loss=0.4716, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5366 - accuracy: 0.7322 - val_loss: 0.4716 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.7291Epoch 25/40: loss=0.5411, accuracy=0.7289, val_loss=0.4896, val_accuracy=0.7748\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5411 - accuracy: 0.7289 - val_loss: 0.4896 - val_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5340 - accuracy: 0.7394\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 26/40: loss=0.5341, accuracy=0.7394, val_loss=0.4680, val_accuracy=0.7906\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5341 - accuracy: 0.7394 - val_loss: 0.4680 - val_accuracy: 0.7906 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.7544Epoch 27/40: loss=0.5001, accuracy=0.7543, val_loss=0.4666, val_accuracy=0.7980\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5001 - accuracy: 0.7543 - val_loss: 0.4666 - val_accuracy: 0.7980 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.7585Epoch 28/40: loss=0.4962, accuracy=0.7577, val_loss=0.4877, val_accuracy=0.7666\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4962 - accuracy: 0.7577 - val_loss: 0.4877 - val_accuracy: 0.7666 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.7587Epoch 29/40: loss=0.4945, accuracy=0.7591, val_loss=0.4580, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4945 - accuracy: 0.7591 - val_loss: 0.4580 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4905 - accuracy: 0.7670Epoch 30/40: loss=0.4900, accuracy=0.7674, val_loss=0.4516, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4900 - accuracy: 0.7674 - val_loss: 0.4516 - val_accuracy: 0.7964 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.7599\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 31/40: loss=0.4894, accuracy=0.7599, val_loss=0.4508, val_accuracy=0.7972\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4894 - accuracy: 0.7599 - val_loss: 0.4508 - val_accuracy: 0.7972 - lr: 2.0000e-05\n",
      "Epoch 31: early stopping\n",
      "Validation accuracy: 0.7988410592079163\n",
      "\n",
      "Refined Training Combination 47/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.4, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9444 - accuracy: 0.5216Epoch 1/40: loss=0.9435, accuracy=0.5215, val_loss=0.7676, val_accuracy=0.5166\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9435 - accuracy: 0.5215 - val_loss: 0.7676 - val_accuracy: 0.5166 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.5235Epoch 2/40: loss=0.9043, accuracy=0.5230, val_loss=0.7865, val_accuracy=0.5381\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9043 - accuracy: 0.5230 - val_loss: 0.7865 - val_accuracy: 0.5381 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8827 - accuracy: 0.5228Epoch 3/40: loss=0.8825, accuracy=0.5232, val_loss=0.6820, val_accuracy=0.6076\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8825 - accuracy: 0.5232 - val_loss: 0.6820 - val_accuracy: 0.6076 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8480 - accuracy: 0.5234Epoch 4/40: loss=0.8478, accuracy=0.5236, val_loss=0.7095, val_accuracy=0.5472\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8478 - accuracy: 0.5236 - val_loss: 0.7095 - val_accuracy: 0.5472 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8361 - accuracy: 0.5230Epoch 5/40: loss=0.8359, accuracy=0.5228, val_loss=0.7202, val_accuracy=0.5621\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8359 - accuracy: 0.5228 - val_loss: 0.7202 - val_accuracy: 0.5621 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8201 - accuracy: 0.5284Epoch 6/40: loss=0.8201, accuracy=0.5284, val_loss=0.7271, val_accuracy=0.5298\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8201 - accuracy: 0.5284 - val_loss: 0.7271 - val_accuracy: 0.5298 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.5597Epoch 7/40: loss=0.7770, accuracy=0.5596, val_loss=0.8201, val_accuracy=0.5149\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7770 - accuracy: 0.5596 - val_loss: 0.8201 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7501 - accuracy: 0.5783Epoch 8/40: loss=0.7495, accuracy=0.5788, val_loss=0.6590, val_accuracy=0.6275\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7495 - accuracy: 0.5788 - val_loss: 0.6590 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.5909Epoch 9/40: loss=0.7339, accuracy=0.5909, val_loss=0.6730, val_accuracy=0.5935\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7339 - accuracy: 0.5909 - val_loss: 0.6730 - val_accuracy: 0.5935 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.6093Epoch 10/40: loss=0.6995, accuracy=0.6093, val_loss=0.7747, val_accuracy=0.5108\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6995 - accuracy: 0.6093 - val_loss: 0.7747 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7003 - accuracy: 0.6084Epoch 11/40: loss=0.7003, accuracy=0.6084, val_loss=0.6726, val_accuracy=0.6084\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7003 - accuracy: 0.6084 - val_loss: 0.6726 - val_accuracy: 0.6084 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6655 - accuracy: 0.6335Epoch 12/40: loss=0.6655, accuracy=0.6335, val_loss=0.6283, val_accuracy=0.6474\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6655 - accuracy: 0.6335 - val_loss: 0.6283 - val_accuracy: 0.6474 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6470 - accuracy: 0.6501Epoch 13/40: loss=0.6469, accuracy=0.6502, val_loss=0.6015, val_accuracy=0.6805\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6469 - accuracy: 0.6502 - val_loss: 0.6015 - val_accuracy: 0.6805 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.6591Epoch 14/40: loss=0.6357, accuracy=0.6591, val_loss=0.6900, val_accuracy=0.5737\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6357 - accuracy: 0.6591 - val_loss: 0.6900 - val_accuracy: 0.5737 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6180 - accuracy: 0.6733Epoch 15/40: loss=0.6179, accuracy=0.6732, val_loss=0.7896, val_accuracy=0.5646\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6179 - accuracy: 0.6732 - val_loss: 0.7896 - val_accuracy: 0.5646 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.6856Epoch 16/40: loss=0.5986, accuracy=0.6856, val_loss=0.5875, val_accuracy=0.7045\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5986 - accuracy: 0.6856 - val_loss: 0.5875 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5905 - accuracy: 0.6978Epoch 17/40: loss=0.5903, accuracy=0.6976, val_loss=0.6087, val_accuracy=0.6763\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5903 - accuracy: 0.6976 - val_loss: 0.6087 - val_accuracy: 0.6763 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5777 - accuracy: 0.6998Epoch 18/40: loss=0.5769, accuracy=0.7003, val_loss=0.5201, val_accuracy=0.7459\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5769 - accuracy: 0.7003 - val_loss: 0.5201 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5739 - accuracy: 0.7043Epoch 19/40: loss=0.5736, accuracy=0.7047, val_loss=0.6401, val_accuracy=0.6540\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5736 - accuracy: 0.7047 - val_loss: 0.6401 - val_accuracy: 0.6540 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.7172Epoch 20/40: loss=0.5590, accuracy=0.7173, val_loss=0.5107, val_accuracy=0.7508\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5590 - accuracy: 0.7173 - val_loss: 0.5107 - val_accuracy: 0.7508 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5607 - accuracy: 0.7166Epoch 21/40: loss=0.5609, accuracy=0.7165, val_loss=0.4916, val_accuracy=0.7434\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5609 - accuracy: 0.7165 - val_loss: 0.4916 - val_accuracy: 0.7434 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.7245Epoch 22/40: loss=0.5449, accuracy=0.7245, val_loss=0.5179, val_accuracy=0.7368\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5449 - accuracy: 0.7245 - val_loss: 0.5179 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.7290Epoch 23/40: loss=0.5410, accuracy=0.7295, val_loss=0.4705, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5410 - accuracy: 0.7295 - val_loss: 0.4705 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5379 - accuracy: 0.7239Epoch 24/40: loss=0.5382, accuracy=0.7237, val_loss=0.5328, val_accuracy=0.7384\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5382 - accuracy: 0.7237 - val_loss: 0.5328 - val_accuracy: 0.7384 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7276Epoch 25/40: loss=0.5339, accuracy=0.7276, val_loss=1.1933, val_accuracy=0.4983\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5339 - accuracy: 0.7276 - val_loss: 1.1933 - val_accuracy: 0.4983 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.7413Epoch 26/40: loss=0.5195, accuracy=0.7413, val_loss=0.9007, val_accuracy=0.5240\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5195 - accuracy: 0.7413 - val_loss: 0.9007 - val_accuracy: 0.5240 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.7340Epoch 27/40: loss=0.5237, accuracy=0.7343, val_loss=0.5449, val_accuracy=0.7310\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5237 - accuracy: 0.7343 - val_loss: 0.5449 - val_accuracy: 0.7310 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5104 - accuracy: 0.7531\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 28/40: loss=0.5099, accuracy=0.7535, val_loss=0.4779, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5099 - accuracy: 0.7535 - val_loss: 0.4779 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.7647Epoch 29/40: loss=0.4941, accuracy=0.7647, val_loss=0.4355, val_accuracy=0.7906\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4941 - accuracy: 0.7647 - val_loss: 0.4355 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.7695Epoch 30/40: loss=0.4756, accuracy=0.7699, val_loss=0.4559, val_accuracy=0.7724\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4756 - accuracy: 0.7699 - val_loss: 0.4559 - val_accuracy: 0.7724 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7614Epoch 31/40: loss=0.4836, accuracy=0.7618, val_loss=0.4546, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4836 - accuracy: 0.7618 - val_loss: 0.4546 - val_accuracy: 0.7839 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.7676Epoch 32/40: loss=0.4743, accuracy=0.7676, val_loss=0.4410, val_accuracy=0.8013\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4743 - accuracy: 0.7676 - val_loss: 0.4410 - val_accuracy: 0.8013 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4766 - accuracy: 0.7689Epoch 33/40: loss=0.4769, accuracy=0.7688, val_loss=0.4424, val_accuracy=0.7939\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4769 - accuracy: 0.7688 - val_loss: 0.4424 - val_accuracy: 0.7939 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7743\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 34/40: loss=0.4708, accuracy=0.7742, val_loss=0.4417, val_accuracy=0.7939\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4708 - accuracy: 0.7742 - val_loss: 0.4417 - val_accuracy: 0.7939 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.7818Epoch 35/40: loss=0.4600, accuracy=0.7823, val_loss=0.4245, val_accuracy=0.8220\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4600 - accuracy: 0.7823 - val_loss: 0.4245 - val_accuracy: 0.8220 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.7815Epoch 36/40: loss=0.4673, accuracy=0.7815, val_loss=0.4256, val_accuracy=0.8104\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4673 - accuracy: 0.7815 - val_loss: 0.4256 - val_accuracy: 0.8104 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.7804Epoch 37/40: loss=0.4628, accuracy=0.7804, val_loss=0.4331, val_accuracy=0.8022\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4628 - accuracy: 0.7804 - val_loss: 0.4331 - val_accuracy: 0.8022 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4603 - accuracy: 0.7832Epoch 38/40: loss=0.4600, accuracy=0.7833, val_loss=0.4278, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4600 - accuracy: 0.7833 - val_loss: 0.4278 - val_accuracy: 0.8104 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.7765Epoch 39/40: loss=0.4639, accuracy=0.7765, val_loss=0.4316, val_accuracy=0.7997\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4639 - accuracy: 0.7765 - val_loss: 0.4316 - val_accuracy: 0.7997 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.7832\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 40/40: loss=0.4548, accuracy=0.7827, val_loss=0.4312, val_accuracy=0.8022\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.4548 - accuracy: 0.7827 - val_loss: 0.4312 - val_accuracy: 0.8022 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.8220198750495911\n",
      "\n",
      "Refined Training Combination 48/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1073 - accuracy: 0.5097Epoch 1/40: loss=1.1068, accuracy=0.5101, val_loss=0.9781, val_accuracy=0.5447\n",
      "604/604 [==============================] - 16s 22ms/step - loss: 1.1068 - accuracy: 0.5101 - val_loss: 0.9781 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8866 - accuracy: 0.4994Epoch 2/40: loss=0.8865, accuracy=0.4996, val_loss=0.6979, val_accuracy=0.5919\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8865 - accuracy: 0.4996 - val_loss: 0.6979 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.5182Epoch 3/40: loss=0.8385, accuracy=0.5182, val_loss=0.7003, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8385 - accuracy: 0.5182 - val_loss: 0.7003 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8344 - accuracy: 0.5332Epoch 4/40: loss=0.8338, accuracy=0.5335, val_loss=0.9315, val_accuracy=0.4081\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8338 - accuracy: 0.5335 - val_loss: 0.9315 - val_accuracy: 0.4081 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.5023Epoch 5/40: loss=0.8275, accuracy=0.5023, val_loss=0.7504, val_accuracy=0.4644\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8275 - accuracy: 0.5023 - val_loss: 0.7504 - val_accuracy: 0.4644 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.5160Epoch 6/40: loss=0.8176, accuracy=0.5172, val_loss=0.8755, val_accuracy=0.6018\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8176 - accuracy: 0.5172 - val_loss: 0.8755 - val_accuracy: 0.6018 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8145 - accuracy: 0.5307\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/40: loss=0.8142, accuracy=0.5308, val_loss=0.7855, val_accuracy=0.4015\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8142 - accuracy: 0.5308 - val_loss: 0.7855 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.5017Epoch 8/40: loss=0.7541, accuracy=0.5017, val_loss=0.7158, val_accuracy=0.5397\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7541 - accuracy: 0.5017 - val_loss: 0.7158 - val_accuracy: 0.5397 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7364 - accuracy: 0.5197Epoch 9/40: loss=0.7367, accuracy=0.5190, val_loss=0.6712, val_accuracy=0.5927\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7367 - accuracy: 0.5190 - val_loss: 0.6712 - val_accuracy: 0.5927 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7348 - accuracy: 0.5276Epoch 10/40: loss=0.7347, accuracy=0.5277, val_loss=0.7171, val_accuracy=0.5298\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7347 - accuracy: 0.5277 - val_loss: 0.7171 - val_accuracy: 0.5298 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7289 - accuracy: 0.5332Epoch 11/40: loss=0.7289, accuracy=0.5333, val_loss=0.6711, val_accuracy=0.6134\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7289 - accuracy: 0.5333 - val_loss: 0.6711 - val_accuracy: 0.6134 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.5586Epoch 12/40: loss=0.7090, accuracy=0.5586, val_loss=0.6628, val_accuracy=0.6291\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7090 - accuracy: 0.5586 - val_loss: 0.6628 - val_accuracy: 0.6291 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.5892Epoch 13/40: loss=0.6838, accuracy=0.5892, val_loss=0.6440, val_accuracy=0.6349\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6838 - accuracy: 0.5892 - val_loss: 0.6440 - val_accuracy: 0.6349 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.6283Epoch 14/40: loss=0.6564, accuracy=0.6287, val_loss=0.7097, val_accuracy=0.5919\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6564 - accuracy: 0.6287 - val_loss: 0.7097 - val_accuracy: 0.5919 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6241 - accuracy: 0.6681Epoch 15/40: loss=0.6246, accuracy=0.6680, val_loss=1.0308, val_accuracy=0.4727\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6246 - accuracy: 0.6680 - val_loss: 1.0308 - val_accuracy: 0.4727 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6245 - accuracy: 0.6698Epoch 16/40: loss=0.6247, accuracy=0.6695, val_loss=0.6723, val_accuracy=0.5778\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6247 - accuracy: 0.6695 - val_loss: 0.6723 - val_accuracy: 0.5778 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6430 - accuracy: 0.6443Epoch 17/40: loss=0.6425, accuracy=0.6447, val_loss=0.5481, val_accuracy=0.7276\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6425 - accuracy: 0.6447 - val_loss: 0.5481 - val_accuracy: 0.7276 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6103 - accuracy: 0.6771Epoch 18/40: loss=0.6098, accuracy=0.6774, val_loss=0.5695, val_accuracy=0.7061\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6098 - accuracy: 0.6774 - val_loss: 0.5695 - val_accuracy: 0.7061 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6025 - accuracy: 0.6785Epoch 19/40: loss=0.6023, accuracy=0.6784, val_loss=0.5520, val_accuracy=0.7219\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6023 - accuracy: 0.6784 - val_loss: 0.5520 - val_accuracy: 0.7219 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.6871Epoch 20/40: loss=0.6031, accuracy=0.6877, val_loss=0.7563, val_accuracy=0.5795\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6031 - accuracy: 0.6877 - val_loss: 0.7563 - val_accuracy: 0.5795 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5985 - accuracy: 0.6862Epoch 21/40: loss=0.5989, accuracy=0.6861, val_loss=0.7190, val_accuracy=0.5886\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5989 - accuracy: 0.6861 - val_loss: 0.7190 - val_accuracy: 0.5886 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.7067\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 22/40: loss=0.5819, accuracy=0.7070, val_loss=0.9496, val_accuracy=0.4727\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5819 - accuracy: 0.7070 - val_loss: 0.9496 - val_accuracy: 0.4727 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.7067Epoch 23/40: loss=0.5680, accuracy=0.7067, val_loss=0.6836, val_accuracy=0.6250\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5680 - accuracy: 0.7067 - val_loss: 0.6836 - val_accuracy: 0.6250 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5489 - accuracy: 0.7236Epoch 24/40: loss=0.5487, accuracy=0.7237, val_loss=0.6098, val_accuracy=0.6796\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5487 - accuracy: 0.7237 - val_loss: 0.6098 - val_accuracy: 0.6796 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7206Epoch 25/40: loss=0.5479, accuracy=0.7206, val_loss=0.6224, val_accuracy=0.6689\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5479 - accuracy: 0.7206 - val_loss: 0.6224 - val_accuracy: 0.6689 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7330Epoch 26/40: loss=0.5371, accuracy=0.7330, val_loss=0.5538, val_accuracy=0.7285\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5371 - accuracy: 0.7330 - val_loss: 0.5538 - val_accuracy: 0.7285 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5590 - accuracy: 0.7220\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5587, accuracy=0.7221, val_loss=0.6489, val_accuracy=0.6565\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5587 - accuracy: 0.7221 - val_loss: 0.6489 - val_accuracy: 0.6565 - lr: 4.0000e-05\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7284768223762512\n",
      "\n",
      "Refined Training Combination 49/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.0001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9392 - accuracy: 0.5137Epoch 1/40: loss=0.9382, accuracy=0.5143, val_loss=0.7942, val_accuracy=0.5480\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.9382 - accuracy: 0.5143 - val_loss: 0.7942 - val_accuracy: 0.5480 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9031 - accuracy: 0.5114Epoch 2/40: loss=0.9025, accuracy=0.5116, val_loss=0.7017, val_accuracy=0.5720\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.9025 - accuracy: 0.5116 - val_loss: 0.7017 - val_accuracy: 0.5720 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8688 - accuracy: 0.5226Epoch 3/40: loss=0.8692, accuracy=0.5217, val_loss=0.7107, val_accuracy=0.5546\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8692 - accuracy: 0.5217 - val_loss: 0.7107 - val_accuracy: 0.5546 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8646 - accuracy: 0.5172Epoch 4/40: loss=0.8643, accuracy=0.5170, val_loss=0.7213, val_accuracy=0.5579\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8643 - accuracy: 0.5170 - val_loss: 0.7213 - val_accuracy: 0.5579 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8335 - accuracy: 0.5197Epoch 5/40: loss=0.8338, accuracy=0.5197, val_loss=0.7462, val_accuracy=0.5000\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8338 - accuracy: 0.5197 - val_loss: 0.7462 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8102 - accuracy: 0.5235Epoch 6/40: loss=0.8096, accuracy=0.5240, val_loss=0.7342, val_accuracy=0.5381\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8096 - accuracy: 0.5240 - val_loss: 0.7342 - val_accuracy: 0.5381 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7878 - accuracy: 0.5364\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/40: loss=0.7878, accuracy=0.5364, val_loss=0.7018, val_accuracy=0.5373\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7878 - accuracy: 0.5364 - val_loss: 0.7018 - val_accuracy: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7619 - accuracy: 0.5359Epoch 8/40: loss=0.7619, accuracy=0.5360, val_loss=0.6682, val_accuracy=0.5977\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7619 - accuracy: 0.5360 - val_loss: 0.6682 - val_accuracy: 0.5977 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7559 - accuracy: 0.5361Epoch 9/40: loss=0.7566, accuracy=0.5352, val_loss=0.6614, val_accuracy=0.6076\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7566 - accuracy: 0.5352 - val_loss: 0.6614 - val_accuracy: 0.6076 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7341 - accuracy: 0.5536Epoch 10/40: loss=0.7343, accuracy=0.5536, val_loss=0.6700, val_accuracy=0.6010\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7343 - accuracy: 0.5536 - val_loss: 0.6700 - val_accuracy: 0.6010 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7405 - accuracy: 0.5505Epoch 11/40: loss=0.7400, accuracy=0.5507, val_loss=0.6796, val_accuracy=0.5902\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7400 - accuracy: 0.5507 - val_loss: 0.6796 - val_accuracy: 0.5902 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.5535Epoch 12/40: loss=0.7364, accuracy=0.5538, val_loss=0.6754, val_accuracy=0.5935\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7364 - accuracy: 0.5538 - val_loss: 0.6754 - val_accuracy: 0.5935 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7156 - accuracy: 0.5651Epoch 13/40: loss=0.7157, accuracy=0.5652, val_loss=0.6867, val_accuracy=0.5646\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7157 - accuracy: 0.5652 - val_loss: 0.6867 - val_accuracy: 0.5646 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7262 - accuracy: 0.5590Epoch 14/40: loss=0.7265, accuracy=0.5592, val_loss=0.6593, val_accuracy=0.6093\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7265 - accuracy: 0.5592 - val_loss: 0.6593 - val_accuracy: 0.6093 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7214 - accuracy: 0.5811Epoch 15/40: loss=0.7216, accuracy=0.5807, val_loss=0.6635, val_accuracy=0.6134\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7216 - accuracy: 0.5807 - val_loss: 0.6635 - val_accuracy: 0.6134 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.5721Epoch 16/40: loss=0.7201, accuracy=0.5722, val_loss=0.6599, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7201 - accuracy: 0.5722 - val_loss: 0.6599 - val_accuracy: 0.5985 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.5766Epoch 17/40: loss=0.7125, accuracy=0.5766, val_loss=0.6529, val_accuracy=0.6333\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7125 - accuracy: 0.5766 - val_loss: 0.6529 - val_accuracy: 0.6333 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7067 - accuracy: 0.5757Epoch 18/40: loss=0.7073, accuracy=0.5753, val_loss=0.6753, val_accuracy=0.6093\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7073 - accuracy: 0.5753 - val_loss: 0.6753 - val_accuracy: 0.6093 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7022 - accuracy: 0.5927Epoch 19/40: loss=0.7022, accuracy=0.5927, val_loss=0.6555, val_accuracy=0.5944\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7022 - accuracy: 0.5927 - val_loss: 0.6555 - val_accuracy: 0.5944 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7079 - accuracy: 0.5863Epoch 20/40: loss=0.7080, accuracy=0.5859, val_loss=0.6588, val_accuracy=0.6242\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7080 - accuracy: 0.5859 - val_loss: 0.6588 - val_accuracy: 0.6242 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6962 - accuracy: 0.5869Epoch 21/40: loss=0.6961, accuracy=0.5871, val_loss=0.6306, val_accuracy=0.6490\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6961 - accuracy: 0.5871 - val_loss: 0.6306 - val_accuracy: 0.6490 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7052 - accuracy: 0.5875Epoch 22/40: loss=0.7055, accuracy=0.5869, val_loss=0.6749, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7055 - accuracy: 0.5869 - val_loss: 0.6749 - val_accuracy: 0.5960 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5977Epoch 23/40: loss=0.6907, accuracy=0.5977, val_loss=0.7006, val_accuracy=0.5836\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6907 - accuracy: 0.5977 - val_loss: 0.7006 - val_accuracy: 0.5836 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.5906Epoch 24/40: loss=0.6957, accuracy=0.5904, val_loss=0.6554, val_accuracy=0.6242\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6957 - accuracy: 0.5904 - val_loss: 0.6554 - val_accuracy: 0.6242 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6905 - accuracy: 0.5939Epoch 25/40: loss=0.6901, accuracy=0.5944, val_loss=0.6871, val_accuracy=0.5877\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6901 - accuracy: 0.5944 - val_loss: 0.6871 - val_accuracy: 0.5877 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6822 - accuracy: 0.6082\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 26/40: loss=0.6814, accuracy=0.6087, val_loss=0.7005, val_accuracy=0.6018\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6814 - accuracy: 0.6087 - val_loss: 0.7005 - val_accuracy: 0.6018 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6695 - accuracy: 0.6231Epoch 27/40: loss=0.6693, accuracy=0.6231, val_loss=0.6782, val_accuracy=0.6233\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6693 - accuracy: 0.6231 - val_loss: 0.6782 - val_accuracy: 0.6233 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.6188Epoch 28/40: loss=0.6685, accuracy=0.6188, val_loss=0.6600, val_accuracy=0.6325\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6685 - accuracy: 0.6188 - val_loss: 0.6600 - val_accuracy: 0.6325 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.6111Epoch 29/40: loss=0.6747, accuracy=0.6111, val_loss=0.6742, val_accuracy=0.6175\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6747 - accuracy: 0.6111 - val_loss: 0.6742 - val_accuracy: 0.6175 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.6223Epoch 30/40: loss=0.6675, accuracy=0.6221, val_loss=0.6686, val_accuracy=0.6308\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6675 - accuracy: 0.6221 - val_loss: 0.6686 - val_accuracy: 0.6308 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6636 - accuracy: 0.6289\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 31/40: loss=0.6643, accuracy=0.6283, val_loss=0.6512, val_accuracy=0.6416\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6643 - accuracy: 0.6283 - val_loss: 0.6512 - val_accuracy: 0.6416 - lr: 4.0000e-06\n",
      "Epoch 31: early stopping\n",
      "Validation accuracy: 0.6490066051483154\n",
      "\n",
      "Refined Training Combination 50/50: num_residual_blocks=8, dropout_rate=0.35, learning_rate=0.001, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.6, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.5360Epoch 1/40: loss=1.0880, accuracy=0.5360, val_loss=1.0179, val_accuracy=0.5166\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 1.0880 - accuracy: 0.5360 - val_loss: 1.0179 - val_accuracy: 0.5166 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8682 - accuracy: 0.5211Epoch 2/40: loss=0.8679, accuracy=0.5213, val_loss=0.8389, val_accuracy=0.4851\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8679 - accuracy: 0.5213 - val_loss: 0.8389 - val_accuracy: 0.4851 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.5589Epoch 3/40: loss=0.7882, accuracy=0.5588, val_loss=0.6932, val_accuracy=0.5935\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7882 - accuracy: 0.5588 - val_loss: 0.6932 - val_accuracy: 0.5935 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7599 - accuracy: 0.5790Epoch 4/40: loss=0.7597, accuracy=0.5797, val_loss=0.9007, val_accuracy=0.4470\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7597 - accuracy: 0.5797 - val_loss: 0.9007 - val_accuracy: 0.4470 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7323 - accuracy: 0.6084Epoch 5/40: loss=0.7319, accuracy=0.6091, val_loss=0.9033, val_accuracy=0.6043\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7319 - accuracy: 0.6091 - val_loss: 0.9033 - val_accuracy: 0.6043 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7614 - accuracy: 0.5970Epoch 6/40: loss=0.7608, accuracy=0.5975, val_loss=0.7849, val_accuracy=0.6126\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7608 - accuracy: 0.5975 - val_loss: 0.7849 - val_accuracy: 0.6126 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7635 - accuracy: 0.6039Epoch 7/40: loss=0.7635, accuracy=0.6039, val_loss=1.0030, val_accuracy=0.6656\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7635 - accuracy: 0.6039 - val_loss: 1.0030 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.6086\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.7412, accuracy=0.6072, val_loss=0.7411, val_accuracy=0.4694\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7412 - accuracy: 0.6072 - val_loss: 0.7411 - val_accuracy: 0.4694 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5883Epoch 9/40: loss=0.6918, accuracy=0.5886, val_loss=0.9711, val_accuracy=0.4901\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6918 - accuracy: 0.5886 - val_loss: 0.9711 - val_accuracy: 0.4901 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6595 - accuracy: 0.6426Epoch 10/40: loss=0.6596, accuracy=0.6426, val_loss=0.6192, val_accuracy=0.6656\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6596 - accuracy: 0.6426 - val_loss: 0.6192 - val_accuracy: 0.6656 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6140 - accuracy: 0.6678Epoch 11/40: loss=0.6144, accuracy=0.6678, val_loss=0.6660, val_accuracy=0.6374\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6144 - accuracy: 0.6678 - val_loss: 0.6660 - val_accuracy: 0.6374 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.6864Epoch 12/40: loss=0.6050, accuracy=0.6865, val_loss=0.6967, val_accuracy=0.5778\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6050 - accuracy: 0.6865 - val_loss: 0.6967 - val_accuracy: 0.5778 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.6998Epoch 13/40: loss=0.5948, accuracy=0.7001, val_loss=0.5712, val_accuracy=0.6813\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5948 - accuracy: 0.7001 - val_loss: 0.5712 - val_accuracy: 0.6813 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5966 - accuracy: 0.6962Epoch 14/40: loss=0.5965, accuracy=0.6960, val_loss=0.5718, val_accuracy=0.6846\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5965 - accuracy: 0.6960 - val_loss: 0.5718 - val_accuracy: 0.6846 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.6990Epoch 15/40: loss=0.5913, accuracy=0.6991, val_loss=0.7425, val_accuracy=0.5902\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5913 - accuracy: 0.6991 - val_loss: 0.7425 - val_accuracy: 0.5902 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7127Epoch 16/40: loss=0.5765, accuracy=0.7127, val_loss=0.5202, val_accuracy=0.7368\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5765 - accuracy: 0.7127 - val_loss: 0.5202 - val_accuracy: 0.7368 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5835 - accuracy: 0.6999Epoch 17/40: loss=0.5832, accuracy=0.7005, val_loss=0.5125, val_accuracy=0.7450\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5832 - accuracy: 0.7005 - val_loss: 0.5125 - val_accuracy: 0.7450 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5823 - accuracy: 0.7151Epoch 18/40: loss=0.5815, accuracy=0.7159, val_loss=0.7408, val_accuracy=0.6076\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5815 - accuracy: 0.7159 - val_loss: 0.7408 - val_accuracy: 0.6076 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5763 - accuracy: 0.7117Epoch 19/40: loss=0.5768, accuracy=0.7113, val_loss=0.5434, val_accuracy=0.7392\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5768 - accuracy: 0.7113 - val_loss: 0.5434 - val_accuracy: 0.7392 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7056Epoch 20/40: loss=0.5774, accuracy=0.7059, val_loss=0.7371, val_accuracy=0.6217\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5774 - accuracy: 0.7059 - val_loss: 0.7371 - val_accuracy: 0.6217 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.7185Epoch 21/40: loss=0.5707, accuracy=0.7185, val_loss=0.9123, val_accuracy=0.5281\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5707 - accuracy: 0.7185 - val_loss: 0.9123 - val_accuracy: 0.5281 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7107Epoch 22/40: loss=0.5742, accuracy=0.7107, val_loss=0.5024, val_accuracy=0.7541\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5742 - accuracy: 0.7107 - val_loss: 0.5024 - val_accuracy: 0.7541 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.7234Epoch 23/40: loss=0.5609, accuracy=0.7227, val_loss=0.5685, val_accuracy=0.7078\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5609 - accuracy: 0.7227 - val_loss: 0.5685 - val_accuracy: 0.7078 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.7263Epoch 24/40: loss=0.5546, accuracy=0.7270, val_loss=0.5243, val_accuracy=0.7334\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5546 - accuracy: 0.7270 - val_loss: 0.5243 - val_accuracy: 0.7334 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7175Epoch 25/40: loss=0.5587, accuracy=0.7175, val_loss=0.5391, val_accuracy=0.7177\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5587 - accuracy: 0.7175 - val_loss: 0.5391 - val_accuracy: 0.7177 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.7299Epoch 26/40: loss=0.5598, accuracy=0.7299, val_loss=0.5379, val_accuracy=0.7434\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5598 - accuracy: 0.7299 - val_loss: 0.5379 - val_accuracy: 0.7434 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.7170Epoch 27/40: loss=0.5527, accuracy=0.7169, val_loss=0.4943, val_accuracy=0.7632\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5527 - accuracy: 0.7169 - val_loss: 0.4943 - val_accuracy: 0.7632 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7228Epoch 28/40: loss=0.5501, accuracy=0.7227, val_loss=0.5767, val_accuracy=0.7003\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5501 - accuracy: 0.7227 - val_loss: 0.5767 - val_accuracy: 0.7003 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7301Epoch 29/40: loss=0.5392, accuracy=0.7301, val_loss=0.5557, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5392 - accuracy: 0.7301 - val_loss: 0.5557 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.7244Epoch 30/40: loss=0.5512, accuracy=0.7248, val_loss=0.5025, val_accuracy=0.7599\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5512 - accuracy: 0.7248 - val_loss: 0.5025 - val_accuracy: 0.7599 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7351Epoch 31/40: loss=0.5412, accuracy=0.7351, val_loss=0.4475, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5412 - accuracy: 0.7351 - val_loss: 0.4475 - val_accuracy: 0.7889 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.7272Epoch 32/40: loss=0.5430, accuracy=0.7272, val_loss=0.6745, val_accuracy=0.6490\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5430 - accuracy: 0.7272 - val_loss: 0.6745 - val_accuracy: 0.6490 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.7304Epoch 33/40: loss=0.5395, accuracy=0.7305, val_loss=0.4898, val_accuracy=0.7558\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5395 - accuracy: 0.7305 - val_loss: 0.4898 - val_accuracy: 0.7558 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7292Epoch 34/40: loss=0.5496, accuracy=0.7295, val_loss=0.5212, val_accuracy=0.7293\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5496 - accuracy: 0.7295 - val_loss: 0.5212 - val_accuracy: 0.7293 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.7372Epoch 35/40: loss=0.5291, accuracy=0.7372, val_loss=0.4496, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5291 - accuracy: 0.7372 - val_loss: 0.4496 - val_accuracy: 0.7790 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.7311\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40: loss=0.5402, accuracy=0.7316, val_loss=0.5906, val_accuracy=0.6896\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5402 - accuracy: 0.7316 - val_loss: 0.5906 - val_accuracy: 0.6896 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.7506Epoch 37/40: loss=0.5077, accuracy=0.7506, val_loss=0.4611, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5077 - accuracy: 0.7506 - val_loss: 0.4611 - val_accuracy: 0.7773 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5038 - accuracy: 0.7546Epoch 38/40: loss=0.5039, accuracy=0.7546, val_loss=0.4393, val_accuracy=0.7947\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5039 - accuracy: 0.7546 - val_loss: 0.4393 - val_accuracy: 0.7947 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4949 - accuracy: 0.7633Epoch 39/40: loss=0.4945, accuracy=0.7632, val_loss=0.4733, val_accuracy=0.7690\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4945 - accuracy: 0.7632 - val_loss: 0.4733 - val_accuracy: 0.7690 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5003 - accuracy: 0.7541Epoch 40/40: loss=0.4999, accuracy=0.7546, val_loss=0.5185, val_accuracy=0.7583\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4999 - accuracy: 0.7546 - val_loss: 0.5185 - val_accuracy: 0.7583 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.7947019934654236\n",
      "\n",
      "Refined best parameters found: num_residual_blocks=9, dropout_rate=0.35, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Refined best validation accuracy: 0.9950330853462219\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "build_complex_model() missing 4 required positional arguments: 'filters', 'kernel_size', 'num_dense_layers', and 'activation_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 204\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefined best validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_accuracy_refined\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Train the final model with the refined best parameters found\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m final_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_complex_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params_refined\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params_refined\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params_refined\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    207\u001b[0m     final_history \u001b[38;5;241m=\u001b[39m final_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    208\u001b[0m         train_generator,\n\u001b[0;32m    209\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m BATCH_SIZE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    215\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: build_complex_model() missing 4 required positional arguments: 'filters', 'kernel_size', 'num_dense_layers', and 'activation_function'"
     ]
    }
   ],
   "source": [
    "# Define data augmentation\n",
    "def create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip):\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=rotation_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "def residual_block(x, filters, kernel_size):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('tanh')(x)\n",
    "    return x\n",
    "\n",
    "def build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function):\n",
    "    # Input layer for combined images\n",
    "    combined_input = Input(shape=(input_shape[1], input_shape[2], input_shape[3]), name='combined_input')\n",
    "    \n",
    "    # Convolutional base\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), activation=activation_function, padding='same')(combined_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, filters, kernel_size)\n",
    "        if x.shape[1] >= 2 and x.shape[2] >= 2:\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        x = Dense(2048, activation=activation_function)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# Define refined grid search parameters\n",
    "num_residual_blocks_options = [7, 8, 9]\n",
    "dropout_rate_options = [0.35, 0.4, 0.45]\n",
    "learning_rate_options = [0.001, 0.0005, 0.0001]\n",
    "filters_options = [128]\n",
    "kernel_size_options = [1]\n",
    "num_dense_layers_options = [1]\n",
    "activation_function_options = ['tanh']\n",
    "rotation_range_options = [0, 10, 20]\n",
    "width_shift_range_options = [0.0, 0.1, 0.2]\n",
    "height_shift_range_options = [0.0, 0.1, 0.2]\n",
    "shear_range_options = [0.4, 0.5, 0.6]\n",
    "zoom_range_options = [0.0, 0.1, 0.2]\n",
    "horizontal_flip_options = [False, True]\n",
    "\n",
    "# Create grid search parameter combinations\n",
    "refined_parameter_combinations = list(product(num_residual_blocks_options, dropout_rate_options, learning_rate_options,\n",
    "                                              filters_options, kernel_size_options, num_dense_layers_options,\n",
    "                                              activation_function_options, rotation_range_options, width_shift_range_options,\n",
    "                                              height_shift_range_options, shear_range_options, zoom_range_options, horizontal_flip_options))\n",
    "\n",
    "# Select 50 unique combinations\n",
    "np.random.seed(42)\n",
    "selected_refined_combinations = np.random.choice(len(refined_parameter_combinations), 50, replace=False)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Callbacks for training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Custom callback to print epoch details\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']}: loss={logs['loss']:.4f}, accuracy={logs['accuracy']:.4f}, val_loss={logs['val_loss']:.4f}, val_accuracy={logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Perform refined grid search\n",
    "best_val_accuracy_refined = 0\n",
    "best_params_refined = None\n",
    "best_model_save_path = 'best_refined_model.h5'\n",
    "\n",
    "for idx, combination_idx in enumerate(selected_refined_combinations):\n",
    "    num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip = refined_parameter_combinations[combination_idx]\n",
    "    print(f\"\\nRefined Training Combination {idx + 1}/50: num_residual_blocks={num_residual_blocks}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, filters={filters}, kernel_size={kernel_size}, num_dense_layers={num_dense_layers}, activation_function={activation_function}, rotation_range={rotation_range}, width_shift_range={width_shift_range}, height_shift_range={height_shift_range}, shear_range={shear_range}, zoom_range={zoom_range}, horizontal_flip={horizontal_flip}\")\n",
    "    \n",
    "    datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "    datagen.fit(X_train)\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "            epochs=40,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy_refined:\n",
    "        best_val_accuracy_refined = val_accuracy\n",
    "        best_params_refined = (num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "        model.save(best_model_save_path)\n",
    "        print(f\"Model with validation accuracy {val_accuracy} saved to {best_model_save_path}\")\n",
    "\n",
    "print(f\"\\nRefined best parameters found: num_residual_blocks={best_params_refined[0]}, dropout_rate={best_params_refined[1]}, learning_rate={best_params_refined[2]}, filters={best_params_refined[3]}, kernel_size={best_params_refined[4]}, num_dense_layers={best_params_refined[5]}, activation_function={best_params_refined[6]}, rotation_range={best_params_refined[7]}, width_shift_range={best_params_refined[8]}, height_shift_range={best_params_refined[9]}, shear_range={best_params_refined[10]}, zoom_range={best_params_refined[11]}, horizontal_flip={best_params_refined[12]}\")\n",
    "print(f\"Refined best validation accuracy: {best_val_accuracy_refined}\")\n",
    "\n",
    "# Train the final model with the refined best parameters found\n",
    "final_model = build_complex_model(input_shape, best_params_refined[0], best_params_refined[1], best_params_refined[2])\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    final_history = final_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Save the best model to a local directory\n",
    "model_save_path = 'best_model_best_acc.h5'\n",
    "final_model.save(model_save_path)\n",
    "print(f\"Best model saved to {model_save_path}\")\n",
    "\n",
    "# Make predictions\n",
    "with tf.device('/GPU:0'):\n",
    "    val_predictions = final_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_val_true, y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef363776-6837-484b-9708-a09ce680e71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a47d69a-9aca-4fdd-b9cb-99dc7bcfecca",
   "metadata": {},
   "source": [
    "# Loaded Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44871ed1-4cb7-4307-ab0c-e79362338710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_refined_model.h5\n",
      "38/38 [==============================] - 1s 11ms/step\n",
      "Confusion Matrix for loaded model:\n",
      "[[712  12]\n",
      " [  3 481]]\n",
      "Classification Report for loaded model:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Healthy_augmented       1.00      0.98      0.99       724\n",
      "Damaged_augmented       0.98      0.99      0.98       484\n",
      "\n",
      "         accuracy                           0.99      1208\n",
      "        macro avg       0.99      0.99      0.99      1208\n",
      "     weighted avg       0.99      0.99      0.99      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from the local directory\n",
    "model_save_path = 'best_refined_model.h5'\n",
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "with tf.device('/GPU:0'):\n",
    "    loaded_val_predictions = loaded_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(loaded_val_predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "loaded_y_val_pred = np.argmax(loaded_val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix for the loaded model\n",
    "loaded_conf_matrix = confusion_matrix(y_val_true, loaded_y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix for loaded model:\")\n",
    "print(loaded_conf_matrix)\n",
    "\n",
    "# Generate the classification report for the loaded model\n",
    "loaded_class_report = classification_report(y_val_true, loaded_y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report for loaded model:\")\n",
    "print(loaded_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e8174-5dd1-4992-9f99-67ea31bd6ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2381a6-38c7-4b2f-9c56-0227a5d2329f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f420ae-c2e0-4c13-a6d3-ada831b1cb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis Thanasis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

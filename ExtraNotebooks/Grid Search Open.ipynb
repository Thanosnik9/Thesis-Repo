{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e8bc41-db65-478d-ab65-dfffe6ca71ee",
   "metadata": {},
   "source": [
    "# Inserting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5ac207-a84f-49fb-bd7b-bd152d45c08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  1\n",
      "Training data shape: (4832, 64, 64, 6)\n",
      "Validation data shape: (1208, 64, 64, 6)\n",
      "Training labels shape: (4832, 2)\n",
      "Validation labels shape: (1208, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from itertools import product\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\Θάνος\\\\Desktop\\\\Thesis Thanasis\\\\data_aug_3'\n",
    "subfolders = ['clear', 'clouds']\n",
    "categories = ['Healthy_augmented', 'Damaged_augmented']\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def load_data(base_dir, subfolders, categories, img_height, img_width):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        class_num = categories.index(category)\n",
    "        clear_path = os.path.join(base_dir, subfolders[0], category)\n",
    "        clouds_path = os.path.join(base_dir, subfolders[1], category)\n",
    "        clear_images = sorted(os.listdir(clear_path))\n",
    "        clouds_images = sorted(os.listdir(clouds_path))\n",
    "        \n",
    "        for clear_img_name, clouds_img_name in zip(clear_images, clouds_images):\n",
    "            if clear_img_name.endswith('.png') and clouds_img_name.endswith('.png'):\n",
    "                clear_img_path = os.path.join(clear_path, clear_img_name)\n",
    "                clouds_img_path = os.path.join(clouds_path, clouds_img_name)\n",
    "                \n",
    "                clear_img = tf.keras.preprocessing.image.load_img(clear_img_path, target_size=(img_height, img_width))\n",
    "                clouds_img = tf.keras.preprocessing.image.load_img(clouds_img_path, target_size=(img_height, img_width))\n",
    "                \n",
    "                clear_img_array = tf.keras.preprocessing.image.img_to_array(clear_img)\n",
    "                clouds_img_array = tf.keras.preprocessing.image.img_to_array(clouds_img)\n",
    "                \n",
    "                combined_img = np.concatenate((clear_img_array, clouds_img_array), axis=-1)\n",
    "                \n",
    "                data.append(combined_img)\n",
    "                labels.append(class_num)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_data(base_dir, subfolders, categories, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Normalize the images\n",
    "data = data / 255.0\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae94da-37c1-4bbd-b36c-859a13ccc1d8",
   "metadata": {},
   "source": [
    "# Finding the best combination of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d7196-1f00-4e57-8323-fa6e4e455b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.8640915593705293, 1: 1.18664047151277}\n",
      "\n",
      "Initial Training Combination 1/50: num_residual_blocks=6, dropout_rate=0.25, learning_rate=0.0001, filters=128, kernel_size=7, num_dense_layers=2, activation_function=tanh, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.4, zoom_range=0.3, horizontal_flip=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:2094: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n",
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2493 - accuracy: 0.5155Epoch 1/40: loss=1.2486, accuracy=0.5157, val_loss=1.3963, val_accuracy=0.4652\n",
      "604/604 [==============================] - 35s 41ms/step - loss: 1.2486 - accuracy: 0.5157 - val_loss: 1.3963 - val_accuracy: 0.4652 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.6010Epoch 2/40: loss=1.0001, accuracy=0.6010, val_loss=0.9949, val_accuracy=0.6209\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 1.0001 - accuracy: 0.6010 - val_loss: 0.9949 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8913 - accuracy: 0.6196Epoch 3/40: loss=0.8907, accuracy=0.6198, val_loss=1.0770, val_accuracy=0.6275\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.8907 - accuracy: 0.6198 - val_loss: 1.0770 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7976 - accuracy: 0.6482Epoch 4/40: loss=0.7973, accuracy=0.6482, val_loss=1.7361, val_accuracy=0.6325\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.7973 - accuracy: 0.6482 - val_loss: 1.7361 - val_accuracy: 0.6325 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7272 - accuracy: 0.6522Epoch 5/40: loss=0.7271, accuracy=0.6523, val_loss=0.9471, val_accuracy=0.6796\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.7271 - accuracy: 0.6523 - val_loss: 0.9471 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.6718Epoch 6/40: loss=0.6824, accuracy=0.6720, val_loss=0.7884, val_accuracy=0.6705\n",
      "604/604 [==============================] - 24s 40ms/step - loss: 0.6824 - accuracy: 0.6720 - val_loss: 0.7884 - val_accuracy: 0.6705 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.6755Epoch 7/40: loss=0.6494, accuracy=0.6755, val_loss=0.4996, val_accuracy=0.7790\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.6494 - accuracy: 0.6755 - val_loss: 0.4996 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6189 - accuracy: 0.6998Epoch 8/40: loss=0.6183, accuracy=0.7003, val_loss=0.5396, val_accuracy=0.7550\n",
      "604/604 [==============================] - 24s 41ms/step - loss: 0.6183 - accuracy: 0.7003 - val_loss: 0.5396 - val_accuracy: 0.7550 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7078Epoch 9/40: loss=0.5939, accuracy=0.7078, val_loss=0.7653, val_accuracy=0.6813\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5939 - accuracy: 0.7078 - val_loss: 0.7653 - val_accuracy: 0.6813 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5871 - accuracy: 0.7117Epoch 10/40: loss=0.5869, accuracy=0.7119, val_loss=0.4720, val_accuracy=0.7873\n",
      "604/604 [==============================] - 25s 41ms/step - loss: 0.5869 - accuracy: 0.7119 - val_loss: 0.4720 - val_accuracy: 0.7873 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.7199Epoch 11/40: loss=0.5632, accuracy=0.7202, val_loss=1.0819, val_accuracy=0.5331\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5632 - accuracy: 0.7202 - val_loss: 1.0819 - val_accuracy: 0.5331 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5690 - accuracy: 0.7121Epoch 12/40: loss=0.5688, accuracy=0.7119, val_loss=1.5738, val_accuracy=0.4222\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5688 - accuracy: 0.7119 - val_loss: 1.5738 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7248Epoch 13/40: loss=0.5601, accuracy=0.7248, val_loss=0.7384, val_accuracy=0.6209\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5601 - accuracy: 0.7248 - val_loss: 0.7384 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.7345Epoch 14/40: loss=0.5445, accuracy=0.7345, val_loss=0.7238, val_accuracy=0.7136\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5445 - accuracy: 0.7345 - val_loss: 0.7238 - val_accuracy: 0.7136 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.7423\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 15/40: loss=0.5406, accuracy=0.7423, val_loss=0.8824, val_accuracy=0.6424\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5406 - accuracy: 0.7423 - val_loss: 0.8824 - val_accuracy: 0.6424 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5157 - accuracy: 0.7512Epoch 16/40: loss=0.5153, accuracy=0.7514, val_loss=0.5275, val_accuracy=0.7715\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5153 - accuracy: 0.7514 - val_loss: 0.5275 - val_accuracy: 0.7715 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7663Epoch 17/40: loss=0.4965, accuracy=0.7663, val_loss=0.5337, val_accuracy=0.7773\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.4965 - accuracy: 0.7663 - val_loss: 0.5337 - val_accuracy: 0.7773 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.7794Epoch 18/40: loss=0.4926, accuracy=0.7794, val_loss=0.5619, val_accuracy=0.7409\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.4926 - accuracy: 0.7794 - val_loss: 0.5619 - val_accuracy: 0.7409 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7703Epoch 19/40: loss=0.4932, accuracy=0.7703, val_loss=0.6088, val_accuracy=0.7434\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.4932 - accuracy: 0.7703 - val_loss: 0.6088 - val_accuracy: 0.7434 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.7676\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 20/40: loss=0.4884, accuracy=0.7672, val_loss=0.5922, val_accuracy=0.7624\n",
      "604/604 [==============================] - 27s 45ms/step - loss: 0.4884 - accuracy: 0.7672 - val_loss: 0.5922 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 20: early stopping\n",
      "Validation accuracy: 0.7872516512870789\n",
      "\n",
      "Initial Training Combination 2/50: num_residual_blocks=7, dropout_rate=0.35, learning_rate=5e-05, filters=128, kernel_size=7, num_dense_layers=2, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.4, shear_range=0.3, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0412 - accuracy: 0.5151Epoch 1/40: loss=1.0417, accuracy=0.5151, val_loss=0.7398, val_accuracy=0.6258\n",
      "604/604 [==============================] - 33s 45ms/step - loss: 1.0417 - accuracy: 0.5151 - val_loss: 0.7398 - val_accuracy: 0.6258 - lr: 5.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9184 - accuracy: 0.5919Epoch 2/40: loss=0.9184, accuracy=0.5919, val_loss=0.8444, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.9184 - accuracy: 0.5919 - val_loss: 0.8444 - val_accuracy: 0.5993 - lr: 5.0000e-05\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.6229Epoch 3/40: loss=0.8517, accuracy=0.6229, val_loss=0.5806, val_accuracy=0.7550\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.8517 - accuracy: 0.6229 - val_loss: 0.5806 - val_accuracy: 0.7550 - lr: 5.0000e-05\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7889 - accuracy: 0.6499Epoch 4/40: loss=0.7899, accuracy=0.6494, val_loss=0.7137, val_accuracy=0.6805\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.7899 - accuracy: 0.6494 - val_loss: 0.7137 - val_accuracy: 0.6805 - lr: 5.0000e-05\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7937 - accuracy: 0.6493Epoch 5/40: loss=0.7939, accuracy=0.6488, val_loss=0.5663, val_accuracy=0.7873\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.7939 - accuracy: 0.6488 - val_loss: 0.5663 - val_accuracy: 0.7873 - lr: 5.0000e-05\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7646 - accuracy: 0.6472Epoch 6/40: loss=0.7645, accuracy=0.6471, val_loss=0.5253, val_accuracy=0.7682\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.7645 - accuracy: 0.6471 - val_loss: 0.5253 - val_accuracy: 0.7682 - lr: 5.0000e-05\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7565 - accuracy: 0.6546Epoch 7/40: loss=0.7557, accuracy=0.6550, val_loss=0.6605, val_accuracy=0.7533\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.7557 - accuracy: 0.6550 - val_loss: 0.6605 - val_accuracy: 0.7533 - lr: 5.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7143 - accuracy: 0.6675Epoch 8/40: loss=0.7136, accuracy=0.6680, val_loss=0.6427, val_accuracy=0.7666\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7136 - accuracy: 0.6680 - val_loss: 0.6427 - val_accuracy: 0.7666 - lr: 5.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.6810Epoch 9/40: loss=0.6920, accuracy=0.6811, val_loss=0.7213, val_accuracy=0.7376\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.6920 - accuracy: 0.6811 - val_loss: 0.7213 - val_accuracy: 0.7376 - lr: 5.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.6758Epoch 10/40: loss=0.6975, accuracy=0.6759, val_loss=1.1670, val_accuracy=0.6151\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.6975 - accuracy: 0.6759 - val_loss: 1.1670 - val_accuracy: 0.6151 - lr: 5.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6578 - accuracy: 0.6835\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 11/40: loss=0.6574, accuracy=0.6838, val_loss=0.5722, val_accuracy=0.7748\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.6574 - accuracy: 0.6838 - val_loss: 0.5722 - val_accuracy: 0.7748 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.7111Epoch 12/40: loss=0.6234, accuracy=0.7111, val_loss=0.5545, val_accuracy=0.7848\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.6234 - accuracy: 0.7111 - val_loss: 0.5545 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.7130Epoch 13/40: loss=0.6084, accuracy=0.7130, val_loss=0.4593, val_accuracy=0.7914\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.6084 - accuracy: 0.7130 - val_loss: 0.4593 - val_accuracy: 0.7914 - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.7241Epoch 14/40: loss=0.5980, accuracy=0.7237, val_loss=0.9660, val_accuracy=0.6275\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5980 - accuracy: 0.7237 - val_loss: 0.9660 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5818 - accuracy: 0.7226Epoch 15/40: loss=0.5814, accuracy=0.7229, val_loss=0.7571, val_accuracy=0.7045\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.5814 - accuracy: 0.7229 - val_loss: 0.7571 - val_accuracy: 0.7045 - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.7237Epoch 16/40: loss=0.5809, accuracy=0.7237, val_loss=0.6827, val_accuracy=0.7326\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.5809 - accuracy: 0.7237 - val_loss: 0.6827 - val_accuracy: 0.7326 - lr: 1.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7399Epoch 17/40: loss=0.5610, accuracy=0.7399, val_loss=0.5788, val_accuracy=0.7715\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.5610 - accuracy: 0.7399 - val_loss: 0.5788 - val_accuracy: 0.7715 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7434\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 18/40: loss=0.5566, accuracy=0.7434, val_loss=0.4833, val_accuracy=0.7972\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.5566 - accuracy: 0.7434 - val_loss: 0.4833 - val_accuracy: 0.7972 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7342Epoch 19/40: loss=0.5490, accuracy=0.7339, val_loss=0.5222, val_accuracy=0.7839\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.5490 - accuracy: 0.7339 - val_loss: 0.5222 - val_accuracy: 0.7839 - lr: 2.0000e-06\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7382Epoch 20/40: loss=0.5482, accuracy=0.7382, val_loss=0.4777, val_accuracy=0.7980\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.5482 - accuracy: 0.7382 - val_loss: 0.4777 - val_accuracy: 0.7980 - lr: 2.0000e-06\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7506Epoch 21/40: loss=0.5342, accuracy=0.7506, val_loss=0.5215, val_accuracy=0.7856\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5342 - accuracy: 0.7506 - val_loss: 0.5215 - val_accuracy: 0.7856 - lr: 2.0000e-06\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7434Epoch 22/40: loss=0.5425, accuracy=0.7434, val_loss=0.4582, val_accuracy=0.8030\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.5425 - accuracy: 0.7434 - val_loss: 0.4582 - val_accuracy: 0.8030 - lr: 2.0000e-06\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.7496Epoch 23/40: loss=0.5381, accuracy=0.7496, val_loss=0.4448, val_accuracy=0.8079\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.5381 - accuracy: 0.7496 - val_loss: 0.4448 - val_accuracy: 0.8079 - lr: 2.0000e-06\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.7533Epoch 24/40: loss=0.5284, accuracy=0.7535, val_loss=0.4557, val_accuracy=0.8022\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5284 - accuracy: 0.7535 - val_loss: 0.4557 - val_accuracy: 0.8022 - lr: 2.0000e-06\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.7488Epoch 25/40: loss=0.5361, accuracy=0.7488, val_loss=0.5634, val_accuracy=0.7707\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.5361 - accuracy: 0.7488 - val_loss: 0.5634 - val_accuracy: 0.7707 - lr: 2.0000e-06\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7533Epoch 26/40: loss=0.5374, accuracy=0.7535, val_loss=0.4843, val_accuracy=0.7988\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5374 - accuracy: 0.7535 - val_loss: 0.4843 - val_accuracy: 0.7988 - lr: 2.0000e-06\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.7515Epoch 27/40: loss=0.5349, accuracy=0.7514, val_loss=0.4608, val_accuracy=0.7980\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5349 - accuracy: 0.7514 - val_loss: 0.4608 - val_accuracy: 0.7980 - lr: 2.0000e-06\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5118 - accuracy: 0.7587\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Epoch 28/40: loss=0.5119, accuracy=0.7585, val_loss=0.5896, val_accuracy=0.7682\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5119 - accuracy: 0.7585 - val_loss: 0.5896 - val_accuracy: 0.7682 - lr: 2.0000e-06\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.7633Epoch 29/40: loss=0.5212, accuracy=0.7630, val_loss=0.5137, val_accuracy=0.7881\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5212 - accuracy: 0.7630 - val_loss: 0.5137 - val_accuracy: 0.7881 - lr: 4.0000e-07\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5241 - accuracy: 0.7579Epoch 30/40: loss=0.5236, accuracy=0.7583, val_loss=0.5042, val_accuracy=0.7881\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5236 - accuracy: 0.7583 - val_loss: 0.5042 - val_accuracy: 0.7881 - lr: 4.0000e-07\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7641Epoch 31/40: loss=0.5074, accuracy=0.7639, val_loss=0.5275, val_accuracy=0.7806\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5074 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7806 - lr: 4.0000e-07\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.7531Epoch 32/40: loss=0.5374, accuracy=0.7531, val_loss=0.5090, val_accuracy=0.7873\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.5374 - accuracy: 0.7531 - val_loss: 0.5090 - val_accuracy: 0.7873 - lr: 4.0000e-07\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7485\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 33/40: loss=0.5243, accuracy=0.7486, val_loss=0.5062, val_accuracy=0.7881\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.5243 - accuracy: 0.7486 - val_loss: 0.5062 - val_accuracy: 0.7881 - lr: 4.0000e-07\n",
      "Epoch 33: early stopping\n",
      "Validation accuracy: 0.807947039604187\n",
      "\n",
      "Initial Training Combination 3/50: num_residual_blocks=6, dropout_rate=0.35, learning_rate=0.05, filters=32, kernel_size=3, num_dense_layers=2, activation_function=relu, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 3.7330 - accuracy: 0.5253Epoch 1/40: loss=3.7234, accuracy=0.5259, val_loss=0.7497, val_accuracy=0.4089\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 3.7234 - accuracy: 0.5259 - val_loss: 0.7497 - val_accuracy: 0.4089 - lr: 0.0500\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8901 - accuracy: 0.5457Epoch 2/40: loss=0.8901, accuracy=0.5457, val_loss=2.3663, val_accuracy=0.5944\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8901 - accuracy: 0.5457 - val_loss: 2.3663 - val_accuracy: 0.5944 - lr: 0.0500\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8243 - accuracy: 0.5818Epoch 3/40: loss=0.8241, accuracy=0.5811, val_loss=4.7227, val_accuracy=0.6407\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8241 - accuracy: 0.5811 - val_loss: 4.7227 - val_accuracy: 0.6407 - lr: 0.0500\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0619 - accuracy: 0.5756Epoch 4/40: loss=1.0616, accuracy=0.5755, val_loss=17.0058, val_accuracy=0.3974\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 1.0616 - accuracy: 0.5755 - val_loss: 17.0058 - val_accuracy: 0.3974 - lr: 0.0500\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4414 - accuracy: 0.5534Epoch 5/40: loss=1.4403, accuracy=0.5536, val_loss=30.2000, val_accuracy=0.5488\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 1.4403 - accuracy: 0.5536 - val_loss: 30.2000 - val_accuracy: 0.5488 - lr: 0.0500\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.5493 - accuracy: 0.5471\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 6/40: loss=1.5498, accuracy=0.5468, val_loss=1.4855, val_accuracy=0.6068\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 1.5498 - accuracy: 0.5468 - val_loss: 1.4855 - val_accuracy: 0.6068 - lr: 0.0500\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.6099Epoch 7/40: loss=0.6980, accuracy=0.6095, val_loss=1.1715, val_accuracy=0.6573\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6980 - accuracy: 0.6095 - val_loss: 1.1715 - val_accuracy: 0.6573 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "600/604 [============================>.] - ETA: 0s - loss: 0.6484 - accuracy: 0.6215Epoch 8/40: loss=0.6493, accuracy=0.6202, val_loss=1.5317, val_accuracy=0.6689\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6493 - accuracy: 0.6202 - val_loss: 1.5317 - val_accuracy: 0.6689 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6468 - accuracy: 0.6337Epoch 9/40: loss=0.6469, accuracy=0.6335, val_loss=0.6505, val_accuracy=0.6714\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6469 - accuracy: 0.6335 - val_loss: 0.6505 - val_accuracy: 0.6714 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6445Epoch 10/40: loss=0.6429, accuracy=0.6445, val_loss=0.6482, val_accuracy=0.6854\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6429 - accuracy: 0.6445 - val_loss: 0.6482 - val_accuracy: 0.6854 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.6306Epoch 11/40: loss=0.6564, accuracy=0.6306, val_loss=1.0969, val_accuracy=0.6416\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6564 - accuracy: 0.6306 - val_loss: 1.0969 - val_accuracy: 0.6416 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6568 - accuracy: 0.6287Epoch 12/40: loss=0.6566, accuracy=0.6289, val_loss=2.2985, val_accuracy=0.6738\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6566 - accuracy: 0.6289 - val_loss: 2.2985 - val_accuracy: 0.6738 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6590 - accuracy: 0.6387Epoch 13/40: loss=0.6588, accuracy=0.6393, val_loss=54.9889, val_accuracy=0.6904\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6588 - accuracy: 0.6393 - val_loss: 54.9889 - val_accuracy: 0.6904 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6637 - accuracy: 0.6308Epoch 14/40: loss=0.6646, accuracy=0.6302, val_loss=3.9689, val_accuracy=0.7078\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6646 - accuracy: 0.6302 - val_loss: 3.9689 - val_accuracy: 0.7078 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.6422\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 15/40: loss=0.6584, accuracy=0.6422, val_loss=7.4119, val_accuracy=0.7086\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6584 - accuracy: 0.6422 - val_loss: 7.4119 - val_accuracy: 0.7086 - lr: 0.0100\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6141 - accuracy: 0.6663Epoch 16/40: loss=0.6140, accuracy=0.6664, val_loss=0.7738, val_accuracy=0.6813\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6140 - accuracy: 0.6664 - val_loss: 0.7738 - val_accuracy: 0.6813 - lr: 0.0020\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6014 - accuracy: 0.6800Epoch 17/40: loss=0.6011, accuracy=0.6803, val_loss=0.9771, val_accuracy=0.7161\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.6011 - accuracy: 0.6803 - val_loss: 0.9771 - val_accuracy: 0.7161 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.6757Epoch 18/40: loss=0.5998, accuracy=0.6757, val_loss=1.8978, val_accuracy=0.6896\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5998 - accuracy: 0.6757 - val_loss: 1.8978 - val_accuracy: 0.6896 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.6861Epoch 19/40: loss=0.5976, accuracy=0.6861, val_loss=0.6953, val_accuracy=0.6978\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5976 - accuracy: 0.6861 - val_loss: 0.6953 - val_accuracy: 0.6978 - lr: 0.0020\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.6878\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 20/40: loss=0.5961, accuracy=0.6879, val_loss=2.9494, val_accuracy=0.7202\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5961 - accuracy: 0.6879 - val_loss: 2.9494 - val_accuracy: 0.7202 - lr: 0.0020\n",
      "Epoch 20: early stopping\n",
      "Validation accuracy: 0.7201986908912659\n",
      "\n",
      "Initial Training Combination 4/50: num_residual_blocks=6, dropout_rate=0.55, learning_rate=1e-05, filters=64, kernel_size=7, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.4, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.5075Epoch 1/40: loss=1.0009, accuracy=0.5075, val_loss=0.6915, val_accuracy=0.5447\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.0009 - accuracy: 0.5075 - val_loss: 0.6915 - val_accuracy: 0.5447 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9905 - accuracy: 0.5029Epoch 2/40: loss=0.9905, accuracy=0.5029, val_loss=0.6508, val_accuracy=0.6341\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9905 - accuracy: 0.5029 - val_loss: 0.6508 - val_accuracy: 0.6341 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9611 - accuracy: 0.5350Epoch 3/40: loss=0.9611, accuracy=0.5350, val_loss=0.6696, val_accuracy=0.6349\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9611 - accuracy: 0.5350 - val_loss: 0.6696 - val_accuracy: 0.6349 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9492 - accuracy: 0.5323Epoch 4/40: loss=0.9492, accuracy=0.5323, val_loss=0.7097, val_accuracy=0.6225\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9492 - accuracy: 0.5323 - val_loss: 0.7097 - val_accuracy: 0.6225 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.5563Epoch 5/40: loss=0.9045, accuracy=0.5563, val_loss=0.7300, val_accuracy=0.6407\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9045 - accuracy: 0.5563 - val_loss: 0.7300 - val_accuracy: 0.6407 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8305 - accuracy: 0.6031Epoch 6/40: loss=0.8305, accuracy=0.6031, val_loss=1.2275, val_accuracy=0.5662\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8305 - accuracy: 0.6031 - val_loss: 1.2275 - val_accuracy: 0.5662 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8238 - accuracy: 0.6109\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 7/40: loss=0.8238, accuracy=0.6109, val_loss=1.5739, val_accuracy=0.4983\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8238 - accuracy: 0.6109 - val_loss: 1.5739 - val_accuracy: 0.4983 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7718 - accuracy: 0.6413Epoch 8/40: loss=0.7718, accuracy=0.6413, val_loss=1.0507, val_accuracy=0.6308\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7718 - accuracy: 0.6413 - val_loss: 1.0507 - val_accuracy: 0.6308 - lr: 2.0000e-06\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7869 - accuracy: 0.6335Epoch 9/40: loss=0.7869, accuracy=0.6335, val_loss=0.7870, val_accuracy=0.7078\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7869 - accuracy: 0.6335 - val_loss: 0.7870 - val_accuracy: 0.7078 - lr: 2.0000e-06\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.6529Epoch 10/40: loss=0.7471, accuracy=0.6529, val_loss=1.1466, val_accuracy=0.6225\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7471 - accuracy: 0.6529 - val_loss: 1.1466 - val_accuracy: 0.6225 - lr: 2.0000e-06\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.6519Epoch 11/40: loss=0.7601, accuracy=0.6519, val_loss=1.1836, val_accuracy=0.6142\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7601 - accuracy: 0.6519 - val_loss: 1.1836 - val_accuracy: 0.6142 - lr: 2.0000e-06\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7535 - accuracy: 0.6608\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 12/40: loss=0.7535, accuracy=0.6608, val_loss=0.8555, val_accuracy=0.6970\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7535 - accuracy: 0.6608 - val_loss: 0.8555 - val_accuracy: 0.6970 - lr: 2.0000e-06\n",
      "Epoch 12: early stopping\n",
      "Validation accuracy: 0.7077814340591431\n",
      "\n",
      "Initial Training Combination 5/50: num_residual_blocks=5, dropout_rate=0.5, learning_rate=1e-06, filters=32, kernel_size=7, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.3, zoom_range=0.4, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0154 - accuracy: 0.4992Epoch 1/40: loss=1.0188, accuracy=0.4986, val_loss=0.7455, val_accuracy=0.4975\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0188 - accuracy: 0.4986 - val_loss: 0.7455 - val_accuracy: 0.4975 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0316 - accuracy: 0.5017Epoch 2/40: loss=1.0323, accuracy=0.5010, val_loss=0.8505, val_accuracy=0.4536\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 1.0323 - accuracy: 0.5010 - val_loss: 0.8505 - val_accuracy: 0.4536 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0098 - accuracy: 0.5145Epoch 3/40: loss=1.0094, accuracy=0.5149, val_loss=0.8590, val_accuracy=0.4404\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 1.0094 - accuracy: 0.5149 - val_loss: 0.8590 - val_accuracy: 0.4404 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0020 - accuracy: 0.5139Epoch 4/40: loss=1.0022, accuracy=0.5137, val_loss=0.8335, val_accuracy=0.4528\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 1.0022 - accuracy: 0.5137 - val_loss: 0.8335 - val_accuracy: 0.4528 - lr: 1.0000e-06\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0032 - accuracy: 0.5158Epoch 5/40: loss=1.0031, accuracy=0.5159, val_loss=0.8368, val_accuracy=0.4503\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 1.0031 - accuracy: 0.5159 - val_loss: 0.8368 - val_accuracy: 0.4503 - lr: 1.0000e-06\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.5056\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "Epoch 6/40: loss=0.9983, accuracy=0.5056, val_loss=0.8578, val_accuracy=0.4495\n",
      "604/604 [==============================] - 9s 14ms/step - loss: 0.9983 - accuracy: 0.5056 - val_loss: 0.8578 - val_accuracy: 0.4495 - lr: 1.0000e-06\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0354 - accuracy: 0.4954Epoch 7/40: loss=1.0340, accuracy=0.4961, val_loss=0.8333, val_accuracy=0.4536\n",
      "604/604 [==============================] - 54s 90ms/step - loss: 1.0340 - accuracy: 0.4961 - val_loss: 0.8333 - val_accuracy: 0.4536 - lr: 2.0000e-07\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0216 - accuracy: 0.4905Epoch 8/40: loss=1.0212, accuracy=0.4907, val_loss=0.8561, val_accuracy=0.4470\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0212 - accuracy: 0.4907 - val_loss: 0.8561 - val_accuracy: 0.4470 - lr: 2.0000e-07\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0066 - accuracy: 0.5062Epoch 9/40: loss=1.0063, accuracy=0.5064, val_loss=0.8484, val_accuracy=0.4520\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0063 - accuracy: 0.5064 - val_loss: 0.8484 - val_accuracy: 0.4520 - lr: 2.0000e-07\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.5064Epoch 10/40: loss=1.0134, accuracy=0.5064, val_loss=0.8424, val_accuracy=0.4495\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 1.0134 - accuracy: 0.5064 - val_loss: 0.8424 - val_accuracy: 0.4495 - lr: 2.0000e-07\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0012 - accuracy: 0.5144\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11/40: loss=1.0020, accuracy=0.5135, val_loss=0.8469, val_accuracy=0.4462\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0020 - accuracy: 0.5135 - val_loss: 0.8469 - val_accuracy: 0.4462 - lr: 2.0000e-07\n",
      "Epoch 11: early stopping\n",
      "Validation accuracy: 0.49751654267311096\n",
      "\n",
      "Initial Training Combination 6/50: num_residual_blocks=6, dropout_rate=0.55, learning_rate=0.05, filters=32, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=40, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 4.4305 - accuracy: 0.5002Epoch 1/40: loss=4.4305, accuracy=0.5002, val_loss=0.8643, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 4.4305 - accuracy: 0.5002 - val_loss: 0.8643 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8443 - accuracy: 0.4985Epoch 2/40: loss=0.8444, accuracy=0.4979, val_loss=1.0978, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8444 - accuracy: 0.4979 - val_loss: 1.0978 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9419 - accuracy: 0.5010Epoch 3/40: loss=0.9421, accuracy=0.5008, val_loss=0.8922, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9421 - accuracy: 0.5008 - val_loss: 0.8922 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0911 - accuracy: 0.4923Epoch 4/40: loss=1.0907, accuracy=0.4921, val_loss=1.2075, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.0907 - accuracy: 0.4921 - val_loss: 1.2075 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.3738 - accuracy: 0.4983Epoch 5/40: loss=1.3738, accuracy=0.4983, val_loss=0.7787, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 1.3738 - accuracy: 0.4983 - val_loss: 0.7787 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4308 - accuracy: 0.5083Epoch 6/40: loss=1.4341, accuracy=0.5079, val_loss=4.1745, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.4341 - accuracy: 0.5079 - val_loss: 4.1745 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.7681 - accuracy: 0.4996Epoch 7/40: loss=1.7656, accuracy=0.5004, val_loss=2.4746, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.7656 - accuracy: 0.5004 - val_loss: 2.4746 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.3366 - accuracy: 0.5044Epoch 8/40: loss=1.3367, accuracy=0.5046, val_loss=1.2327, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.3367 - accuracy: 0.5046 - val_loss: 1.2327 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1866 - accuracy: 0.4936Epoch 9/40: loss=1.1860, accuracy=0.4934, val_loss=0.8211, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.1860 - accuracy: 0.4934 - val_loss: 0.8211 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.3036 - accuracy: 0.4919\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 10/40: loss=1.3036, accuracy=0.4919, val_loss=0.7813, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.3036 - accuracy: 0.4919 - val_loss: 0.7813 - val_accuracy: 0.5985 - lr: 0.0500\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7336 - accuracy: 0.4994Epoch 11/40: loss=0.7332, accuracy=0.4998, val_loss=0.6770, val_accuracy=0.5993\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7332 - accuracy: 0.4998 - val_loss: 0.6770 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.5087Epoch 12/40: loss=0.7014, accuracy=0.5089, val_loss=0.6784, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7014 - accuracy: 0.5089 - val_loss: 0.6784 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7055 - accuracy: 0.5041Epoch 13/40: loss=0.7056, accuracy=0.5041, val_loss=0.6790, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7056 - accuracy: 0.5041 - val_loss: 0.6790 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7064 - accuracy: 0.4994Epoch 14/40: loss=0.7065, accuracy=0.4986, val_loss=0.7487, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7065 - accuracy: 0.4986 - val_loss: 0.7487 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7083 - accuracy: 0.4803Epoch 15/40: loss=0.7082, accuracy=0.4805, val_loss=0.8908, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7082 - accuracy: 0.4805 - val_loss: 0.8908 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7277 - accuracy: 0.4849\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 16/40: loss=0.7277, accuracy=0.4849, val_loss=0.7077, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7277 - accuracy: 0.4849 - val_loss: 0.7077 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6964 - accuracy: 0.4950Epoch 17/40: loss=0.6963, accuracy=0.4950, val_loss=0.6930, val_accuracy=0.5455\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6963 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5455 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.4871Epoch 18/40: loss=0.6955, accuracy=0.4872, val_loss=0.6866, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6955 - accuracy: 0.4872 - val_loss: 0.6866 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.4988Epoch 19/40: loss=0.6950, accuracy=0.4988, val_loss=0.6853, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6950 - accuracy: 0.4988 - val_loss: 0.6853 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.4990Epoch 20/40: loss=0.6947, accuracy=0.4986, val_loss=0.7001, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6947 - accuracy: 0.4986 - val_loss: 0.7001 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.5043\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.6956, accuracy=0.5043, val_loss=0.7243, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6956 - accuracy: 0.5043 - val_loss: 0.7243 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 7/50: num_residual_blocks=5, dropout_rate=0.5, learning_rate=0.005, filters=64, kernel_size=3, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.4680 - accuracy: 0.5015Epoch 1/40: loss=1.4682, accuracy=0.5012, val_loss=0.9610, val_accuracy=0.5488\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.4682 - accuracy: 0.5012 - val_loss: 0.9610 - val_accuracy: 0.5488 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1043 - accuracy: 0.5320Epoch 2/40: loss=1.1037, accuracy=0.5323, val_loss=0.9206, val_accuracy=0.4975\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.1037 - accuracy: 0.5323 - val_loss: 0.9206 - val_accuracy: 0.4975 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8688 - accuracy: 0.5962Epoch 3/40: loss=0.8688, accuracy=0.5962, val_loss=0.6760, val_accuracy=0.7227\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8688 - accuracy: 0.5962 - val_loss: 0.6760 - val_accuracy: 0.7227 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.6248Epoch 4/40: loss=0.7829, accuracy=0.6254, val_loss=1.3240, val_accuracy=0.4429\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7829 - accuracy: 0.6254 - val_loss: 1.3240 - val_accuracy: 0.4429 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7273 - accuracy: 0.6358Epoch 5/40: loss=0.7282, accuracy=0.6347, val_loss=0.9304, val_accuracy=0.7111\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7282 - accuracy: 0.6347 - val_loss: 0.9304 - val_accuracy: 0.7111 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.6537Epoch 6/40: loss=0.6797, accuracy=0.6531, val_loss=0.9183, val_accuracy=0.5224\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6797 - accuracy: 0.6531 - val_loss: 0.9183 - val_accuracy: 0.5224 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6487 - accuracy: 0.6672Epoch 7/40: loss=0.6482, accuracy=0.6672, val_loss=11.6165, val_accuracy=0.6242\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6482 - accuracy: 0.6672 - val_loss: 11.6165 - val_accuracy: 0.6242 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6332 - accuracy: 0.6735\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 8/40: loss=0.6330, accuracy=0.6738, val_loss=4.6313, val_accuracy=0.6581\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6330 - accuracy: 0.6738 - val_loss: 4.6313 - val_accuracy: 0.6581 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.6951Epoch 9/40: loss=0.5944, accuracy=0.6952, val_loss=0.6330, val_accuracy=0.6937\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5944 - accuracy: 0.6952 - val_loss: 0.6330 - val_accuracy: 0.6937 - lr: 1.0000e-03\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7080Epoch 10/40: loss=0.5682, accuracy=0.7080, val_loss=0.5756, val_accuracy=0.7599\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5682 - accuracy: 0.7080 - val_loss: 0.5756 - val_accuracy: 0.7599 - lr: 1.0000e-03\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7071Epoch 11/40: loss=0.5700, accuracy=0.7074, val_loss=0.6458, val_accuracy=0.6416\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5700 - accuracy: 0.7074 - val_loss: 0.6458 - val_accuracy: 0.6416 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5608 - accuracy: 0.7153Epoch 12/40: loss=0.5618, accuracy=0.7146, val_loss=0.6495, val_accuracy=0.6374\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5618 - accuracy: 0.7146 - val_loss: 0.6495 - val_accuracy: 0.6374 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.7255Epoch 13/40: loss=0.5533, accuracy=0.7260, val_loss=0.7620, val_accuracy=0.6507\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5533 - accuracy: 0.7260 - val_loss: 0.7620 - val_accuracy: 0.6507 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5648 - accuracy: 0.7199Epoch 14/40: loss=0.5644, accuracy=0.7204, val_loss=0.6062, val_accuracy=0.6796\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5644 - accuracy: 0.7204 - val_loss: 0.6062 - val_accuracy: 0.6796 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.7188\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 15/40: loss=0.5515, accuracy=0.7188, val_loss=0.6481, val_accuracy=0.6763\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5515 - accuracy: 0.7188 - val_loss: 0.6481 - val_accuracy: 0.6763 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7267Epoch 16/40: loss=0.5500, accuracy=0.7264, val_loss=0.5902, val_accuracy=0.6978\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5500 - accuracy: 0.7264 - val_loss: 0.5902 - val_accuracy: 0.6978 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5422 - accuracy: 0.7311Epoch 17/40: loss=0.5422, accuracy=0.7312, val_loss=0.5804, val_accuracy=0.7161\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5422 - accuracy: 0.7312 - val_loss: 0.5804 - val_accuracy: 0.7161 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7357Epoch 18/40: loss=0.5384, accuracy=0.7355, val_loss=0.5144, val_accuracy=0.7682\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5384 - accuracy: 0.7355 - val_loss: 0.5144 - val_accuracy: 0.7682 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7388Epoch 19/40: loss=0.5321, accuracy=0.7388, val_loss=0.5688, val_accuracy=0.7268\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5321 - accuracy: 0.7388 - val_loss: 0.5688 - val_accuracy: 0.7268 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7380Epoch 20/40: loss=0.5326, accuracy=0.7376, val_loss=0.5026, val_accuracy=0.7657\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5326 - accuracy: 0.7376 - val_loss: 0.5026 - val_accuracy: 0.7657 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7265Epoch 21/40: loss=0.5394, accuracy=0.7260, val_loss=0.5409, val_accuracy=0.7401\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5394 - accuracy: 0.7260 - val_loss: 0.5409 - val_accuracy: 0.7401 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7321Epoch 22/40: loss=0.5432, accuracy=0.7316, val_loss=0.5296, val_accuracy=0.7550\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5432 - accuracy: 0.7316 - val_loss: 0.5296 - val_accuracy: 0.7550 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5264 - accuracy: 0.7440Epoch 23/40: loss=0.5264, accuracy=0.7438, val_loss=0.5659, val_accuracy=0.7161\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5264 - accuracy: 0.7438 - val_loss: 0.5659 - val_accuracy: 0.7161 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7289Epoch 24/40: loss=0.5344, accuracy=0.7289, val_loss=0.4888, val_accuracy=0.7781\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5344 - accuracy: 0.7289 - val_loss: 0.4888 - val_accuracy: 0.7781 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.7428Epoch 25/40: loss=0.5277, accuracy=0.7428, val_loss=0.4904, val_accuracy=0.7781\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5277 - accuracy: 0.7428 - val_loss: 0.4904 - val_accuracy: 0.7781 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7452Epoch 26/40: loss=0.5216, accuracy=0.7454, val_loss=0.5221, val_accuracy=0.7624\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5216 - accuracy: 0.7454 - val_loss: 0.5221 - val_accuracy: 0.7624 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.7446Epoch 27/40: loss=0.5182, accuracy=0.7444, val_loss=0.5089, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5182 - accuracy: 0.7444 - val_loss: 0.5089 - val_accuracy: 0.7707 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.7463Epoch 28/40: loss=0.5155, accuracy=0.7459, val_loss=0.4879, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5155 - accuracy: 0.7459 - val_loss: 0.4879 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5234 - accuracy: 0.7404Epoch 29/40: loss=0.5235, accuracy=0.7405, val_loss=0.5253, val_accuracy=0.7608\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5235 - accuracy: 0.7405 - val_loss: 0.5253 - val_accuracy: 0.7608 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.7539Epoch 30/40: loss=0.5143, accuracy=0.7535, val_loss=0.5132, val_accuracy=0.7724\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5132 - val_accuracy: 0.7724 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.7537Epoch 31/40: loss=0.5173, accuracy=0.7533, val_loss=0.4797, val_accuracy=0.7873\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5173 - accuracy: 0.7533 - val_loss: 0.4797 - val_accuracy: 0.7873 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.7535Epoch 32/40: loss=0.5142, accuracy=0.7531, val_loss=0.4803, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5142 - accuracy: 0.7531 - val_loss: 0.4803 - val_accuracy: 0.7873 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.7419Epoch 33/40: loss=0.5203, accuracy=0.7419, val_loss=0.4689, val_accuracy=0.7897\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5203 - accuracy: 0.7419 - val_loss: 0.4689 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.7504Epoch 34/40: loss=0.5160, accuracy=0.7502, val_loss=0.4761, val_accuracy=0.7873\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5160 - accuracy: 0.7502 - val_loss: 0.4761 - val_accuracy: 0.7873 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.7510Epoch 35/40: loss=0.5149, accuracy=0.7510, val_loss=0.4936, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5149 - accuracy: 0.7510 - val_loss: 0.4936 - val_accuracy: 0.7831 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5066 - accuracy: 0.7542Epoch 36/40: loss=0.5065, accuracy=0.7546, val_loss=0.4567, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5065 - accuracy: 0.7546 - val_loss: 0.4567 - val_accuracy: 0.7955 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5023 - accuracy: 0.7618Epoch 37/40: loss=0.5026, accuracy=0.7616, val_loss=0.4740, val_accuracy=0.7831\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5026 - accuracy: 0.7616 - val_loss: 0.4740 - val_accuracy: 0.7831 - lr: 2.0000e-04\n",
      "Epoch 38/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5086 - accuracy: 0.7556Epoch 38/40: loss=0.5088, accuracy=0.7556, val_loss=0.4387, val_accuracy=0.7988\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5088 - accuracy: 0.7556 - val_loss: 0.4387 - val_accuracy: 0.7988 - lr: 2.0000e-04\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7668Epoch 39/40: loss=0.4984, accuracy=0.7672, val_loss=0.4922, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4984 - accuracy: 0.7672 - val_loss: 0.4922 - val_accuracy: 0.7922 - lr: 2.0000e-04\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5226 - accuracy: 0.7546Epoch 40/40: loss=0.5227, accuracy=0.7543, val_loss=0.4553, val_accuracy=0.7964\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5227 - accuracy: 0.7543 - val_loss: 0.4553 - val_accuracy: 0.7964 - lr: 2.0000e-04\n",
      "Validation accuracy: 0.7988410592079163\n",
      "\n",
      "Initial Training Combination 8/50: num_residual_blocks=7, dropout_rate=0.25, learning_rate=0.001, filters=128, kernel_size=5, num_dense_layers=3, activation_function=tanh, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.4, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.4251 - accuracy: 0.4882Epoch 1/40: loss=1.4242, accuracy=0.4882, val_loss=0.7839, val_accuracy=0.4007\n",
      "604/604 [==============================] - 21s 30ms/step - loss: 1.4242 - accuracy: 0.4882 - val_loss: 0.7839 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9312 - accuracy: 0.4983Epoch 2/40: loss=0.9308, accuracy=0.4981, val_loss=0.8655, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.9308 - accuracy: 0.4981 - val_loss: 0.8655 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8962 - accuracy: 0.5129Epoch 3/40: loss=0.8963, accuracy=0.5128, val_loss=0.7437, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.8963 - accuracy: 0.5128 - val_loss: 0.7437 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8823 - accuracy: 0.5015Epoch 4/40: loss=0.8819, accuracy=0.5014, val_loss=1.1235, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.8819 - accuracy: 0.5014 - val_loss: 1.1235 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8637 - accuracy: 0.5116Epoch 5/40: loss=0.8630, accuracy=0.5122, val_loss=0.8455, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.8630 - accuracy: 0.5122 - val_loss: 0.8455 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8558 - accuracy: 0.4919Epoch 6/40: loss=0.8559, accuracy=0.4915, val_loss=0.8048, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.8559 - accuracy: 0.4915 - val_loss: 0.8048 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8440 - accuracy: 0.4950Epoch 7/40: loss=0.8438, accuracy=0.4954, val_loss=0.7140, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.8438 - accuracy: 0.4954 - val_loss: 0.7140 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.4944Epoch 8/40: loss=0.8316, accuracy=0.4940, val_loss=0.7002, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.8316 - accuracy: 0.4940 - val_loss: 0.7002 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8171 - accuracy: 0.4942Epoch 9/40: loss=0.8169, accuracy=0.4946, val_loss=0.7163, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.8169 - accuracy: 0.4946 - val_loss: 0.7163 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8051 - accuracy: 0.5037Epoch 10/40: loss=0.8047, accuracy=0.5039, val_loss=0.9533, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.8047 - accuracy: 0.5039 - val_loss: 0.9533 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8057 - accuracy: 0.4886Epoch 11/40: loss=0.8056, accuracy=0.4886, val_loss=0.6766, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.8056 - accuracy: 0.4886 - val_loss: 0.6766 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7899 - accuracy: 0.4944Epoch 12/40: loss=0.7900, accuracy=0.4946, val_loss=0.6738, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7900 - accuracy: 0.4946 - val_loss: 0.6738 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7859 - accuracy: 0.4971Epoch 13/40: loss=0.7857, accuracy=0.4973, val_loss=0.7037, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.7857 - accuracy: 0.4973 - val_loss: 0.7037 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7797 - accuracy: 0.4909Epoch 14/40: loss=0.7794, accuracy=0.4907, val_loss=0.6766, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7794 - accuracy: 0.4907 - val_loss: 0.6766 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7734 - accuracy: 0.4934Epoch 15/40: loss=0.7737, accuracy=0.4932, val_loss=0.6793, val_accuracy=0.5786\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.7737 - accuracy: 0.4932 - val_loss: 0.6793 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7650 - accuracy: 0.4944Epoch 16/40: loss=0.7651, accuracy=0.4942, val_loss=0.6790, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7651 - accuracy: 0.4942 - val_loss: 0.6790 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7606 - accuracy: 0.4992\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 17/40: loss=0.7609, accuracy=0.4992, val_loss=0.7162, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7609 - accuracy: 0.4992 - val_loss: 0.7162 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7351 - accuracy: 0.4934Epoch 18/40: loss=0.7352, accuracy=0.4932, val_loss=0.7827, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.7352 - accuracy: 0.4932 - val_loss: 0.7827 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7206 - accuracy: 0.4880Epoch 19/40: loss=0.7209, accuracy=0.4876, val_loss=0.6859, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7209 - accuracy: 0.4876 - val_loss: 0.6859 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7131 - accuracy: 0.4998Epoch 20/40: loss=0.7130, accuracy=0.5000, val_loss=0.7204, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7130 - accuracy: 0.5000 - val_loss: 0.7204 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7102 - accuracy: 0.4915Epoch 21/40: loss=0.7102, accuracy=0.4915, val_loss=0.7736, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7102 - accuracy: 0.4915 - val_loss: 0.7736 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7117 - accuracy: 0.4884\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 22/40: loss=0.7116, accuracy=0.4884, val_loss=0.6937, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7116 - accuracy: 0.4884 - val_loss: 0.6937 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 22: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 9/50: num_residual_blocks=7, dropout_rate=0.3, learning_rate=0.01, filters=64, kernel_size=3, num_dense_layers=3, activation_function=relu, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 2.6310 - accuracy: 0.5070Epoch 1/40: loss=2.6324, accuracy=0.5072, val_loss=1.2248, val_accuracy=0.4603\n",
      "604/604 [==============================] - 25s 20ms/step - loss: 2.6324 - accuracy: 0.5072 - val_loss: 1.2248 - val_accuracy: 0.4603 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.5366 - accuracy: 0.5058Epoch 2/40: loss=1.5351, accuracy=0.5062, val_loss=1.2336, val_accuracy=0.4983\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.5351 - accuracy: 0.5062 - val_loss: 1.2336 - val_accuracy: 0.4983 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0530 - accuracy: 0.5039Epoch 3/40: loss=1.0530, accuracy=0.5039, val_loss=0.9709, val_accuracy=0.4015\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 1.0530 - accuracy: 0.5039 - val_loss: 0.9709 - val_accuracy: 0.4015 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.5114Epoch 4/40: loss=0.8105, accuracy=0.5114, val_loss=16.4987, val_accuracy=0.4040\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8105 - accuracy: 0.5114 - val_loss: 16.4987 - val_accuracy: 0.4040 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7173 - accuracy: 0.5480Epoch 5/40: loss=0.7172, accuracy=0.5478, val_loss=0.9657, val_accuracy=0.6325\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7172 - accuracy: 0.5478 - val_loss: 0.9657 - val_accuracy: 0.6325 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.5721Epoch 6/40: loss=0.6806, accuracy=0.5720, val_loss=0.7554, val_accuracy=0.6391\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6806 - accuracy: 0.5720 - val_loss: 0.7554 - val_accuracy: 0.6391 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5813Epoch 7/40: loss=0.6772, accuracy=0.5813, val_loss=0.8070, val_accuracy=0.6250\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6772 - accuracy: 0.5813 - val_loss: 0.8070 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6833 - accuracy: 0.5880Epoch 8/40: loss=0.6829, accuracy=0.5886, val_loss=0.6231, val_accuracy=0.6498\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6829 - accuracy: 0.5886 - val_loss: 0.6231 - val_accuracy: 0.6498 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6842 - accuracy: 0.5843Epoch 9/40: loss=0.6843, accuracy=0.5842, val_loss=0.9194, val_accuracy=0.5472\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6843 - accuracy: 0.5842 - val_loss: 0.9194 - val_accuracy: 0.5472 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6986 - accuracy: 0.5811Epoch 10/40: loss=0.6991, accuracy=0.5809, val_loss=0.7162, val_accuracy=0.6291\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6991 - accuracy: 0.5809 - val_loss: 0.7162 - val_accuracy: 0.6291 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6968 - accuracy: 0.5853Epoch 11/40: loss=0.6973, accuracy=0.5844, val_loss=0.7033, val_accuracy=0.6134\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6973 - accuracy: 0.5844 - val_loss: 0.7033 - val_accuracy: 0.6134 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.6082Epoch 12/40: loss=0.6990, accuracy=0.6082, val_loss=0.7007, val_accuracy=0.6118\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6990 - accuracy: 0.6082 - val_loss: 0.7007 - val_accuracy: 0.6118 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.6389\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 13/40: loss=0.6712, accuracy=0.6389, val_loss=1.3556, val_accuracy=0.6565\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6712 - accuracy: 0.6389 - val_loss: 1.3556 - val_accuracy: 0.6565 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7026Epoch 14/40: loss=0.5772, accuracy=0.7026, val_loss=0.6034, val_accuracy=0.7566\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5772 - accuracy: 0.7026 - val_loss: 0.6034 - val_accuracy: 0.7566 - lr: 0.0020\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5652 - accuracy: 0.7061Epoch 15/40: loss=0.5654, accuracy=0.7061, val_loss=0.8393, val_accuracy=0.7053\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5654 - accuracy: 0.7061 - val_loss: 0.8393 - val_accuracy: 0.7053 - lr: 0.0020\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.7213Epoch 16/40: loss=0.5548, accuracy=0.7210, val_loss=0.4826, val_accuracy=0.7724\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5548 - accuracy: 0.7210 - val_loss: 0.4826 - val_accuracy: 0.7724 - lr: 0.0020\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.7344Epoch 17/40: loss=0.5401, accuracy=0.7343, val_loss=1.3829, val_accuracy=0.7061\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5401 - accuracy: 0.7343 - val_loss: 1.3829 - val_accuracy: 0.7061 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.7319Epoch 18/40: loss=0.5358, accuracy=0.7316, val_loss=0.5932, val_accuracy=0.7442\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5358 - accuracy: 0.7316 - val_loss: 0.5932 - val_accuracy: 0.7442 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5587 - accuracy: 0.7284Epoch 19/40: loss=0.5579, accuracy=0.7291, val_loss=1.0290, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5579 - accuracy: 0.7291 - val_loss: 1.0290 - val_accuracy: 0.7848 - lr: 0.0020\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7430Epoch 20/40: loss=0.5287, accuracy=0.7430, val_loss=41.5852, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5287 - accuracy: 0.7430 - val_loss: 41.5852 - val_accuracy: 0.7318 - lr: 0.0020\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5322 - accuracy: 0.7392\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 21/40: loss=0.5325, accuracy=0.7388, val_loss=2.1556, val_accuracy=0.7119\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5325 - accuracy: 0.7388 - val_loss: 2.1556 - val_accuracy: 0.7119 - lr: 0.0020\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.7517Epoch 22/40: loss=0.5161, accuracy=0.7517, val_loss=0.5287, val_accuracy=0.7864\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5161 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7864 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7601Epoch 23/40: loss=0.5134, accuracy=0.7601, val_loss=0.4433, val_accuracy=0.8038\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5134 - accuracy: 0.7601 - val_loss: 0.4433 - val_accuracy: 0.8038 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5019 - accuracy: 0.7583Epoch 24/40: loss=0.5026, accuracy=0.7581, val_loss=0.5848, val_accuracy=0.8005\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5026 - accuracy: 0.7581 - val_loss: 0.5848 - val_accuracy: 0.8005 - lr: 4.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.7707Epoch 25/40: loss=0.4965, accuracy=0.7709, val_loss=0.5528, val_accuracy=0.7889\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4965 - accuracy: 0.7709 - val_loss: 0.5528 - val_accuracy: 0.7889 - lr: 4.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.7632Epoch 26/40: loss=0.4994, accuracy=0.7632, val_loss=0.4456, val_accuracy=0.8245\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4994 - accuracy: 0.7632 - val_loss: 0.4456 - val_accuracy: 0.8245 - lr: 4.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.7548Epoch 27/40: loss=0.5081, accuracy=0.7546, val_loss=0.4346, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5081 - accuracy: 0.7546 - val_loss: 0.4346 - val_accuracy: 0.8121 - lr: 4.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.7687Epoch 28/40: loss=0.4981, accuracy=0.7688, val_loss=0.4561, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4981 - accuracy: 0.7688 - val_loss: 0.4561 - val_accuracy: 0.8146 - lr: 4.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.7645Epoch 29/40: loss=0.4968, accuracy=0.7643, val_loss=0.8496, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4968 - accuracy: 0.7643 - val_loss: 0.8496 - val_accuracy: 0.7848 - lr: 4.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7612Epoch 30/40: loss=0.5025, accuracy=0.7612, val_loss=0.4686, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5025 - accuracy: 0.7612 - val_loss: 0.4686 - val_accuracy: 0.8137 - lr: 4.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.7719Epoch 31/40: loss=0.4917, accuracy=0.7719, val_loss=0.4444, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4917 - accuracy: 0.7719 - val_loss: 0.4444 - val_accuracy: 0.8146 - lr: 4.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.7647\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 32/40: loss=0.5021, accuracy=0.7651, val_loss=0.4929, val_accuracy=0.8278\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5021 - accuracy: 0.7651 - val_loss: 0.4929 - val_accuracy: 0.8278 - lr: 4.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.7682Epoch 33/40: loss=0.4928, accuracy=0.7682, val_loss=0.4565, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4928 - accuracy: 0.7682 - val_loss: 0.4565 - val_accuracy: 0.8179 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.7714Epoch 34/40: loss=0.4958, accuracy=0.7717, val_loss=0.4727, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4958 - accuracy: 0.7717 - val_loss: 0.4727 - val_accuracy: 0.8137 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.7637Epoch 35/40: loss=0.4958, accuracy=0.7639, val_loss=0.4367, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4958 - accuracy: 0.7639 - val_loss: 0.4367 - val_accuracy: 0.8220 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.7684Epoch 36/40: loss=0.4914, accuracy=0.7684, val_loss=0.5372, val_accuracy=0.8220\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4914 - accuracy: 0.7684 - val_loss: 0.5372 - val_accuracy: 0.8220 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4947 - accuracy: 0.7682\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 37/40: loss=0.4954, accuracy=0.7678, val_loss=0.4401, val_accuracy=0.8228\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4954 - accuracy: 0.7678 - val_loss: 0.4401 - val_accuracy: 0.8228 - lr: 8.0000e-05\n",
      "Epoch 37: early stopping\n",
      "Validation accuracy: 0.8278145790100098\n",
      "\n",
      "Initial Training Combination 10/50: num_residual_blocks=5, dropout_rate=0.6, learning_rate=0.005, filters=128, kernel_size=3, num_dense_layers=3, activation_function=tanh, rotation_range=40, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 2.2151 - accuracy: 0.4979Epoch 1/40: loss=2.2137, accuracy=0.4975, val_loss=0.6814, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 2.2137 - accuracy: 0.4975 - val_loss: 0.6814 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.6226 - accuracy: 0.5091Epoch 2/40: loss=1.6208, accuracy=0.5093, val_loss=0.6856, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.6208 - accuracy: 0.5093 - val_loss: 0.6856 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.4829 - accuracy: 0.4994Epoch 3/40: loss=1.4812, accuracy=0.4996, val_loss=0.6957, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.4812 - accuracy: 0.4996 - val_loss: 0.6957 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.3071 - accuracy: 0.4977Epoch 4/40: loss=1.3063, accuracy=0.4981, val_loss=0.6750, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 1.3063 - accuracy: 0.4981 - val_loss: 0.6750 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1145 - accuracy: 0.4954Epoch 5/40: loss=1.1145, accuracy=0.4959, val_loss=0.6908, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.1145 - accuracy: 0.4959 - val_loss: 0.6908 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0039 - accuracy: 0.4911Epoch 6/40: loss=1.0034, accuracy=0.4909, val_loss=0.6828, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0034 - accuracy: 0.4909 - val_loss: 0.6828 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9122 - accuracy: 0.4990Epoch 7/40: loss=0.9127, accuracy=0.4988, val_loss=0.9492, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9127 - accuracy: 0.4988 - val_loss: 0.9492 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8593 - accuracy: 0.4890Epoch 8/40: loss=0.8586, accuracy=0.4886, val_loss=0.7263, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8586 - accuracy: 0.4886 - val_loss: 0.7263 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8072 - accuracy: 0.4940\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 9/40: loss=0.8057, accuracy=0.4957, val_loss=0.6820, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8057 - accuracy: 0.4957 - val_loss: 0.6820 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7416 - accuracy: 0.5054Epoch 10/40: loss=0.7416, accuracy=0.5054, val_loss=0.6746, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7416 - accuracy: 0.5054 - val_loss: 0.6746 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7281 - accuracy: 0.4927Epoch 11/40: loss=0.7282, accuracy=0.4925, val_loss=0.7239, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7282 - accuracy: 0.4925 - val_loss: 0.7239 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7109 - accuracy: 0.5037Epoch 12/40: loss=0.7109, accuracy=0.5039, val_loss=0.6979, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7109 - accuracy: 0.5039 - val_loss: 0.6979 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7178 - accuracy: 0.4888Epoch 13/40: loss=0.7177, accuracy=0.4886, val_loss=0.6921, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7177 - accuracy: 0.4886 - val_loss: 0.6921 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.4940Epoch 14/40: loss=0.7142, accuracy=0.4940, val_loss=0.6829, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7142 - accuracy: 0.4940 - val_loss: 0.6829 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7129 - accuracy: 0.5010\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 15/40: loss=0.7129, accuracy=0.5010, val_loss=0.6951, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7129 - accuracy: 0.5010 - val_loss: 0.6951 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.5010Epoch 16/40: loss=0.7076, accuracy=0.5010, val_loss=0.6918, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7076 - accuracy: 0.5010 - val_loss: 0.6918 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.4973Epoch 17/40: loss=0.7081, accuracy=0.4973, val_loss=0.6864, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7081 - accuracy: 0.4973 - val_loss: 0.6864 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7078 - accuracy: 0.4992Epoch 18/40: loss=0.7078, accuracy=0.4990, val_loss=0.6988, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7078 - accuracy: 0.4990 - val_loss: 0.6988 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.4963Epoch 19/40: loss=0.7048, accuracy=0.4963, val_loss=0.6921, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7048 - accuracy: 0.4963 - val_loss: 0.6921 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.5002\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 20/40: loss=0.7028, accuracy=0.5002, val_loss=0.6865, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7028 - accuracy: 0.5002 - val_loss: 0.6865 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 20: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 11/50: num_residual_blocks=6, dropout_rate=0.55, learning_rate=5e-05, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.4, height_shift_range=0.4, shear_range=0.3, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0358 - accuracy: 0.5199Epoch 1/40: loss=1.0356, accuracy=0.5201, val_loss=0.7169, val_accuracy=0.5563\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0356 - accuracy: 0.5201 - val_loss: 0.7169 - val_accuracy: 0.5563 - lr: 5.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9825 - accuracy: 0.5317Epoch 2/40: loss=0.9825, accuracy=0.5317, val_loss=0.6748, val_accuracy=0.6250\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9825 - accuracy: 0.5317 - val_loss: 0.6748 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9610 - accuracy: 0.5362Epoch 3/40: loss=0.9647, accuracy=0.5352, val_loss=0.7024, val_accuracy=0.6656\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9647 - accuracy: 0.5352 - val_loss: 0.7024 - val_accuracy: 0.6656 - lr: 5.0000e-05\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9119 - accuracy: 0.5654Epoch 4/40: loss=0.9128, accuracy=0.5652, val_loss=0.6465, val_accuracy=0.6722\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9128 - accuracy: 0.5652 - val_loss: 0.6465 - val_accuracy: 0.6722 - lr: 5.0000e-05\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8504 - accuracy: 0.5874Epoch 5/40: loss=0.8508, accuracy=0.5875, val_loss=0.6185, val_accuracy=0.6838\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8508 - accuracy: 0.5875 - val_loss: 0.6185 - val_accuracy: 0.6838 - lr: 5.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.5973Epoch 6/40: loss=0.8263, accuracy=0.5973, val_loss=0.6692, val_accuracy=0.6887\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8263 - accuracy: 0.5973 - val_loss: 0.6692 - val_accuracy: 0.6887 - lr: 5.0000e-05\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.6132Epoch 7/40: loss=0.8062, accuracy=0.6132, val_loss=0.7675, val_accuracy=0.6763\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8062 - accuracy: 0.6132 - val_loss: 0.7675 - val_accuracy: 0.6763 - lr: 5.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7812 - accuracy: 0.6113Epoch 8/40: loss=0.7805, accuracy=0.6115, val_loss=0.7160, val_accuracy=0.7136\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7805 - accuracy: 0.6115 - val_loss: 0.7160 - val_accuracy: 0.7136 - lr: 5.0000e-05\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.6337Epoch 9/40: loss=0.7454, accuracy=0.6337, val_loss=0.6363, val_accuracy=0.7293\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7454 - accuracy: 0.6337 - val_loss: 0.6363 - val_accuracy: 0.7293 - lr: 5.0000e-05\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.6325\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 10/40: loss=0.7474, accuracy=0.6325, val_loss=0.8922, val_accuracy=0.5927\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7474 - accuracy: 0.6325 - val_loss: 0.8922 - val_accuracy: 0.5927 - lr: 5.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7177 - accuracy: 0.6412Epoch 11/40: loss=0.7183, accuracy=0.6411, val_loss=0.5657, val_accuracy=0.7425\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7183 - accuracy: 0.6411 - val_loss: 0.5657 - val_accuracy: 0.7425 - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7027 - accuracy: 0.6544Epoch 12/40: loss=0.7027, accuracy=0.6544, val_loss=0.5858, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7027 - accuracy: 0.6544 - val_loss: 0.5858 - val_accuracy: 0.7450 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7192 - accuracy: 0.6393Epoch 13/40: loss=0.7198, accuracy=0.6389, val_loss=0.5890, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7198 - accuracy: 0.6389 - val_loss: 0.5890 - val_accuracy: 0.7450 - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7022 - accuracy: 0.6459Epoch 14/40: loss=0.7021, accuracy=0.6459, val_loss=0.5940, val_accuracy=0.7401\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7021 - accuracy: 0.6459 - val_loss: 0.5940 - val_accuracy: 0.7401 - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7010 - accuracy: 0.6381Epoch 15/40: loss=0.7013, accuracy=0.6376, val_loss=0.5626, val_accuracy=0.7558\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7013 - accuracy: 0.6376 - val_loss: 0.5626 - val_accuracy: 0.7558 - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.6599Epoch 16/40: loss=0.6784, accuracy=0.6596, val_loss=0.5677, val_accuracy=0.7517\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6784 - accuracy: 0.6596 - val_loss: 0.5677 - val_accuracy: 0.7517 - lr: 1.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.6557Epoch 17/40: loss=0.6803, accuracy=0.6556, val_loss=0.5336, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6803 - accuracy: 0.6556 - val_loss: 0.5336 - val_accuracy: 0.7575 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6567 - accuracy: 0.6701Epoch 18/40: loss=0.6568, accuracy=0.6699, val_loss=0.6230, val_accuracy=0.7368\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6568 - accuracy: 0.6699 - val_loss: 0.6230 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.6631Epoch 19/40: loss=0.6714, accuracy=0.6635, val_loss=0.5541, val_accuracy=0.7591\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6714 - accuracy: 0.6635 - val_loss: 0.5541 - val_accuracy: 0.7591 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.6575Epoch 20/40: loss=0.6665, accuracy=0.6581, val_loss=0.6104, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6665 - accuracy: 0.6581 - val_loss: 0.6104 - val_accuracy: 0.7301 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6658 - accuracy: 0.6622Epoch 21/40: loss=0.6652, accuracy=0.6625, val_loss=0.6413, val_accuracy=0.7194\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6652 - accuracy: 0.6625 - val_loss: 0.6413 - val_accuracy: 0.7194 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.6727\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 22/40: loss=0.6514, accuracy=0.6728, val_loss=0.5705, val_accuracy=0.7508\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6514 - accuracy: 0.6728 - val_loss: 0.5705 - val_accuracy: 0.7508 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.6766Epoch 23/40: loss=0.6446, accuracy=0.6765, val_loss=0.5694, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6446 - accuracy: 0.6765 - val_loss: 0.5694 - val_accuracy: 0.7442 - lr: 2.0000e-06\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.6699Epoch 24/40: loss=0.6562, accuracy=0.6695, val_loss=0.5588, val_accuracy=0.7525\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6562 - accuracy: 0.6695 - val_loss: 0.5588 - val_accuracy: 0.7525 - lr: 2.0000e-06\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6584 - accuracy: 0.6721Epoch 25/40: loss=0.6581, accuracy=0.6722, val_loss=0.5716, val_accuracy=0.7417\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6581 - accuracy: 0.6722 - val_loss: 0.5716 - val_accuracy: 0.7417 - lr: 2.0000e-06\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6549 - accuracy: 0.6725Epoch 26/40: loss=0.6552, accuracy=0.6724, val_loss=0.5621, val_accuracy=0.7475\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6552 - accuracy: 0.6724 - val_loss: 0.5621 - val_accuracy: 0.7475 - lr: 2.0000e-06\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6448 - accuracy: 0.6744\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.6449, accuracy=0.6749, val_loss=0.5536, val_accuracy=0.7517\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6449 - accuracy: 0.6749 - val_loss: 0.5536 - val_accuracy: 0.7517 - lr: 2.0000e-06\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7591059803962708\n",
      "\n",
      "Initial Training Combination 12/50: num_residual_blocks=8, dropout_rate=0.5, learning_rate=0.0001, filters=32, kernel_size=3, num_dense_layers=3, activation_function=tanh, rotation_range=40, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.4, zoom_range=0.4, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "  6/604 [..............................] - ETA: 31s - loss: 1.1376 - accuracy: 0.5000 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0233s vs `on_train_batch_end` time: 0.0348s). Check your callbacks.\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1480 - accuracy: 0.5087Epoch 1/40: loss=1.1480, accuracy=0.5087, val_loss=1.0409, val_accuracy=0.5323\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 1.1480 - accuracy: 0.5087 - val_loss: 1.0409 - val_accuracy: 0.5323 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0478 - accuracy: 0.5255Epoch 2/40: loss=1.0480, accuracy=0.5252, val_loss=0.9394, val_accuracy=0.4445\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0480 - accuracy: 0.5252 - val_loss: 0.9394 - val_accuracy: 0.4445 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9706 - accuracy: 0.5269Epoch 3/40: loss=0.9706, accuracy=0.5269, val_loss=0.7423, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9706 - accuracy: 0.5269 - val_loss: 0.7423 - val_accuracy: 0.5985 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.5509Epoch 4/40: loss=0.8796, accuracy=0.5509, val_loss=0.6830, val_accuracy=0.6399\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8796 - accuracy: 0.5509 - val_loss: 0.6830 - val_accuracy: 0.6399 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8339 - accuracy: 0.5624Epoch 5/40: loss=0.8341, accuracy=0.5623, val_loss=0.8246, val_accuracy=0.6093\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8341 - accuracy: 0.5623 - val_loss: 0.8246 - val_accuracy: 0.6093 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7910 - accuracy: 0.5755Epoch 6/40: loss=0.7903, accuracy=0.5760, val_loss=0.8793, val_accuracy=0.5323\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7903 - accuracy: 0.5760 - val_loss: 0.8793 - val_accuracy: 0.5323 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7373 - accuracy: 0.6051Epoch 7/40: loss=0.7369, accuracy=0.6049, val_loss=0.9643, val_accuracy=0.5505\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7369 - accuracy: 0.6049 - val_loss: 0.9643 - val_accuracy: 0.5505 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6877 - accuracy: 0.6316Epoch 8/40: loss=0.6870, accuracy=0.6318, val_loss=0.6589, val_accuracy=0.7252\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6870 - accuracy: 0.6318 - val_loss: 0.6589 - val_accuracy: 0.7252 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.6442Epoch 9/40: loss=0.6613, accuracy=0.6442, val_loss=0.9767, val_accuracy=0.6250\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6613 - accuracy: 0.6442 - val_loss: 0.9767 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6334 - accuracy: 0.6700Epoch 10/40: loss=0.6334, accuracy=0.6699, val_loss=0.5242, val_accuracy=0.7575\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6334 - accuracy: 0.6699 - val_loss: 0.5242 - val_accuracy: 0.7575 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.6832Epoch 11/40: loss=0.6244, accuracy=0.6832, val_loss=0.7968, val_accuracy=0.6565\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6244 - accuracy: 0.6832 - val_loss: 0.7968 - val_accuracy: 0.6565 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.6860Epoch 12/40: loss=0.6056, accuracy=0.6858, val_loss=0.7917, val_accuracy=0.6631\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6056 - accuracy: 0.6858 - val_loss: 0.7917 - val_accuracy: 0.6631 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.7025Epoch 13/40: loss=0.5884, accuracy=0.7022, val_loss=0.8178, val_accuracy=0.6573\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5884 - accuracy: 0.7022 - val_loss: 0.8178 - val_accuracy: 0.6573 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.6935Epoch 14/40: loss=0.5896, accuracy=0.6935, val_loss=0.4981, val_accuracy=0.7724\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5896 - accuracy: 0.6935 - val_loss: 0.4981 - val_accuracy: 0.7724 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5787 - accuracy: 0.7012Epoch 15/40: loss=0.5787, accuracy=0.7012, val_loss=0.4880, val_accuracy=0.7790\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5787 - accuracy: 0.7012 - val_loss: 0.4880 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.7141Epoch 16/40: loss=0.5677, accuracy=0.7140, val_loss=1.0405, val_accuracy=0.5662\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5677 - accuracy: 0.7140 - val_loss: 1.0405 - val_accuracy: 0.5662 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7191Epoch 17/40: loss=0.5686, accuracy=0.7188, val_loss=0.6396, val_accuracy=0.7045\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5686 - accuracy: 0.7188 - val_loss: 0.6396 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7200Epoch 18/40: loss=0.5552, accuracy=0.7200, val_loss=0.4882, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5552 - accuracy: 0.7200 - val_loss: 0.4882 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5579 - accuracy: 0.7284Epoch 19/40: loss=0.5581, accuracy=0.7281, val_loss=0.5215, val_accuracy=0.7732\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5581 - accuracy: 0.7281 - val_loss: 0.5215 - val_accuracy: 0.7732 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7289\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 20/40: loss=0.5498, accuracy=0.7289, val_loss=0.6680, val_accuracy=0.7392\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5498 - accuracy: 0.7289 - val_loss: 0.6680 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7388Epoch 21/40: loss=0.5388, accuracy=0.7390, val_loss=0.7568, val_accuracy=0.6871\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5388 - accuracy: 0.7390 - val_loss: 0.7568 - val_accuracy: 0.6871 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7419Epoch 22/40: loss=0.5316, accuracy=0.7419, val_loss=0.5677, val_accuracy=0.7657\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5316 - accuracy: 0.7419 - val_loss: 0.5677 - val_accuracy: 0.7657 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7388Epoch 23/40: loss=0.5295, accuracy=0.7380, val_loss=0.6552, val_accuracy=0.7235\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5295 - accuracy: 0.7380 - val_loss: 0.6552 - val_accuracy: 0.7235 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.7546Epoch 24/40: loss=0.5149, accuracy=0.7539, val_loss=0.5836, val_accuracy=0.7483\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5149 - accuracy: 0.7539 - val_loss: 0.5836 - val_accuracy: 0.7483 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5252 - accuracy: 0.7415\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 25/40: loss=0.5253, accuracy=0.7415, val_loss=0.5478, val_accuracy=0.7707\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5253 - accuracy: 0.7415 - val_loss: 0.5478 - val_accuracy: 0.7707 - lr: 2.0000e-05\n",
      "Epoch 25: early stopping\n",
      "Validation accuracy: 0.7847682237625122\n",
      "\n",
      "Initial Training Combination 13/50: num_residual_blocks=4, dropout_rate=0.5, learning_rate=1e-05, filters=64, kernel_size=5, num_dense_layers=3, activation_function=relu, rotation_range=40, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0209 - accuracy: 0.4940Epoch 1/40: loss=1.0200, accuracy=0.4940, val_loss=0.7305, val_accuracy=0.4603\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0200 - accuracy: 0.4940 - val_loss: 0.7305 - val_accuracy: 0.4603 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0451 - accuracy: 0.4936Epoch 2/40: loss=1.0454, accuracy=0.4936, val_loss=0.6742, val_accuracy=0.5836\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0454 - accuracy: 0.4936 - val_loss: 0.6742 - val_accuracy: 0.5836 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9886 - accuracy: 0.5224Epoch 3/40: loss=0.9886, accuracy=0.5224, val_loss=0.7116, val_accuracy=0.5174\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9886 - accuracy: 0.5224 - val_loss: 0.7116 - val_accuracy: 0.5174 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9738 - accuracy: 0.5166Epoch 4/40: loss=0.9741, accuracy=0.5166, val_loss=0.6947, val_accuracy=0.5488\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9741 - accuracy: 0.5166 - val_loss: 0.6947 - val_accuracy: 0.5488 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9628 - accuracy: 0.5064Epoch 5/40: loss=0.9625, accuracy=0.5064, val_loss=0.7326, val_accuracy=0.5149\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9625 - accuracy: 0.5064 - val_loss: 0.7326 - val_accuracy: 0.5149 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9709 - accuracy: 0.5052Epoch 6/40: loss=0.9710, accuracy=0.5050, val_loss=0.6627, val_accuracy=0.5919\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9710 - accuracy: 0.5050 - val_loss: 0.6627 - val_accuracy: 0.5919 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9672 - accuracy: 0.5125Epoch 7/40: loss=0.9675, accuracy=0.5124, val_loss=0.7169, val_accuracy=0.5555\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9675 - accuracy: 0.5124 - val_loss: 0.7169 - val_accuracy: 0.5555 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9162 - accuracy: 0.5280Epoch 8/40: loss=0.9165, accuracy=0.5279, val_loss=0.6807, val_accuracy=0.5935\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9165 - accuracy: 0.5279 - val_loss: 0.6807 - val_accuracy: 0.5935 - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9227 - accuracy: 0.5303Epoch 9/40: loss=0.9231, accuracy=0.5302, val_loss=0.8226, val_accuracy=0.5149\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9231 - accuracy: 0.5302 - val_loss: 0.8226 - val_accuracy: 0.5149 - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9187 - accuracy: 0.5295Epoch 10/40: loss=0.9198, accuracy=0.5288, val_loss=0.6869, val_accuracy=0.6175\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9198 - accuracy: 0.5288 - val_loss: 0.6869 - val_accuracy: 0.6175 - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8909 - accuracy: 0.5477\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 11/40: loss=0.8906, accuracy=0.5478, val_loss=1.1436, val_accuracy=0.4412\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8906 - accuracy: 0.5478 - val_loss: 1.1436 - val_accuracy: 0.4412 - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8919 - accuracy: 0.5408Epoch 12/40: loss=0.8926, accuracy=0.5410, val_loss=0.9034, val_accuracy=0.5033\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8926 - accuracy: 0.5410 - val_loss: 0.9034 - val_accuracy: 0.5033 - lr: 2.0000e-06\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9046 - accuracy: 0.5408Epoch 13/40: loss=0.9032, accuracy=0.5412, val_loss=0.8186, val_accuracy=0.5513\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9032 - accuracy: 0.5412 - val_loss: 0.8186 - val_accuracy: 0.5513 - lr: 2.0000e-06\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9081 - accuracy: 0.5410Epoch 14/40: loss=0.9097, accuracy=0.5406, val_loss=0.8696, val_accuracy=0.5298\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9097 - accuracy: 0.5406 - val_loss: 0.8696 - val_accuracy: 0.5298 - lr: 2.0000e-06\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9076 - accuracy: 0.5386Epoch 15/40: loss=0.9079, accuracy=0.5383, val_loss=0.9647, val_accuracy=0.5033\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9079 - accuracy: 0.5383 - val_loss: 0.9647 - val_accuracy: 0.5033 - lr: 2.0000e-06\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9083 - accuracy: 0.5328\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 16/40: loss=0.9080, accuracy=0.5331, val_loss=0.9294, val_accuracy=0.5174\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9080 - accuracy: 0.5331 - val_loss: 0.9294 - val_accuracy: 0.5174 - lr: 2.0000e-06\n",
      "Epoch 16: early stopping\n",
      "Validation accuracy: 0.6175496578216553\n",
      "\n",
      "Initial Training Combination 14/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=0.005, filters=128, kernel_size=3, num_dense_layers=3, activation_function=tanh, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.4, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 2.1534 - accuracy: 0.4961Epoch 1/40: loss=2.1520, accuracy=0.4963, val_loss=0.6768, val_accuracy=0.5993\n",
      "604/604 [==============================] - 17s 23ms/step - loss: 2.1520 - accuracy: 0.4963 - val_loss: 0.6768 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4679 - accuracy: 0.5035Epoch 2/40: loss=1.4680, accuracy=0.5031, val_loss=0.6748, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 1.4680 - accuracy: 0.5031 - val_loss: 0.6748 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4167 - accuracy: 0.4900Epoch 3/40: loss=1.4165, accuracy=0.4897, val_loss=0.7070, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.4165 - accuracy: 0.4897 - val_loss: 0.7070 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.2025 - accuracy: 0.4983Epoch 4/40: loss=1.2020, accuracy=0.4977, val_loss=0.7989, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.2020 - accuracy: 0.4977 - val_loss: 0.7989 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0704 - accuracy: 0.4977Epoch 5/40: loss=1.0701, accuracy=0.4975, val_loss=0.6737, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.0701 - accuracy: 0.4975 - val_loss: 0.6737 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9621 - accuracy: 0.4979Epoch 6/40: loss=0.9621, accuracy=0.4979, val_loss=0.8111, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9621 - accuracy: 0.4979 - val_loss: 0.8111 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8709 - accuracy: 0.5029Epoch 7/40: loss=0.8709, accuracy=0.5029, val_loss=0.6803, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8709 - accuracy: 0.5029 - val_loss: 0.6803 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.5070Epoch 8/40: loss=0.8295, accuracy=0.5070, val_loss=0.6965, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8295 - accuracy: 0.5070 - val_loss: 0.6965 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7987 - accuracy: 0.4954Epoch 9/40: loss=0.7987, accuracy=0.4957, val_loss=0.9096, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7987 - accuracy: 0.4957 - val_loss: 0.9096 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7722 - accuracy: 0.4948\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 10/40: loss=0.7722, accuracy=0.4948, val_loss=0.6760, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7722 - accuracy: 0.4948 - val_loss: 0.6760 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.4967Epoch 11/40: loss=0.7294, accuracy=0.4967, val_loss=0.6933, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7294 - accuracy: 0.4967 - val_loss: 0.6933 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7195 - accuracy: 0.4915Epoch 12/40: loss=0.7194, accuracy=0.4915, val_loss=0.7016, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7194 - accuracy: 0.4915 - val_loss: 0.7016 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7075 - accuracy: 0.5044Epoch 13/40: loss=0.7074, accuracy=0.5046, val_loss=0.6841, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7074 - accuracy: 0.5046 - val_loss: 0.6841 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7049 - accuracy: 0.5033Epoch 14/40: loss=0.7049, accuracy=0.5033, val_loss=0.6803, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7049 - accuracy: 0.5033 - val_loss: 0.6803 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7068 - accuracy: 0.5044\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 15/40: loss=0.7071, accuracy=0.5041, val_loss=0.6828, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7071 - accuracy: 0.5041 - val_loss: 0.6828 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 15: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 15/50: num_residual_blocks=8, dropout_rate=0.55, learning_rate=0.0005, filters=128, kernel_size=7, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.1, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.4994Epoch 1/40: loss=1.0036, accuracy=0.4994, val_loss=0.6899, val_accuracy=0.5687\n",
      "604/604 [==============================] - 33s 49ms/step - loss: 1.0036 - accuracy: 0.4994 - val_loss: 0.6899 - val_accuracy: 0.5687 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8803 - accuracy: 0.5064Epoch 2/40: loss=0.8808, accuracy=0.5060, val_loss=0.7069, val_accuracy=0.4007\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.8808 - accuracy: 0.5060 - val_loss: 0.7069 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8276 - accuracy: 0.5029Epoch 3/40: loss=0.8276, accuracy=0.5029, val_loss=0.7029, val_accuracy=0.4007\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.8276 - accuracy: 0.5029 - val_loss: 0.7029 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.5114Epoch 4/40: loss=0.8012, accuracy=0.5114, val_loss=0.6932, val_accuracy=0.4611\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.8012 - accuracy: 0.5114 - val_loss: 0.6932 - val_accuracy: 0.4611 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8097 - accuracy: 0.4915Epoch 5/40: loss=0.8095, accuracy=0.4917, val_loss=0.6836, val_accuracy=0.5993\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.8095 - accuracy: 0.4917 - val_loss: 0.6836 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7984 - accuracy: 0.4988Epoch 6/40: loss=0.7993, accuracy=0.4986, val_loss=0.6908, val_accuracy=0.5993\n",
      "604/604 [==============================] - 29s 49ms/step - loss: 0.7993 - accuracy: 0.4986 - val_loss: 0.6908 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7879 - accuracy: 0.5021Epoch 7/40: loss=0.7879, accuracy=0.5021, val_loss=0.6824, val_accuracy=0.5993\n",
      "604/604 [==============================] - 31s 51ms/step - loss: 0.7879 - accuracy: 0.5021 - val_loss: 0.6824 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7902 - accuracy: 0.5027Epoch 8/40: loss=0.7902, accuracy=0.5027, val_loss=0.6850, val_accuracy=0.5993\n",
      "604/604 [==============================] - 31s 51ms/step - loss: 0.7902 - accuracy: 0.5027 - val_loss: 0.6850 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7961 - accuracy: 0.5037Epoch 9/40: loss=0.7961, accuracy=0.5037, val_loss=0.7011, val_accuracy=0.4007\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.7961 - accuracy: 0.5037 - val_loss: 0.7011 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7398 - accuracy: 0.5676Epoch 10/40: loss=0.7402, accuracy=0.5673, val_loss=0.7712, val_accuracy=0.4007\n",
      "604/604 [==============================] - 31s 50ms/step - loss: 0.7402 - accuracy: 0.5673 - val_loss: 0.7712 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6978 - accuracy: 0.6265Epoch 11/40: loss=0.6977, accuracy=0.6267, val_loss=0.6477, val_accuracy=0.5952\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6977 - accuracy: 0.6267 - val_loss: 0.6477 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.6318Epoch 12/40: loss=0.6887, accuracy=0.6318, val_loss=0.5949, val_accuracy=0.6780\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6887 - accuracy: 0.6318 - val_loss: 0.5949 - val_accuracy: 0.6780 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.6498Epoch 13/40: loss=0.6717, accuracy=0.6498, val_loss=0.5256, val_accuracy=0.7268\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6717 - accuracy: 0.6498 - val_loss: 0.5256 - val_accuracy: 0.7268 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.6482Epoch 14/40: loss=0.6674, accuracy=0.6482, val_loss=0.5859, val_accuracy=0.6821\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6674 - accuracy: 0.6482 - val_loss: 0.5859 - val_accuracy: 0.6821 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.6410Epoch 15/40: loss=0.6737, accuracy=0.6407, val_loss=0.6726, val_accuracy=0.6159\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6737 - accuracy: 0.6407 - val_loss: 0.6726 - val_accuracy: 0.6159 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.6480Epoch 16/40: loss=0.6719, accuracy=0.6482, val_loss=0.5065, val_accuracy=0.7632\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6719 - accuracy: 0.6482 - val_loss: 0.5065 - val_accuracy: 0.7632 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6621 - accuracy: 0.6513Epoch 17/40: loss=0.6624, accuracy=0.6513, val_loss=0.4929, val_accuracy=0.7608\n",
      "604/604 [==============================] - 29s 49ms/step - loss: 0.6624 - accuracy: 0.6513 - val_loss: 0.4929 - val_accuracy: 0.7608 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.6726Epoch 18/40: loss=0.6377, accuracy=0.6726, val_loss=0.5919, val_accuracy=0.6714\n",
      "604/604 [==============================] - 29s 49ms/step - loss: 0.6377 - accuracy: 0.6726 - val_loss: 0.5919 - val_accuracy: 0.6714 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6444 - accuracy: 0.6708Epoch 19/40: loss=0.6451, accuracy=0.6705, val_loss=0.6022, val_accuracy=0.6813\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6451 - accuracy: 0.6705 - val_loss: 0.6022 - val_accuracy: 0.6813 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.6494Epoch 20/40: loss=0.6663, accuracy=0.6494, val_loss=0.4841, val_accuracy=0.7657\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6663 - accuracy: 0.6494 - val_loss: 0.4841 - val_accuracy: 0.7657 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.6747Epoch 21/40: loss=0.6423, accuracy=0.6747, val_loss=0.6567, val_accuracy=0.6465\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6423 - accuracy: 0.6747 - val_loss: 0.6567 - val_accuracy: 0.6465 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6295 - accuracy: 0.6847Epoch 22/40: loss=0.6301, accuracy=0.6846, val_loss=0.6065, val_accuracy=0.6780\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6301 - accuracy: 0.6846 - val_loss: 0.6065 - val_accuracy: 0.6780 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6264 - accuracy: 0.6938Epoch 23/40: loss=0.6266, accuracy=0.6937, val_loss=0.9937, val_accuracy=0.4429\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6266 - accuracy: 0.6937 - val_loss: 0.9937 - val_accuracy: 0.4429 - lr: 5.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6360 - accuracy: 0.6816Epoch 24/40: loss=0.6361, accuracy=0.6815, val_loss=0.7814, val_accuracy=0.6498\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6361 - accuracy: 0.6815 - val_loss: 0.7814 - val_accuracy: 0.6498 - lr: 5.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6290 - accuracy: 0.6822Epoch 25/40: loss=0.6284, accuracy=0.6827, val_loss=0.4815, val_accuracy=0.7724\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6284 - accuracy: 0.6827 - val_loss: 0.4815 - val_accuracy: 0.7724 - lr: 5.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.6842Epoch 26/40: loss=0.6281, accuracy=0.6842, val_loss=0.9067, val_accuracy=0.5058\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6281 - accuracy: 0.6842 - val_loss: 0.9067 - val_accuracy: 0.5058 - lr: 5.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6271 - accuracy: 0.6934Epoch 27/40: loss=0.6270, accuracy=0.6935, val_loss=0.6205, val_accuracy=0.6755\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6270 - accuracy: 0.6935 - val_loss: 0.6205 - val_accuracy: 0.6755 - lr: 5.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.6767Epoch 28/40: loss=0.6343, accuracy=0.6767, val_loss=0.8600, val_accuracy=0.4959\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.6343 - accuracy: 0.6767 - val_loss: 0.8600 - val_accuracy: 0.4959 - lr: 5.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.6918Epoch 29/40: loss=0.6235, accuracy=0.6918, val_loss=0.9171, val_accuracy=0.5257\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6235 - accuracy: 0.6918 - val_loss: 0.9171 - val_accuracy: 0.5257 - lr: 5.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6136 - accuracy: 0.6922\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 30/40: loss=0.6134, accuracy=0.6923, val_loss=0.5690, val_accuracy=0.7293\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6134 - accuracy: 0.6923 - val_loss: 0.5690 - val_accuracy: 0.7293 - lr: 5.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7139Epoch 31/40: loss=0.5780, accuracy=0.7138, val_loss=0.4537, val_accuracy=0.7906\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5780 - accuracy: 0.7138 - val_loss: 0.4537 - val_accuracy: 0.7906 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5730 - accuracy: 0.7204Epoch 32/40: loss=0.5728, accuracy=0.7202, val_loss=0.4637, val_accuracy=0.7839\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.5728 - accuracy: 0.7202 - val_loss: 0.4637 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7293Epoch 33/40: loss=0.5620, accuracy=0.7293, val_loss=0.4578, val_accuracy=0.7864\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.5620 - accuracy: 0.7293 - val_loss: 0.4578 - val_accuracy: 0.7864 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7374Epoch 34/40: loss=0.5458, accuracy=0.7372, val_loss=0.4715, val_accuracy=0.7839\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.5458 - accuracy: 0.7372 - val_loss: 0.4715 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7328Epoch 35/40: loss=0.5522, accuracy=0.7328, val_loss=0.4472, val_accuracy=0.7939\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5522 - accuracy: 0.7328 - val_loss: 0.4472 - val_accuracy: 0.7939 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.7349Epoch 36/40: loss=0.5332, accuracy=0.7345, val_loss=0.4950, val_accuracy=0.7674\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5332 - accuracy: 0.7345 - val_loss: 0.4950 - val_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.7341Epoch 37/40: loss=0.5494, accuracy=0.7341, val_loss=0.4384, val_accuracy=0.8022\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5494 - accuracy: 0.7341 - val_loss: 0.4384 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7434Epoch 38/40: loss=0.5326, accuracy=0.7428, val_loss=0.4681, val_accuracy=0.7765\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.5326 - accuracy: 0.7428 - val_loss: 0.4681 - val_accuracy: 0.7765 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5252 - accuracy: 0.7508Epoch 39/40: loss=0.5254, accuracy=0.7508, val_loss=0.4336, val_accuracy=0.8005\n",
      "604/604 [==============================] - 31s 51ms/step - loss: 0.5254 - accuracy: 0.7508 - val_loss: 0.4336 - val_accuracy: 0.8005 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7473Epoch 40/40: loss=0.5248, accuracy=0.7473, val_loss=0.5195, val_accuracy=0.7558\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5248 - accuracy: 0.7473 - val_loss: 0.5195 - val_accuracy: 0.7558 - lr: 1.0000e-04\n",
      "Validation accuracy: 0.8021523356437683\n",
      "\n",
      "Initial Training Combination 16/50: num_residual_blocks=4, dropout_rate=0.45, learning_rate=1e-06, filters=64, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=40, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.4, zoom_range=0.4, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.4985Epoch 1/40: loss=1.0789, accuracy=0.4979, val_loss=0.8836, val_accuracy=0.4288\n",
      "604/604 [==============================] - 16s 19ms/step - loss: 1.0789 - accuracy: 0.4979 - val_loss: 0.8836 - val_accuracy: 0.4288 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0607 - accuracy: 0.5069Epoch 2/40: loss=1.0613, accuracy=0.5070, val_loss=0.8279, val_accuracy=0.4636\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.0613 - accuracy: 0.5070 - val_loss: 0.8279 - val_accuracy: 0.4636 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.5095Epoch 3/40: loss=1.0332, accuracy=0.5095, val_loss=0.8421, val_accuracy=0.4677\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0332 - accuracy: 0.5095 - val_loss: 0.8421 - val_accuracy: 0.4677 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0194 - accuracy: 0.5120Epoch 4/40: loss=1.0187, accuracy=0.5124, val_loss=0.8570, val_accuracy=0.4719\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 1.0187 - accuracy: 0.5124 - val_loss: 0.8570 - val_accuracy: 0.4719 - lr: 1.0000e-06\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0531 - accuracy: 0.5021Epoch 5/40: loss=1.0518, accuracy=0.5025, val_loss=0.8501, val_accuracy=0.4810\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0518 - accuracy: 0.5025 - val_loss: 0.8501 - val_accuracy: 0.4810 - lr: 1.0000e-06\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9723 - accuracy: 0.5325Epoch 6/40: loss=0.9723, accuracy=0.5325, val_loss=0.9224, val_accuracy=0.4702\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.9723 - accuracy: 0.5325 - val_loss: 0.9224 - val_accuracy: 0.4702 - lr: 1.0000e-06\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9686 - accuracy: 0.5398\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "Epoch 7/40: loss=0.9684, accuracy=0.5401, val_loss=0.9413, val_accuracy=0.4743\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9684 - accuracy: 0.5401 - val_loss: 0.9413 - val_accuracy: 0.4743 - lr: 1.0000e-06\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9767 - accuracy: 0.5309Epoch 8/40: loss=0.9762, accuracy=0.5312, val_loss=0.9374, val_accuracy=0.4810\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9762 - accuracy: 0.5312 - val_loss: 0.9374 - val_accuracy: 0.4810 - lr: 2.0000e-07\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.5238Epoch 9/40: loss=1.0123, accuracy=0.5240, val_loss=0.9176, val_accuracy=0.4892\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0123 - accuracy: 0.5240 - val_loss: 0.9176 - val_accuracy: 0.4892 - lr: 2.0000e-07\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9975 - accuracy: 0.5263Epoch 10/40: loss=0.9975, accuracy=0.5263, val_loss=0.9009, val_accuracy=0.5008\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9975 - accuracy: 0.5263 - val_loss: 0.9009 - val_accuracy: 0.5008 - lr: 2.0000e-07\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9888 - accuracy: 0.5294Epoch 11/40: loss=0.9888, accuracy=0.5294, val_loss=0.9391, val_accuracy=0.4884\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.9888 - accuracy: 0.5294 - val_loss: 0.9391 - val_accuracy: 0.4884 - lr: 2.0000e-07\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.5379\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 12/40: loss=0.9677, accuracy=0.5385, val_loss=0.9388, val_accuracy=0.4950\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9677 - accuracy: 0.5385 - val_loss: 0.9388 - val_accuracy: 0.4950 - lr: 2.0000e-07\n",
      "Epoch 12: early stopping\n",
      "Validation accuracy: 0.5008277893066406\n",
      "\n",
      "Initial Training Combination 17/50: num_residual_blocks=5, dropout_rate=0.5, learning_rate=0.005, filters=64, kernel_size=7, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 2.1645 - accuracy: 0.5014Epoch 1/40: loss=2.1645, accuracy=0.5014, val_loss=0.6811, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 2.1645 - accuracy: 0.5014 - val_loss: 0.6811 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.7724 - accuracy: 0.4925Epoch 2/40: loss=1.7724, accuracy=0.4925, val_loss=0.7514, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.7724 - accuracy: 0.4925 - val_loss: 0.7514 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.4903Epoch 3/40: loss=1.5695, accuracy=0.4903, val_loss=0.7059, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.5695 - accuracy: 0.4903 - val_loss: 0.7059 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.3339 - accuracy: 0.4934Epoch 4/40: loss=1.3339, accuracy=0.4934, val_loss=0.6848, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 1.3339 - accuracy: 0.4934 - val_loss: 0.6848 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2027 - accuracy: 0.4998Epoch 5/40: loss=1.2022, accuracy=0.5002, val_loss=0.7668, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.2022 - accuracy: 0.5002 - val_loss: 0.7668 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0529 - accuracy: 0.4919\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 6/40: loss=1.0523, accuracy=0.4923, val_loss=0.7034, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.0523 - accuracy: 0.4923 - val_loss: 0.7034 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.4994Epoch 7/40: loss=0.8897, accuracy=0.4992, val_loss=0.6737, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8897 - accuracy: 0.4992 - val_loss: 0.6737 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8092 - accuracy: 0.4865Epoch 8/40: loss=0.8092, accuracy=0.4865, val_loss=0.6825, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8092 - accuracy: 0.4865 - val_loss: 0.6825 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.4977Epoch 9/40: loss=0.7756, accuracy=0.4977, val_loss=0.6860, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7756 - accuracy: 0.4977 - val_loss: 0.6860 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7595 - accuracy: 0.4832Epoch 10/40: loss=0.7595, accuracy=0.4832, val_loss=0.6814, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7595 - accuracy: 0.4832 - val_loss: 0.6814 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.4872Epoch 11/40: loss=0.7509, accuracy=0.4872, val_loss=0.7080, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7509 - accuracy: 0.4872 - val_loss: 0.7080 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.4946\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 12/40: loss=0.7442, accuracy=0.4948, val_loss=0.6876, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7442 - accuracy: 0.4948 - val_loss: 0.6876 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.5083Epoch 13/40: loss=0.7282, accuracy=0.5083, val_loss=0.6951, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7282 - accuracy: 0.5083 - val_loss: 0.6951 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7411 - accuracy: 0.4799Epoch 14/40: loss=0.7408, accuracy=0.4803, val_loss=0.6960, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7408 - accuracy: 0.4803 - val_loss: 0.6960 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7271 - accuracy: 0.4975Epoch 15/40: loss=0.7271, accuracy=0.4973, val_loss=0.6948, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7271 - accuracy: 0.4973 - val_loss: 0.6948 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7238 - accuracy: 0.4969Epoch 16/40: loss=0.7243, accuracy=0.4961, val_loss=0.6863, val_accuracy=0.5993\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.7243 - accuracy: 0.4961 - val_loss: 0.6863 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7149 - accuracy: 0.5015\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 17/40: loss=0.7147, accuracy=0.5017, val_loss=0.6942, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7147 - accuracy: 0.5017 - val_loss: 0.6942 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 17: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 18/50: num_residual_blocks=5, dropout_rate=0.55, learning_rate=0.005, filters=128, kernel_size=5, num_dense_layers=1, activation_function=relu, rotation_range=10, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0735 - accuracy: 0.5377Epoch 1/40: loss=1.0726, accuracy=0.5381, val_loss=1.3290, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 28ms/step - loss: 1.0726 - accuracy: 0.5381 - val_loss: 1.3290 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.5972Epoch 2/40: loss=0.9256, accuracy=0.5977, val_loss=1.2191, val_accuracy=0.6689\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9256 - accuracy: 0.5977 - val_loss: 1.2191 - val_accuracy: 0.6689 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8099 - accuracy: 0.6204Epoch 3/40: loss=0.8098, accuracy=0.6204, val_loss=0.8253, val_accuracy=0.7533\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.8098 - accuracy: 0.6204 - val_loss: 0.8253 - val_accuracy: 0.7533 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7995 - accuracy: 0.5860Epoch 4/40: loss=0.7984, accuracy=0.5863, val_loss=0.7289, val_accuracy=0.6043\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7984 - accuracy: 0.5863 - val_loss: 0.7289 - val_accuracy: 0.6043 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7337 - accuracy: 0.6082Epoch 5/40: loss=0.7330, accuracy=0.6087, val_loss=0.7387, val_accuracy=0.5381\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.7330 - accuracy: 0.6087 - val_loss: 0.7387 - val_accuracy: 0.5381 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6355 - accuracy: 0.6672Epoch 6/40: loss=0.6354, accuracy=0.6668, val_loss=0.4954, val_accuracy=0.7467\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6354 - accuracy: 0.6668 - val_loss: 0.4954 - val_accuracy: 0.7467 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.6753Epoch 7/40: loss=0.6300, accuracy=0.6753, val_loss=0.6220, val_accuracy=0.6333\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6300 - accuracy: 0.6753 - val_loss: 0.6220 - val_accuracy: 0.6333 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.6916Epoch 8/40: loss=0.5976, accuracy=0.6916, val_loss=1.7284, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5976 - accuracy: 0.6916 - val_loss: 1.7284 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.6409Epoch 9/40: loss=0.6563, accuracy=0.6409, val_loss=0.8147, val_accuracy=0.4031\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6563 - accuracy: 0.6409 - val_loss: 0.8147 - val_accuracy: 0.4031 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6484 - accuracy: 0.6246Epoch 10/40: loss=0.6480, accuracy=0.6248, val_loss=0.9581, val_accuracy=0.7144\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.6480 - accuracy: 0.6248 - val_loss: 0.9581 - val_accuracy: 0.7144 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6126 - accuracy: 0.6721\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 11/40: loss=0.6129, accuracy=0.6718, val_loss=0.6335, val_accuracy=0.6796\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6129 - accuracy: 0.6718 - val_loss: 0.6335 - val_accuracy: 0.6796 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5683 - accuracy: 0.7110Epoch 12/40: loss=0.5682, accuracy=0.7107, val_loss=0.4890, val_accuracy=0.7699\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5682 - accuracy: 0.7107 - val_loss: 0.4890 - val_accuracy: 0.7699 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.7152Epoch 13/40: loss=0.5621, accuracy=0.7152, val_loss=0.5290, val_accuracy=0.7483\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5621 - accuracy: 0.7152 - val_loss: 0.5290 - val_accuracy: 0.7483 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5598 - accuracy: 0.7184Epoch 14/40: loss=0.5605, accuracy=0.7177, val_loss=0.5645, val_accuracy=0.7177\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5605 - accuracy: 0.7177 - val_loss: 0.5645 - val_accuracy: 0.7177 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.7207Epoch 15/40: loss=0.5547, accuracy=0.7204, val_loss=0.7160, val_accuracy=0.6043\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5547 - accuracy: 0.7204 - val_loss: 0.7160 - val_accuracy: 0.6043 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.7301Epoch 16/40: loss=0.5430, accuracy=0.7305, val_loss=0.7172, val_accuracy=0.5861\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5430 - accuracy: 0.7305 - val_loss: 0.7172 - val_accuracy: 0.5861 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5489 - accuracy: 0.7245\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 17/40: loss=0.5495, accuracy=0.7239, val_loss=0.8212, val_accuracy=0.5621\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5495 - accuracy: 0.7239 - val_loss: 0.8212 - val_accuracy: 0.5621 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7222Epoch 18/40: loss=0.5481, accuracy=0.7216, val_loss=0.5020, val_accuracy=0.7492\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5481 - accuracy: 0.7216 - val_loss: 0.5020 - val_accuracy: 0.7492 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5414 - accuracy: 0.7313Epoch 19/40: loss=0.5415, accuracy=0.7314, val_loss=0.5005, val_accuracy=0.7583\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5415 - accuracy: 0.7314 - val_loss: 0.5005 - val_accuracy: 0.7583 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.7270Epoch 20/40: loss=0.5454, accuracy=0.7270, val_loss=0.5489, val_accuracy=0.7334\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5454 - accuracy: 0.7270 - val_loss: 0.5489 - val_accuracy: 0.7334 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7324Epoch 21/40: loss=0.5403, accuracy=0.7320, val_loss=0.5592, val_accuracy=0.7210\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5403 - accuracy: 0.7320 - val_loss: 0.5592 - val_accuracy: 0.7210 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.7311\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 22/40: loss=0.5406, accuracy=0.7310, val_loss=0.5349, val_accuracy=0.7368\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5406 - accuracy: 0.7310 - val_loss: 0.5349 - val_accuracy: 0.7368 - lr: 2.0000e-04\n",
      "Epoch 22: early stopping\n",
      "Validation accuracy: 0.7698675394058228\n",
      "\n",
      "Initial Training Combination 19/50: num_residual_blocks=5, dropout_rate=0.55, learning_rate=0.01, filters=32, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=10, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.2, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 2.0103 - accuracy: 0.5141Epoch 1/40: loss=2.0103, accuracy=0.5141, val_loss=0.9893, val_accuracy=0.6598\n",
      "604/604 [==============================] - 17s 23ms/step - loss: 2.0103 - accuracy: 0.5141 - val_loss: 0.9893 - val_accuracy: 0.6598 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1552 - accuracy: 0.5950Epoch 2/40: loss=1.1556, accuracy=0.5948, val_loss=0.8636, val_accuracy=0.7070\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.1556 - accuracy: 0.5948 - val_loss: 0.8636 - val_accuracy: 0.7070 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8278 - accuracy: 0.6223Epoch 3/40: loss=0.8284, accuracy=0.6221, val_loss=0.6290, val_accuracy=0.6780\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8284 - accuracy: 0.6221 - val_loss: 0.6290 - val_accuracy: 0.6780 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.6378Epoch 4/40: loss=0.7043, accuracy=0.6378, val_loss=7.4289, val_accuracy=0.4015\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7043 - accuracy: 0.6378 - val_loss: 7.4289 - val_accuracy: 0.4015 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6985 - accuracy: 0.5997Epoch 5/40: loss=0.6984, accuracy=0.6000, val_loss=0.7176, val_accuracy=0.6598\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6984 - accuracy: 0.6000 - val_loss: 0.7176 - val_accuracy: 0.6598 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.5375Epoch 6/40: loss=0.7153, accuracy=0.5375, val_loss=0.7406, val_accuracy=0.4421\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7153 - accuracy: 0.5375 - val_loss: 0.7406 - val_accuracy: 0.4421 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5790Epoch 7/40: loss=0.6927, accuracy=0.5788, val_loss=59.9407, val_accuracy=0.4851\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6927 - accuracy: 0.5788 - val_loss: 59.9407 - val_accuracy: 0.4851 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7228 - accuracy: 0.5046\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/40: loss=0.7226, accuracy=0.5046, val_loss=0.8005, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7226 - accuracy: 0.5046 - val_loss: 0.8005 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.5618Epoch 9/40: loss=0.6805, accuracy=0.5615, val_loss=0.6511, val_accuracy=0.6465\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6805 - accuracy: 0.5615 - val_loss: 0.6511 - val_accuracy: 0.6465 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.6217Epoch 10/40: loss=0.6510, accuracy=0.6217, val_loss=1.5355, val_accuracy=0.6987\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6510 - accuracy: 0.6217 - val_loss: 1.5355 - val_accuracy: 0.6987 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6267 - accuracy: 0.6559Epoch 11/40: loss=0.6265, accuracy=0.6560, val_loss=0.5964, val_accuracy=0.7219\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6265 - accuracy: 0.6560 - val_loss: 0.5964 - val_accuracy: 0.7219 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6710Epoch 12/40: loss=0.6116, accuracy=0.6707, val_loss=0.6261, val_accuracy=0.6722\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6116 - accuracy: 0.6707 - val_loss: 0.6261 - val_accuracy: 0.6722 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.6828Epoch 13/40: loss=0.5968, accuracy=0.6829, val_loss=0.6795, val_accuracy=0.6912\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5968 - accuracy: 0.6829 - val_loss: 0.6795 - val_accuracy: 0.6912 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.6931Epoch 14/40: loss=0.5923, accuracy=0.6931, val_loss=0.6493, val_accuracy=0.7525\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5923 - accuracy: 0.6931 - val_loss: 0.6493 - val_accuracy: 0.7525 - lr: 0.0020\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.6865Epoch 15/40: loss=0.5878, accuracy=0.6871, val_loss=0.5781, val_accuracy=0.7533\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5878 - accuracy: 0.6871 - val_loss: 0.5781 - val_accuracy: 0.7533 - lr: 0.0020\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.7076Epoch 16/40: loss=0.5808, accuracy=0.7076, val_loss=0.7708, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5808 - accuracy: 0.7076 - val_loss: 0.7708 - val_accuracy: 0.7599 - lr: 0.0020\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.7009Epoch 17/40: loss=0.5874, accuracy=0.7007, val_loss=0.6436, val_accuracy=0.7616\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5874 - accuracy: 0.7007 - val_loss: 0.6436 - val_accuracy: 0.7616 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5829 - accuracy: 0.7101Epoch 18/40: loss=0.5831, accuracy=0.7096, val_loss=0.7134, val_accuracy=0.6656\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5831 - accuracy: 0.7096 - val_loss: 0.7134 - val_accuracy: 0.6656 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5830 - accuracy: 0.7047Epoch 19/40: loss=0.5824, accuracy=0.7053, val_loss=0.5687, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5824 - accuracy: 0.7053 - val_loss: 0.5687 - val_accuracy: 0.7575 - lr: 0.0020\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.7136Epoch 20/40: loss=0.5697, accuracy=0.7136, val_loss=0.4973, val_accuracy=0.7632\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5697 - accuracy: 0.7136 - val_loss: 0.4973 - val_accuracy: 0.7632 - lr: 0.0020\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7203Epoch 21/40: loss=0.5682, accuracy=0.7208, val_loss=1.4804, val_accuracy=0.4503\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5682 - accuracy: 0.7208 - val_loss: 1.4804 - val_accuracy: 0.4503 - lr: 0.0020\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.7086Epoch 22/40: loss=0.5752, accuracy=0.7086, val_loss=0.6165, val_accuracy=0.7268\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5752 - accuracy: 0.7086 - val_loss: 0.6165 - val_accuracy: 0.7268 - lr: 0.0020\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.7175Epoch 23/40: loss=0.5667, accuracy=0.7179, val_loss=0.6044, val_accuracy=0.7748\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5667 - accuracy: 0.7179 - val_loss: 0.6044 - val_accuracy: 0.7748 - lr: 0.0020\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.7185Epoch 24/40: loss=0.5779, accuracy=0.7185, val_loss=1.1302, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5779 - accuracy: 0.7185 - val_loss: 1.1302 - val_accuracy: 0.7649 - lr: 0.0020\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7231\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 25/40: loss=0.5688, accuracy=0.7229, val_loss=1.0997, val_accuracy=0.7359\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5688 - accuracy: 0.7229 - val_loss: 1.0997 - val_accuracy: 0.7359 - lr: 0.0020\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5504 - accuracy: 0.7386Epoch 26/40: loss=0.5514, accuracy=0.7384, val_loss=2.0702, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5514 - accuracy: 0.7384 - val_loss: 2.0702 - val_accuracy: 0.7889 - lr: 4.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5381 - accuracy: 0.7403Epoch 27/40: loss=0.5377, accuracy=0.7405, val_loss=1.1619, val_accuracy=0.7922\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5377 - accuracy: 0.7405 - val_loss: 1.1619 - val_accuracy: 0.7922 - lr: 4.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7355Epoch 28/40: loss=0.5390, accuracy=0.7355, val_loss=0.4747, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5390 - accuracy: 0.7355 - val_loss: 0.4747 - val_accuracy: 0.8038 - lr: 4.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.7504Epoch 29/40: loss=0.5314, accuracy=0.7498, val_loss=1.1617, val_accuracy=0.7715\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5314 - accuracy: 0.7498 - val_loss: 1.1617 - val_accuracy: 0.7715 - lr: 4.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.7317Epoch 30/40: loss=0.5441, accuracy=0.7324, val_loss=0.8645, val_accuracy=0.7980\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5441 - accuracy: 0.7324 - val_loss: 0.8645 - val_accuracy: 0.7980 - lr: 4.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.7448Epoch 31/40: loss=0.5323, accuracy=0.7448, val_loss=1.0213, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5323 - accuracy: 0.7448 - val_loss: 1.0213 - val_accuracy: 0.7856 - lr: 4.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7382Epoch 32/40: loss=0.5413, accuracy=0.7382, val_loss=0.8727, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5413 - accuracy: 0.7382 - val_loss: 0.8727 - val_accuracy: 0.7889 - lr: 4.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7438\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 33/40: loss=0.5296, accuracy=0.7434, val_loss=1.3433, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5296 - accuracy: 0.7434 - val_loss: 1.3433 - val_accuracy: 0.7881 - lr: 4.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7440Epoch 34/40: loss=0.5373, accuracy=0.7438, val_loss=1.1026, val_accuracy=0.7831\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5373 - accuracy: 0.7438 - val_loss: 1.1026 - val_accuracy: 0.7831 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.7419Epoch 35/40: loss=0.5320, accuracy=0.7419, val_loss=0.9778, val_accuracy=0.7873\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5320 - accuracy: 0.7419 - val_loss: 0.9778 - val_accuracy: 0.7873 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.7396Epoch 36/40: loss=0.5267, accuracy=0.7401, val_loss=1.0598, val_accuracy=0.7815\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5267 - accuracy: 0.7401 - val_loss: 1.0598 - val_accuracy: 0.7815 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7502Epoch 37/40: loss=0.5282, accuracy=0.7502, val_loss=1.0215, val_accuracy=0.7864\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5282 - accuracy: 0.7502 - val_loss: 1.0215 - val_accuracy: 0.7864 - lr: 8.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.7461\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.5213, accuracy=0.7463, val_loss=0.9313, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5213 - accuracy: 0.7463 - val_loss: 0.9313 - val_accuracy: 0.7781 - lr: 8.0000e-05\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8038079738616943\n",
      "\n",
      "Initial Training Combination 20/50: num_residual_blocks=6, dropout_rate=0.6, learning_rate=0.0001, filters=64, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.3, height_shift_range=0.4, shear_range=0.4, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "  5/604 [..............................] - ETA: 29s - loss: 0.8800 - accuracy: 0.5250 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0250s vs `on_train_batch_end` time: 0.0275s). Check your callbacks.\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0383 - accuracy: 0.5228Epoch 1/40: loss=1.0383, accuracy=0.5228, val_loss=1.1359, val_accuracy=0.5041\n",
      "604/604 [==============================] - 19s 23ms/step - loss: 1.0383 - accuracy: 0.5228 - val_loss: 1.1359 - val_accuracy: 0.5041 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9406 - accuracy: 0.5924Epoch 2/40: loss=0.9402, accuracy=0.5923, val_loss=0.8460, val_accuracy=0.6722\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9402 - accuracy: 0.5923 - val_loss: 0.8460 - val_accuracy: 0.6722 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.6109Epoch 3/40: loss=0.8495, accuracy=0.6109, val_loss=1.4267, val_accuracy=0.6258\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8495 - accuracy: 0.6109 - val_loss: 1.4267 - val_accuracy: 0.6258 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7845 - accuracy: 0.6441Epoch 4/40: loss=0.7857, accuracy=0.6434, val_loss=0.8895, val_accuracy=0.6664\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7857 - accuracy: 0.6434 - val_loss: 0.8895 - val_accuracy: 0.6664 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.6492Epoch 5/40: loss=0.7389, accuracy=0.6492, val_loss=0.7859, val_accuracy=0.6945\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7389 - accuracy: 0.6492 - val_loss: 0.7859 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7025 - accuracy: 0.6586Epoch 6/40: loss=0.7027, accuracy=0.6587, val_loss=2.1071, val_accuracy=0.4255\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7027 - accuracy: 0.6587 - val_loss: 2.1071 - val_accuracy: 0.4255 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6694 - accuracy: 0.6721Epoch 7/40: loss=0.6689, accuracy=0.6722, val_loss=0.5393, val_accuracy=0.7831\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6689 - accuracy: 0.6722 - val_loss: 0.5393 - val_accuracy: 0.7831 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6422 - accuracy: 0.6886Epoch 8/40: loss=0.6419, accuracy=0.6887, val_loss=1.2206, val_accuracy=0.5364\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6419 - accuracy: 0.6887 - val_loss: 1.2206 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6234 - accuracy: 0.6858Epoch 9/40: loss=0.6240, accuracy=0.6852, val_loss=1.3736, val_accuracy=0.5050\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6240 - accuracy: 0.6852 - val_loss: 1.3736 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5897 - accuracy: 0.7094Epoch 10/40: loss=0.5897, accuracy=0.7094, val_loss=0.6360, val_accuracy=0.7392\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5897 - accuracy: 0.7094 - val_loss: 0.6360 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5847 - accuracy: 0.7063Epoch 11/40: loss=0.5853, accuracy=0.7059, val_loss=0.7473, val_accuracy=0.7268\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5853 - accuracy: 0.7059 - val_loss: 0.7473 - val_accuracy: 0.7268 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5690 - accuracy: 0.7220\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 12/40: loss=0.5687, accuracy=0.7221, val_loss=0.5654, val_accuracy=0.7864\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5687 - accuracy: 0.7221 - val_loss: 0.5654 - val_accuracy: 0.7864 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5558 - accuracy: 0.7284Epoch 13/40: loss=0.5557, accuracy=0.7285, val_loss=0.9228, val_accuracy=0.6548\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5557 - accuracy: 0.7285 - val_loss: 0.9228 - val_accuracy: 0.6548 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.7440Epoch 14/40: loss=0.5328, accuracy=0.7440, val_loss=1.3715, val_accuracy=0.5315\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5328 - accuracy: 0.7440 - val_loss: 1.3715 - val_accuracy: 0.5315 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.7374Epoch 15/40: loss=0.5398, accuracy=0.7374, val_loss=1.1849, val_accuracy=0.5728\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5398 - accuracy: 0.7374 - val_loss: 1.1849 - val_accuracy: 0.5728 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.7417Epoch 16/40: loss=0.5285, accuracy=0.7421, val_loss=0.7388, val_accuracy=0.7094\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5285 - accuracy: 0.7421 - val_loss: 0.7388 - val_accuracy: 0.7094 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5256 - accuracy: 0.7475\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 17/40: loss=0.5256, accuracy=0.7475, val_loss=0.5724, val_accuracy=0.7682\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5256 - accuracy: 0.7475 - val_loss: 0.5724 - val_accuracy: 0.7682 - lr: 2.0000e-05\n",
      "Epoch 17: early stopping\n",
      "Validation accuracy: 0.7864238619804382\n",
      "\n",
      "Initial Training Combination 21/50: num_residual_blocks=6, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=7, num_dense_layers=2, activation_function=tanh, rotation_range=40, width_shift_range=0.4, height_shift_range=0.3, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2759 - accuracy: 0.4965Epoch 1/40: loss=1.2759, accuracy=0.4965, val_loss=0.6771, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 43ms/step - loss: 1.2759 - accuracy: 0.4965 - val_loss: 0.6771 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9378 - accuracy: 0.5004Epoch 2/40: loss=0.9378, accuracy=0.5004, val_loss=0.6756, val_accuracy=0.5993\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.9378 - accuracy: 0.5004 - val_loss: 0.6756 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9087 - accuracy: 0.5079Epoch 3/40: loss=0.9089, accuracy=0.5079, val_loss=0.7041, val_accuracy=0.4007\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.9089 - accuracy: 0.5079 - val_loss: 0.7041 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9173 - accuracy: 0.4882Epoch 4/40: loss=0.9173, accuracy=0.4882, val_loss=0.6959, val_accuracy=0.4007\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.9173 - accuracy: 0.4882 - val_loss: 0.6959 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.5044Epoch 5/40: loss=0.8761, accuracy=0.5046, val_loss=0.7656, val_accuracy=0.4007\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.8761 - accuracy: 0.5046 - val_loss: 0.7656 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.5031Epoch 6/40: loss=0.8707, accuracy=0.5031, val_loss=0.7013, val_accuracy=0.4007\n",
      "604/604 [==============================] - 27s 44ms/step - loss: 0.8707 - accuracy: 0.5031 - val_loss: 0.7013 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.5033\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/40: loss=0.8641, accuracy=0.5033, val_loss=0.6755, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.8641 - accuracy: 0.5033 - val_loss: 0.6755 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.5068Epoch 8/40: loss=0.7777, accuracy=0.5068, val_loss=0.6784, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7777 - accuracy: 0.5068 - val_loss: 0.6784 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7377 - accuracy: 0.4985Epoch 9/40: loss=0.7380, accuracy=0.4979, val_loss=0.7230, val_accuracy=0.4007\n",
      "604/604 [==============================] - 25s 42ms/step - loss: 0.7380 - accuracy: 0.4979 - val_loss: 0.7230 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7216 - accuracy: 0.5077Epoch 10/40: loss=0.7213, accuracy=0.5081, val_loss=0.7212, val_accuracy=0.4007\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.7213 - accuracy: 0.5081 - val_loss: 0.7212 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7236 - accuracy: 0.5077Epoch 11/40: loss=0.7237, accuracy=0.5075, val_loss=0.7517, val_accuracy=0.4007\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7237 - accuracy: 0.5075 - val_loss: 0.7517 - val_accuracy: 0.4007 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7164 - accuracy: 0.5093\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 12/40: loss=0.7164, accuracy=0.5093, val_loss=0.6785, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7164 - accuracy: 0.5093 - val_loss: 0.6785 - val_accuracy: 0.5993 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7250 - accuracy: 0.4932Epoch 13/40: loss=0.7249, accuracy=0.4934, val_loss=0.6794, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7249 - accuracy: 0.4934 - val_loss: 0.6794 - val_accuracy: 0.5993 - lr: 4.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7148 - accuracy: 0.5046Epoch 14/40: loss=0.7149, accuracy=0.5046, val_loss=0.6807, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 42ms/step - loss: 0.7149 - accuracy: 0.5046 - val_loss: 0.6807 - val_accuracy: 0.5993 - lr: 4.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.5077Epoch 15/40: loss=0.7098, accuracy=0.5083, val_loss=0.6777, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7098 - accuracy: 0.5083 - val_loss: 0.6777 - val_accuracy: 0.5993 - lr: 4.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7094 - accuracy: 0.5106Epoch 16/40: loss=0.7095, accuracy=0.5106, val_loss=0.6781, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 44ms/step - loss: 0.7095 - accuracy: 0.5106 - val_loss: 0.6781 - val_accuracy: 0.5993 - lr: 4.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7077 - accuracy: 0.5087\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 17/40: loss=0.7076, accuracy=0.5087, val_loss=0.6785, val_accuracy=0.5993\n",
      "604/604 [==============================] - 26s 43ms/step - loss: 0.7076 - accuracy: 0.5087 - val_loss: 0.6785 - val_accuracy: 0.5993 - lr: 4.0000e-05\n",
      "Epoch 17: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 22/50: num_residual_blocks=8, dropout_rate=0.55, learning_rate=5e-05, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=40, width_shift_range=0.1, height_shift_range=0.3, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0386 - accuracy: 0.5170Epoch 1/40: loss=1.0370, accuracy=0.5178, val_loss=0.7401, val_accuracy=0.6010\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 1.0370 - accuracy: 0.5178 - val_loss: 0.7401 - val_accuracy: 0.6010 - lr: 5.0000e-05\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9627 - accuracy: 0.5375Epoch 2/40: loss=0.9623, accuracy=0.5379, val_loss=0.7417, val_accuracy=0.5803\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.9623 - accuracy: 0.5379 - val_loss: 0.7417 - val_accuracy: 0.5803 - lr: 5.0000e-05\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9136 - accuracy: 0.5559Epoch 3/40: loss=0.9136, accuracy=0.5559, val_loss=0.9817, val_accuracy=0.5795\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.9136 - accuracy: 0.5559 - val_loss: 0.9817 - val_accuracy: 0.5795 - lr: 5.0000e-05\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8814 - accuracy: 0.5756Epoch 4/40: loss=0.8811, accuracy=0.5755, val_loss=0.9730, val_accuracy=0.5977\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8811 - accuracy: 0.5755 - val_loss: 0.9730 - val_accuracy: 0.5977 - lr: 5.0000e-05\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8382 - accuracy: 0.6026Epoch 5/40: loss=0.8382, accuracy=0.6026, val_loss=0.8615, val_accuracy=0.5762\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8382 - accuracy: 0.6026 - val_loss: 0.8615 - val_accuracy: 0.5762 - lr: 5.0000e-05\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8440 - accuracy: 0.5926Epoch 6/40: loss=0.8455, accuracy=0.5923, val_loss=0.6654, val_accuracy=0.6796\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.8455 - accuracy: 0.5923 - val_loss: 0.6654 - val_accuracy: 0.6796 - lr: 5.0000e-05\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8077 - accuracy: 0.5941Epoch 7/40: loss=0.8072, accuracy=0.5948, val_loss=0.8624, val_accuracy=0.6043\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8072 - accuracy: 0.5948 - val_loss: 0.8624 - val_accuracy: 0.6043 - lr: 5.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7863 - accuracy: 0.6063Epoch 8/40: loss=0.7877, accuracy=0.6060, val_loss=0.7459, val_accuracy=0.6482\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7877 - accuracy: 0.6060 - val_loss: 0.7459 - val_accuracy: 0.6482 - lr: 5.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7278 - accuracy: 0.6416Epoch 9/40: loss=0.7272, accuracy=0.6420, val_loss=0.6920, val_accuracy=0.6962\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7272 - accuracy: 0.6420 - val_loss: 0.6920 - val_accuracy: 0.6962 - lr: 5.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.6445Epoch 10/40: loss=0.7193, accuracy=0.6449, val_loss=0.7434, val_accuracy=0.6730\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7193 - accuracy: 0.6449 - val_loss: 0.7434 - val_accuracy: 0.6730 - lr: 5.0000e-05\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.6554Epoch 11/40: loss=0.6969, accuracy=0.6554, val_loss=0.5486, val_accuracy=0.7508\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6969 - accuracy: 0.6554 - val_loss: 0.5486 - val_accuracy: 0.7508 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.6745Epoch 12/40: loss=0.6658, accuracy=0.6745, val_loss=0.5713, val_accuracy=0.7525\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6658 - accuracy: 0.6745 - val_loss: 0.5713 - val_accuracy: 0.7525 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.6645Epoch 13/40: loss=0.6727, accuracy=0.6645, val_loss=0.5182, val_accuracy=0.7649\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6727 - accuracy: 0.6645 - val_loss: 0.5182 - val_accuracy: 0.7649 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6583 - accuracy: 0.6748Epoch 14/40: loss=0.6582, accuracy=0.6753, val_loss=0.8279, val_accuracy=0.6755\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6582 - accuracy: 0.6753 - val_loss: 0.8279 - val_accuracy: 0.6755 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6433 - accuracy: 0.6870Epoch 15/40: loss=0.6433, accuracy=0.6871, val_loss=0.9501, val_accuracy=0.6109\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6433 - accuracy: 0.6871 - val_loss: 0.9501 - val_accuracy: 0.6109 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6968Epoch 16/40: loss=0.6202, accuracy=0.6968, val_loss=1.0609, val_accuracy=0.5944\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6202 - accuracy: 0.6968 - val_loss: 1.0609 - val_accuracy: 0.5944 - lr: 5.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6093 - accuracy: 0.7010Epoch 17/40: loss=0.6099, accuracy=0.7007, val_loss=0.5788, val_accuracy=0.7434\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6099 - accuracy: 0.7007 - val_loss: 0.5788 - val_accuracy: 0.7434 - lr: 5.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5996 - accuracy: 0.7006\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 18/40: loss=0.5999, accuracy=0.6999, val_loss=0.5312, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5999 - accuracy: 0.6999 - val_loss: 0.5312 - val_accuracy: 0.7517 - lr: 5.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.6959Epoch 19/40: loss=0.5966, accuracy=0.6960, val_loss=0.5890, val_accuracy=0.7392\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5966 - accuracy: 0.6960 - val_loss: 0.5890 - val_accuracy: 0.7392 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.7080Epoch 20/40: loss=0.5796, accuracy=0.7080, val_loss=0.6996, val_accuracy=0.7053\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5796 - accuracy: 0.7080 - val_loss: 0.6996 - val_accuracy: 0.7053 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.7214Epoch 21/40: loss=0.5615, accuracy=0.7212, val_loss=0.6363, val_accuracy=0.7219\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5615 - accuracy: 0.7212 - val_loss: 0.6363 - val_accuracy: 0.7219 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.7051Epoch 22/40: loss=0.5780, accuracy=0.7051, val_loss=0.6397, val_accuracy=0.7144\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5780 - accuracy: 0.7051 - val_loss: 0.6397 - val_accuracy: 0.7144 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5729 - accuracy: 0.7106\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 23/40: loss=0.5729, accuracy=0.7107, val_loss=0.6414, val_accuracy=0.7194\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5729 - accuracy: 0.7107 - val_loss: 0.6414 - val_accuracy: 0.7194 - lr: 1.0000e-05\n",
      "Epoch 23: early stopping\n",
      "Validation accuracy: 0.7649006843566895\n",
      "\n",
      "Initial Training Combination 23/50: num_residual_blocks=4, dropout_rate=0.6, learning_rate=0.005, filters=64, kernel_size=5, num_dense_layers=1, activation_function=relu, rotation_range=30, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.2, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1992 - accuracy: 0.5172Epoch 1/40: loss=1.1992, accuracy=0.5172, val_loss=4.6034, val_accuracy=0.5969\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.1992 - accuracy: 0.5172 - val_loss: 4.6034 - val_accuracy: 0.5969 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9597 - accuracy: 0.5891Epoch 2/40: loss=0.9587, accuracy=0.5894, val_loss=0.6705, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9587 - accuracy: 0.5894 - val_loss: 0.6705 - val_accuracy: 0.7483 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8965 - accuracy: 0.5858Epoch 3/40: loss=0.8960, accuracy=0.5859, val_loss=0.5844, val_accuracy=0.7036\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8960 - accuracy: 0.5859 - val_loss: 0.5844 - val_accuracy: 0.7036 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7558 - accuracy: 0.6211Epoch 4/40: loss=0.7561, accuracy=0.6211, val_loss=0.5436, val_accuracy=0.7401\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7561 - accuracy: 0.6211 - val_loss: 0.5436 - val_accuracy: 0.7401 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.6480Epoch 5/40: loss=0.6826, accuracy=0.6484, val_loss=0.6630, val_accuracy=0.6308\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6826 - accuracy: 0.6484 - val_loss: 0.6630 - val_accuracy: 0.6308 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.6627Epoch 6/40: loss=0.6517, accuracy=0.6625, val_loss=2.9677, val_accuracy=0.6002\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6517 - accuracy: 0.6625 - val_loss: 2.9677 - val_accuracy: 0.6002 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.6828Epoch 7/40: loss=0.6195, accuracy=0.6827, val_loss=1.5091, val_accuracy=0.6076\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6195 - accuracy: 0.6827 - val_loss: 1.5091 - val_accuracy: 0.6076 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.6646Epoch 8/40: loss=0.6311, accuracy=0.6647, val_loss=0.9443, val_accuracy=0.6697\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6311 - accuracy: 0.6647 - val_loss: 0.9443 - val_accuracy: 0.6697 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6090 - accuracy: 0.6876\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 9/40: loss=0.6092, accuracy=0.6873, val_loss=1.0481, val_accuracy=0.4677\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6092 - accuracy: 0.6873 - val_loss: 1.0481 - val_accuracy: 0.4677 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.6991Epoch 10/40: loss=0.5782, accuracy=0.6989, val_loss=0.7967, val_accuracy=0.5604\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5782 - accuracy: 0.6989 - val_loss: 0.7967 - val_accuracy: 0.5604 - lr: 1.0000e-03\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5531 - accuracy: 0.7210Epoch 11/40: loss=0.5535, accuracy=0.7210, val_loss=0.5540, val_accuracy=0.7301\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5535 - accuracy: 0.7210 - val_loss: 0.5540 - val_accuracy: 0.7301 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7248Epoch 12/40: loss=0.5552, accuracy=0.7248, val_loss=0.4914, val_accuracy=0.7765\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5552 - accuracy: 0.7248 - val_loss: 0.4914 - val_accuracy: 0.7765 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7119Epoch 13/40: loss=0.5635, accuracy=0.7121, val_loss=0.5031, val_accuracy=0.7765\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5635 - accuracy: 0.7121 - val_loss: 0.5031 - val_accuracy: 0.7765 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.7235Epoch 14/40: loss=0.5537, accuracy=0.7235, val_loss=0.6155, val_accuracy=0.6887\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5537 - accuracy: 0.7235 - val_loss: 0.6155 - val_accuracy: 0.6887 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.7315Epoch 15/40: loss=0.5450, accuracy=0.7318, val_loss=0.5408, val_accuracy=0.7384\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5450 - accuracy: 0.7318 - val_loss: 0.5408 - val_accuracy: 0.7384 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.7280Epoch 16/40: loss=0.5543, accuracy=0.7283, val_loss=1.0439, val_accuracy=0.4710\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5543 - accuracy: 0.7283 - val_loss: 1.0439 - val_accuracy: 0.4710 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7214Epoch 17/40: loss=0.5492, accuracy=0.7214, val_loss=0.4613, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5492 - accuracy: 0.7214 - val_loss: 0.4613 - val_accuracy: 0.7856 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.7330Epoch 18/40: loss=0.5453, accuracy=0.7332, val_loss=0.5177, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5453 - accuracy: 0.7332 - val_loss: 0.5177 - val_accuracy: 0.7517 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.7319Epoch 19/40: loss=0.5379, accuracy=0.7320, val_loss=0.4678, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5379 - accuracy: 0.7320 - val_loss: 0.4678 - val_accuracy: 0.7848 - lr: 1.0000e-03\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5475 - accuracy: 0.7338Epoch 20/40: loss=0.5476, accuracy=0.7337, val_loss=0.4953, val_accuracy=0.7343\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5476 - accuracy: 0.7337 - val_loss: 0.4953 - val_accuracy: 0.7343 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.7367Epoch 21/40: loss=0.5393, accuracy=0.7372, val_loss=0.5634, val_accuracy=0.7409\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5393 - accuracy: 0.7372 - val_loss: 0.5634 - val_accuracy: 0.7409 - lr: 1.0000e-03\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7361\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 22/40: loss=0.5390, accuracy=0.7361, val_loss=0.4823, val_accuracy=0.7798\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5390 - accuracy: 0.7361 - val_loss: 0.4823 - val_accuracy: 0.7798 - lr: 1.0000e-03\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.7351Epoch 23/40: loss=0.5374, accuracy=0.7353, val_loss=0.5562, val_accuracy=0.7103\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5374 - accuracy: 0.7353 - val_loss: 0.5562 - val_accuracy: 0.7103 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.7409Epoch 24/40: loss=0.5283, accuracy=0.7409, val_loss=0.4955, val_accuracy=0.7541\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5283 - accuracy: 0.7409 - val_loss: 0.4955 - val_accuracy: 0.7541 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.7473Epoch 25/40: loss=0.5217, accuracy=0.7473, val_loss=0.5236, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5217 - accuracy: 0.7473 - val_loss: 0.5236 - val_accuracy: 0.7459 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.7500Epoch 26/40: loss=0.5174, accuracy=0.7500, val_loss=0.5353, val_accuracy=0.7434\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.5353 - val_accuracy: 0.7434 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.7471\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5209, accuracy=0.7471, val_loss=0.4866, val_accuracy=0.7649\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5209 - accuracy: 0.7471 - val_loss: 0.4866 - val_accuracy: 0.7649 - lr: 2.0000e-04\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7855960130691528\n",
      "\n",
      "Initial Training Combination 24/50: num_residual_blocks=5, dropout_rate=0.6, learning_rate=1e-06, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "  4/604 [..............................] - ETA: 47s - loss: 1.2672 - accuracy: 0.3750WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0274s vs `on_train_batch_end` time: 0.0301s). Check your callbacks.\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0407 - accuracy: 0.5083Epoch 1/40: loss=1.0407, accuracy=0.5083, val_loss=0.7022, val_accuracy=0.5480\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 1.0407 - accuracy: 0.5083 - val_loss: 0.7022 - val_accuracy: 0.5480 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0257 - accuracy: 0.5085Epoch 2/40: loss=1.0257, accuracy=0.5085, val_loss=0.7010, val_accuracy=0.5439\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 1.0257 - accuracy: 0.5085 - val_loss: 0.7010 - val_accuracy: 0.5439 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.4990Epoch 3/40: loss=1.0474, accuracy=0.4990, val_loss=0.7147, val_accuracy=0.5207\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 1.0474 - accuracy: 0.4990 - val_loss: 0.7147 - val_accuracy: 0.5207 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0111 - accuracy: 0.5116Epoch 4/40: loss=1.0111, accuracy=0.5116, val_loss=0.7129, val_accuracy=0.5306\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0111 - accuracy: 0.5116 - val_loss: 0.7129 - val_accuracy: 0.5306 - lr: 1.0000e-06\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.5207Epoch 5/40: loss=1.0020, accuracy=0.5207, val_loss=0.6913, val_accuracy=0.5687\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.0020 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5687 - lr: 1.0000e-06\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9851 - accuracy: 0.5234Epoch 6/40: loss=0.9846, accuracy=0.5232, val_loss=0.7024, val_accuracy=0.5472\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.9846 - accuracy: 0.5232 - val_loss: 0.7024 - val_accuracy: 0.5472 - lr: 1.0000e-06\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0142 - accuracy: 0.5075Epoch 7/40: loss=1.0119, accuracy=0.5085, val_loss=0.7229, val_accuracy=0.5199\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0119 - accuracy: 0.5085 - val_loss: 0.7229 - val_accuracy: 0.5199 - lr: 1.0000e-06\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9858 - accuracy: 0.5223Epoch 8/40: loss=0.9876, accuracy=0.5219, val_loss=0.7100, val_accuracy=0.5447\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9876 - accuracy: 0.5219 - val_loss: 0.7100 - val_accuracy: 0.5447 - lr: 1.0000e-06\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0178 - accuracy: 0.5012Epoch 9/40: loss=1.0173, accuracy=0.5010, val_loss=0.7224, val_accuracy=0.5373\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 1.0173 - accuracy: 0.5010 - val_loss: 0.7224 - val_accuracy: 0.5373 - lr: 1.0000e-06\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0093 - accuracy: 0.5081\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "Epoch 10/40: loss=1.0093, accuracy=0.5081, val_loss=0.7077, val_accuracy=0.5571\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0093 - accuracy: 0.5081 - val_loss: 0.7077 - val_accuracy: 0.5571 - lr: 1.0000e-06\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0189 - accuracy: 0.5042Epoch 11/40: loss=1.0179, accuracy=0.5043, val_loss=0.6983, val_accuracy=0.5637\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0179 - accuracy: 0.5043 - val_loss: 0.6983 - val_accuracy: 0.5637 - lr: 2.0000e-07\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0286 - accuracy: 0.5174Epoch 12/40: loss=1.0286, accuracy=0.5174, val_loss=0.7306, val_accuracy=0.5339\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 1.0286 - accuracy: 0.5174 - val_loss: 0.7306 - val_accuracy: 0.5339 - lr: 2.0000e-07\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0026 - accuracy: 0.5159Epoch 13/40: loss=1.0026, accuracy=0.5159, val_loss=0.7041, val_accuracy=0.5588\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0026 - accuracy: 0.5159 - val_loss: 0.7041 - val_accuracy: 0.5588 - lr: 2.0000e-07\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.5234Epoch 14/40: loss=0.9928, accuracy=0.5234, val_loss=0.7008, val_accuracy=0.5704\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9928 - accuracy: 0.5234 - val_loss: 0.7008 - val_accuracy: 0.5704 - lr: 2.0000e-07\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9904 - accuracy: 0.5172\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 15/40: loss=0.9895, accuracy=0.5178, val_loss=0.7140, val_accuracy=0.5530\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9895 - accuracy: 0.5178 - val_loss: 0.7140 - val_accuracy: 0.5530 - lr: 2.0000e-07\n",
      "Epoch 15: early stopping\n",
      "Validation accuracy: 0.570364236831665\n",
      "\n",
      "Initial Training Combination 25/50: num_residual_blocks=7, dropout_rate=0.35, learning_rate=0.005, filters=128, kernel_size=7, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.3, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 2.0865 - accuracy: 0.5097Epoch 1/40: loss=2.0865, accuracy=0.5097, val_loss=0.6797, val_accuracy=0.5993\n",
      "604/604 [==============================] - 29s 46ms/step - loss: 2.0865 - accuracy: 0.5097 - val_loss: 0.6797 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 2.1432 - accuracy: 0.5008Epoch 2/40: loss=2.1412, accuracy=0.5010, val_loss=0.6978, val_accuracy=0.4007\n",
      "604/604 [==============================] - 27s 45ms/step - loss: 2.1412 - accuracy: 0.5010 - val_loss: 0.6978 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.8144 - accuracy: 0.5184Epoch 3/40: loss=1.8144, accuracy=0.5184, val_loss=0.6826, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 1.8144 - accuracy: 0.5184 - val_loss: 0.6826 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.6085 - accuracy: 0.5008Epoch 4/40: loss=1.6085, accuracy=0.5008, val_loss=0.8576, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 1.6085 - accuracy: 0.5008 - val_loss: 0.8576 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.3968 - accuracy: 0.5046Epoch 5/40: loss=1.3980, accuracy=0.5043, val_loss=0.7986, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 45ms/step - loss: 1.3980 - accuracy: 0.5043 - val_loss: 0.7986 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2217 - accuracy: 0.5131Epoch 6/40: loss=1.2216, accuracy=0.5128, val_loss=0.6794, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 1.2216 - accuracy: 0.5128 - val_loss: 0.6794 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.4996Epoch 7/40: loss=1.0872, accuracy=0.4996, val_loss=0.7287, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 1.0872 - accuracy: 0.4996 - val_loss: 0.7287 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0012 - accuracy: 0.4934Epoch 8/40: loss=1.0012, accuracy=0.4934, val_loss=0.6858, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 1.0012 - accuracy: 0.4934 - val_loss: 0.6858 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9040 - accuracy: 0.5021Epoch 9/40: loss=0.9047, accuracy=0.5019, val_loss=0.6742, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.9047 - accuracy: 0.5019 - val_loss: 0.6742 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.4882Epoch 10/40: loss=0.8494, accuracy=0.4882, val_loss=0.7212, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.8494 - accuracy: 0.4882 - val_loss: 0.7212 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7955 - accuracy: 0.5151Epoch 11/40: loss=0.7952, accuracy=0.5153, val_loss=0.7546, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7952 - accuracy: 0.5153 - val_loss: 0.7546 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7766 - accuracy: 0.5046Epoch 12/40: loss=0.7765, accuracy=0.5046, val_loss=0.7021, val_accuracy=0.4007\n",
      "604/604 [==============================] - 27s 45ms/step - loss: 0.7765 - accuracy: 0.5046 - val_loss: 0.7021 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7504 - accuracy: 0.4985Epoch 13/40: loss=0.7502, accuracy=0.4990, val_loss=0.6740, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7502 - accuracy: 0.4990 - val_loss: 0.6740 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.5066Epoch 14/40: loss=0.7395, accuracy=0.5066, val_loss=0.6738, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7395 - accuracy: 0.5066 - val_loss: 0.6738 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7266 - accuracy: 0.5060Epoch 15/40: loss=0.7266, accuracy=0.5060, val_loss=0.6823, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7266 - accuracy: 0.5060 - val_loss: 0.6823 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7248 - accuracy: 0.4884Epoch 16/40: loss=0.7248, accuracy=0.4884, val_loss=0.6761, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7248 - accuracy: 0.4884 - val_loss: 0.6761 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7179 - accuracy: 0.5025Epoch 17/40: loss=0.7179, accuracy=0.5025, val_loss=0.6982, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7179 - accuracy: 0.5025 - val_loss: 0.6982 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7293 - accuracy: 0.4950Epoch 18/40: loss=0.7296, accuracy=0.4946, val_loss=0.7281, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7296 - accuracy: 0.4946 - val_loss: 0.7281 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7303 - accuracy: 0.5075\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 19/40: loss=0.7303, accuracy=0.5075, val_loss=0.6790, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 45ms/step - loss: 0.7303 - accuracy: 0.5075 - val_loss: 0.6790 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.5091Epoch 20/40: loss=0.7138, accuracy=0.5091, val_loss=0.7007, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7138 - accuracy: 0.5091 - val_loss: 0.7007 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.5108Epoch 21/40: loss=0.7001, accuracy=0.5110, val_loss=0.7084, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7001 - accuracy: 0.5110 - val_loss: 0.7084 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.4925Epoch 22/40: loss=0.7004, accuracy=0.4925, val_loss=0.6969, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.7004 - accuracy: 0.4925 - val_loss: 0.6969 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.4952Epoch 23/40: loss=0.6990, accuracy=0.4952, val_loss=0.7056, val_accuracy=0.4007\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.6990 - accuracy: 0.4952 - val_loss: 0.7056 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.5046\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.6988, accuracy=0.5046, val_loss=0.6804, val_accuracy=0.5993\n",
      "604/604 [==============================] - 28s 46ms/step - loss: 0.6988 - accuracy: 0.5046 - val_loss: 0.6804 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 26/50: num_residual_blocks=6, dropout_rate=0.25, learning_rate=0.005, filters=128, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=40, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.4, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.9933 - accuracy: 0.5139Epoch 1/40: loss=1.9933, accuracy=0.5139, val_loss=0.9516, val_accuracy=0.4007\n",
      "604/604 [==============================] - 17s 23ms/step - loss: 1.9933 - accuracy: 0.5139 - val_loss: 0.9516 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.9080 - accuracy: 0.5031Epoch 2/40: loss=1.9069, accuracy=0.5031, val_loss=1.0351, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.9069 - accuracy: 0.5031 - val_loss: 1.0351 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.6303 - accuracy: 0.5102Epoch 3/40: loss=1.6296, accuracy=0.5099, val_loss=0.6757, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 1.6296 - accuracy: 0.5099 - val_loss: 0.6757 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4853 - accuracy: 0.4934Epoch 4/40: loss=1.4849, accuracy=0.4932, val_loss=0.7707, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.4849 - accuracy: 0.4932 - val_loss: 0.7707 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.2738 - accuracy: 0.4877Epoch 5/40: loss=1.2724, accuracy=0.4878, val_loss=0.8937, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.2724 - accuracy: 0.4878 - val_loss: 0.8937 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1091 - accuracy: 0.4934Epoch 6/40: loss=1.1107, accuracy=0.4930, val_loss=0.6758, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.1107 - accuracy: 0.4930 - val_loss: 0.6758 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0005 - accuracy: 0.5129Epoch 7/40: loss=1.0002, accuracy=0.5126, val_loss=0.6738, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0002 - accuracy: 0.5126 - val_loss: 0.6738 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9305 - accuracy: 0.4948Epoch 8/40: loss=0.9306, accuracy=0.4948, val_loss=0.6920, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9306 - accuracy: 0.4948 - val_loss: 0.6920 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8638 - accuracy: 0.5077Epoch 9/40: loss=0.8645, accuracy=0.5070, val_loss=0.6894, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8645 - accuracy: 0.5070 - val_loss: 0.6894 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8234 - accuracy: 0.5006Epoch 10/40: loss=0.8234, accuracy=0.5008, val_loss=0.7324, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8234 - accuracy: 0.5008 - val_loss: 0.7324 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.4944Epoch 11/40: loss=0.7881, accuracy=0.4946, val_loss=0.6734, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7881 - accuracy: 0.4946 - val_loss: 0.6734 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7612 - accuracy: 0.4938Epoch 12/40: loss=0.7616, accuracy=0.4930, val_loss=0.7652, val_accuracy=0.4007\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.7616 - accuracy: 0.4930 - val_loss: 0.7652 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.4901Epoch 13/40: loss=0.7455, accuracy=0.4901, val_loss=0.6804, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7455 - accuracy: 0.4901 - val_loss: 0.6804 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7296 - accuracy: 0.5120Epoch 14/40: loss=0.7296, accuracy=0.5120, val_loss=0.7353, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7296 - accuracy: 0.5120 - val_loss: 0.7353 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7260 - accuracy: 0.4892Epoch 15/40: loss=0.7260, accuracy=0.4890, val_loss=0.6923, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7260 - accuracy: 0.4890 - val_loss: 0.6923 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.5120\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 16/40: loss=0.7187, accuracy=0.5120, val_loss=0.7327, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7187 - accuracy: 0.5120 - val_loss: 0.7327 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.4965Epoch 17/40: loss=0.7086, accuracy=0.4965, val_loss=0.7045, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7086 - accuracy: 0.4965 - val_loss: 0.7045 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.4930Epoch 18/40: loss=0.7012, accuracy=0.4930, val_loss=0.6957, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7012 - accuracy: 0.4930 - val_loss: 0.6957 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.5054Epoch 19/40: loss=0.6970, accuracy=0.5054, val_loss=0.6850, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6970 - accuracy: 0.5054 - val_loss: 0.6850 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6986 - accuracy: 0.4919Epoch 20/40: loss=0.6985, accuracy=0.4923, val_loss=0.7043, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6985 - accuracy: 0.4923 - val_loss: 0.7043 - val_accuracy: 0.4007 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6973 - accuracy: 0.5015\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.6973, accuracy=0.5017, val_loss=0.6763, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6973 - accuracy: 0.5017 - val_loss: 0.6763 - val_accuracy: 0.5993 - lr: 1.0000e-03\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 27/50: num_residual_blocks=8, dropout_rate=0.5, learning_rate=0.05, filters=32, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.4, zoom_range=0.4, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 15.2600 - accuracy: 0.4928Epoch 1/40: loss=15.2600, accuracy=0.4928, val_loss=12.7375, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 21ms/step - loss: 15.2600 - accuracy: 0.4928 - val_loss: 12.7375 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 4.4743 - accuracy: 0.5149Epoch 2/40: loss=4.4695, accuracy=0.5153, val_loss=0.6864, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 4.4695 - accuracy: 0.5153 - val_loss: 0.6864 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.2641 - accuracy: 0.4911Epoch 3/40: loss=1.2652, accuracy=0.4903, val_loss=0.7018, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.2652 - accuracy: 0.4903 - val_loss: 0.7018 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.3078 - accuracy: 0.4977Epoch 4/40: loss=1.3070, accuracy=0.4977, val_loss=0.7731, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.3070 - accuracy: 0.4977 - val_loss: 0.7731 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 3.3280 - accuracy: 0.5050Epoch 5/40: loss=3.3283, accuracy=0.5043, val_loss=3.7545, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 3.3283 - accuracy: 0.5043 - val_loss: 3.7545 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 4.2306 - accuracy: 0.4890Epoch 6/40: loss=4.2306, accuracy=0.4890, val_loss=2.2242, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 4.2306 - accuracy: 0.4890 - val_loss: 2.2242 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 4.5309 - accuracy: 0.5048\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 7/40: loss=4.5269, accuracy=0.5054, val_loss=1.2912, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 4.5269 - accuracy: 0.5054 - val_loss: 1.2912 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0481 - accuracy: 0.5042Epoch 8/40: loss=1.0472, accuracy=0.5043, val_loss=0.6815, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.0472 - accuracy: 0.5043 - val_loss: 0.6815 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7369 - accuracy: 0.5008Epoch 9/40: loss=0.7368, accuracy=0.5008, val_loss=0.6749, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7368 - accuracy: 0.5008 - val_loss: 0.6749 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7165 - accuracy: 0.5029Epoch 10/40: loss=0.7165, accuracy=0.5029, val_loss=0.6945, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7165 - accuracy: 0.5029 - val_loss: 0.6945 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7081 - accuracy: 0.4942Epoch 11/40: loss=0.7080, accuracy=0.4940, val_loss=0.7530, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7080 - accuracy: 0.4940 - val_loss: 0.7530 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.4888Epoch 12/40: loss=0.7117, accuracy=0.4882, val_loss=0.6948, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7117 - accuracy: 0.4882 - val_loss: 0.6948 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7344 - accuracy: 0.5091Epoch 13/40: loss=0.7344, accuracy=0.5091, val_loss=0.6758, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7344 - accuracy: 0.5091 - val_loss: 0.6758 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7886 - accuracy: 0.4925\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 14/40: loss=0.7903, accuracy=0.4919, val_loss=0.7107, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7903 - accuracy: 0.4919 - val_loss: 0.7107 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7224 - accuracy: 0.4963Epoch 15/40: loss=0.7224, accuracy=0.4963, val_loss=0.6989, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7224 - accuracy: 0.4963 - val_loss: 0.6989 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7030 - accuracy: 0.4992Epoch 16/40: loss=0.7029, accuracy=0.4996, val_loss=0.6793, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7029 - accuracy: 0.4996 - val_loss: 0.6793 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7006 - accuracy: 0.5031Epoch 17/40: loss=0.7005, accuracy=0.5029, val_loss=0.7055, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7005 - accuracy: 0.5029 - val_loss: 0.7055 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7014 - accuracy: 0.4921Epoch 18/40: loss=0.7012, accuracy=0.4925, val_loss=0.6836, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7012 - accuracy: 0.4925 - val_loss: 0.6836 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6988 - accuracy: 0.5050\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19/40: loss=0.6989, accuracy=0.5048, val_loss=0.6844, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6989 - accuracy: 0.5048 - val_loss: 0.6844 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 19: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 28/50: num_residual_blocks=4, dropout_rate=0.5, learning_rate=1e-06, filters=128, kernel_size=7, num_dense_layers=3, activation_function=tanh, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0763 - accuracy: 0.4880Epoch 1/40: loss=1.0763, accuracy=0.4880, val_loss=0.7230, val_accuracy=0.5364\n",
      "604/604 [==============================] - 24s 36ms/step - loss: 1.0763 - accuracy: 0.4880 - val_loss: 0.7230 - val_accuracy: 0.5364 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0632 - accuracy: 0.4996Epoch 2/40: loss=1.0626, accuracy=0.4998, val_loss=0.8206, val_accuracy=0.4793\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 1.0626 - accuracy: 0.4998 - val_loss: 0.8206 - val_accuracy: 0.4793 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0194 - accuracy: 0.5133Epoch 3/40: loss=1.0184, accuracy=0.5137, val_loss=0.8656, val_accuracy=0.4594\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 1.0184 - accuracy: 0.5137 - val_loss: 0.8656 - val_accuracy: 0.4594 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0614 - accuracy: 0.4985Epoch 4/40: loss=1.0604, accuracy=0.4992, val_loss=0.7946, val_accuracy=0.5083\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 1.0604 - accuracy: 0.4992 - val_loss: 0.7946 - val_accuracy: 0.5083 - lr: 1.0000e-06\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0023 - accuracy: 0.5122Epoch 5/40: loss=1.0022, accuracy=0.5124, val_loss=0.7391, val_accuracy=0.5397\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 1.0022 - accuracy: 0.5124 - val_loss: 0.7391 - val_accuracy: 0.5397 - lr: 1.0000e-06\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9972 - accuracy: 0.5214\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "Epoch 6/40: loss=0.9970, accuracy=0.5215, val_loss=0.7490, val_accuracy=0.5546\n",
      "604/604 [==============================] - 22s 37ms/step - loss: 0.9970 - accuracy: 0.5215 - val_loss: 0.7490 - val_accuracy: 0.5546 - lr: 1.0000e-06\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0171 - accuracy: 0.5112Epoch 7/40: loss=1.0168, accuracy=0.5112, val_loss=0.7758, val_accuracy=0.5281\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 1.0168 - accuracy: 0.5112 - val_loss: 0.7758 - val_accuracy: 0.5281 - lr: 2.0000e-07\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9784 - accuracy: 0.5350Epoch 8/40: loss=0.9778, accuracy=0.5352, val_loss=0.7576, val_accuracy=0.5530\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.9778 - accuracy: 0.5352 - val_loss: 0.7576 - val_accuracy: 0.5530 - lr: 2.0000e-07\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9945 - accuracy: 0.5230Epoch 9/40: loss=0.9950, accuracy=0.5228, val_loss=0.7596, val_accuracy=0.5497\n",
      "604/604 [==============================] - 22s 37ms/step - loss: 0.9950 - accuracy: 0.5228 - val_loss: 0.7596 - val_accuracy: 0.5497 - lr: 2.0000e-07\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9873 - accuracy: 0.5261Epoch 10/40: loss=0.9868, accuracy=0.5265, val_loss=0.7573, val_accuracy=0.5530\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.9868 - accuracy: 0.5265 - val_loss: 0.7573 - val_accuracy: 0.5530 - lr: 2.0000e-07\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0053 - accuracy: 0.5131\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11/40: loss=1.0049, accuracy=0.5135, val_loss=0.7658, val_accuracy=0.5571\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 1.0049 - accuracy: 0.5135 - val_loss: 0.7658 - val_accuracy: 0.5571 - lr: 2.0000e-07\n",
      "Epoch 11: early stopping\n",
      "Validation accuracy: 0.5571191906929016\n",
      "\n",
      "Initial Training Combination 29/50: num_residual_blocks=5, dropout_rate=0.5, learning_rate=0.005, filters=64, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=40, width_shift_range=0.4, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.4993 - accuracy: 0.4998Epoch 1/40: loss=1.4993, accuracy=0.4998, val_loss=1.4257, val_accuracy=0.5993\n",
      "604/604 [==============================] - 18s 25ms/step - loss: 1.4993 - accuracy: 0.4998 - val_loss: 1.4257 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1729 - accuracy: 0.5124Epoch 2/40: loss=1.1729, accuracy=0.5124, val_loss=0.6795, val_accuracy=0.5820\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.1729 - accuracy: 0.5124 - val_loss: 0.6795 - val_accuracy: 0.5820 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9899 - accuracy: 0.5403Epoch 3/40: loss=0.9882, accuracy=0.5408, val_loss=1.6886, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9882 - accuracy: 0.5408 - val_loss: 1.6886 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9416 - accuracy: 0.4954Epoch 4/40: loss=0.9416, accuracy=0.4952, val_loss=0.7273, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9416 - accuracy: 0.4952 - val_loss: 0.7273 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8581 - accuracy: 0.5083Epoch 5/40: loss=0.8578, accuracy=0.5085, val_loss=0.6954, val_accuracy=0.4826\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8578 - accuracy: 0.5085 - val_loss: 0.6954 - val_accuracy: 0.4826 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7515 - accuracy: 0.5723Epoch 6/40: loss=0.7508, accuracy=0.5724, val_loss=140.8365, val_accuracy=0.5985\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7508 - accuracy: 0.5724 - val_loss: 140.8365 - val_accuracy: 0.5985 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.6412Epoch 7/40: loss=0.6684, accuracy=0.6407, val_loss=0.5942, val_accuracy=0.7301\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6684 - accuracy: 0.6407 - val_loss: 0.5942 - val_accuracy: 0.7301 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6359 - accuracy: 0.6694Epoch 8/40: loss=0.6359, accuracy=0.6691, val_loss=0.8381, val_accuracy=0.5604\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6359 - accuracy: 0.6691 - val_loss: 0.8381 - val_accuracy: 0.5604 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.6689Epoch 9/40: loss=0.6303, accuracy=0.6689, val_loss=0.9376, val_accuracy=0.4868\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6303 - accuracy: 0.6689 - val_loss: 0.9376 - val_accuracy: 0.4868 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.6810Epoch 10/40: loss=0.6092, accuracy=0.6805, val_loss=0.6020, val_accuracy=0.6813\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6092 - accuracy: 0.6805 - val_loss: 0.6020 - val_accuracy: 0.6813 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.6985Epoch 11/40: loss=0.5945, accuracy=0.6985, val_loss=0.5380, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5945 - accuracy: 0.6985 - val_loss: 0.5380 - val_accuracy: 0.7649 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.6858Epoch 12/40: loss=0.5978, accuracy=0.6858, val_loss=11.1703, val_accuracy=0.3684\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5978 - accuracy: 0.6858 - val_loss: 11.1703 - val_accuracy: 0.3684 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.6339Epoch 13/40: loss=0.6485, accuracy=0.6339, val_loss=0.8892, val_accuracy=0.5737\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6485 - accuracy: 0.6339 - val_loss: 0.8892 - val_accuracy: 0.5737 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.6745Epoch 14/40: loss=0.6099, accuracy=0.6745, val_loss=1.2785, val_accuracy=0.4114\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6099 - accuracy: 0.6745 - val_loss: 1.2785 - val_accuracy: 0.4114 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.6858Epoch 15/40: loss=0.6060, accuracy=0.6858, val_loss=0.6084, val_accuracy=0.7674\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6060 - accuracy: 0.6858 - val_loss: 0.6084 - val_accuracy: 0.7674 - lr: 0.0050\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.6741\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 16/40: loss=0.6122, accuracy=0.6740, val_loss=0.8126, val_accuracy=0.4114\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6122 - accuracy: 0.6740 - val_loss: 0.8126 - val_accuracy: 0.4114 - lr: 0.0050\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.6511Epoch 17/40: loss=0.6307, accuracy=0.6511, val_loss=0.6201, val_accuracy=0.6714\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6307 - accuracy: 0.6511 - val_loss: 0.6201 - val_accuracy: 0.6714 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.6993Epoch 18/40: loss=0.5797, accuracy=0.6993, val_loss=0.5843, val_accuracy=0.7392\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5797 - accuracy: 0.6993 - val_loss: 0.5843 - val_accuracy: 0.7392 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.7057Epoch 19/40: loss=0.5719, accuracy=0.7057, val_loss=0.7320, val_accuracy=0.6598\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5719 - accuracy: 0.7057 - val_loss: 0.7320 - val_accuracy: 0.6598 - lr: 1.0000e-03\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7159Epoch 20/40: loss=0.5680, accuracy=0.7156, val_loss=0.7278, val_accuracy=0.6954\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5680 - accuracy: 0.7156 - val_loss: 0.7278 - val_accuracy: 0.6954 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.7229\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.5556, accuracy=0.7229, val_loss=0.5905, val_accuracy=0.7293\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5556 - accuracy: 0.7229 - val_loss: 0.5905 - val_accuracy: 0.7293 - lr: 1.0000e-03\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.7673841118812561\n",
      "\n",
      "Initial Training Combination 30/50: num_residual_blocks=7, dropout_rate=0.45, learning_rate=1e-05, filters=128, kernel_size=7, num_dense_layers=3, activation_function=tanh, rotation_range=10, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0547 - accuracy: 0.5012Epoch 1/40: loss=1.0556, accuracy=0.5006, val_loss=0.6670, val_accuracy=0.6084\n",
      "604/604 [==============================] - 33s 49ms/step - loss: 1.0556 - accuracy: 0.5006 - val_loss: 0.6670 - val_accuracy: 0.6084 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0271 - accuracy: 0.5079Epoch 2/40: loss=1.0266, accuracy=0.5083, val_loss=0.6991, val_accuracy=0.5811\n",
      "604/604 [==============================] - 28s 47ms/step - loss: 1.0266 - accuracy: 0.5083 - val_loss: 0.6991 - val_accuracy: 0.5811 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0008 - accuracy: 0.5029Epoch 3/40: loss=1.0019, accuracy=0.5025, val_loss=0.7885, val_accuracy=0.5108\n",
      "604/604 [==============================] - 28s 47ms/step - loss: 1.0019 - accuracy: 0.5025 - val_loss: 0.7885 - val_accuracy: 0.5108 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9526 - accuracy: 0.5236Epoch 4/40: loss=0.9526, accuracy=0.5236, val_loss=0.7692, val_accuracy=0.5091\n",
      "604/604 [==============================] - 29s 47ms/step - loss: 0.9526 - accuracy: 0.5236 - val_loss: 0.7692 - val_accuracy: 0.5091 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9110 - accuracy: 0.5303Epoch 5/40: loss=0.9111, accuracy=0.5304, val_loss=0.6234, val_accuracy=0.6540\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.9111 - accuracy: 0.5304 - val_loss: 0.6234 - val_accuracy: 0.6540 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9139 - accuracy: 0.5344Epoch 6/40: loss=0.9139, accuracy=0.5344, val_loss=0.6786, val_accuracy=0.6531\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.9139 - accuracy: 0.5344 - val_loss: 0.6786 - val_accuracy: 0.6531 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8617 - accuracy: 0.5703Epoch 7/40: loss=0.8613, accuracy=0.5704, val_loss=0.6961, val_accuracy=0.6863\n",
      "604/604 [==============================] - 29s 47ms/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 0.6961 - val_accuracy: 0.6863 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8230 - accuracy: 0.5935Epoch 8/40: loss=0.8231, accuracy=0.5933, val_loss=1.1770, val_accuracy=0.5745\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.8231 - accuracy: 0.5933 - val_loss: 1.1770 - val_accuracy: 0.5745 - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7858 - accuracy: 0.6244Epoch 9/40: loss=0.7859, accuracy=0.6242, val_loss=0.6453, val_accuracy=0.7467\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7859 - accuracy: 0.6242 - val_loss: 0.6453 - val_accuracy: 0.7467 - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.6302\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 10/40: loss=0.7668, accuracy=0.6302, val_loss=1.8528, val_accuracy=0.4834\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7668 - accuracy: 0.6302 - val_loss: 1.8528 - val_accuracy: 0.4834 - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7542 - accuracy: 0.6389Epoch 11/40: loss=0.7549, accuracy=0.6385, val_loss=0.7681, val_accuracy=0.7310\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7549 - accuracy: 0.6385 - val_loss: 0.7681 - val_accuracy: 0.7310 - lr: 2.0000e-06\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.6403Epoch 12/40: loss=0.7570, accuracy=0.6403, val_loss=0.9274, val_accuracy=0.6937\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7570 - accuracy: 0.6403 - val_loss: 0.9274 - val_accuracy: 0.6937 - lr: 2.0000e-06\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7290 - accuracy: 0.6505Epoch 13/40: loss=0.7290, accuracy=0.6505, val_loss=0.8177, val_accuracy=0.7392\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7290 - accuracy: 0.6505 - val_loss: 0.8177 - val_accuracy: 0.7392 - lr: 2.0000e-06\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.6563Epoch 14/40: loss=0.7337, accuracy=0.6567, val_loss=1.4688, val_accuracy=0.6060\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7337 - accuracy: 0.6567 - val_loss: 1.4688 - val_accuracy: 0.6060 - lr: 2.0000e-06\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7129 - accuracy: 0.6635\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 15/40: loss=0.7129, accuracy=0.6635, val_loss=1.2450, val_accuracy=0.6474\n",
      "604/604 [==============================] - 29s 48ms/step - loss: 0.7129 - accuracy: 0.6635 - val_loss: 1.2450 - val_accuracy: 0.6474 - lr: 2.0000e-06\n",
      "Epoch 15: early stopping\n",
      "Validation accuracy: 0.746688723564148\n",
      "\n",
      "Initial Training Combination 31/50: num_residual_blocks=8, dropout_rate=0.45, learning_rate=0.05, filters=128, kernel_size=7, num_dense_layers=1, activation_function=relu, rotation_range=30, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 3.7833 - accuracy: 0.5430Epoch 1/40: loss=3.7833, accuracy=0.5430, val_loss=0.6471, val_accuracy=0.6010\n",
      "604/604 [==============================] - 34s 51ms/step - loss: 3.7833 - accuracy: 0.5430 - val_loss: 0.6471 - val_accuracy: 0.6010 - lr: 0.0500\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8272 - accuracy: 0.5608Epoch 2/40: loss=0.8272, accuracy=0.5608, val_loss=16.3125, val_accuracy=0.4007\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.8272 - accuracy: 0.5608 - val_loss: 16.3125 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0655 - accuracy: 0.5618Epoch 3/40: loss=1.0666, accuracy=0.5615, val_loss=2.7756, val_accuracy=0.6449\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.0666 - accuracy: 0.5615 - val_loss: 2.7756 - val_accuracy: 0.6449 - lr: 0.0500\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1860 - accuracy: 0.5213Epoch 4/40: loss=1.1860, accuracy=0.5213, val_loss=0.6263, val_accuracy=0.6780\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.1860 - accuracy: 0.5213 - val_loss: 0.6263 - val_accuracy: 0.6780 - lr: 0.0500\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.3124 - accuracy: 0.5321Epoch 5/40: loss=1.3119, accuracy=0.5321, val_loss=1.1485, val_accuracy=0.4007\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.3119 - accuracy: 0.5321 - val_loss: 1.1485 - val_accuracy: 0.4007 - lr: 0.0500\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1826 - accuracy: 0.5755Epoch 6/40: loss=1.1826, accuracy=0.5755, val_loss=0.7298, val_accuracy=0.5993\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.1826 - accuracy: 0.5755 - val_loss: 0.7298 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0736 - accuracy: 0.5844Epoch 7/40: loss=1.0736, accuracy=0.5844, val_loss=3.9294, val_accuracy=0.5050\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.0736 - accuracy: 0.5844 - val_loss: 3.9294 - val_accuracy: 0.5050 - lr: 0.0500\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.5536 - accuracy: 0.5945Epoch 8/40: loss=1.5536, accuracy=0.5946, val_loss=1.3703, val_accuracy=0.4901\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.5536 - accuracy: 0.5946 - val_loss: 1.3703 - val_accuracy: 0.4901 - lr: 0.0500\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1307 - accuracy: 0.5947\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 9/40: loss=1.1350, accuracy=0.5944, val_loss=1.1395, val_accuracy=0.5993\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.1350 - accuracy: 0.5944 - val_loss: 1.1395 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.6709Epoch 10/40: loss=0.6340, accuracy=0.6709, val_loss=0.5417, val_accuracy=0.7376\n",
      "604/604 [==============================] - 31s 50ms/step - loss: 0.6340 - accuracy: 0.6709 - val_loss: 0.5417 - val_accuracy: 0.7376 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.6918Epoch 11/40: loss=0.5924, accuracy=0.6918, val_loss=0.5326, val_accuracy=0.7368\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5924 - accuracy: 0.6918 - val_loss: 0.5326 - val_accuracy: 0.7368 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5772 - accuracy: 0.6994Epoch 12/40: loss=0.5769, accuracy=0.6999, val_loss=0.5061, val_accuracy=0.7624\n",
      "604/604 [==============================] - 31s 51ms/step - loss: 0.5769 - accuracy: 0.6999 - val_loss: 0.5061 - val_accuracy: 0.7624 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7047Epoch 13/40: loss=0.5781, accuracy=0.7047, val_loss=0.6734, val_accuracy=0.6109\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5781 - accuracy: 0.7047 - val_loss: 0.6734 - val_accuracy: 0.6109 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.7082Epoch 14/40: loss=0.5908, accuracy=0.7082, val_loss=0.8323, val_accuracy=0.5306\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5908 - accuracy: 0.7082 - val_loss: 0.8323 - val_accuracy: 0.5306 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.6950Epoch 15/40: loss=0.5984, accuracy=0.6950, val_loss=0.8975, val_accuracy=0.4876\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5984 - accuracy: 0.6950 - val_loss: 0.8975 - val_accuracy: 0.4876 - lr: 0.0100\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.6921Epoch 16/40: loss=0.6101, accuracy=0.6921, val_loss=0.5283, val_accuracy=0.7368\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6101 - accuracy: 0.6921 - val_loss: 0.5283 - val_accuracy: 0.7368 - lr: 0.0100\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.6861\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 17/40: loss=0.6133, accuracy=0.6861, val_loss=0.6510, val_accuracy=0.6656\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6133 - accuracy: 0.6861 - val_loss: 0.6510 - val_accuracy: 0.6656 - lr: 0.0100\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.7243Epoch 18/40: loss=0.5633, accuracy=0.7245, val_loss=0.5620, val_accuracy=0.6978\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5633 - accuracy: 0.7245 - val_loss: 0.5620 - val_accuracy: 0.6978 - lr: 0.0020\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5482 - accuracy: 0.7328Epoch 19/40: loss=0.5480, accuracy=0.7328, val_loss=0.5373, val_accuracy=0.7227\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5480 - accuracy: 0.7328 - val_loss: 0.5373 - val_accuracy: 0.7227 - lr: 0.0020\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7349Epoch 20/40: loss=0.5435, accuracy=0.7347, val_loss=0.5477, val_accuracy=0.7136\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5435 - accuracy: 0.7347 - val_loss: 0.5477 - val_accuracy: 0.7136 - lr: 0.0020\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7355Epoch 21/40: loss=0.5380, accuracy=0.7355, val_loss=0.4839, val_accuracy=0.7724\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5380 - accuracy: 0.7355 - val_loss: 0.4839 - val_accuracy: 0.7724 - lr: 0.0020\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7349Epoch 22/40: loss=0.5434, accuracy=0.7349, val_loss=0.5047, val_accuracy=0.7608\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5434 - accuracy: 0.7349 - val_loss: 0.5047 - val_accuracy: 0.7608 - lr: 0.0020\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5519 - accuracy: 0.7268Epoch 23/40: loss=0.5516, accuracy=0.7270, val_loss=0.4727, val_accuracy=0.7856\n",
      "604/604 [==============================] - 31s 51ms/step - loss: 0.5516 - accuracy: 0.7270 - val_loss: 0.4727 - val_accuracy: 0.7856 - lr: 0.0020\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.7382Epoch 24/40: loss=0.5419, accuracy=0.7382, val_loss=0.4627, val_accuracy=0.7930\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5419 - accuracy: 0.7382 - val_loss: 0.4627 - val_accuracy: 0.7930 - lr: 0.0020\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.7307Epoch 25/40: loss=0.5466, accuracy=0.7308, val_loss=0.5047, val_accuracy=0.7575\n",
      "604/604 [==============================] - 32s 52ms/step - loss: 0.5466 - accuracy: 0.7308 - val_loss: 0.5047 - val_accuracy: 0.7575 - lr: 0.0020\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7328Epoch 26/40: loss=0.5388, accuracy=0.7332, val_loss=0.5173, val_accuracy=0.7459\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5388 - accuracy: 0.7332 - val_loss: 0.5173 - val_accuracy: 0.7459 - lr: 0.0020\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7338Epoch 27/40: loss=0.5378, accuracy=0.7334, val_loss=0.4874, val_accuracy=0.7666\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5378 - accuracy: 0.7334 - val_loss: 0.4874 - val_accuracy: 0.7666 - lr: 0.0020\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5315 - accuracy: 0.7450Epoch 28/40: loss=0.5310, accuracy=0.7452, val_loss=0.5384, val_accuracy=0.7318\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5310 - accuracy: 0.7452 - val_loss: 0.5384 - val_accuracy: 0.7318 - lr: 0.0020\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7328\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 29/40: loss=0.5374, accuracy=0.7328, val_loss=0.6040, val_accuracy=0.6697\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5374 - accuracy: 0.7328 - val_loss: 0.6040 - val_accuracy: 0.6697 - lr: 0.0020\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7355Epoch 30/40: loss=0.5408, accuracy=0.7355, val_loss=0.4671, val_accuracy=0.7906\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5408 - accuracy: 0.7355 - val_loss: 0.4671 - val_accuracy: 0.7906 - lr: 4.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7467Epoch 31/40: loss=0.5215, accuracy=0.7467, val_loss=0.4955, val_accuracy=0.7583\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5215 - accuracy: 0.7467 - val_loss: 0.4955 - val_accuracy: 0.7583 - lr: 4.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.7398Epoch 32/40: loss=0.5299, accuracy=0.7397, val_loss=0.4936, val_accuracy=0.7591\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5299 - accuracy: 0.7397 - val_loss: 0.4936 - val_accuracy: 0.7591 - lr: 4.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5180 - accuracy: 0.7521Epoch 33/40: loss=0.5179, accuracy=0.7521, val_loss=0.4940, val_accuracy=0.7583\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5179 - accuracy: 0.7521 - val_loss: 0.4940 - val_accuracy: 0.7583 - lr: 4.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.7446\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 34/40: loss=0.5232, accuracy=0.7442, val_loss=0.5087, val_accuracy=0.7467\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.5232 - accuracy: 0.7442 - val_loss: 0.5087 - val_accuracy: 0.7467 - lr: 4.0000e-04\n",
      "Epoch 34: early stopping\n",
      "Validation accuracy: 0.7930463552474976\n",
      "\n",
      "Initial Training Combination 32/50: num_residual_blocks=7, dropout_rate=0.6, learning_rate=0.0001, filters=32, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9897 - accuracy: 0.5054Epoch 1/40: loss=0.9893, accuracy=0.5056, val_loss=0.6835, val_accuracy=0.5671\n",
      "604/604 [==============================] - 18s 26ms/step - loss: 0.9893 - accuracy: 0.5056 - val_loss: 0.6835 - val_accuracy: 0.5671 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9676 - accuracy: 0.5064Epoch 2/40: loss=0.9681, accuracy=0.5060, val_loss=0.7159, val_accuracy=0.5265\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9681 - accuracy: 0.5060 - val_loss: 0.7159 - val_accuracy: 0.5265 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9156 - accuracy: 0.5052Epoch 3/40: loss=0.9151, accuracy=0.5048, val_loss=0.7656, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9151 - accuracy: 0.5048 - val_loss: 0.7656 - val_accuracy: 0.5985 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8892 - accuracy: 0.5079Epoch 4/40: loss=0.8908, accuracy=0.5070, val_loss=0.7060, val_accuracy=0.5753\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8908 - accuracy: 0.5070 - val_loss: 0.7060 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8443 - accuracy: 0.5158Epoch 5/40: loss=0.8450, accuracy=0.5157, val_loss=0.7266, val_accuracy=0.5977\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8450 - accuracy: 0.5157 - val_loss: 0.7266 - val_accuracy: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8087 - accuracy: 0.5214\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/40: loss=0.8091, accuracy=0.5209, val_loss=0.7374, val_accuracy=0.5066\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8091 - accuracy: 0.5209 - val_loss: 0.7374 - val_accuracy: 0.5066 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.5182Epoch 7/40: loss=0.8099, accuracy=0.5186, val_loss=0.7353, val_accuracy=0.5563\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8099 - accuracy: 0.5186 - val_loss: 0.7353 - val_accuracy: 0.5563 - lr: 2.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7704 - accuracy: 0.5450Epoch 8/40: loss=0.7700, accuracy=0.5453, val_loss=0.6592, val_accuracy=0.6217\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7700 - accuracy: 0.5453 - val_loss: 0.6592 - val_accuracy: 0.6217 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.5575Epoch 9/40: loss=0.7577, accuracy=0.5569, val_loss=0.7088, val_accuracy=0.6118\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7577 - accuracy: 0.5569 - val_loss: 0.7088 - val_accuracy: 0.6118 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7243 - accuracy: 0.5877Epoch 10/40: loss=0.7242, accuracy=0.5875, val_loss=1.1732, val_accuracy=0.4793\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7242 - accuracy: 0.5875 - val_loss: 1.1732 - val_accuracy: 0.4793 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.6147Epoch 11/40: loss=0.6907, accuracy=0.6147, val_loss=1.7348, val_accuracy=0.4222\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6907 - accuracy: 0.6147 - val_loss: 1.7348 - val_accuracy: 0.4222 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.6424Epoch 12/40: loss=0.6748, accuracy=0.6416, val_loss=0.6179, val_accuracy=0.7285\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6748 - accuracy: 0.6416 - val_loss: 0.6179 - val_accuracy: 0.7285 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.6765Epoch 13/40: loss=0.6434, accuracy=0.6767, val_loss=0.7532, val_accuracy=0.6581\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6434 - accuracy: 0.6767 - val_loss: 0.7532 - val_accuracy: 0.6581 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6488 - accuracy: 0.6624Epoch 14/40: loss=0.6484, accuracy=0.6620, val_loss=1.3070, val_accuracy=0.5008\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6484 - accuracy: 0.6620 - val_loss: 1.3070 - val_accuracy: 0.5008 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6402 - accuracy: 0.6629Epoch 15/40: loss=0.6398, accuracy=0.6631, val_loss=1.1801, val_accuracy=0.4983\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6398 - accuracy: 0.6631 - val_loss: 1.1801 - val_accuracy: 0.4983 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6247 - accuracy: 0.6770Epoch 16/40: loss=0.6255, accuracy=0.6769, val_loss=1.5626, val_accuracy=0.4147\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6255 - accuracy: 0.6769 - val_loss: 1.5626 - val_accuracy: 0.4147 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6202 - accuracy: 0.6817Epoch 17/40: loss=0.6198, accuracy=0.6819, val_loss=0.5953, val_accuracy=0.7276\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6198 - accuracy: 0.6819 - val_loss: 0.5953 - val_accuracy: 0.7276 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.6769Epoch 18/40: loss=0.6206, accuracy=0.6767, val_loss=1.2129, val_accuracy=0.4810\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6206 - accuracy: 0.6767 - val_loss: 1.2129 - val_accuracy: 0.4810 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.6900Epoch 19/40: loss=0.6000, accuracy=0.6900, val_loss=0.5973, val_accuracy=0.7575\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6000 - accuracy: 0.6900 - val_loss: 0.5973 - val_accuracy: 0.7575 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6166 - accuracy: 0.6723Epoch 20/40: loss=0.6166, accuracy=0.6724, val_loss=1.3703, val_accuracy=0.4379\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6166 - accuracy: 0.6724 - val_loss: 1.3703 - val_accuracy: 0.4379 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.6941Epoch 21/40: loss=0.5909, accuracy=0.6941, val_loss=1.4081, val_accuracy=0.4346\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5909 - accuracy: 0.6941 - val_loss: 1.4081 - val_accuracy: 0.4346 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5870 - accuracy: 0.6973\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 22/40: loss=0.5875, accuracy=0.6968, val_loss=0.7776, val_accuracy=0.6242\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5875 - accuracy: 0.6968 - val_loss: 0.7776 - val_accuracy: 0.6242 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.6917Epoch 23/40: loss=0.5932, accuracy=0.6918, val_loss=0.9278, val_accuracy=0.5704\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5932 - accuracy: 0.6918 - val_loss: 0.9278 - val_accuracy: 0.5704 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5911 - accuracy: 0.6959Epoch 24/40: loss=0.5913, accuracy=0.6958, val_loss=1.2826, val_accuracy=0.4719\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5913 - accuracy: 0.6958 - val_loss: 1.2826 - val_accuracy: 0.4719 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5767 - accuracy: 0.7094Epoch 25/40: loss=0.5768, accuracy=0.7090, val_loss=1.0087, val_accuracy=0.5430\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5768 - accuracy: 0.7090 - val_loss: 1.0087 - val_accuracy: 0.5430 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5813 - accuracy: 0.7076Epoch 26/40: loss=0.5816, accuracy=0.7078, val_loss=0.8488, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5816 - accuracy: 0.7078 - val_loss: 0.8488 - val_accuracy: 0.5985 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5831 - accuracy: 0.7015\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5826, accuracy=0.7020, val_loss=1.0124, val_accuracy=0.5364\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5826 - accuracy: 0.7020 - val_loss: 1.0124 - val_accuracy: 0.5364 - lr: 4.0000e-06\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7574503421783447\n",
      "\n",
      "Initial Training Combination 33/50: num_residual_blocks=4, dropout_rate=0.45, learning_rate=0.001, filters=32, kernel_size=7, num_dense_layers=3, activation_function=relu, rotation_range=10, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.2, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "  5/604 [..............................] - ETA: 22s - loss: 1.1951 - accuracy: 0.4750 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.0190s). Check your callbacks.\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0876 - accuracy: 0.5283Epoch 1/40: loss=1.0885, accuracy=0.5284, val_loss=1.2975, val_accuracy=0.5050\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0885 - accuracy: 0.5284 - val_loss: 1.2975 - val_accuracy: 0.5050 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8822 - accuracy: 0.5068Epoch 2/40: loss=0.8822, accuracy=0.5070, val_loss=1.1148, val_accuracy=0.5952\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8822 - accuracy: 0.5070 - val_loss: 1.1148 - val_accuracy: 0.5952 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.4876Epoch 3/40: loss=0.8951, accuracy=0.4876, val_loss=0.7699, val_accuracy=0.4487\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8951 - accuracy: 0.4876 - val_loss: 0.7699 - val_accuracy: 0.4487 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.5023Epoch 4/40: loss=0.8737, accuracy=0.5023, val_loss=0.8036, val_accuracy=0.4131\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8737 - accuracy: 0.5023 - val_loss: 0.8036 - val_accuracy: 0.4131 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8727 - accuracy: 0.4942Epoch 5/40: loss=0.8726, accuracy=0.4942, val_loss=0.6869, val_accuracy=0.5637\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8726 - accuracy: 0.4942 - val_loss: 0.6869 - val_accuracy: 0.5637 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8591 - accuracy: 0.5081Epoch 6/40: loss=0.8593, accuracy=0.5075, val_loss=0.7027, val_accuracy=0.5505\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8593 - accuracy: 0.5075 - val_loss: 0.7027 - val_accuracy: 0.5505 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8785 - accuracy: 0.4954Epoch 7/40: loss=0.8778, accuracy=0.4959, val_loss=0.9315, val_accuracy=0.4992\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8778 - accuracy: 0.4959 - val_loss: 0.9315 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8459 - accuracy: 0.5131Epoch 8/40: loss=0.8459, accuracy=0.5130, val_loss=0.9614, val_accuracy=0.4421\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8459 - accuracy: 0.5130 - val_loss: 0.9614 - val_accuracy: 0.4421 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8701 - accuracy: 0.4923Epoch 9/40: loss=0.8706, accuracy=0.4917, val_loss=0.6973, val_accuracy=0.5348\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8706 - accuracy: 0.4917 - val_loss: 0.6973 - val_accuracy: 0.5348 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8522 - accuracy: 0.5017\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.8523, accuracy=0.5019, val_loss=0.9917, val_accuracy=0.4164\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.8523 - accuracy: 0.5019 - val_loss: 0.9917 - val_accuracy: 0.4164 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8041 - accuracy: 0.4851Epoch 11/40: loss=0.8045, accuracy=0.4847, val_loss=0.6803, val_accuracy=0.5952\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8045 - accuracy: 0.4847 - val_loss: 0.6803 - val_accuracy: 0.5952 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7662 - accuracy: 0.5066Epoch 12/40: loss=0.7661, accuracy=0.5068, val_loss=0.6961, val_accuracy=0.4156\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7661 - accuracy: 0.5068 - val_loss: 0.6961 - val_accuracy: 0.4156 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7590 - accuracy: 0.5054Epoch 13/40: loss=0.7592, accuracy=0.5052, val_loss=0.6835, val_accuracy=0.5886\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7592 - accuracy: 0.5052 - val_loss: 0.6835 - val_accuracy: 0.5886 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7494 - accuracy: 0.5097Epoch 14/40: loss=0.7492, accuracy=0.5097, val_loss=0.7463, val_accuracy=0.4387\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7492 - accuracy: 0.5097 - val_loss: 0.7463 - val_accuracy: 0.4387 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7464 - accuracy: 0.4988Epoch 15/40: loss=0.7464, accuracy=0.4988, val_loss=0.9135, val_accuracy=0.4172\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7464 - accuracy: 0.4988 - val_loss: 0.9135 - val_accuracy: 0.4172 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7360 - accuracy: 0.4975\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 16/40: loss=0.7360, accuracy=0.4973, val_loss=0.7645, val_accuracy=0.4363\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7360 - accuracy: 0.4973 - val_loss: 0.7645 - val_accuracy: 0.4363 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7254 - accuracy: 0.5029Epoch 17/40: loss=0.7254, accuracy=0.5029, val_loss=0.7188, val_accuracy=0.4247\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7254 - accuracy: 0.5029 - val_loss: 0.7188 - val_accuracy: 0.4247 - lr: 4.0000e-05\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7215 - accuracy: 0.5096Epoch 18/40: loss=0.7212, accuracy=0.5099, val_loss=0.7080, val_accuracy=0.4694\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7212 - accuracy: 0.5099 - val_loss: 0.7080 - val_accuracy: 0.4694 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7128 - accuracy: 0.5193Epoch 19/40: loss=0.7130, accuracy=0.5190, val_loss=0.7377, val_accuracy=0.4437\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7130 - accuracy: 0.5190 - val_loss: 0.7377 - val_accuracy: 0.4437 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7186 - accuracy: 0.5037Epoch 20/40: loss=0.7189, accuracy=0.5037, val_loss=0.7158, val_accuracy=0.4478\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7189 - accuracy: 0.5037 - val_loss: 0.7158 - val_accuracy: 0.4478 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7168 - accuracy: 0.5087\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 21/40: loss=0.7170, accuracy=0.5081, val_loss=0.7016, val_accuracy=0.4487\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7170 - accuracy: 0.5081 - val_loss: 0.7016 - val_accuracy: 0.4487 - lr: 4.0000e-05\n",
      "Epoch 21: early stopping\n",
      "Validation accuracy: 0.5951986908912659\n",
      "\n",
      "Initial Training Combination 34/50: num_residual_blocks=8, dropout_rate=0.3, learning_rate=0.005, filters=64, kernel_size=7, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.1, height_shift_range=0.4, shear_range=0.1, zoom_range=0.4, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.7559 - accuracy: 0.4977Epoch 1/40: loss=1.7552, accuracy=0.4973, val_loss=12.0502, val_accuracy=0.5993\n",
      "604/604 [==============================] - 24s 29ms/step - loss: 1.7552 - accuracy: 0.4973 - val_loss: 12.0502 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.4465 - accuracy: 0.4983Epoch 2/40: loss=1.4471, accuracy=0.4979, val_loss=3.0774, val_accuracy=0.4694\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 1.4471 - accuracy: 0.4979 - val_loss: 3.0774 - val_accuracy: 0.4694 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1633 - accuracy: 0.4971Epoch 3/40: loss=1.1633, accuracy=0.4971, val_loss=0.7864, val_accuracy=0.4983\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 1.1633 - accuracy: 0.4971 - val_loss: 0.7864 - val_accuracy: 0.4983 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9890 - accuracy: 0.5000Epoch 4/40: loss=0.9886, accuracy=0.5002, val_loss=4.6659, val_accuracy=0.5555\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.9886 - accuracy: 0.5002 - val_loss: 4.6659 - val_accuracy: 0.5555 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9348 - accuracy: 0.4876Epoch 5/40: loss=0.9348, accuracy=0.4876, val_loss=11.2757, val_accuracy=0.4603\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.9348 - accuracy: 0.4876 - val_loss: 11.2757 - val_accuracy: 0.4603 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8273 - accuracy: 0.5269Epoch 6/40: loss=0.8274, accuracy=0.5269, val_loss=4.1668, val_accuracy=0.5190\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.8274 - accuracy: 0.5269 - val_loss: 4.1668 - val_accuracy: 0.5190 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7811 - accuracy: 0.5334Epoch 7/40: loss=0.7805, accuracy=0.5337, val_loss=5.6124, val_accuracy=0.5629\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7805 - accuracy: 0.5337 - val_loss: 5.6124 - val_accuracy: 0.5629 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.5495\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 8/40: loss=0.7476, accuracy=0.5495, val_loss=1.4694, val_accuracy=0.4619\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.7476 - accuracy: 0.5495 - val_loss: 1.4694 - val_accuracy: 0.4619 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.5809Epoch 9/40: loss=0.6878, accuracy=0.5809, val_loss=0.7801, val_accuracy=0.5588\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6878 - accuracy: 0.5809 - val_loss: 0.7801 - val_accuracy: 0.5588 - lr: 1.0000e-03\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5956Epoch 10/40: loss=0.6774, accuracy=0.5960, val_loss=0.9455, val_accuracy=0.6060\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.6774 - accuracy: 0.5960 - val_loss: 0.9455 - val_accuracy: 0.6060 - lr: 1.0000e-03\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.5890Epoch 11/40: loss=0.6813, accuracy=0.5890, val_loss=0.8332, val_accuracy=0.5505\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6813 - accuracy: 0.5890 - val_loss: 0.8332 - val_accuracy: 0.5505 - lr: 1.0000e-03\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5943Epoch 12/40: loss=0.6718, accuracy=0.5938, val_loss=1.2293, val_accuracy=0.6333\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.6718 - accuracy: 0.5938 - val_loss: 1.2293 - val_accuracy: 0.6333 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6596 - accuracy: 0.6204Epoch 13/40: loss=0.6598, accuracy=0.6202, val_loss=1.2528, val_accuracy=0.6490\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6598 - accuracy: 0.6202 - val_loss: 1.2528 - val_accuracy: 0.6490 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.6256\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 14/40: loss=0.6450, accuracy=0.6256, val_loss=0.9750, val_accuracy=0.6705\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6450 - accuracy: 0.6256 - val_loss: 0.9750 - val_accuracy: 0.6705 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6102 - accuracy: 0.6631Epoch 15/40: loss=0.6101, accuracy=0.6633, val_loss=1.1870, val_accuracy=0.7103\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.6101 - accuracy: 0.6633 - val_loss: 1.1870 - val_accuracy: 0.7103 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5949 - accuracy: 0.6857Epoch 16/40: loss=0.5947, accuracy=0.6861, val_loss=1.1202, val_accuracy=0.7252\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5947 - accuracy: 0.6861 - val_loss: 1.1202 - val_accuracy: 0.7252 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.6885Epoch 17/40: loss=0.5902, accuracy=0.6885, val_loss=0.8625, val_accuracy=0.7376\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5902 - accuracy: 0.6885 - val_loss: 0.8625 - val_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.6993Epoch 18/40: loss=0.5772, accuracy=0.6993, val_loss=1.9434, val_accuracy=0.6647\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5772 - accuracy: 0.6993 - val_loss: 1.9434 - val_accuracy: 0.6647 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.7012Epoch 19/40: loss=0.5795, accuracy=0.7012, val_loss=0.7561, val_accuracy=0.7674\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5795 - accuracy: 0.7012 - val_loss: 0.7561 - val_accuracy: 0.7674 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7101Epoch 20/40: loss=0.5614, accuracy=0.7101, val_loss=0.5895, val_accuracy=0.7699\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5614 - accuracy: 0.7101 - val_loss: 0.5895 - val_accuracy: 0.7699 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7148Epoch 21/40: loss=0.5647, accuracy=0.7148, val_loss=1.2723, val_accuracy=0.6200\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5647 - accuracy: 0.7148 - val_loss: 1.2723 - val_accuracy: 0.6200 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7136Epoch 22/40: loss=0.5606, accuracy=0.7136, val_loss=0.5486, val_accuracy=0.7624\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5606 - accuracy: 0.7136 - val_loss: 0.5486 - val_accuracy: 0.7624 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.7141Epoch 23/40: loss=0.5577, accuracy=0.7142, val_loss=0.5548, val_accuracy=0.7715\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5577 - accuracy: 0.7142 - val_loss: 0.5548 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5515 - accuracy: 0.7216Epoch 24/40: loss=0.5519, accuracy=0.7214, val_loss=0.5404, val_accuracy=0.7740\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5519 - accuracy: 0.7214 - val_loss: 0.5404 - val_accuracy: 0.7740 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7192Epoch 25/40: loss=0.5499, accuracy=0.7192, val_loss=0.5094, val_accuracy=0.7699\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5499 - accuracy: 0.7192 - val_loss: 0.5094 - val_accuracy: 0.7699 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.7322Epoch 26/40: loss=0.5420, accuracy=0.7322, val_loss=0.7287, val_accuracy=0.7425\n",
      "604/604 [==============================] - 17s 27ms/step - loss: 0.5420 - accuracy: 0.7322 - val_loss: 0.7287 - val_accuracy: 0.7425 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.7324Epoch 27/40: loss=0.5367, accuracy=0.7324, val_loss=0.4663, val_accuracy=0.7873\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5367 - accuracy: 0.7324 - val_loss: 0.4663 - val_accuracy: 0.7873 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7342Epoch 28/40: loss=0.5333, accuracy=0.7347, val_loss=0.5500, val_accuracy=0.7715\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5333 - accuracy: 0.7347 - val_loss: 0.5500 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5350 - accuracy: 0.7316Epoch 29/40: loss=0.5351, accuracy=0.7312, val_loss=0.6893, val_accuracy=0.7401\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5351 - accuracy: 0.7312 - val_loss: 0.6893 - val_accuracy: 0.7401 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.7368Epoch 30/40: loss=0.5290, accuracy=0.7368, val_loss=0.7626, val_accuracy=0.7127\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5290 - accuracy: 0.7368 - val_loss: 0.7626 - val_accuracy: 0.7127 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7411Epoch 31/40: loss=0.5191, accuracy=0.7409, val_loss=0.5630, val_accuracy=0.7715\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5191 - accuracy: 0.7409 - val_loss: 0.5630 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5222 - accuracy: 0.7477\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Epoch 32/40: loss=0.5224, accuracy=0.7475, val_loss=0.9247, val_accuracy=0.5969\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5224 - accuracy: 0.7475 - val_loss: 0.9247 - val_accuracy: 0.5969 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5114 - accuracy: 0.7469Epoch 33/40: loss=0.5114, accuracy=0.7469, val_loss=0.5661, val_accuracy=0.7508\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5114 - accuracy: 0.7469 - val_loss: 0.5661 - val_accuracy: 0.7508 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.7498Epoch 34/40: loss=0.5076, accuracy=0.7498, val_loss=0.7441, val_accuracy=0.7657\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5076 - accuracy: 0.7498 - val_loss: 0.7441 - val_accuracy: 0.7657 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.7465Epoch 35/40: loss=0.5162, accuracy=0.7465, val_loss=0.5806, val_accuracy=0.7599\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5162 - accuracy: 0.7465 - val_loss: 0.5806 - val_accuracy: 0.7599 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5056 - accuracy: 0.7560Epoch 36/40: loss=0.5059, accuracy=0.7556, val_loss=0.4686, val_accuracy=0.8013\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5059 - accuracy: 0.7556 - val_loss: 0.4686 - val_accuracy: 0.8013 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.7571\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 7.99999907030724e-06.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 37/40: loss=0.5010, accuracy=0.7566, val_loss=0.6580, val_accuracy=0.7988\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5010 - accuracy: 0.7566 - val_loss: 0.6580 - val_accuracy: 0.7988 - lr: 4.0000e-05\n",
      "Epoch 37: early stopping\n",
      "Validation accuracy: 0.8013244867324829\n",
      "\n",
      "Initial Training Combination 35/50: num_residual_blocks=5, dropout_rate=0.4, learning_rate=0.01, filters=128, kernel_size=3, num_dense_layers=3, activation_function=tanh, rotation_range=20, width_shift_range=0.4, height_shift_range=0.3, shear_range=0.4, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "  5/604 [..............................] - ETA: 35s - loss: 11.6217 - accuracy: 0.4500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0256s vs `on_train_batch_end` time: 0.0310s). Check your callbacks.\n",
      "602/604 [============================>.] - ETA: 0s - loss: 2.8992 - accuracy: 0.5000Epoch 1/40: loss=2.9028, accuracy=0.4988, val_loss=0.6994, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 2.9028 - accuracy: 0.4988 - val_loss: 0.6994 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 2.0647 - accuracy: 0.4959Epoch 2/40: loss=2.0636, accuracy=0.4961, val_loss=2.0239, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 2.0636 - accuracy: 0.4961 - val_loss: 2.0239 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.3302 - accuracy: 0.5035Epoch 3/40: loss=1.3292, accuracy=0.5033, val_loss=0.6756, val_accuracy=0.5993\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 1.3292 - accuracy: 0.5033 - val_loss: 0.6756 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9687 - accuracy: 0.5062Epoch 4/40: loss=0.9687, accuracy=0.5062, val_loss=0.6988, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9687 - accuracy: 0.5062 - val_loss: 0.6988 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8328 - accuracy: 0.4931Epoch 5/40: loss=0.8329, accuracy=0.4932, val_loss=0.7246, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8329 - accuracy: 0.4932 - val_loss: 0.7246 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7730 - accuracy: 0.4876Epoch 6/40: loss=0.7731, accuracy=0.4876, val_loss=0.6776, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7731 - accuracy: 0.4876 - val_loss: 0.6776 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7447 - accuracy: 0.4996Epoch 7/40: loss=0.7447, accuracy=0.4996, val_loss=0.7036, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7447 - accuracy: 0.4996 - val_loss: 0.7036 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7306 - accuracy: 0.4886\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/40: loss=0.7306, accuracy=0.4884, val_loss=0.7234, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7306 - accuracy: 0.4884 - val_loss: 0.7234 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7017 - accuracy: 0.5021Epoch 9/40: loss=0.7018, accuracy=0.5023, val_loss=0.6828, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7018 - accuracy: 0.5023 - val_loss: 0.6828 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6976 - accuracy: 0.4933Epoch 10/40: loss=0.6980, accuracy=0.4932, val_loss=0.6834, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6980 - accuracy: 0.4932 - val_loss: 0.6834 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.4990Epoch 11/40: loss=0.6971, accuracy=0.4990, val_loss=0.7007, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6971 - accuracy: 0.4990 - val_loss: 0.7007 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6983 - accuracy: 0.4915Epoch 12/40: loss=0.6984, accuracy=0.4917, val_loss=0.6890, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6984 - accuracy: 0.4917 - val_loss: 0.6890 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6983 - accuracy: 0.4950\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 13/40: loss=0.6984, accuracy=0.4946, val_loss=0.6863, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6984 - accuracy: 0.4946 - val_loss: 0.6863 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 13: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 36/50: num_residual_blocks=6, dropout_rate=0.25, learning_rate=0.005, filters=128, kernel_size=3, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.3, height_shift_range=0.4, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.7127 - accuracy: 0.4925Epoch 1/40: loss=1.7102, accuracy=0.4932, val_loss=3.4431, val_accuracy=0.4023\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 1.7102 - accuracy: 0.4932 - val_loss: 3.4431 - val_accuracy: 0.4023 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.4040 - accuracy: 0.5150Epoch 2/40: loss=1.4006, accuracy=0.5159, val_loss=2.9844, val_accuracy=0.4031\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.4006 - accuracy: 0.5159 - val_loss: 2.9844 - val_accuracy: 0.4031 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2344 - accuracy: 0.5158Epoch 3/40: loss=1.2336, accuracy=0.5159, val_loss=0.8470, val_accuracy=0.5770\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 1.2336 - accuracy: 0.5159 - val_loss: 0.8470 - val_accuracy: 0.5770 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1022 - accuracy: 0.5145Epoch 4/40: loss=1.1014, accuracy=0.5151, val_loss=0.6822, val_accuracy=0.6432\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 1.1014 - accuracy: 0.5151 - val_loss: 0.6822 - val_accuracy: 0.6432 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5376Epoch 5/40: loss=0.9807, accuracy=0.5377, val_loss=0.8739, val_accuracy=0.5290\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.9807 - accuracy: 0.5377 - val_loss: 0.8739 - val_accuracy: 0.5290 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8855 - accuracy: 0.5232Epoch 6/40: loss=0.8858, accuracy=0.5230, val_loss=0.7603, val_accuracy=0.5522\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8858 - accuracy: 0.5230 - val_loss: 0.7603 - val_accuracy: 0.5522 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8242 - accuracy: 0.5380Epoch 7/40: loss=0.8235, accuracy=0.5381, val_loss=0.6144, val_accuracy=0.6705\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8235 - accuracy: 0.5381 - val_loss: 0.6144 - val_accuracy: 0.6705 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7482 - accuracy: 0.5763Epoch 8/40: loss=0.7481, accuracy=0.5764, val_loss=1.2867, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7481 - accuracy: 0.5764 - val_loss: 1.2867 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.6327Epoch 9/40: loss=0.6771, accuracy=0.6327, val_loss=0.5301, val_accuracy=0.7094\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.6771 - accuracy: 0.6327 - val_loss: 0.5301 - val_accuracy: 0.7094 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6347 - accuracy: 0.6519Epoch 10/40: loss=0.6344, accuracy=0.6521, val_loss=0.6218, val_accuracy=0.6465\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6344 - accuracy: 0.6521 - val_loss: 0.6218 - val_accuracy: 0.6465 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.6869Epoch 11/40: loss=0.5991, accuracy=0.6869, val_loss=0.7345, val_accuracy=0.5654\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5991 - accuracy: 0.6869 - val_loss: 0.7345 - val_accuracy: 0.5654 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5899 - accuracy: 0.6952Epoch 12/40: loss=0.5899, accuracy=0.6952, val_loss=1.3464, val_accuracy=0.6921\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5899 - accuracy: 0.6952 - val_loss: 1.3464 - val_accuracy: 0.6921 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5748 - accuracy: 0.7083Epoch 13/40: loss=0.5750, accuracy=0.7080, val_loss=6.8364, val_accuracy=0.6068\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5750 - accuracy: 0.7080 - val_loss: 6.8364 - val_accuracy: 0.6068 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5739 - accuracy: 0.7078\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 14/40: loss=0.5746, accuracy=0.7072, val_loss=0.9780, val_accuracy=0.7359\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5746 - accuracy: 0.7072 - val_loss: 0.9780 - val_accuracy: 0.7359 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.7220Epoch 15/40: loss=0.5582, accuracy=0.7219, val_loss=2.4397, val_accuracy=0.7599\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5582 - accuracy: 0.7219 - val_loss: 2.4397 - val_accuracy: 0.7599 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.7409Epoch 16/40: loss=0.5346, accuracy=0.7409, val_loss=0.6135, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5346 - accuracy: 0.7409 - val_loss: 0.6135 - val_accuracy: 0.7318 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.7419Epoch 17/40: loss=0.5367, accuracy=0.7421, val_loss=0.6914, val_accuracy=0.7632\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5367 - accuracy: 0.7421 - val_loss: 0.6914 - val_accuracy: 0.7632 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.7404Epoch 18/40: loss=0.5338, accuracy=0.7409, val_loss=0.6856, val_accuracy=0.6614\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5338 - accuracy: 0.7409 - val_loss: 0.6856 - val_accuracy: 0.6614 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7351\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19/40: loss=0.5413, accuracy=0.7351, val_loss=8.6804, val_accuracy=0.6796\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5413 - accuracy: 0.7351 - val_loss: 8.6804 - val_accuracy: 0.6796 - lr: 1.0000e-03\n",
      "Epoch 19: early stopping\n",
      "Validation accuracy: 0.7632450461387634\n",
      "\n",
      "Initial Training Combination 37/50: num_residual_blocks=6, dropout_rate=0.45, learning_rate=0.005, filters=128, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=40, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.4, zoom_range=0.4, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.5110 - accuracy: 0.5015Epoch 1/40: loss=1.5101, accuracy=0.5017, val_loss=0.8910, val_accuracy=0.5836\n",
      "604/604 [==============================] - 23s 33ms/step - loss: 1.5101 - accuracy: 0.5017 - val_loss: 0.8910 - val_accuracy: 0.5836 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2065 - accuracy: 0.5081Epoch 2/40: loss=1.2059, accuracy=0.5081, val_loss=0.8755, val_accuracy=0.4950\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 1.2059 - accuracy: 0.5081 - val_loss: 0.8755 - val_accuracy: 0.4950 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.4994Epoch 3/40: loss=1.0440, accuracy=0.4994, val_loss=0.7382, val_accuracy=0.5753\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 1.0440 - accuracy: 0.4994 - val_loss: 0.7382 - val_accuracy: 0.5753 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9341 - accuracy: 0.5130Epoch 4/40: loss=0.9341, accuracy=0.5130, val_loss=0.6683, val_accuracy=0.5952\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.9341 - accuracy: 0.5130 - val_loss: 0.6683 - val_accuracy: 0.5952 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.5414Epoch 5/40: loss=0.8281, accuracy=0.5414, val_loss=17.5483, val_accuracy=0.3783\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.8281 - accuracy: 0.5414 - val_loss: 17.5483 - val_accuracy: 0.3783 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.6447Epoch 6/40: loss=0.6830, accuracy=0.6447, val_loss=1.0722, val_accuracy=0.7243\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6830 - accuracy: 0.6447 - val_loss: 1.0722 - val_accuracy: 0.7243 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6495 - accuracy: 0.6618Epoch 7/40: loss=0.6493, accuracy=0.6614, val_loss=0.8608, val_accuracy=0.4776\n",
      "604/604 [==============================] - 17s 27ms/step - loss: 0.6493 - accuracy: 0.6614 - val_loss: 0.8608 - val_accuracy: 0.4776 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6362 - accuracy: 0.6772Epoch 8/40: loss=0.6361, accuracy=0.6772, val_loss=0.8480, val_accuracy=0.5497\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6361 - accuracy: 0.6772 - val_loss: 0.8480 - val_accuracy: 0.5497 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.6815Epoch 9/40: loss=0.6101, accuracy=0.6815, val_loss=0.5055, val_accuracy=0.7467\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6101 - accuracy: 0.6815 - val_loss: 0.5055 - val_accuracy: 0.7467 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.6872Epoch 10/40: loss=0.6025, accuracy=0.6873, val_loss=0.5397, val_accuracy=0.7533\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6025 - accuracy: 0.6873 - val_loss: 0.5397 - val_accuracy: 0.7533 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.6889Epoch 11/40: loss=0.6012, accuracy=0.6889, val_loss=1.4434, val_accuracy=0.4172\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6012 - accuracy: 0.6889 - val_loss: 1.4434 - val_accuracy: 0.4172 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.6498Epoch 12/40: loss=0.6211, accuracy=0.6498, val_loss=0.9715, val_accuracy=0.5935\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6211 - accuracy: 0.6498 - val_loss: 0.9715 - val_accuracy: 0.5935 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6219 - accuracy: 0.6681Epoch 13/40: loss=0.6219, accuracy=0.6683, val_loss=0.9120, val_accuracy=0.4197\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.6219 - accuracy: 0.6683 - val_loss: 0.9120 - val_accuracy: 0.4197 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.6900\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 14/40: loss=0.5959, accuracy=0.6900, val_loss=0.5242, val_accuracy=0.7459\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5959 - accuracy: 0.6900 - val_loss: 0.5242 - val_accuracy: 0.7459 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.6871Epoch 15/40: loss=0.5944, accuracy=0.6871, val_loss=0.7102, val_accuracy=0.5778\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5944 - accuracy: 0.6871 - val_loss: 0.7102 - val_accuracy: 0.5778 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5640 - accuracy: 0.7158Epoch 16/40: loss=0.5640, accuracy=0.7156, val_loss=0.5093, val_accuracy=0.7666\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5640 - accuracy: 0.7156 - val_loss: 0.5093 - val_accuracy: 0.7666 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.7163Epoch 17/40: loss=0.5590, accuracy=0.7163, val_loss=0.5394, val_accuracy=0.7276\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5590 - accuracy: 0.7163 - val_loss: 0.5394 - val_accuracy: 0.7276 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7237Epoch 18/40: loss=0.5574, accuracy=0.7237, val_loss=0.8200, val_accuracy=0.6465\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5574 - accuracy: 0.7237 - val_loss: 0.8200 - val_accuracy: 0.6465 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7224\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19/40: loss=0.5500, accuracy=0.7225, val_loss=0.5822, val_accuracy=0.7194\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5500 - accuracy: 0.7225 - val_loss: 0.5822 - val_accuracy: 0.7194 - lr: 1.0000e-03\n",
      "Epoch 19: early stopping\n",
      "Validation accuracy: 0.7665562629699707\n",
      "\n",
      "Initial Training Combination 38/50: num_residual_blocks=6, dropout_rate=0.35, learning_rate=1e-05, filters=32, kernel_size=5, num_dense_layers=2, activation_function=tanh, rotation_range=40, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.5114Epoch 1/40: loss=0.9802, accuracy=0.5106, val_loss=0.6840, val_accuracy=0.5563\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.9802 - accuracy: 0.5106 - val_loss: 0.6840 - val_accuracy: 0.5563 - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.4925Epoch 2/40: loss=0.9826, accuracy=0.4925, val_loss=0.7394, val_accuracy=0.5902\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9826 - accuracy: 0.4925 - val_loss: 0.7394 - val_accuracy: 0.5902 - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.5257Epoch 3/40: loss=0.9350, accuracy=0.5252, val_loss=0.6959, val_accuracy=0.5820\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.9350 - accuracy: 0.5252 - val_loss: 0.6959 - val_accuracy: 0.5820 - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.5374Epoch 4/40: loss=0.9169, accuracy=0.5377, val_loss=0.6740, val_accuracy=0.6275\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9169 - accuracy: 0.5377 - val_loss: 0.6740 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8559 - accuracy: 0.5594Epoch 5/40: loss=0.8562, accuracy=0.5594, val_loss=0.7449, val_accuracy=0.5960\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8562 - accuracy: 0.5594 - val_loss: 0.7449 - val_accuracy: 0.5960 - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8331 - accuracy: 0.5815Epoch 6/40: loss=0.8331, accuracy=0.5815, val_loss=0.7044, val_accuracy=0.6531\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8331 - accuracy: 0.5815 - val_loss: 0.7044 - val_accuracy: 0.6531 - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.5679Epoch 7/40: loss=0.8463, accuracy=0.5679, val_loss=0.6525, val_accuracy=0.6829\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8463 - accuracy: 0.5679 - val_loss: 0.6525 - val_accuracy: 0.6829 - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8043 - accuracy: 0.5984Epoch 8/40: loss=0.8037, accuracy=0.5981, val_loss=0.5970, val_accuracy=0.7169\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8037 - accuracy: 0.5981 - val_loss: 0.5970 - val_accuracy: 0.7169 - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7854 - accuracy: 0.6134Epoch 9/40: loss=0.7859, accuracy=0.6130, val_loss=0.6913, val_accuracy=0.6738\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7859 - accuracy: 0.6130 - val_loss: 0.6913 - val_accuracy: 0.6738 - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7604 - accuracy: 0.6273Epoch 10/40: loss=0.7604, accuracy=0.6271, val_loss=0.5448, val_accuracy=0.7260\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7604 - accuracy: 0.6271 - val_loss: 0.5448 - val_accuracy: 0.7260 - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7658 - accuracy: 0.6209Epoch 11/40: loss=0.7658, accuracy=0.6209, val_loss=0.6290, val_accuracy=0.7194\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7658 - accuracy: 0.6209 - val_loss: 0.6290 - val_accuracy: 0.7194 - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.6434Epoch 12/40: loss=0.7449, accuracy=0.6432, val_loss=0.6405, val_accuracy=0.7028\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7449 - accuracy: 0.6432 - val_loss: 0.6405 - val_accuracy: 0.7028 - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7408 - accuracy: 0.6364Epoch 13/40: loss=0.7402, accuracy=0.6370, val_loss=0.6370, val_accuracy=0.7127\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7402 - accuracy: 0.6370 - val_loss: 0.6370 - val_accuracy: 0.7127 - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7390 - accuracy: 0.6385Epoch 14/40: loss=0.7393, accuracy=0.6387, val_loss=0.6059, val_accuracy=0.7227\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7393 - accuracy: 0.6387 - val_loss: 0.6059 - val_accuracy: 0.7227 - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.6430\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 15/40: loss=0.7288, accuracy=0.6430, val_loss=0.6449, val_accuracy=0.7086\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7288 - accuracy: 0.6430 - val_loss: 0.6449 - val_accuracy: 0.7086 - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7269 - accuracy: 0.6491Epoch 16/40: loss=0.7262, accuracy=0.6494, val_loss=0.5576, val_accuracy=0.7434\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7262 - accuracy: 0.6494 - val_loss: 0.5576 - val_accuracy: 0.7434 - lr: 2.0000e-06\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.6491Epoch 17/40: loss=0.7101, accuracy=0.6492, val_loss=0.6520, val_accuracy=0.7161\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7101 - accuracy: 0.6492 - val_loss: 0.6520 - val_accuracy: 0.7161 - lr: 2.0000e-06\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7167 - accuracy: 0.6521Epoch 18/40: loss=0.7167, accuracy=0.6521, val_loss=0.5766, val_accuracy=0.7401\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7167 - accuracy: 0.6521 - val_loss: 0.5766 - val_accuracy: 0.7401 - lr: 2.0000e-06\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7161 - accuracy: 0.6449Epoch 19/40: loss=0.7162, accuracy=0.6445, val_loss=0.5706, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7162 - accuracy: 0.6445 - val_loss: 0.5706 - val_accuracy: 0.7459 - lr: 2.0000e-06\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.6573\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 20/40: loss=0.6934, accuracy=0.6573, val_loss=0.6096, val_accuracy=0.7276\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6934 - accuracy: 0.6573 - val_loss: 0.6096 - val_accuracy: 0.7276 - lr: 2.0000e-06\n",
      "Epoch 20: early stopping\n",
      "Validation accuracy: 0.7458609342575073\n",
      "\n",
      "Initial Training Combination 39/50: num_residual_blocks=6, dropout_rate=0.6, learning_rate=0.001, filters=32, kernel_size=7, num_dense_layers=3, activation_function=relu, rotation_range=30, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.3, zoom_range=0.4, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0910 - accuracy: 0.4994Epoch 1/40: loss=1.0910, accuracy=0.4994, val_loss=0.7973, val_accuracy=0.4272\n",
      "604/604 [==============================] - 15s 19ms/step - loss: 1.0910 - accuracy: 0.4994 - val_loss: 0.7973 - val_accuracy: 0.4272 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8872 - accuracy: 0.4923Epoch 2/40: loss=0.8866, accuracy=0.4925, val_loss=0.7369, val_accuracy=0.5215\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8866 - accuracy: 0.4925 - val_loss: 0.7369 - val_accuracy: 0.5215 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.4880Epoch 3/40: loss=0.8865, accuracy=0.4880, val_loss=0.6767, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8865 - accuracy: 0.4880 - val_loss: 0.6767 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.4967Epoch 4/40: loss=0.8861, accuracy=0.4967, val_loss=1.1346, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8861 - accuracy: 0.4967 - val_loss: 1.1346 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8846 - accuracy: 0.4957Epoch 5/40: loss=0.8846, accuracy=0.4957, val_loss=1.0468, val_accuracy=0.4437\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8846 - accuracy: 0.4957 - val_loss: 1.0468 - val_accuracy: 0.4437 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8658 - accuracy: 0.5139Epoch 6/40: loss=0.8658, accuracy=0.5139, val_loss=0.7105, val_accuracy=0.5960\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8658 - accuracy: 0.5139 - val_loss: 0.7105 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.5120Epoch 7/40: loss=0.8584, accuracy=0.5120, val_loss=1.6939, val_accuracy=0.5927\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8584 - accuracy: 0.5120 - val_loss: 1.6939 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8402 - accuracy: 0.5195\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.8402, accuracy=0.5195, val_loss=3.7603, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8402 - accuracy: 0.5195 - val_loss: 3.7603 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8263 - accuracy: 0.4896Epoch 9/40: loss=0.8261, accuracy=0.4899, val_loss=0.7437, val_accuracy=0.5960\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8261 - accuracy: 0.4899 - val_loss: 0.7437 - val_accuracy: 0.5960 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.5039Epoch 10/40: loss=0.8012, accuracy=0.5039, val_loss=0.9039, val_accuracy=0.5579\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8012 - accuracy: 0.5039 - val_loss: 0.9039 - val_accuracy: 0.5579 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7760 - accuracy: 0.4959Epoch 11/40: loss=0.7765, accuracy=0.4957, val_loss=0.7427, val_accuracy=0.4818\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7765 - accuracy: 0.4957 - val_loss: 0.7427 - val_accuracy: 0.4818 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.4942Epoch 12/40: loss=0.7592, accuracy=0.4942, val_loss=1.0402, val_accuracy=0.5116\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7592 - accuracy: 0.4942 - val_loss: 1.0402 - val_accuracy: 0.5116 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7434 - accuracy: 0.5068\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 13/40: loss=0.7435, accuracy=0.5062, val_loss=0.7053, val_accuracy=0.5770\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7435 - accuracy: 0.5062 - val_loss: 0.7053 - val_accuracy: 0.5770 - lr: 2.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Validation accuracy: 0.5985099077224731\n",
      "\n",
      "Initial Training Combination 40/50: num_residual_blocks=6, dropout_rate=0.6, learning_rate=0.001, filters=64, kernel_size=7, num_dense_layers=2, activation_function=relu, rotation_range=10, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.3, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0704 - accuracy: 0.4983Epoch 1/40: loss=1.0704, accuracy=0.4983, val_loss=1.7289, val_accuracy=0.6101\n",
      "604/604 [==============================] - 18s 27ms/step - loss: 1.0704 - accuracy: 0.4983 - val_loss: 1.7289 - val_accuracy: 0.6101 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8818 - accuracy: 0.5044Epoch 2/40: loss=0.8818, accuracy=0.5043, val_loss=5.1332, val_accuracy=0.5952\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8818 - accuracy: 0.5043 - val_loss: 5.1332 - val_accuracy: 0.5952 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8924 - accuracy: 0.4849Epoch 3/40: loss=0.8919, accuracy=0.4855, val_loss=0.8635, val_accuracy=0.5621\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8919 - accuracy: 0.4855 - val_loss: 0.8635 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8545 - accuracy: 0.5044Epoch 4/40: loss=0.8545, accuracy=0.5043, val_loss=0.8140, val_accuracy=0.5563\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.8545 - accuracy: 0.5043 - val_loss: 0.8140 - val_accuracy: 0.5563 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8454 - accuracy: 0.5012Epoch 5/40: loss=0.8453, accuracy=0.5008, val_loss=0.7180, val_accuracy=0.5447\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8453 - accuracy: 0.5008 - val_loss: 0.7180 - val_accuracy: 0.5447 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8285 - accuracy: 0.4963Epoch 6/40: loss=0.8287, accuracy=0.4961, val_loss=1.0729, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8287 - accuracy: 0.4961 - val_loss: 1.0729 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8100 - accuracy: 0.5039Epoch 7/40: loss=0.8100, accuracy=0.5039, val_loss=0.8597, val_accuracy=0.5820\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.8100 - accuracy: 0.5039 - val_loss: 0.8597 - val_accuracy: 0.5820 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7995 - accuracy: 0.5052Epoch 8/40: loss=0.7998, accuracy=0.5052, val_loss=0.7192, val_accuracy=0.4354\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7998 - accuracy: 0.5052 - val_loss: 0.7192 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8048 - accuracy: 0.4934Epoch 9/40: loss=0.8048, accuracy=0.4934, val_loss=1.1663, val_accuracy=0.4876\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.8048 - accuracy: 0.4934 - val_loss: 1.1663 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7888 - accuracy: 0.5100\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.7887, accuracy=0.5099, val_loss=3.1886, val_accuracy=0.5803\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7887 - accuracy: 0.5099 - val_loss: 3.1886 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7808 - accuracy: 0.5010Epoch 11/40: loss=0.7808, accuracy=0.5008, val_loss=0.8888, val_accuracy=0.5174\n",
      "604/604 [==============================] - 15s 26ms/step - loss: 0.7808 - accuracy: 0.5008 - val_loss: 0.8888 - val_accuracy: 0.5174 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.5112Epoch 12/40: loss=0.7465, accuracy=0.5112, val_loss=0.6972, val_accuracy=0.5017\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7465 - accuracy: 0.5112 - val_loss: 0.6972 - val_accuracy: 0.5017 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.5170Epoch 13/40: loss=0.7280, accuracy=0.5170, val_loss=0.7196, val_accuracy=0.5281\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7280 - accuracy: 0.5170 - val_loss: 0.7196 - val_accuracy: 0.5281 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.5096Epoch 14/40: loss=0.7217, accuracy=0.5112, val_loss=0.6777, val_accuracy=0.5414\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.7217 - accuracy: 0.5112 - val_loss: 0.6777 - val_accuracy: 0.5414 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7080 - accuracy: 0.5346Epoch 15/40: loss=0.7078, accuracy=0.5354, val_loss=0.8882, val_accuracy=0.4031\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7078 - accuracy: 0.5354 - val_loss: 0.8882 - val_accuracy: 0.4031 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6487 - accuracy: 0.6254Epoch 16/40: loss=0.6485, accuracy=0.6254, val_loss=0.7055, val_accuracy=0.7293\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6485 - accuracy: 0.6254 - val_loss: 0.7055 - val_accuracy: 0.7293 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5994 - accuracy: 0.6906Epoch 17/40: loss=0.5999, accuracy=0.6904, val_loss=0.5732, val_accuracy=0.7260\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5999 - accuracy: 0.6904 - val_loss: 0.5732 - val_accuracy: 0.7260 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.6952Epoch 18/40: loss=0.5892, accuracy=0.6954, val_loss=0.6563, val_accuracy=0.6714\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5892 - accuracy: 0.6954 - val_loss: 0.6563 - val_accuracy: 0.6714 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5818 - accuracy: 0.7076Epoch 19/40: loss=0.5827, accuracy=0.7067, val_loss=1.6434, val_accuracy=0.7243\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5827 - accuracy: 0.7067 - val_loss: 1.6434 - val_accuracy: 0.7243 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.6999Epoch 20/40: loss=0.5938, accuracy=0.6999, val_loss=0.9807, val_accuracy=0.5207\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5938 - accuracy: 0.6999 - val_loss: 0.9807 - val_accuracy: 0.5207 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.7038Epoch 21/40: loss=0.5805, accuracy=0.7038, val_loss=0.8375, val_accuracy=0.5786\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5805 - accuracy: 0.7038 - val_loss: 0.8375 - val_accuracy: 0.5786 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.6983\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 22/40: loss=0.5798, accuracy=0.6983, val_loss=1.0693, val_accuracy=0.4387\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5798 - accuracy: 0.6983 - val_loss: 1.0693 - val_accuracy: 0.4387 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5583 - accuracy: 0.7191Epoch 23/40: loss=0.5584, accuracy=0.7190, val_loss=0.7745, val_accuracy=0.6424\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5584 - accuracy: 0.7190 - val_loss: 0.7745 - val_accuracy: 0.6424 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.7092Epoch 24/40: loss=0.5659, accuracy=0.7092, val_loss=0.5767, val_accuracy=0.7351\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5659 - accuracy: 0.7092 - val_loss: 0.5767 - val_accuracy: 0.7351 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7171Epoch 25/40: loss=0.5671, accuracy=0.7171, val_loss=0.5155, val_accuracy=0.7823\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5671 - accuracy: 0.7171 - val_loss: 0.5155 - val_accuracy: 0.7823 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7286Epoch 26/40: loss=0.5505, accuracy=0.7281, val_loss=0.5340, val_accuracy=0.7831\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5505 - accuracy: 0.7281 - val_loss: 0.5340 - val_accuracy: 0.7831 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7239Epoch 27/40: loss=0.5509, accuracy=0.7239, val_loss=0.6692, val_accuracy=0.6755\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5509 - accuracy: 0.7239 - val_loss: 0.6692 - val_accuracy: 0.6755 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.7175Epoch 28/40: loss=0.5553, accuracy=0.7177, val_loss=0.5704, val_accuracy=0.7864\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5553 - accuracy: 0.7177 - val_loss: 0.5704 - val_accuracy: 0.7864 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7232Epoch 29/40: loss=0.5574, accuracy=0.7237, val_loss=0.7233, val_accuracy=0.6465\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5574 - accuracy: 0.7237 - val_loss: 0.7233 - val_accuracy: 0.6465 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5519 - accuracy: 0.7249\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 30/40: loss=0.5523, accuracy=0.7245, val_loss=0.5297, val_accuracy=0.7707\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5523 - accuracy: 0.7245 - val_loss: 0.5297 - val_accuracy: 0.7707 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.7274Epoch 31/40: loss=0.5473, accuracy=0.7268, val_loss=0.5202, val_accuracy=0.7724\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5473 - accuracy: 0.7268 - val_loss: 0.5202 - val_accuracy: 0.7724 - lr: 8.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5530 - accuracy: 0.7209Epoch 32/40: loss=0.5527, accuracy=0.7210, val_loss=0.6094, val_accuracy=0.7144\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5527 - accuracy: 0.7210 - val_loss: 0.6094 - val_accuracy: 0.7144 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7263Epoch 33/40: loss=0.5483, accuracy=0.7264, val_loss=0.5702, val_accuracy=0.7351\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5483 - accuracy: 0.7264 - val_loss: 0.5702 - val_accuracy: 0.7351 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5491 - accuracy: 0.7297Epoch 34/40: loss=0.5487, accuracy=0.7301, val_loss=0.5522, val_accuracy=0.7475\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5487 - accuracy: 0.7301 - val_loss: 0.5522 - val_accuracy: 0.7475 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.7280\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 35/40: loss=0.5409, accuracy=0.7283, val_loss=0.5568, val_accuracy=0.7550\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5409 - accuracy: 0.7283 - val_loss: 0.5568 - val_accuracy: 0.7550 - lr: 8.0000e-06\n",
      "Epoch 35: early stopping\n",
      "Validation accuracy: 0.7864238619804382\n",
      "\n",
      "Initial Training Combination 41/50: num_residual_blocks=4, dropout_rate=0.35, learning_rate=0.005, filters=64, kernel_size=3, num_dense_layers=3, activation_function=relu, rotation_range=40, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "  6/604 [..............................] - ETA: 29s - loss: 3.4269 - accuracy: 0.5208WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.0328s). Check your callbacks.\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.8726 - accuracy: 0.5160Epoch 1/40: loss=1.8707, accuracy=0.5161, val_loss=17.1917, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 24ms/step - loss: 1.8707 - accuracy: 0.5161 - val_loss: 17.1917 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.4541 - accuracy: 0.5050Epoch 2/40: loss=1.4541, accuracy=0.5050, val_loss=1.2654, val_accuracy=0.4272\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 1.4541 - accuracy: 0.5050 - val_loss: 1.2654 - val_accuracy: 0.4272 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2599 - accuracy: 0.5043Epoch 3/40: loss=1.2599, accuracy=0.5043, val_loss=25.5760, val_accuracy=0.5935\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.2599 - accuracy: 0.5043 - val_loss: 25.5760 - val_accuracy: 0.5935 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1065 - accuracy: 0.5017Epoch 4/40: loss=1.1069, accuracy=0.5019, val_loss=6.1565, val_accuracy=0.4313\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 1.1069 - accuracy: 0.5019 - val_loss: 6.1565 - val_accuracy: 0.4313 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9806 - accuracy: 0.5146Epoch 5/40: loss=0.9824, accuracy=0.5143, val_loss=5.3166, val_accuracy=0.5803\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9824 - accuracy: 0.5143 - val_loss: 5.3166 - val_accuracy: 0.5803 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9626 - accuracy: 0.4816Epoch 6/40: loss=0.9626, accuracy=0.4816, val_loss=0.8326, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9626 - accuracy: 0.4816 - val_loss: 0.8326 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8294 - accuracy: 0.4975Epoch 7/40: loss=0.8291, accuracy=0.4977, val_loss=0.8658, val_accuracy=0.4578\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8291 - accuracy: 0.4977 - val_loss: 0.8658 - val_accuracy: 0.4578 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7681 - accuracy: 0.5491Epoch 8/40: loss=0.7681, accuracy=0.5490, val_loss=5.6372, val_accuracy=0.5430\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7681 - accuracy: 0.5490 - val_loss: 5.6372 - val_accuracy: 0.5430 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.5515Epoch 9/40: loss=0.7291, accuracy=0.5515, val_loss=0.8770, val_accuracy=0.5505\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7291 - accuracy: 0.5515 - val_loss: 0.8770 - val_accuracy: 0.5505 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7084 - accuracy: 0.5617Epoch 10/40: loss=0.7089, accuracy=0.5613, val_loss=0.6233, val_accuracy=0.6507\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7089 - accuracy: 0.5613 - val_loss: 0.6233 - val_accuracy: 0.6507 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6816 - accuracy: 0.5763Epoch 11/40: loss=0.6816, accuracy=0.5760, val_loss=1.8664, val_accuracy=0.4222\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6816 - accuracy: 0.5760 - val_loss: 1.8664 - val_accuracy: 0.4222 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.6061Epoch 12/40: loss=0.6625, accuracy=0.6066, val_loss=0.6657, val_accuracy=0.6548\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6625 - accuracy: 0.6066 - val_loss: 0.6657 - val_accuracy: 0.6548 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6544Epoch 13/40: loss=0.6259, accuracy=0.6544, val_loss=6646.3667, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6259 - accuracy: 0.6544 - val_loss: 6646.3667 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6402 - accuracy: 0.6391Epoch 14/40: loss=0.6403, accuracy=0.6389, val_loss=1.5011, val_accuracy=0.6573\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6403 - accuracy: 0.6389 - val_loss: 1.5011 - val_accuracy: 0.6573 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.6138\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 15/40: loss=0.6579, accuracy=0.6142, val_loss=0.9410, val_accuracy=0.6680\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6579 - accuracy: 0.6142 - val_loss: 0.9410 - val_accuracy: 0.6680 - lr: 0.0050\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6143 - accuracy: 0.6681Epoch 16/40: loss=0.6147, accuracy=0.6676, val_loss=0.9482, val_accuracy=0.7094\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6147 - accuracy: 0.6676 - val_loss: 0.9482 - val_accuracy: 0.7094 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5977 - accuracy: 0.6828Epoch 17/40: loss=0.5978, accuracy=0.6827, val_loss=0.6914, val_accuracy=0.7425\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5978 - accuracy: 0.6827 - val_loss: 0.6914 - val_accuracy: 0.7425 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.6786Epoch 18/40: loss=0.5971, accuracy=0.6794, val_loss=0.8231, val_accuracy=0.7119\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5971 - accuracy: 0.6794 - val_loss: 0.8231 - val_accuracy: 0.7119 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.6925Epoch 19/40: loss=0.5801, accuracy=0.6925, val_loss=0.8550, val_accuracy=0.7425\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5801 - accuracy: 0.6925 - val_loss: 0.8550 - val_accuracy: 0.7425 - lr: 1.0000e-03\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5733 - accuracy: 0.6995Epoch 20/40: loss=0.5735, accuracy=0.6991, val_loss=0.5477, val_accuracy=0.7483\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5735 - accuracy: 0.6991 - val_loss: 0.5477 - val_accuracy: 0.7483 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7069Epoch 21/40: loss=0.5640, accuracy=0.7067, val_loss=0.5806, val_accuracy=0.7045\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5640 - accuracy: 0.7067 - val_loss: 0.5806 - val_accuracy: 0.7045 - lr: 1.0000e-03\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.7143Epoch 22/40: loss=0.5577, accuracy=0.7144, val_loss=1.3797, val_accuracy=0.5919\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5577 - accuracy: 0.7144 - val_loss: 1.3797 - val_accuracy: 0.5919 - lr: 1.0000e-03\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.7218Epoch 23/40: loss=0.5586, accuracy=0.7214, val_loss=1.2120, val_accuracy=0.6142\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5586 - accuracy: 0.7214 - val_loss: 1.2120 - val_accuracy: 0.6142 - lr: 1.0000e-03\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7312Epoch 24/40: loss=0.5492, accuracy=0.7312, val_loss=0.4986, val_accuracy=0.7757\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5492 - accuracy: 0.7312 - val_loss: 0.4986 - val_accuracy: 0.7757 - lr: 1.0000e-03\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.7421Epoch 25/40: loss=0.5404, accuracy=0.7421, val_loss=1.0085, val_accuracy=0.5488\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5404 - accuracy: 0.7421 - val_loss: 1.0085 - val_accuracy: 0.5488 - lr: 1.0000e-03\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.7231Epoch 26/40: loss=0.5472, accuracy=0.7231, val_loss=1.2403, val_accuracy=0.5141\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5472 - accuracy: 0.7231 - val_loss: 1.2403 - val_accuracy: 0.5141 - lr: 1.0000e-03\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7173Epoch 27/40: loss=0.5488, accuracy=0.7173, val_loss=0.5815, val_accuracy=0.7575\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5488 - accuracy: 0.7173 - val_loss: 0.5815 - val_accuracy: 0.7575 - lr: 1.0000e-03\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5340 - accuracy: 0.7367Epoch 28/40: loss=0.5341, accuracy=0.7365, val_loss=0.8585, val_accuracy=0.7757\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5341 - accuracy: 0.7365 - val_loss: 0.8585 - val_accuracy: 0.7757 - lr: 1.0000e-03\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5532 - accuracy: 0.7300\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 29/40: loss=0.5537, accuracy=0.7299, val_loss=0.6083, val_accuracy=0.7707\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5537 - accuracy: 0.7299 - val_loss: 0.6083 - val_accuracy: 0.7707 - lr: 1.0000e-03\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.7527Epoch 30/40: loss=0.5201, accuracy=0.7531, val_loss=0.4800, val_accuracy=0.8013\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5201 - accuracy: 0.7531 - val_loss: 0.4800 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7411Epoch 31/40: loss=0.5318, accuracy=0.7411, val_loss=0.4947, val_accuracy=0.7997\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5318 - accuracy: 0.7411 - val_loss: 0.4947 - val_accuracy: 0.7997 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7469Epoch 32/40: loss=0.5279, accuracy=0.7465, val_loss=0.5226, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5279 - accuracy: 0.7465 - val_loss: 0.5226 - val_accuracy: 0.7889 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7467Epoch 33/40: loss=0.5215, accuracy=0.7467, val_loss=0.4763, val_accuracy=0.7980\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5215 - accuracy: 0.7467 - val_loss: 0.4763 - val_accuracy: 0.7980 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.7548Epoch 34/40: loss=0.5154, accuracy=0.7543, val_loss=0.4770, val_accuracy=0.7997\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5154 - accuracy: 0.7543 - val_loss: 0.4770 - val_accuracy: 0.7997 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5202 - accuracy: 0.7488Epoch 35/40: loss=0.5203, accuracy=0.7492, val_loss=0.4454, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5203 - accuracy: 0.7492 - val_loss: 0.4454 - val_accuracy: 0.8079 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7475Epoch 36/40: loss=0.5198, accuracy=0.7473, val_loss=0.4572, val_accuracy=0.7997\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5198 - accuracy: 0.7473 - val_loss: 0.4572 - val_accuracy: 0.7997 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.7477Epoch 37/40: loss=0.5233, accuracy=0.7475, val_loss=0.5003, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5233 - accuracy: 0.7475 - val_loss: 0.5003 - val_accuracy: 0.7740 - lr: 2.0000e-04\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.7382Epoch 38/40: loss=0.5303, accuracy=0.7384, val_loss=0.4542, val_accuracy=0.8154\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5303 - accuracy: 0.7384 - val_loss: 0.4542 - val_accuracy: 0.8154 - lr: 2.0000e-04\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5166 - accuracy: 0.7473Epoch 39/40: loss=0.5161, accuracy=0.7477, val_loss=0.4663, val_accuracy=0.8005\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5161 - accuracy: 0.7477 - val_loss: 0.4663 - val_accuracy: 0.8005 - lr: 2.0000e-04\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5186 - accuracy: 0.7436\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Epoch 40/40: loss=0.5189, accuracy=0.7438, val_loss=0.4530, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5189 - accuracy: 0.7438 - val_loss: 0.4530 - val_accuracy: 0.8104 - lr: 2.0000e-04\n",
      "Validation accuracy: 0.815397322177887\n",
      "\n",
      "Initial Training Combination 42/50: num_residual_blocks=6, dropout_rate=0.3, learning_rate=0.001, filters=64, kernel_size=3, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.1, height_shift_range=0.3, shear_range=0.4, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0626 - accuracy: 0.5594Epoch 1/40: loss=1.0626, accuracy=0.5594, val_loss=1.7596, val_accuracy=0.5207\n",
      "604/604 [==============================] - 18s 26ms/step - loss: 1.0626 - accuracy: 0.5594 - val_loss: 1.7596 - val_accuracy: 0.5207 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7671 - accuracy: 0.6169Epoch 2/40: loss=0.7662, accuracy=0.6175, val_loss=1.2378, val_accuracy=0.5563\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7662 - accuracy: 0.6175 - val_loss: 1.2378 - val_accuracy: 0.5563 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7389 - accuracy: 0.6254Epoch 3/40: loss=0.7382, accuracy=0.6260, val_loss=0.7040, val_accuracy=0.6796\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7382 - accuracy: 0.6260 - val_loss: 0.7040 - val_accuracy: 0.6796 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7274 - accuracy: 0.6323Epoch 4/40: loss=0.7261, accuracy=0.6329, val_loss=0.8746, val_accuracy=0.7136\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7261 - accuracy: 0.6329 - val_loss: 0.8746 - val_accuracy: 0.7136 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.6507Epoch 5/40: loss=0.7097, accuracy=0.6507, val_loss=0.5986, val_accuracy=0.6515\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7097 - accuracy: 0.6507 - val_loss: 0.5986 - val_accuracy: 0.6515 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7073 - accuracy: 0.6514Epoch 6/40: loss=0.7054, accuracy=0.6525, val_loss=1.2330, val_accuracy=0.7392\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7054 - accuracy: 0.6525 - val_loss: 1.2330 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6995 - accuracy: 0.6604Epoch 7/40: loss=0.6994, accuracy=0.6604, val_loss=1.2110, val_accuracy=0.5712\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6994 - accuracy: 0.6604 - val_loss: 1.2110 - val_accuracy: 0.5712 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7999 - accuracy: 0.5566Epoch 8/40: loss=0.8001, accuracy=0.5565, val_loss=1.4874, val_accuracy=0.5298\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.8001 - accuracy: 0.5565 - val_loss: 1.4874 - val_accuracy: 0.5298 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7554 - accuracy: 0.5980Epoch 9/40: loss=0.7548, accuracy=0.5979, val_loss=1.1030, val_accuracy=0.4164\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7548 - accuracy: 0.5979 - val_loss: 1.1030 - val_accuracy: 0.4164 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.6153\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.7645, accuracy=0.6153, val_loss=0.7277, val_accuracy=0.6242\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7645 - accuracy: 0.6153 - val_loss: 0.7277 - val_accuracy: 0.6242 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6092 - accuracy: 0.6957Epoch 11/40: loss=0.6106, accuracy=0.6952, val_loss=0.5377, val_accuracy=0.7583\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6106 - accuracy: 0.6952 - val_loss: 0.5377 - val_accuracy: 0.7583 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6162 - accuracy: 0.6837Epoch 12/40: loss=0.6165, accuracy=0.6836, val_loss=0.5301, val_accuracy=0.7442\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6165 - accuracy: 0.6836 - val_loss: 0.5301 - val_accuracy: 0.7442 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.7051Epoch 13/40: loss=0.5971, accuracy=0.7043, val_loss=0.7649, val_accuracy=0.6291\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5971 - accuracy: 0.7043 - val_loss: 0.7649 - val_accuracy: 0.6291 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5843 - accuracy: 0.7054Epoch 14/40: loss=0.5852, accuracy=0.7053, val_loss=0.5417, val_accuracy=0.7575\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5852 - accuracy: 0.7053 - val_loss: 0.5417 - val_accuracy: 0.7575 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5778 - accuracy: 0.7139Epoch 15/40: loss=0.5774, accuracy=0.7144, val_loss=0.4744, val_accuracy=0.7765\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5774 - accuracy: 0.7144 - val_loss: 0.4744 - val_accuracy: 0.7765 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.7219Epoch 16/40: loss=0.5612, accuracy=0.7219, val_loss=0.6465, val_accuracy=0.7177\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5612 - accuracy: 0.7219 - val_loss: 0.6465 - val_accuracy: 0.7177 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.7177Epoch 17/40: loss=0.5692, accuracy=0.7177, val_loss=0.5466, val_accuracy=0.7392\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5692 - accuracy: 0.7177 - val_loss: 0.5466 - val_accuracy: 0.7392 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7370Epoch 18/40: loss=0.5468, accuracy=0.7370, val_loss=0.4709, val_accuracy=0.7657\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5468 - accuracy: 0.7370 - val_loss: 0.4709 - val_accuracy: 0.7657 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5624 - accuracy: 0.7237Epoch 19/40: loss=0.5626, accuracy=0.7237, val_loss=0.4643, val_accuracy=0.7773\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5626 - accuracy: 0.7237 - val_loss: 0.4643 - val_accuracy: 0.7773 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.7281Epoch 20/40: loss=0.5591, accuracy=0.7281, val_loss=0.4893, val_accuracy=0.7442\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5591 - accuracy: 0.7281 - val_loss: 0.4893 - val_accuracy: 0.7442 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.7394Epoch 21/40: loss=0.5453, accuracy=0.7401, val_loss=0.4322, val_accuracy=0.8022\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5453 - accuracy: 0.7401 - val_loss: 0.4322 - val_accuracy: 0.8022 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.7425Epoch 22/40: loss=0.5387, accuracy=0.7428, val_loss=0.4686, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5387 - accuracy: 0.7428 - val_loss: 0.4686 - val_accuracy: 0.7914 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7326Epoch 23/40: loss=0.5511, accuracy=0.7330, val_loss=0.4351, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5511 - accuracy: 0.7330 - val_loss: 0.4351 - val_accuracy: 0.8088 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.7517Epoch 24/40: loss=0.5216, accuracy=0.7514, val_loss=0.4844, val_accuracy=0.7988\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5216 - accuracy: 0.7514 - val_loss: 0.4844 - val_accuracy: 0.7988 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.7519Epoch 25/40: loss=0.5249, accuracy=0.7519, val_loss=0.4965, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5249 - accuracy: 0.7519 - val_loss: 0.4965 - val_accuracy: 0.7955 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.7492\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 26/40: loss=0.5266, accuracy=0.7494, val_loss=0.7298, val_accuracy=0.6788\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5266 - accuracy: 0.7494 - val_loss: 0.7298 - val_accuracy: 0.6788 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5099 - accuracy: 0.7510Epoch 27/40: loss=0.5100, accuracy=0.7514, val_loss=0.4234, val_accuracy=0.8154\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5100 - accuracy: 0.7514 - val_loss: 0.4234 - val_accuracy: 0.8154 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4972 - accuracy: 0.7664Epoch 28/40: loss=0.4971, accuracy=0.7666, val_loss=0.4046, val_accuracy=0.8204\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4971 - accuracy: 0.7666 - val_loss: 0.4046 - val_accuracy: 0.8204 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7654Epoch 29/40: loss=0.5016, accuracy=0.7655, val_loss=0.4495, val_accuracy=0.8088\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5016 - accuracy: 0.7655 - val_loss: 0.4495 - val_accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7682Epoch 30/40: loss=0.5034, accuracy=0.7682, val_loss=0.4109, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5034 - accuracy: 0.7682 - val_loss: 0.4109 - val_accuracy: 0.8270 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7601Epoch 31/40: loss=0.5126, accuracy=0.7601, val_loss=0.4123, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5126 - accuracy: 0.7601 - val_loss: 0.4123 - val_accuracy: 0.8237 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7643Epoch 32/40: loss=0.4986, accuracy=0.7641, val_loss=0.4101, val_accuracy=0.8262\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4986 - accuracy: 0.7641 - val_loss: 0.4101 - val_accuracy: 0.8262 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4936 - accuracy: 0.7697\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 33/40: loss=0.4934, accuracy=0.7697, val_loss=0.4154, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4934 - accuracy: 0.7697 - val_loss: 0.4154 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7707Epoch 34/40: loss=0.4879, accuracy=0.7707, val_loss=0.4113, val_accuracy=0.8179\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4879 - accuracy: 0.7707 - val_loss: 0.4113 - val_accuracy: 0.8179 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4881 - accuracy: 0.7767Epoch 35/40: loss=0.4876, accuracy=0.7769, val_loss=0.4150, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4876 - accuracy: 0.7769 - val_loss: 0.4150 - val_accuracy: 0.8179 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4741 - accuracy: 0.7768Epoch 36/40: loss=0.4739, accuracy=0.7769, val_loss=0.4099, val_accuracy=0.8204\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4739 - accuracy: 0.7769 - val_loss: 0.4099 - val_accuracy: 0.8204 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4905 - accuracy: 0.7662Epoch 37/40: loss=0.4915, accuracy=0.7657, val_loss=0.4094, val_accuracy=0.8245\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4915 - accuracy: 0.7657 - val_loss: 0.4094 - val_accuracy: 0.8245 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.7701\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.4829, accuracy=0.7701, val_loss=0.4103, val_accuracy=0.8220\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4829 - accuracy: 0.7701 - val_loss: 0.4103 - val_accuracy: 0.8220 - lr: 8.0000e-06\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8269867300987244\n",
      "\n",
      "Initial Training Combination 43/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.05, filters=128, kernel_size=7, num_dense_layers=1, activation_function=relu, rotation_range=40, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.1, zoom_range=0.4, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 3.7991 - accuracy: 0.5536Epoch 1/40: loss=3.7991, accuracy=0.5536, val_loss=0.7760, val_accuracy=0.5993\n",
      "604/604 [==============================] - 32s 50ms/step - loss: 3.7991 - accuracy: 0.5536 - val_loss: 0.7760 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8217 - accuracy: 0.5929Epoch 2/40: loss=0.8218, accuracy=0.5933, val_loss=0.5352, val_accuracy=0.7326\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.8218 - accuracy: 0.5933 - val_loss: 0.5352 - val_accuracy: 0.7326 - lr: 0.0500\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9043 - accuracy: 0.5929Epoch 3/40: loss=0.9043, accuracy=0.5929, val_loss=0.6175, val_accuracy=0.6854\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 0.9043 - accuracy: 0.5929 - val_loss: 0.6175 - val_accuracy: 0.6854 - lr: 0.0500\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.6985 - accuracy: 0.5718Epoch 4/40: loss=1.6985, accuracy=0.5718, val_loss=1.1098, val_accuracy=0.5993\n",
      "604/604 [==============================] - 30s 49ms/step - loss: 1.6985 - accuracy: 0.5718 - val_loss: 1.1098 - val_accuracy: 0.5993 - lr: 0.0500\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0645 - accuracy: 0.5896Epoch 5/40: loss=1.0644, accuracy=0.5898, val_loss=0.6115, val_accuracy=0.6457\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.0644 - accuracy: 0.5898 - val_loss: 0.6115 - val_accuracy: 0.6457 - lr: 0.0500\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.4251 - accuracy: 0.5875Epoch 6/40: loss=1.4307, accuracy=0.5871, val_loss=15.7534, val_accuracy=0.5008\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.4307 - accuracy: 0.5871 - val_loss: 15.7534 - val_accuracy: 0.5008 - lr: 0.0500\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.8013 - accuracy: 0.5828\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 7/40: loss=1.8013, accuracy=0.5828, val_loss=1.1417, val_accuracy=0.4073\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 1.8013 - accuracy: 0.5828 - val_loss: 1.1417 - val_accuracy: 0.4073 - lr: 0.0500\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.6643Epoch 8/40: loss=0.6263, accuracy=0.6643, val_loss=0.5331, val_accuracy=0.7417\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6263 - accuracy: 0.6643 - val_loss: 0.5331 - val_accuracy: 0.7417 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.6808Epoch 9/40: loss=0.6087, accuracy=0.6809, val_loss=0.6690, val_accuracy=0.5778\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6087 - accuracy: 0.6809 - val_loss: 0.6690 - val_accuracy: 0.5778 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.6892Epoch 10/40: loss=0.6044, accuracy=0.6892, val_loss=0.5239, val_accuracy=0.7318\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6044 - accuracy: 0.6892 - val_loss: 0.5239 - val_accuracy: 0.7318 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.6923Epoch 11/40: loss=0.6055, accuracy=0.6923, val_loss=2.0924, val_accuracy=0.2566\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6055 - accuracy: 0.6923 - val_loss: 2.0924 - val_accuracy: 0.2566 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6242 - accuracy: 0.6665Epoch 12/40: loss=0.6241, accuracy=0.6666, val_loss=0.6616, val_accuracy=0.6474\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6241 - accuracy: 0.6666 - val_loss: 0.6616 - val_accuracy: 0.6474 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.6756Epoch 13/40: loss=0.6250, accuracy=0.6759, val_loss=0.5602, val_accuracy=0.7227\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6250 - accuracy: 0.6759 - val_loss: 0.5602 - val_accuracy: 0.7227 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.6577Epoch 14/40: loss=0.6506, accuracy=0.6577, val_loss=0.5213, val_accuracy=0.7566\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6506 - accuracy: 0.6577 - val_loss: 0.5213 - val_accuracy: 0.7566 - lr: 0.0100\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6249 - accuracy: 0.6725Epoch 15/40: loss=0.6245, accuracy=0.6724, val_loss=0.5417, val_accuracy=0.7368\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6245 - accuracy: 0.6724 - val_loss: 0.5417 - val_accuracy: 0.7368 - lr: 0.0100\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6313 - accuracy: 0.6837Epoch 16/40: loss=0.6313, accuracy=0.6836, val_loss=0.6632, val_accuracy=0.6556\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6313 - accuracy: 0.6836 - val_loss: 0.6632 - val_accuracy: 0.6556 - lr: 0.0100\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.6774Epoch 17/40: loss=0.6467, accuracy=0.6774, val_loss=0.6734, val_accuracy=0.5836\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6467 - accuracy: 0.6774 - val_loss: 0.6734 - val_accuracy: 0.5836 - lr: 0.0100\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6158 - accuracy: 0.6880Epoch 18/40: loss=0.6156, accuracy=0.6883, val_loss=0.5899, val_accuracy=0.7003\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6156 - accuracy: 0.6883 - val_loss: 0.5899 - val_accuracy: 0.7003 - lr: 0.0100\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6118 - accuracy: 0.6942\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 19/40: loss=0.6123, accuracy=0.6935, val_loss=39.5034, val_accuracy=0.3320\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6123 - accuracy: 0.6935 - val_loss: 39.5034 - val_accuracy: 0.3320 - lr: 0.0100\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6470 - accuracy: 0.6244Epoch 20/40: loss=0.6468, accuracy=0.6246, val_loss=0.6004, val_accuracy=0.6821\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6468 - accuracy: 0.6246 - val_loss: 0.6004 - val_accuracy: 0.6821 - lr: 0.0020\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.6492Epoch 21/40: loss=0.6333, accuracy=0.6492, val_loss=0.6061, val_accuracy=0.6987\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6333 - accuracy: 0.6492 - val_loss: 0.6061 - val_accuracy: 0.6987 - lr: 0.0020\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.6705Epoch 22/40: loss=0.6162, accuracy=0.6705, val_loss=0.6433, val_accuracy=0.6366\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6162 - accuracy: 0.6705 - val_loss: 0.6433 - val_accuracy: 0.6366 - lr: 0.0020\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.6937Epoch 23/40: loss=0.6016, accuracy=0.6937, val_loss=0.6013, val_accuracy=0.6945\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6016 - accuracy: 0.6937 - val_loss: 0.6013 - val_accuracy: 0.6945 - lr: 0.0020\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.6893\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.6021, accuracy=0.6892, val_loss=0.6608, val_accuracy=0.6358\n",
      "604/604 [==============================] - 30s 50ms/step - loss: 0.6021 - accuracy: 0.6892 - val_loss: 0.6608 - val_accuracy: 0.6358 - lr: 0.0020\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.7566224932670593\n",
      "\n",
      "Initial Training Combination 44/50: num_residual_blocks=8, dropout_rate=0.55, learning_rate=0.005, filters=128, kernel_size=3, num_dense_layers=1, activation_function=relu, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1224 - accuracy: 0.5485Epoch 1/40: loss=1.1231, accuracy=0.5480, val_loss=0.8211, val_accuracy=0.6581\n",
      "604/604 [==============================] - 17s 23ms/step - loss: 1.1231 - accuracy: 0.5480 - val_loss: 0.8211 - val_accuracy: 0.6581 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8716 - accuracy: 0.6308Epoch 2/40: loss=0.8716, accuracy=0.6308, val_loss=0.9599, val_accuracy=0.6010\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.8716 - accuracy: 0.6308 - val_loss: 0.9599 - val_accuracy: 0.6010 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8489 - accuracy: 0.6051Epoch 3/40: loss=0.8486, accuracy=0.6049, val_loss=0.7556, val_accuracy=0.6498\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8486 - accuracy: 0.6049 - val_loss: 0.7556 - val_accuracy: 0.6498 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7258 - accuracy: 0.6416Epoch 4/40: loss=0.7251, accuracy=0.6420, val_loss=0.9556, val_accuracy=0.5877\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.7251 - accuracy: 0.6420 - val_loss: 0.9556 - val_accuracy: 0.5877 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.6867Epoch 5/40: loss=0.6451, accuracy=0.6867, val_loss=1.7480, val_accuracy=0.4843\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6451 - accuracy: 0.6867 - val_loss: 1.7480 - val_accuracy: 0.4843 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6689Epoch 6/40: loss=0.6538, accuracy=0.6691, val_loss=2.8016, val_accuracy=0.4139\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6538 - accuracy: 0.6691 - val_loss: 2.8016 - val_accuracy: 0.4139 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.6818Epoch 7/40: loss=0.6326, accuracy=0.6819, val_loss=0.6343, val_accuracy=0.7012\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6326 - accuracy: 0.6819 - val_loss: 0.6343 - val_accuracy: 0.7012 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5878 - accuracy: 0.7054Epoch 8/40: loss=0.5883, accuracy=0.7045, val_loss=102.1978, val_accuracy=0.5993\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5883 - accuracy: 0.7045 - val_loss: 102.1978 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6094 - accuracy: 0.6874Epoch 9/40: loss=0.6095, accuracy=0.6873, val_loss=0.4904, val_accuracy=0.7873\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6095 - accuracy: 0.6873 - val_loss: 0.4904 - val_accuracy: 0.7873 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5878 - accuracy: 0.7058Epoch 10/40: loss=0.5881, accuracy=0.7057, val_loss=1.2438, val_accuracy=0.6002\n",
      "604/604 [==============================] - 17s 27ms/step - loss: 0.5881 - accuracy: 0.7057 - val_loss: 1.2438 - val_accuracy: 0.6002 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5610 - accuracy: 0.7204Epoch 11/40: loss=0.5611, accuracy=0.7202, val_loss=0.4910, val_accuracy=0.7922\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5611 - accuracy: 0.7202 - val_loss: 0.4910 - val_accuracy: 0.7922 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7318Epoch 12/40: loss=0.5482, accuracy=0.7318, val_loss=0.6183, val_accuracy=0.7127\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5482 - accuracy: 0.7318 - val_loss: 0.6183 - val_accuracy: 0.7127 - lr: 0.0050\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5563 - accuracy: 0.7318Epoch 13/40: loss=0.5560, accuracy=0.7320, val_loss=0.5025, val_accuracy=0.7781\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5560 - accuracy: 0.7320 - val_loss: 0.5025 - val_accuracy: 0.7781 - lr: 0.0050\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.7413\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 14/40: loss=0.5515, accuracy=0.7413, val_loss=0.6997, val_accuracy=0.6250\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5515 - accuracy: 0.7413 - val_loss: 0.6997 - val_accuracy: 0.6250 - lr: 0.0050\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.7477Epoch 15/40: loss=0.5382, accuracy=0.7477, val_loss=0.4874, val_accuracy=0.8013\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5382 - accuracy: 0.7477 - val_loss: 0.4874 - val_accuracy: 0.8013 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.7610Epoch 16/40: loss=0.5144, accuracy=0.7614, val_loss=0.4769, val_accuracy=0.7972\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5144 - accuracy: 0.7614 - val_loss: 0.4769 - val_accuracy: 0.7972 - lr: 1.0000e-03\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.7630Epoch 17/40: loss=0.5028, accuracy=0.7630, val_loss=0.4523, val_accuracy=0.8162\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5028 - accuracy: 0.7630 - val_loss: 0.4523 - val_accuracy: 0.8162 - lr: 1.0000e-03\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.7676Epoch 18/40: loss=0.4969, accuracy=0.7676, val_loss=0.4448, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4969 - accuracy: 0.7676 - val_loss: 0.4448 - val_accuracy: 0.8096 - lr: 1.0000e-03\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.7668Epoch 19/40: loss=0.4960, accuracy=0.7672, val_loss=0.4106, val_accuracy=0.8179\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.4960 - accuracy: 0.7672 - val_loss: 0.4106 - val_accuracy: 0.8179 - lr: 1.0000e-03\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.7579Epoch 20/40: loss=0.5091, accuracy=0.7579, val_loss=0.4309, val_accuracy=0.8005\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5091 - accuracy: 0.7579 - val_loss: 0.4309 - val_accuracy: 0.8005 - lr: 1.0000e-03\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.7593Epoch 21/40: loss=0.5095, accuracy=0.7591, val_loss=0.4549, val_accuracy=0.8096\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5095 - accuracy: 0.7591 - val_loss: 0.4549 - val_accuracy: 0.8096 - lr: 1.0000e-03\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7730Epoch 22/40: loss=0.4996, accuracy=0.7734, val_loss=0.4374, val_accuracy=0.8071\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4996 - accuracy: 0.7734 - val_loss: 0.4374 - val_accuracy: 0.8071 - lr: 1.0000e-03\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.7656Epoch 23/40: loss=0.5175, accuracy=0.7657, val_loss=0.4401, val_accuracy=0.8096\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5175 - accuracy: 0.7657 - val_loss: 0.4401 - val_accuracy: 0.8096 - lr: 1.0000e-03\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.7715\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 24/40: loss=0.5089, accuracy=0.7715, val_loss=0.4959, val_accuracy=0.8055\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5089 - accuracy: 0.7715 - val_loss: 0.4959 - val_accuracy: 0.8055 - lr: 1.0000e-03\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5030 - accuracy: 0.7664Epoch 25/40: loss=0.5027, accuracy=0.7663, val_loss=0.4690, val_accuracy=0.8038\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5027 - accuracy: 0.7663 - val_loss: 0.4690 - val_accuracy: 0.8038 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.7751Epoch 26/40: loss=0.4896, accuracy=0.7755, val_loss=0.4596, val_accuracy=0.8104\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4896 - accuracy: 0.7755 - val_loss: 0.4596 - val_accuracy: 0.8104 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.7786Epoch 27/40: loss=0.4921, accuracy=0.7786, val_loss=0.4851, val_accuracy=0.8104\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.4921 - accuracy: 0.7786 - val_loss: 0.4851 - val_accuracy: 0.8104 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.7784Epoch 28/40: loss=0.4866, accuracy=0.7786, val_loss=0.4605, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4866 - accuracy: 0.7786 - val_loss: 0.4605 - val_accuracy: 0.8137 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.7740\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 29/40: loss=0.4823, accuracy=0.7738, val_loss=0.4608, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4823 - accuracy: 0.7738 - val_loss: 0.4608 - val_accuracy: 0.8088 - lr: 2.0000e-04\n",
      "Epoch 29: early stopping\n",
      "Validation accuracy: 0.8178808093070984\n",
      "\n",
      "Initial Training Combination 45/50: num_residual_blocks=5, dropout_rate=0.45, learning_rate=5e-05, filters=128, kernel_size=5, num_dense_layers=2, activation_function=relu, rotation_range=20, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.3, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "  5/604 [..............................] - ETA: 17s - loss: 1.0614 - accuracy: 0.4500 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0223s vs `on_train_batch_end` time: 0.0317s). Check your callbacks.\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9917 - accuracy: 0.5206Epoch 1/40: loss=0.9930, accuracy=0.5201, val_loss=0.6418, val_accuracy=0.6275\n",
      "604/604 [==============================] - 19s 28ms/step - loss: 0.9930 - accuracy: 0.5201 - val_loss: 0.6418 - val_accuracy: 0.6275 - lr: 5.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9007 - accuracy: 0.5604Epoch 2/40: loss=0.9007, accuracy=0.5604, val_loss=1.6903, val_accuracy=0.4313\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.9007 - accuracy: 0.5604 - val_loss: 1.6903 - val_accuracy: 0.4313 - lr: 5.0000e-05\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8163 - accuracy: 0.6153Epoch 3/40: loss=0.8163, accuracy=0.6153, val_loss=0.7636, val_accuracy=0.6904\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.8163 - accuracy: 0.6153 - val_loss: 0.7636 - val_accuracy: 0.6904 - lr: 5.0000e-05\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7639 - accuracy: 0.6488Epoch 4/40: loss=0.7639, accuracy=0.6488, val_loss=2.1462, val_accuracy=0.4280\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7639 - accuracy: 0.6488 - val_loss: 2.1462 - val_accuracy: 0.4280 - lr: 5.0000e-05\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7355 - accuracy: 0.6643Epoch 5/40: loss=0.7355, accuracy=0.6643, val_loss=0.5418, val_accuracy=0.7575\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7355 - accuracy: 0.6643 - val_loss: 0.5418 - val_accuracy: 0.7575 - lr: 5.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7083 - accuracy: 0.6676Epoch 6/40: loss=0.7083, accuracy=0.6676, val_loss=1.2372, val_accuracy=0.5306\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7083 - accuracy: 0.6676 - val_loss: 1.2372 - val_accuracy: 0.5306 - lr: 5.0000e-05\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.6883Epoch 7/40: loss=0.6824, accuracy=0.6871, val_loss=0.5896, val_accuracy=0.7641\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6824 - accuracy: 0.6871 - val_loss: 0.5896 - val_accuracy: 0.7641 - lr: 5.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.6874Epoch 8/40: loss=0.6758, accuracy=0.6875, val_loss=0.5251, val_accuracy=0.7732\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6758 - accuracy: 0.6875 - val_loss: 0.5251 - val_accuracy: 0.7732 - lr: 5.0000e-05\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.6896Epoch 9/40: loss=0.6580, accuracy=0.6896, val_loss=1.5542, val_accuracy=0.4478\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6580 - accuracy: 0.6896 - val_loss: 1.5542 - val_accuracy: 0.4478 - lr: 5.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.6984Epoch 10/40: loss=0.6318, accuracy=0.6987, val_loss=0.4695, val_accuracy=0.7972\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6318 - accuracy: 0.6987 - val_loss: 0.4695 - val_accuracy: 0.7972 - lr: 5.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6421 - accuracy: 0.6953Epoch 11/40: loss=0.6418, accuracy=0.6954, val_loss=0.6458, val_accuracy=0.6896\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6418 - accuracy: 0.6954 - val_loss: 0.6458 - val_accuracy: 0.6896 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6288 - accuracy: 0.6942Epoch 12/40: loss=0.6283, accuracy=0.6945, val_loss=1.5295, val_accuracy=0.4338\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6283 - accuracy: 0.6945 - val_loss: 1.5295 - val_accuracy: 0.4338 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6275 - accuracy: 0.7041Epoch 13/40: loss=0.6289, accuracy=0.7032, val_loss=0.5047, val_accuracy=0.7839\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6289 - accuracy: 0.7032 - val_loss: 0.5047 - val_accuracy: 0.7839 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.7036Epoch 14/40: loss=0.5953, accuracy=0.7034, val_loss=0.5804, val_accuracy=0.7442\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5953 - accuracy: 0.7034 - val_loss: 0.5804 - val_accuracy: 0.7442 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.7138\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 15/40: loss=0.5893, accuracy=0.7138, val_loss=0.6948, val_accuracy=0.6929\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5893 - accuracy: 0.7138 - val_loss: 0.6948 - val_accuracy: 0.6929 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.7436Epoch 16/40: loss=0.5595, accuracy=0.7434, val_loss=0.6330, val_accuracy=0.7103\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5595 - accuracy: 0.7434 - val_loss: 0.6330 - val_accuracy: 0.7103 - lr: 1.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.7442Epoch 17/40: loss=0.5378, accuracy=0.7444, val_loss=0.4100, val_accuracy=0.7988\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5378 - accuracy: 0.7444 - val_loss: 0.4100 - val_accuracy: 0.7988 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.7376Epoch 18/40: loss=0.5401, accuracy=0.7374, val_loss=0.4260, val_accuracy=0.7955\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5401 - accuracy: 0.7374 - val_loss: 0.4260 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5529 - accuracy: 0.7434Epoch 19/40: loss=0.5532, accuracy=0.7432, val_loss=0.3954, val_accuracy=0.8195\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5532 - accuracy: 0.7432 - val_loss: 0.3954 - val_accuracy: 0.8195 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.7575Epoch 20/40: loss=0.5208, accuracy=0.7575, val_loss=0.4276, val_accuracy=0.8129\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5208 - accuracy: 0.7575 - val_loss: 0.4276 - val_accuracy: 0.8129 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7529Epoch 21/40: loss=0.5286, accuracy=0.7527, val_loss=0.4186, val_accuracy=0.8046\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.5286 - accuracy: 0.7527 - val_loss: 0.4186 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7630Epoch 22/40: loss=0.5156, accuracy=0.7630, val_loss=0.4886, val_accuracy=0.7632\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5156 - accuracy: 0.7630 - val_loss: 0.4886 - val_accuracy: 0.7632 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7620Epoch 23/40: loss=0.5193, accuracy=0.7620, val_loss=0.5983, val_accuracy=0.7210\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5193 - accuracy: 0.7620 - val_loss: 0.5983 - val_accuracy: 0.7210 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.7527\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 24/40: loss=0.5142, accuracy=0.7527, val_loss=0.4543, val_accuracy=0.7889\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5142 - accuracy: 0.7527 - val_loss: 0.4543 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.7716Epoch 25/40: loss=0.4973, accuracy=0.7713, val_loss=0.4275, val_accuracy=0.7955\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.4973 - accuracy: 0.7713 - val_loss: 0.4275 - val_accuracy: 0.7955 - lr: 2.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.7614Epoch 26/40: loss=0.5095, accuracy=0.7614, val_loss=0.4423, val_accuracy=0.7889\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5095 - accuracy: 0.7614 - val_loss: 0.4423 - val_accuracy: 0.7889 - lr: 2.0000e-06\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.7719Epoch 27/40: loss=0.4911, accuracy=0.7719, val_loss=0.4353, val_accuracy=0.7873\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.4911 - accuracy: 0.7719 - val_loss: 0.4353 - val_accuracy: 0.7873 - lr: 2.0000e-06\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7656Epoch 28/40: loss=0.5001, accuracy=0.7655, val_loss=0.4568, val_accuracy=0.7773\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5001 - accuracy: 0.7655 - val_loss: 0.4568 - val_accuracy: 0.7773 - lr: 2.0000e-06\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.7769\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 29/40: loss=0.4869, accuracy=0.7769, val_loss=0.4520, val_accuracy=0.7781\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.4869 - accuracy: 0.7769 - val_loss: 0.4520 - val_accuracy: 0.7781 - lr: 2.0000e-06\n",
      "Epoch 29: early stopping\n",
      "Validation accuracy: 0.8195364475250244\n",
      "\n",
      "Initial Training Combination 46/50: num_residual_blocks=5, dropout_rate=0.55, learning_rate=0.01, filters=32, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.4, height_shift_range=0.1, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 3.7363 - accuracy: 0.4950Epoch 1/40: loss=3.7350, accuracy=0.4954, val_loss=1.1481, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 3.7350 - accuracy: 0.4954 - val_loss: 1.1481 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 3.1896 - accuracy: 0.5012Epoch 2/40: loss=3.1908, accuracy=0.5006, val_loss=0.8058, val_accuracy=0.4007\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 3.1908 - accuracy: 0.5006 - val_loss: 0.8058 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 2.2381 - accuracy: 0.4996Epoch 3/40: loss=2.2359, accuracy=0.4994, val_loss=0.6962, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 2.2359 - accuracy: 0.4994 - val_loss: 0.6962 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.4967Epoch 4/40: loss=1.5285, accuracy=0.4969, val_loss=0.6733, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.5285 - accuracy: 0.4969 - val_loss: 0.6733 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0867 - accuracy: 0.5015Epoch 5/40: loss=1.0850, accuracy=0.5019, val_loss=0.7327, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0850 - accuracy: 0.5019 - val_loss: 0.7327 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9006 - accuracy: 0.4842Epoch 6/40: loss=0.9010, accuracy=0.4841, val_loss=0.6733, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9010 - accuracy: 0.4841 - val_loss: 0.6733 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.5100Epoch 7/40: loss=0.7904, accuracy=0.5099, val_loss=0.6986, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7904 - accuracy: 0.5099 - val_loss: 0.6986 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7591 - accuracy: 0.4946Epoch 8/40: loss=0.7590, accuracy=0.4944, val_loss=0.7100, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7590 - accuracy: 0.4944 - val_loss: 0.7100 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7323 - accuracy: 0.5098\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 9/40: loss=0.7322, accuracy=0.5097, val_loss=0.6733, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7322 - accuracy: 0.5097 - val_loss: 0.6733 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7047 - accuracy: 0.4998Epoch 10/40: loss=0.7048, accuracy=0.4998, val_loss=0.6998, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7048 - accuracy: 0.4998 - val_loss: 0.6998 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7009 - accuracy: 0.4942Epoch 11/40: loss=0.7009, accuracy=0.4938, val_loss=0.7047, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7009 - accuracy: 0.4938 - val_loss: 0.7047 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6985 - accuracy: 0.5046Epoch 12/40: loss=0.6985, accuracy=0.5037, val_loss=0.7145, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6985 - accuracy: 0.5037 - val_loss: 0.7145 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7000 - accuracy: 0.4907Epoch 13/40: loss=0.7001, accuracy=0.4901, val_loss=0.7009, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7001 - accuracy: 0.4901 - val_loss: 0.7009 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6976 - accuracy: 0.5120\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 14/40: loss=0.6978, accuracy=0.5116, val_loss=0.7000, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6978 - accuracy: 0.5116 - val_loss: 0.7000 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.4992Epoch 15/40: loss=0.6986, accuracy=0.4992, val_loss=0.6926, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6986 - accuracy: 0.4992 - val_loss: 0.6926 - val_accuracy: 0.5993 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6972 - accuracy: 0.4942Epoch 16/40: loss=0.6971, accuracy=0.4942, val_loss=0.6964, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6971 - accuracy: 0.4942 - val_loss: 0.6964 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.5021Epoch 17/40: loss=0.6954, accuracy=0.5019, val_loss=0.6878, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6954 - accuracy: 0.5019 - val_loss: 0.6878 - val_accuracy: 0.5993 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.5108Epoch 18/40: loss=0.6959, accuracy=0.5108, val_loss=0.6970, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6959 - accuracy: 0.5108 - val_loss: 0.6970 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6969 - accuracy: 0.4890\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19/40: loss=0.6969, accuracy=0.4888, val_loss=0.7005, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6969 - accuracy: 0.4888 - val_loss: 0.7005 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 19: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 47/50: num_residual_blocks=4, dropout_rate=0.25, learning_rate=1e-06, filters=128, kernel_size=3, num_dense_layers=3, activation_function=relu, rotation_range=10, width_shift_range=0.4, height_shift_range=0.2, shear_range=0.4, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "  5/604 [..............................] - ETA: 36s - loss: 1.0626 - accuracy: 0.4750WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0248s vs `on_train_batch_end` time: 0.0305s). Check your callbacks.\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0480 - accuracy: 0.5108Epoch 1/40: loss=1.0480, accuracy=0.5108, val_loss=0.7153, val_accuracy=0.5464\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.0480 - accuracy: 0.5108 - val_loss: 0.7153 - val_accuracy: 0.5464 - lr: 1.0000e-06\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0243 - accuracy: 0.5089Epoch 2/40: loss=1.0243, accuracy=0.5089, val_loss=0.7214, val_accuracy=0.5745\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0243 - accuracy: 0.5089 - val_loss: 0.7214 - val_accuracy: 0.5745 - lr: 1.0000e-06\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9894 - accuracy: 0.5249Epoch 3/40: loss=0.9891, accuracy=0.5250, val_loss=0.7076, val_accuracy=0.5853\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9891 - accuracy: 0.5250 - val_loss: 0.7076 - val_accuracy: 0.5853 - lr: 1.0000e-06\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0211 - accuracy: 0.5162Epoch 4/40: loss=1.0219, accuracy=0.5159, val_loss=0.7016, val_accuracy=0.5969\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0219 - accuracy: 0.5159 - val_loss: 0.7016 - val_accuracy: 0.5969 - lr: 1.0000e-06\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.5325Epoch 5/40: loss=0.9864, accuracy=0.5325, val_loss=0.6974, val_accuracy=0.6109\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9864 - accuracy: 0.5325 - val_loss: 0.6974 - val_accuracy: 0.6109 - lr: 1.0000e-06\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9547 - accuracy: 0.5374Epoch 6/40: loss=0.9552, accuracy=0.5370, val_loss=0.6875, val_accuracy=0.6151\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9552 - accuracy: 0.5370 - val_loss: 0.6875 - val_accuracy: 0.6151 - lr: 1.0000e-06\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9854 - accuracy: 0.5323Epoch 7/40: loss=0.9853, accuracy=0.5323, val_loss=0.6819, val_accuracy=0.6192\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9853 - accuracy: 0.5323 - val_loss: 0.6819 - val_accuracy: 0.6192 - lr: 1.0000e-06\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.5391Epoch 8/40: loss=0.9505, accuracy=0.5391, val_loss=0.6790, val_accuracy=0.6399\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9505 - accuracy: 0.5391 - val_loss: 0.6790 - val_accuracy: 0.6399 - lr: 1.0000e-06\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.5561Epoch 9/40: loss=0.9340, accuracy=0.5561, val_loss=0.6666, val_accuracy=0.6416\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9340 - accuracy: 0.5561 - val_loss: 0.6666 - val_accuracy: 0.6416 - lr: 1.0000e-06\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.5544Epoch 10/40: loss=0.9230, accuracy=0.5544, val_loss=0.6840, val_accuracy=0.6300\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9230 - accuracy: 0.5544 - val_loss: 0.6840 - val_accuracy: 0.6300 - lr: 1.0000e-06\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9107 - accuracy: 0.5630Epoch 11/40: loss=0.9099, accuracy=0.5635, val_loss=0.6739, val_accuracy=0.6407\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9099 - accuracy: 0.5635 - val_loss: 0.6739 - val_accuracy: 0.6407 - lr: 1.0000e-06\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.5594Epoch 12/40: loss=0.9224, accuracy=0.5594, val_loss=0.6864, val_accuracy=0.6291\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9224 - accuracy: 0.5594 - val_loss: 0.6864 - val_accuracy: 0.6291 - lr: 1.0000e-06\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.5538Epoch 13/40: loss=0.9262, accuracy=0.5540, val_loss=0.6848, val_accuracy=0.6374\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9262 - accuracy: 0.5540 - val_loss: 0.6848 - val_accuracy: 0.6374 - lr: 1.0000e-06\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9248 - accuracy: 0.5583\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.9999999949504855e-07.\n",
      "Epoch 14/40: loss=0.9254, accuracy=0.5584, val_loss=0.6691, val_accuracy=0.6474\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.9254 - accuracy: 0.5584 - val_loss: 0.6691 - val_accuracy: 0.6474 - lr: 1.0000e-06\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8942 - accuracy: 0.5682Epoch 15/40: loss=0.8941, accuracy=0.5683, val_loss=0.6651, val_accuracy=0.6548\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.8941 - accuracy: 0.5683 - val_loss: 0.6651 - val_accuracy: 0.6548 - lr: 2.0000e-07\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9010 - accuracy: 0.5763Epoch 16/40: loss=0.9016, accuracy=0.5762, val_loss=0.6812, val_accuracy=0.6424\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9016 - accuracy: 0.5762 - val_loss: 0.6812 - val_accuracy: 0.6424 - lr: 2.0000e-07\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8983 - accuracy: 0.5793Epoch 17/40: loss=0.8982, accuracy=0.5788, val_loss=0.6857, val_accuracy=0.6424\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8982 - accuracy: 0.5788 - val_loss: 0.6857 - val_accuracy: 0.6424 - lr: 2.0000e-07\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9193 - accuracy: 0.5768Epoch 18/40: loss=0.9188, accuracy=0.5772, val_loss=0.6595, val_accuracy=0.6548\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.9188 - accuracy: 0.5772 - val_loss: 0.6595 - val_accuracy: 0.6548 - lr: 2.0000e-07\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8876 - accuracy: 0.5771Epoch 19/40: loss=0.8879, accuracy=0.5766, val_loss=0.6763, val_accuracy=0.6540\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8879 - accuracy: 0.5766 - val_loss: 0.6763 - val_accuracy: 0.6540 - lr: 2.0000e-07\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9025 - accuracy: 0.5727Epoch 20/40: loss=0.9024, accuracy=0.5722, val_loss=0.6615, val_accuracy=0.6565\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9024 - accuracy: 0.5722 - val_loss: 0.6615 - val_accuracy: 0.6565 - lr: 2.0000e-07\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9029 - accuracy: 0.5614Epoch 21/40: loss=0.9018, accuracy=0.5615, val_loss=0.6700, val_accuracy=0.6565\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.9018 - accuracy: 0.5615 - val_loss: 0.6700 - val_accuracy: 0.6565 - lr: 2.0000e-07\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8997 - accuracy: 0.5723Epoch 22/40: loss=0.8995, accuracy=0.5722, val_loss=0.6824, val_accuracy=0.6482\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8995 - accuracy: 0.5722 - val_loss: 0.6824 - val_accuracy: 0.6482 - lr: 2.0000e-07\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8810 - accuracy: 0.5780\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 23/40: loss=0.8810, accuracy=0.5780, val_loss=0.6768, val_accuracy=0.6531\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8810 - accuracy: 0.5780 - val_loss: 0.6768 - val_accuracy: 0.6531 - lr: 2.0000e-07\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8882 - accuracy: 0.5806Epoch 24/40: loss=0.8875, accuracy=0.5811, val_loss=0.6886, val_accuracy=0.6382\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8875 - accuracy: 0.5811 - val_loss: 0.6886 - val_accuracy: 0.6382 - lr: 1.0000e-07\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8810 - accuracy: 0.5790Epoch 25/40: loss=0.8796, accuracy=0.5795, val_loss=0.6736, val_accuracy=0.6515\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.8796 - accuracy: 0.5795 - val_loss: 0.6736 - val_accuracy: 0.6515 - lr: 1.0000e-07\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8739 - accuracy: 0.5900Epoch 26/40: loss=0.8743, accuracy=0.5892, val_loss=0.6828, val_accuracy=0.6440\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8743 - accuracy: 0.5892 - val_loss: 0.6828 - val_accuracy: 0.6440 - lr: 1.0000e-07\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8993 - accuracy: 0.5818Epoch 27/40: loss=0.8990, accuracy=0.5815, val_loss=0.6686, val_accuracy=0.6565\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8990 - accuracy: 0.5815 - val_loss: 0.6686 - val_accuracy: 0.6565 - lr: 1.0000e-07\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8908 - accuracy: 0.5741Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28/40: loss=0.8908, accuracy=0.5741, val_loss=0.6685, val_accuracy=0.6556\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8908 - accuracy: 0.5741 - val_loss: 0.6685 - val_accuracy: 0.6556 - lr: 1.0000e-07\n",
      "Epoch 28: early stopping\n",
      "Validation accuracy: 0.6564569473266602\n",
      "\n",
      "Initial Training Combination 48/50: num_residual_blocks=7, dropout_rate=0.35, learning_rate=0.005, filters=64, kernel_size=3, num_dense_layers=3, activation_function=relu, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.3, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.8588 - accuracy: 0.4971Epoch 1/40: loss=1.8588, accuracy=0.4971, val_loss=1.1615, val_accuracy=0.5339\n",
      "604/604 [==============================] - 17s 23ms/step - loss: 1.8588 - accuracy: 0.4971 - val_loss: 1.1615 - val_accuracy: 0.5339 - lr: 0.0050\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.4751 - accuracy: 0.5172Epoch 2/40: loss=1.4751, accuracy=0.5172, val_loss=5.3604, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 1.4751 - accuracy: 0.5172 - val_loss: 5.3604 - val_accuracy: 0.5993 - lr: 0.0050\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2345 - accuracy: 0.4983Epoch 3/40: loss=1.2345, accuracy=0.4983, val_loss=0.9935, val_accuracy=0.4661\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 1.2345 - accuracy: 0.4983 - val_loss: 0.9935 - val_accuracy: 0.4661 - lr: 0.0050\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.4940Epoch 4/40: loss=1.0983, accuracy=0.4940, val_loss=1.7352, val_accuracy=0.5579\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.0983 - accuracy: 0.4940 - val_loss: 1.7352 - val_accuracy: 0.5579 - lr: 0.0050\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.4963Epoch 5/40: loss=1.0174, accuracy=0.4963, val_loss=1.0040, val_accuracy=0.5273\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.0174 - accuracy: 0.4963 - val_loss: 1.0040 - val_accuracy: 0.5273 - lr: 0.0050\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8986 - accuracy: 0.5127Epoch 6/40: loss=0.8985, accuracy=0.5124, val_loss=0.9759, val_accuracy=0.5182\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8985 - accuracy: 0.5124 - val_loss: 0.9759 - val_accuracy: 0.5182 - lr: 0.0050\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8197 - accuracy: 0.4919Epoch 7/40: loss=0.8194, accuracy=0.4921, val_loss=1.1044, val_accuracy=0.4611\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.8194 - accuracy: 0.4921 - val_loss: 1.1044 - val_accuracy: 0.4611 - lr: 0.0050\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7826 - accuracy: 0.5035Epoch 8/40: loss=0.7823, accuracy=0.5037, val_loss=45607.2344, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7823 - accuracy: 0.5037 - val_loss: 45607.2344 - val_accuracy: 0.4007 - lr: 0.0050\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7501 - accuracy: 0.5174Epoch 9/40: loss=0.7501, accuracy=0.5174, val_loss=3.4205, val_accuracy=0.5811\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7501 - accuracy: 0.5174 - val_loss: 3.4205 - val_accuracy: 0.5811 - lr: 0.0050\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.5027Epoch 10/40: loss=0.7261, accuracy=0.5027, val_loss=34.9209, val_accuracy=0.5298\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7261 - accuracy: 0.5027 - val_loss: 34.9209 - val_accuracy: 0.5298 - lr: 0.0050\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.5188\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 11/40: loss=0.7052, accuracy=0.5188, val_loss=33.9801, val_accuracy=0.5406\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7052 - accuracy: 0.5188 - val_loss: 33.9801 - val_accuracy: 0.5406 - lr: 0.0050\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5337Epoch 12/40: loss=0.6916, accuracy=0.5337, val_loss=48.3707, val_accuracy=0.4503\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6916 - accuracy: 0.5337 - val_loss: 48.3707 - val_accuracy: 0.4503 - lr: 1.0000e-03\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.5284Epoch 13/40: loss=0.6900, accuracy=0.5284, val_loss=56.6443, val_accuracy=0.5356\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6900 - accuracy: 0.5284 - val_loss: 56.6443 - val_accuracy: 0.5356 - lr: 1.0000e-03\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.5435Epoch 14/40: loss=0.6875, accuracy=0.5435, val_loss=73.3974, val_accuracy=0.5132\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6875 - accuracy: 0.5435 - val_loss: 73.3974 - val_accuracy: 0.5132 - lr: 1.0000e-03\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.5541Epoch 15/40: loss=0.6849, accuracy=0.5544, val_loss=156.7220, val_accuracy=0.5190\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6849 - accuracy: 0.5544 - val_loss: 156.7220 - val_accuracy: 0.5190 - lr: 1.0000e-03\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5623\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 16/40: loss=0.6829, accuracy=0.5623, val_loss=16.8811, val_accuracy=0.5315\n",
      "604/604 [==============================] - 17s 27ms/step - loss: 0.6829 - accuracy: 0.5623 - val_loss: 16.8811 - val_accuracy: 0.5315 - lr: 1.0000e-03\n",
      "Epoch 16: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 49/50: num_residual_blocks=5, dropout_rate=0.6, learning_rate=5e-05, filters=128, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9175 - accuracy: 0.5782Epoch 1/40: loss=0.9171, accuracy=0.5784, val_loss=1.0785, val_accuracy=0.6002\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9171 - accuracy: 0.5784 - val_loss: 1.0785 - val_accuracy: 0.6002 - lr: 5.0000e-05\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8448 - accuracy: 0.6289Epoch 2/40: loss=0.8448, accuracy=0.6289, val_loss=0.5463, val_accuracy=0.7392\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8448 - accuracy: 0.6289 - val_loss: 0.5463 - val_accuracy: 0.7392 - lr: 5.0000e-05\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8016 - accuracy: 0.6346Epoch 3/40: loss=0.8003, accuracy=0.6351, val_loss=0.7848, val_accuracy=0.6349\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8003 - accuracy: 0.6351 - val_loss: 0.7848 - val_accuracy: 0.6349 - lr: 5.0000e-05\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7484 - accuracy: 0.6553Epoch 4/40: loss=0.7471, accuracy=0.6558, val_loss=0.5348, val_accuracy=0.7450\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7471 - accuracy: 0.6558 - val_loss: 0.5348 - val_accuracy: 0.7450 - lr: 5.0000e-05\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7341 - accuracy: 0.6761Epoch 5/40: loss=0.7341, accuracy=0.6761, val_loss=0.7112, val_accuracy=0.6573\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7341 - accuracy: 0.6761 - val_loss: 0.7112 - val_accuracy: 0.6573 - lr: 5.0000e-05\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.6699Epoch 6/40: loss=0.7144, accuracy=0.6699, val_loss=0.4990, val_accuracy=0.7806\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7144 - accuracy: 0.6699 - val_loss: 0.4990 - val_accuracy: 0.7806 - lr: 5.0000e-05\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.6818Epoch 7/40: loss=0.6909, accuracy=0.6813, val_loss=1.0313, val_accuracy=0.6565\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6909 - accuracy: 0.6813 - val_loss: 1.0313 - val_accuracy: 0.6565 - lr: 5.0000e-05\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.6851Epoch 8/40: loss=0.6847, accuracy=0.6854, val_loss=0.5930, val_accuracy=0.7260\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6847 - accuracy: 0.6854 - val_loss: 0.5930 - val_accuracy: 0.7260 - lr: 5.0000e-05\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.6925Epoch 9/40: loss=0.6572, accuracy=0.6925, val_loss=1.2045, val_accuracy=0.4826\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6572 - accuracy: 0.6925 - val_loss: 1.2045 - val_accuracy: 0.4826 - lr: 5.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6412 - accuracy: 0.6978Epoch 10/40: loss=0.6411, accuracy=0.6974, val_loss=0.6038, val_accuracy=0.7177\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6411 - accuracy: 0.6974 - val_loss: 0.6038 - val_accuracy: 0.7177 - lr: 5.0000e-05\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.6874Epoch 11/40: loss=0.6563, accuracy=0.6871, val_loss=0.4542, val_accuracy=0.7873\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6563 - accuracy: 0.6871 - val_loss: 0.4542 - val_accuracy: 0.7873 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6399 - accuracy: 0.6957Epoch 12/40: loss=0.6396, accuracy=0.6960, val_loss=0.5817, val_accuracy=0.6987\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6396 - accuracy: 0.6960 - val_loss: 0.5817 - val_accuracy: 0.6987 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5882 - accuracy: 0.7211Epoch 13/40: loss=0.5881, accuracy=0.7210, val_loss=0.4779, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5881 - accuracy: 0.7210 - val_loss: 0.4779 - val_accuracy: 0.7765 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5892 - accuracy: 0.7211Epoch 14/40: loss=0.5887, accuracy=0.7216, val_loss=0.6668, val_accuracy=0.7219\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5887 - accuracy: 0.7216 - val_loss: 0.6668 - val_accuracy: 0.7219 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7250Epoch 15/40: loss=0.5825, accuracy=0.7250, val_loss=0.5940, val_accuracy=0.7144\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5825 - accuracy: 0.7250 - val_loss: 0.5940 - val_accuracy: 0.7144 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.7330\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 16/40: loss=0.5634, accuracy=0.7328, val_loss=0.7442, val_accuracy=0.6540\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5634 - accuracy: 0.7328 - val_loss: 0.7442 - val_accuracy: 0.6540 - lr: 5.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.7488Epoch 17/40: loss=0.5357, accuracy=0.7479, val_loss=0.3926, val_accuracy=0.8154\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5357 - accuracy: 0.7479 - val_loss: 0.3926 - val_accuracy: 0.8154 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.7539Epoch 18/40: loss=0.5443, accuracy=0.7541, val_loss=0.4122, val_accuracy=0.8079\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5443 - accuracy: 0.7541 - val_loss: 0.4122 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5252 - accuracy: 0.7560Epoch 19/40: loss=0.5250, accuracy=0.7560, val_loss=0.4930, val_accuracy=0.7666\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5250 - accuracy: 0.7560 - val_loss: 0.4930 - val_accuracy: 0.7666 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7577Epoch 20/40: loss=0.5241, accuracy=0.7577, val_loss=0.4429, val_accuracy=0.7964\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5241 - accuracy: 0.7577 - val_loss: 0.4429 - val_accuracy: 0.7964 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5178 - accuracy: 0.7695Epoch 21/40: loss=0.5174, accuracy=0.7697, val_loss=0.4179, val_accuracy=0.8113\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5174 - accuracy: 0.7697 - val_loss: 0.4179 - val_accuracy: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.7616\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "Epoch 22/40: loss=0.5094, accuracy=0.7616, val_loss=0.4047, val_accuracy=0.8278\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5094 - accuracy: 0.7616 - val_loss: 0.4047 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.7680Epoch 23/40: loss=0.5033, accuracy=0.7680, val_loss=0.4033, val_accuracy=0.8195\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5033 - accuracy: 0.7680 - val_loss: 0.4033 - val_accuracy: 0.8195 - lr: 2.0000e-06\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.7701Epoch 24/40: loss=0.5083, accuracy=0.7701, val_loss=0.3931, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5083 - accuracy: 0.7701 - val_loss: 0.3931 - val_accuracy: 0.8204 - lr: 2.0000e-06\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7703Epoch 25/40: loss=0.4999, accuracy=0.7705, val_loss=0.4111, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4999 - accuracy: 0.7705 - val_loss: 0.4111 - val_accuracy: 0.8187 - lr: 2.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7668Epoch 26/40: loss=0.5041, accuracy=0.7668, val_loss=0.4026, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5041 - accuracy: 0.7668 - val_loss: 0.4026 - val_accuracy: 0.8179 - lr: 2.0000e-06\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5017 - accuracy: 0.7695\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5025, accuracy=0.7692, val_loss=0.4029, val_accuracy=0.8162\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5025 - accuracy: 0.7692 - val_loss: 0.4029 - val_accuracy: 0.8162 - lr: 2.0000e-06\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.8278145790100098\n",
      "\n",
      "Initial Training Combination 50/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=64, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8897 - accuracy: 0.5957Epoch 1/40: loss=0.8899, accuracy=0.5960, val_loss=0.8081, val_accuracy=0.5712\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 0.8899 - accuracy: 0.5960 - val_loss: 0.8081 - val_accuracy: 0.5712 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7777 - accuracy: 0.6436Epoch 2/40: loss=0.7777, accuracy=0.6436, val_loss=0.7633, val_accuracy=0.5538\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7777 - accuracy: 0.6436 - val_loss: 0.7633 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7288 - accuracy: 0.6657Epoch 3/40: loss=0.7294, accuracy=0.6656, val_loss=0.5252, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7294 - accuracy: 0.6656 - val_loss: 0.5252 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7377 - accuracy: 0.6694Epoch 4/40: loss=0.7367, accuracy=0.6699, val_loss=0.8117, val_accuracy=0.6531\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7367 - accuracy: 0.6699 - val_loss: 0.8117 - val_accuracy: 0.6531 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7103 - accuracy: 0.6827Epoch 5/40: loss=0.7105, accuracy=0.6827, val_loss=1.3688, val_accuracy=0.4437\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7105 - accuracy: 0.6827 - val_loss: 1.3688 - val_accuracy: 0.4437 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7149 - accuracy: 0.6752Epoch 6/40: loss=0.7163, accuracy=0.6751, val_loss=0.4883, val_accuracy=0.7781\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7163 - accuracy: 0.6751 - val_loss: 0.4883 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7160 - accuracy: 0.6763Epoch 7/40: loss=0.7177, accuracy=0.6763, val_loss=0.5154, val_accuracy=0.7715\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7177 - accuracy: 0.6763 - val_loss: 0.5154 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6851 - accuracy: 0.6996Epoch 8/40: loss=0.6848, accuracy=0.6997, val_loss=0.6630, val_accuracy=0.6631\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6848 - accuracy: 0.6997 - val_loss: 0.6630 - val_accuracy: 0.6631 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7074 - accuracy: 0.6748Epoch 9/40: loss=0.7068, accuracy=0.6749, val_loss=0.6252, val_accuracy=0.6871\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7068 - accuracy: 0.6749 - val_loss: 0.6252 - val_accuracy: 0.6871 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.7010Epoch 10/40: loss=0.6719, accuracy=0.7010, val_loss=0.6187, val_accuracy=0.7409\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6719 - accuracy: 0.7010 - val_loss: 0.6187 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.7068\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 11/40: loss=0.6855, accuracy=0.7061, val_loss=0.6963, val_accuracy=0.6556\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6855 - accuracy: 0.7061 - val_loss: 0.6963 - val_accuracy: 0.6556 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7143Epoch 12/40: loss=0.6306, accuracy=0.7146, val_loss=0.4239, val_accuracy=0.8146\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.6306 - accuracy: 0.7146 - val_loss: 0.4239 - val_accuracy: 0.8146 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.7436Epoch 13/40: loss=0.5785, accuracy=0.7436, val_loss=0.4319, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5785 - accuracy: 0.7436 - val_loss: 0.4319 - val_accuracy: 0.8096 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.7477Epoch 14/40: loss=0.5626, accuracy=0.7475, val_loss=0.4293, val_accuracy=0.8253\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5626 - accuracy: 0.7475 - val_loss: 0.4293 - val_accuracy: 0.8253 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7589Epoch 15/40: loss=0.5424, accuracy=0.7589, val_loss=0.4683, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5424 - accuracy: 0.7589 - val_loss: 0.4683 - val_accuracy: 0.7806 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5219 - accuracy: 0.7635Epoch 16/40: loss=0.5218, accuracy=0.7637, val_loss=0.4203, val_accuracy=0.8055\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5218 - accuracy: 0.7637 - val_loss: 0.4203 - val_accuracy: 0.8055 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.7724Epoch 17/40: loss=0.5069, accuracy=0.7721, val_loss=0.4177, val_accuracy=0.8030\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5069 - accuracy: 0.7721 - val_loss: 0.4177 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5030 - accuracy: 0.7760Epoch 18/40: loss=0.5026, accuracy=0.7763, val_loss=0.3924, val_accuracy=0.8228\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5026 - accuracy: 0.7763 - val_loss: 0.3924 - val_accuracy: 0.8228 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.7834Epoch 19/40: loss=0.4756, accuracy=0.7831, val_loss=0.4229, val_accuracy=0.8195\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4756 - accuracy: 0.7831 - val_loss: 0.4229 - val_accuracy: 0.8195 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.7788Epoch 20/40: loss=0.4759, accuracy=0.7792, val_loss=0.4097, val_accuracy=0.8079\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4759 - accuracy: 0.7792 - val_loss: 0.4097 - val_accuracy: 0.8079 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.7774Epoch 21/40: loss=0.4816, accuracy=0.7773, val_loss=0.3993, val_accuracy=0.8311\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4816 - accuracy: 0.7773 - val_loss: 0.3993 - val_accuracy: 0.8311 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.7951Epoch 22/40: loss=0.4556, accuracy=0.7951, val_loss=0.4097, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4556 - accuracy: 0.7951 - val_loss: 0.4097 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.7991\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/40: loss=0.4540, accuracy=0.7990, val_loss=0.3975, val_accuracy=0.8195\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4540 - accuracy: 0.7990 - val_loss: 0.3975 - val_accuracy: 0.8195 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.7960Epoch 24/40: loss=0.4427, accuracy=0.7964, val_loss=0.3791, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4427 - accuracy: 0.7964 - val_loss: 0.3791 - val_accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8091Epoch 25/40: loss=0.4344, accuracy=0.8092, val_loss=0.4089, val_accuracy=0.8179\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4344 - accuracy: 0.8092 - val_loss: 0.4089 - val_accuracy: 0.8179 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4316 - accuracy: 0.8135Epoch 26/40: loss=0.4315, accuracy=0.8135, val_loss=0.3942, val_accuracy=0.8270\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4315 - accuracy: 0.8135 - val_loss: 0.3942 - val_accuracy: 0.8270 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8103Epoch 27/40: loss=0.4277, accuracy=0.8104, val_loss=0.3952, val_accuracy=0.8303\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4277 - accuracy: 0.8104 - val_loss: 0.3952 - val_accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4433 - accuracy: 0.7956Epoch 28/40: loss=0.4428, accuracy=0.7959, val_loss=0.3725, val_accuracy=0.8452\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4428 - accuracy: 0.7959 - val_loss: 0.3725 - val_accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4121 - accuracy: 0.8148Epoch 29/40: loss=0.4120, accuracy=0.8148, val_loss=0.3736, val_accuracy=0.8369\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4120 - accuracy: 0.8148 - val_loss: 0.3736 - val_accuracy: 0.8369 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4158 - accuracy: 0.8171Epoch 30/40: loss=0.4152, accuracy=0.8177, val_loss=0.3748, val_accuracy=0.8369\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.3748 - val_accuracy: 0.8369 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.8180Epoch 31/40: loss=0.4122, accuracy=0.8177, val_loss=0.3724, val_accuracy=0.8386\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4122 - accuracy: 0.8177 - val_loss: 0.3724 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.8219Epoch 32/40: loss=0.4107, accuracy=0.8218, val_loss=0.3951, val_accuracy=0.8353\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4107 - accuracy: 0.8218 - val_loss: 0.3951 - val_accuracy: 0.8353 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4044 - accuracy: 0.8267\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 33/40: loss=0.4049, accuracy=0.8264, val_loss=0.3813, val_accuracy=0.8353\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4049 - accuracy: 0.8264 - val_loss: 0.3813 - val_accuracy: 0.8353 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8153Epoch 34/40: loss=0.4067, accuracy=0.8146, val_loss=0.3775, val_accuracy=0.8369\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4067 - accuracy: 0.8146 - val_loss: 0.3775 - val_accuracy: 0.8369 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8250Epoch 35/40: loss=0.4034, accuracy=0.8247, val_loss=0.3801, val_accuracy=0.8353\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4034 - accuracy: 0.8247 - val_loss: 0.3801 - val_accuracy: 0.8353 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4097 - accuracy: 0.8215Epoch 36/40: loss=0.4095, accuracy=0.8216, val_loss=0.3744, val_accuracy=0.8386\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4095 - accuracy: 0.8216 - val_loss: 0.3744 - val_accuracy: 0.8386 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8337Epoch 37/40: loss=0.3907, accuracy=0.8340, val_loss=0.3873, val_accuracy=0.8311\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3907 - accuracy: 0.8340 - val_loss: 0.3873 - val_accuracy: 0.8311 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8362\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 38/40: loss=0.3808, accuracy=0.8361, val_loss=0.3775, val_accuracy=0.8336\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3808 - accuracy: 0.8361 - val_loss: 0.3775 - val_accuracy: 0.8336 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8292Epoch 39/40: loss=0.3912, accuracy=0.8293, val_loss=0.3782, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3912 - accuracy: 0.8293 - val_loss: 0.3782 - val_accuracy: 0.8377 - lr: 1.6000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8282Epoch 40/40: loss=0.4003, accuracy=0.8282, val_loss=0.3769, val_accuracy=0.8369\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.4003 - accuracy: 0.8282 - val_loss: 0.3769 - val_accuracy: 0.8369 - lr: 1.6000e-06\n",
      "Validation accuracy: 0.8451986908912659\n",
      "\n",
      "Best parameters found in initial grid search: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=64, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Best validation accuracy: 0.8451986908912659\n",
      "\n",
      "Refined Training Combination 1/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=64, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.30000000000000004, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9210 - accuracy: 0.5904Epoch 1/40: loss=0.9213, accuracy=0.5902, val_loss=0.6142, val_accuracy=0.6026\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 0.9213 - accuracy: 0.5902 - val_loss: 0.6142 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.6550Epoch 2/40: loss=0.7460, accuracy=0.6550, val_loss=1.2778, val_accuracy=0.6051\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7460 - accuracy: 0.6550 - val_loss: 1.2778 - val_accuracy: 0.6051 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7470 - accuracy: 0.6503Epoch 3/40: loss=0.7460, accuracy=0.6511, val_loss=0.4861, val_accuracy=0.7823\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7460 - accuracy: 0.6511 - val_loss: 0.4861 - val_accuracy: 0.7823 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7256 - accuracy: 0.6766Epoch 4/40: loss=0.7254, accuracy=0.6767, val_loss=0.5086, val_accuracy=0.7583\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7254 - accuracy: 0.6767 - val_loss: 0.5086 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7139 - accuracy: 0.6900Epoch 5/40: loss=0.7137, accuracy=0.6902, val_loss=1.1071, val_accuracy=0.4123\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7137 - accuracy: 0.6902 - val_loss: 1.1071 - val_accuracy: 0.4123 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6992 - accuracy: 0.6894Epoch 6/40: loss=0.6988, accuracy=0.6896, val_loss=0.9780, val_accuracy=0.6424\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6988 - accuracy: 0.6896 - val_loss: 0.9780 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.6847Epoch 7/40: loss=0.6922, accuracy=0.6846, val_loss=0.6487, val_accuracy=0.7127\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6922 - accuracy: 0.6846 - val_loss: 0.6487 - val_accuracy: 0.7127 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.6912\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.6932, accuracy=0.6912, val_loss=0.5534, val_accuracy=0.7326\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6932 - accuracy: 0.6912 - val_loss: 0.5534 - val_accuracy: 0.7326 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.7083Epoch 9/40: loss=0.6552, accuracy=0.7078, val_loss=0.4316, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6552 - accuracy: 0.7078 - val_loss: 0.4316 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5936 - accuracy: 0.7369Epoch 10/40: loss=0.5931, accuracy=0.7368, val_loss=0.5208, val_accuracy=0.7624\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5931 - accuracy: 0.7368 - val_loss: 0.5208 - val_accuracy: 0.7624 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5829 - accuracy: 0.7348Epoch 11/40: loss=0.5821, accuracy=0.7351, val_loss=0.5831, val_accuracy=0.7003\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5821 - accuracy: 0.7351 - val_loss: 0.5831 - val_accuracy: 0.7003 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.7564Epoch 12/40: loss=0.5447, accuracy=0.7566, val_loss=0.4294, val_accuracy=0.7988\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5447 - accuracy: 0.7566 - val_loss: 0.4294 - val_accuracy: 0.7988 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7571Epoch 13/40: loss=0.5320, accuracy=0.7570, val_loss=0.4178, val_accuracy=0.8063\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5320 - accuracy: 0.7570 - val_loss: 0.4178 - val_accuracy: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5113 - accuracy: 0.7575Epoch 14/40: loss=0.5115, accuracy=0.7575, val_loss=0.4132, val_accuracy=0.8063\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5115 - accuracy: 0.7575 - val_loss: 0.4132 - val_accuracy: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.7664Epoch 15/40: loss=0.5020, accuracy=0.7668, val_loss=0.5954, val_accuracy=0.7417\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5020 - accuracy: 0.7668 - val_loss: 0.5954 - val_accuracy: 0.7417 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4905 - accuracy: 0.7780Epoch 16/40: loss=0.4899, accuracy=0.7784, val_loss=0.4712, val_accuracy=0.7906\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4899 - accuracy: 0.7784 - val_loss: 0.4712 - val_accuracy: 0.7906 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.7762Epoch 17/40: loss=0.4848, accuracy=0.7763, val_loss=0.5236, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4848 - accuracy: 0.7763 - val_loss: 0.5236 - val_accuracy: 0.7641 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7791Epoch 18/40: loss=0.4722, accuracy=0.7790, val_loss=0.4427, val_accuracy=0.8063\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4722 - accuracy: 0.7790 - val_loss: 0.4427 - val_accuracy: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7892\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/40: loss=0.4671, accuracy=0.7889, val_loss=0.4668, val_accuracy=0.7657\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4671 - accuracy: 0.7889 - val_loss: 0.4668 - val_accuracy: 0.7657 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7993Epoch 20/40: loss=0.4428, accuracy=0.7993, val_loss=0.4093, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4428 - accuracy: 0.7993 - val_loss: 0.4093 - val_accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4537 - accuracy: 0.7950Epoch 21/40: loss=0.4533, accuracy=0.7953, val_loss=0.4029, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4533 - accuracy: 0.7953 - val_loss: 0.4029 - val_accuracy: 0.8071 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4380 - accuracy: 0.7938Epoch 22/40: loss=0.4373, accuracy=0.7943, val_loss=0.3833, val_accuracy=0.8303\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4373 - accuracy: 0.7943 - val_loss: 0.3833 - val_accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.7999Epoch 23/40: loss=0.4361, accuracy=0.7999, val_loss=0.3944, val_accuracy=0.8162\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4361 - accuracy: 0.7999 - val_loss: 0.3944 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.7984Epoch 24/40: loss=0.4330, accuracy=0.7984, val_loss=0.3986, val_accuracy=0.8171\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4330 - accuracy: 0.7984 - val_loss: 0.3986 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8142Epoch 25/40: loss=0.4183, accuracy=0.8144, val_loss=0.3784, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4183 - accuracy: 0.8144 - val_loss: 0.3784 - val_accuracy: 0.8328 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4138 - accuracy: 0.8100Epoch 26/40: loss=0.4140, accuracy=0.8096, val_loss=0.3945, val_accuracy=0.8212\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4140 - accuracy: 0.8096 - val_loss: 0.3945 - val_accuracy: 0.8212 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.8147Epoch 27/40: loss=0.4202, accuracy=0.8144, val_loss=0.3767, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4202 - accuracy: 0.8144 - val_loss: 0.3767 - val_accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8160Epoch 28/40: loss=0.4237, accuracy=0.8160, val_loss=0.3833, val_accuracy=0.8228\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4237 - accuracy: 0.8160 - val_loss: 0.3833 - val_accuracy: 0.8228 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8179Epoch 29/40: loss=0.4103, accuracy=0.8179, val_loss=0.3756, val_accuracy=0.8402\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4103 - accuracy: 0.8179 - val_loss: 0.3756 - val_accuracy: 0.8402 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.8180Epoch 30/40: loss=0.4064, accuracy=0.8179, val_loss=0.3817, val_accuracy=0.8336\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4064 - accuracy: 0.8179 - val_loss: 0.3817 - val_accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8223Epoch 31/40: loss=0.3997, accuracy=0.8226, val_loss=0.3689, val_accuracy=0.8402\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3997 - accuracy: 0.8226 - val_loss: 0.3689 - val_accuracy: 0.8402 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4093 - accuracy: 0.8245Epoch 32/40: loss=0.4087, accuracy=0.8249, val_loss=0.3789, val_accuracy=0.8303\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4087 - accuracy: 0.8249 - val_loss: 0.3789 - val_accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8270Epoch 33/40: loss=0.3941, accuracy=0.8270, val_loss=0.3624, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3941 - accuracy: 0.8270 - val_loss: 0.3624 - val_accuracy: 0.8411 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8321Epoch 34/40: loss=0.3876, accuracy=0.8324, val_loss=0.3616, val_accuracy=0.8435\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3876 - accuracy: 0.8324 - val_loss: 0.3616 - val_accuracy: 0.8435 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8302Epoch 35/40: loss=0.3888, accuracy=0.8301, val_loss=0.3856, val_accuracy=0.8253\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3888 - accuracy: 0.8301 - val_loss: 0.3856 - val_accuracy: 0.8253 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4005 - accuracy: 0.8264Epoch 36/40: loss=0.4007, accuracy=0.8264, val_loss=0.3824, val_accuracy=0.8311\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4007 - accuracy: 0.8264 - val_loss: 0.3824 - val_accuracy: 0.8311 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8308Epoch 37/40: loss=0.3831, accuracy=0.8311, val_loss=0.3866, val_accuracy=0.8295\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3831 - accuracy: 0.8311 - val_loss: 0.3866 - val_accuracy: 0.8295 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8341Epoch 38/40: loss=0.3794, accuracy=0.8344, val_loss=0.3885, val_accuracy=0.8320\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3794 - accuracy: 0.8344 - val_loss: 0.3885 - val_accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.8372\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 39/40: loss=0.3730, accuracy=0.8373, val_loss=0.3638, val_accuracy=0.8427\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3730 - accuracy: 0.8373 - val_loss: 0.3638 - val_accuracy: 0.8427 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8409Epoch 40/40: loss=0.3643, accuracy=0.8409, val_loss=0.3687, val_accuracy=0.8394\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3643 - accuracy: 0.8409 - val_loss: 0.3687 - val_accuracy: 0.8394 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.8435430526733398\n",
      "\n",
      "Refined Training Combination 2/50: num_residual_blocks=7, dropout_rate=0.5, learning_rate=0.002, filters=64, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.30000000000000004, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0902 - accuracy: 0.5706Epoch 1/40: loss=1.0902, accuracy=0.5708, val_loss=1.6464, val_accuracy=0.5993\n",
      "604/604 [==============================] - 17s 20ms/step - loss: 1.0902 - accuracy: 0.5708 - val_loss: 1.6464 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1018 - accuracy: 0.5851Epoch 2/40: loss=1.1008, accuracy=0.5855, val_loss=0.5808, val_accuracy=0.7459\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.1008 - accuracy: 0.5855 - val_loss: 0.5808 - val_accuracy: 0.7459 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0277 - accuracy: 0.6136Epoch 3/40: loss=1.0277, accuracy=0.6136, val_loss=1.0982, val_accuracy=0.4089\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0277 - accuracy: 0.6136 - val_loss: 1.0982 - val_accuracy: 0.4089 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9994 - accuracy: 0.6080Epoch 4/40: loss=0.9994, accuracy=0.6080, val_loss=0.6332, val_accuracy=0.6242\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.9994 - accuracy: 0.6080 - val_loss: 0.6332 - val_accuracy: 0.6242 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.6488Epoch 5/40: loss=0.9044, accuracy=0.6488, val_loss=0.7816, val_accuracy=0.5778\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9044 - accuracy: 0.6488 - val_loss: 0.7816 - val_accuracy: 0.5778 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9416 - accuracy: 0.6306Epoch 6/40: loss=0.9425, accuracy=0.6304, val_loss=0.5305, val_accuracy=0.7649\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.9425 - accuracy: 0.6304 - val_loss: 0.5305 - val_accuracy: 0.7649 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.6434Epoch 7/40: loss=0.8912, accuracy=0.6434, val_loss=0.7341, val_accuracy=0.6242\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8912 - accuracy: 0.6434 - val_loss: 0.7341 - val_accuracy: 0.6242 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8839 - accuracy: 0.6462Epoch 8/40: loss=0.8849, accuracy=0.6451, val_loss=1.0403, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8849 - accuracy: 0.6451 - val_loss: 1.0403 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8751 - accuracy: 0.6397Epoch 9/40: loss=0.8739, accuracy=0.6403, val_loss=0.5598, val_accuracy=0.7177\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8739 - accuracy: 0.6403 - val_loss: 0.5598 - val_accuracy: 0.7177 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.6459Epoch 10/40: loss=0.8480, accuracy=0.6459, val_loss=0.5411, val_accuracy=0.7649\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8480 - accuracy: 0.6459 - val_loss: 0.5411 - val_accuracy: 0.7649 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.6463\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 11/40: loss=0.8254, accuracy=0.6463, val_loss=1.1625, val_accuracy=0.6084\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8254 - accuracy: 0.6463 - val_loss: 1.1625 - val_accuracy: 0.6084 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7442 - accuracy: 0.6656Epoch 12/40: loss=0.7442, accuracy=0.6656, val_loss=0.5011, val_accuracy=0.7740\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7442 - accuracy: 0.6656 - val_loss: 0.5011 - val_accuracy: 0.7740 - lr: 4.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.6997Epoch 13/40: loss=0.6728, accuracy=0.6997, val_loss=0.4754, val_accuracy=0.7864\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6728 - accuracy: 0.6997 - val_loss: 0.4754 - val_accuracy: 0.7864 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6259 - accuracy: 0.7166Epoch 14/40: loss=0.6259, accuracy=0.7163, val_loss=0.5239, val_accuracy=0.7368\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6259 - accuracy: 0.7163 - val_loss: 0.5239 - val_accuracy: 0.7368 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5952 - accuracy: 0.7245Epoch 15/40: loss=0.5947, accuracy=0.7250, val_loss=0.4721, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5947 - accuracy: 0.7250 - val_loss: 0.4721 - val_accuracy: 0.7740 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5721 - accuracy: 0.7378Epoch 16/40: loss=0.5714, accuracy=0.7382, val_loss=0.5233, val_accuracy=0.7500\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5714 - accuracy: 0.7382 - val_loss: 0.5233 - val_accuracy: 0.7500 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5708 - accuracy: 0.7286Epoch 17/40: loss=0.5720, accuracy=0.7276, val_loss=0.4561, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5720 - accuracy: 0.7276 - val_loss: 0.4561 - val_accuracy: 0.7897 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.7394Epoch 18/40: loss=0.5606, accuracy=0.7392, val_loss=0.4547, val_accuracy=0.7947\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5606 - accuracy: 0.7392 - val_loss: 0.4547 - val_accuracy: 0.7947 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.7498Epoch 19/40: loss=0.5428, accuracy=0.7498, val_loss=0.5078, val_accuracy=0.7666\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5428 - accuracy: 0.7498 - val_loss: 0.5078 - val_accuracy: 0.7666 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.7411Epoch 20/40: loss=0.5494, accuracy=0.7411, val_loss=0.4604, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5494 - accuracy: 0.7411 - val_loss: 0.4604 - val_accuracy: 0.7856 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.7496Epoch 21/40: loss=0.5334, accuracy=0.7498, val_loss=0.6044, val_accuracy=0.6829\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5334 - accuracy: 0.7498 - val_loss: 0.6044 - val_accuracy: 0.6829 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.7483Epoch 22/40: loss=0.5397, accuracy=0.7490, val_loss=0.4684, val_accuracy=0.7815\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5397 - accuracy: 0.7490 - val_loss: 0.4684 - val_accuracy: 0.7815 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.7494\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 23/40: loss=0.5271, accuracy=0.7498, val_loss=0.5018, val_accuracy=0.7641\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5271 - accuracy: 0.7498 - val_loss: 0.5018 - val_accuracy: 0.7641 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7616Epoch 24/40: loss=0.5318, accuracy=0.7616, val_loss=0.4427, val_accuracy=0.7955\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5318 - accuracy: 0.7616 - val_loss: 0.4427 - val_accuracy: 0.7955 - lr: 8.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.7610Epoch 25/40: loss=0.5041, accuracy=0.7614, val_loss=0.4255, val_accuracy=0.8005\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5041 - accuracy: 0.7614 - val_loss: 0.4255 - val_accuracy: 0.8005 - lr: 8.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.7707Epoch 26/40: loss=0.5002, accuracy=0.7707, val_loss=0.4175, val_accuracy=0.8146\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5002 - accuracy: 0.7707 - val_loss: 0.4175 - val_accuracy: 0.8146 - lr: 8.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7724Epoch 27/40: loss=0.4929, accuracy=0.7724, val_loss=0.4178, val_accuracy=0.8088\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4929 - accuracy: 0.7724 - val_loss: 0.4178 - val_accuracy: 0.8088 - lr: 8.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.7653Epoch 28/40: loss=0.5049, accuracy=0.7653, val_loss=0.4130, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5049 - accuracy: 0.7653 - val_loss: 0.4130 - val_accuracy: 0.8096 - lr: 8.0000e-05\n",
      "Epoch 29/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4883 - accuracy: 0.7789Epoch 29/40: loss=0.4876, accuracy=0.7796, val_loss=0.4149, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4876 - accuracy: 0.7796 - val_loss: 0.4149 - val_accuracy: 0.8129 - lr: 8.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4922 - accuracy: 0.7718Epoch 30/40: loss=0.4920, accuracy=0.7719, val_loss=0.4224, val_accuracy=0.8088\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4920 - accuracy: 0.7719 - val_loss: 0.4224 - val_accuracy: 0.8088 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.7776Epoch 31/40: loss=0.4859, accuracy=0.7777, val_loss=0.4165, val_accuracy=0.8071\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4859 - accuracy: 0.7777 - val_loss: 0.4165 - val_accuracy: 0.8071 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.7755Epoch 32/40: loss=0.4896, accuracy=0.7755, val_loss=0.4214, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4896 - accuracy: 0.7755 - val_loss: 0.4214 - val_accuracy: 0.8079 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.7791Epoch 33/40: loss=0.4740, accuracy=0.7794, val_loss=0.4126, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4740 - accuracy: 0.7794 - val_loss: 0.4126 - val_accuracy: 0.8187 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7799Epoch 34/40: loss=0.4798, accuracy=0.7796, val_loss=0.4184, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4798 - accuracy: 0.7796 - val_loss: 0.4184 - val_accuracy: 0.8071 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.7781Epoch 35/40: loss=0.4783, accuracy=0.7781, val_loss=0.4138, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4783 - accuracy: 0.7781 - val_loss: 0.4138 - val_accuracy: 0.8113 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7761Epoch 36/40: loss=0.4807, accuracy=0.7759, val_loss=0.4148, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4807 - accuracy: 0.7759 - val_loss: 0.4148 - val_accuracy: 0.8071 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7805Epoch 37/40: loss=0.4740, accuracy=0.7808, val_loss=0.4197, val_accuracy=0.8079\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4740 - accuracy: 0.7808 - val_loss: 0.4197 - val_accuracy: 0.8079 - lr: 8.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.7763Epoch 38/40: loss=0.4782, accuracy=0.7763, val_loss=0.4118, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4782 - accuracy: 0.7763 - val_loss: 0.4118 - val_accuracy: 0.8113 - lr: 8.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7813Epoch 39/40: loss=0.4726, accuracy=0.7815, val_loss=0.4065, val_accuracy=0.8121\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4726 - accuracy: 0.7815 - val_loss: 0.4065 - val_accuracy: 0.8121 - lr: 8.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.7883Epoch 40/40: loss=0.4614, accuracy=0.7883, val_loss=0.4117, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4614 - accuracy: 0.7883 - val_loss: 0.4117 - val_accuracy: 0.8220 - lr: 8.0000e-05\n",
      "Validation accuracy: 0.8220198750495911\n",
      "\n",
      "Refined Training Combination 3/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.5, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.6275Epoch 1/40: loss=0.8136, accuracy=0.6275, val_loss=0.9724, val_accuracy=0.6018\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 0.8136 - accuracy: 0.6275 - val_loss: 0.9724 - val_accuracy: 0.6018 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.6818Epoch 2/40: loss=0.6877, accuracy=0.6819, val_loss=0.6412, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6877 - accuracy: 0.6819 - val_loss: 0.6412 - val_accuracy: 0.7012 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.7113Epoch 3/40: loss=0.6240, accuracy=0.7111, val_loss=1.0128, val_accuracy=0.6051\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6240 - accuracy: 0.7111 - val_loss: 1.0128 - val_accuracy: 0.6051 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5867 - accuracy: 0.7280Epoch 4/40: loss=0.5864, accuracy=0.7283, val_loss=0.4304, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5864 - accuracy: 0.7283 - val_loss: 0.4304 - val_accuracy: 0.8104 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7268Epoch 5/40: loss=0.5764, accuracy=0.7270, val_loss=0.4128, val_accuracy=0.8030\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5764 - accuracy: 0.7270 - val_loss: 0.4128 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.7552Epoch 6/40: loss=0.5442, accuracy=0.7548, val_loss=0.4637, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5442 - accuracy: 0.7548 - val_loss: 0.4637 - val_accuracy: 0.7881 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.7396Epoch 7/40: loss=0.5539, accuracy=0.7394, val_loss=0.4258, val_accuracy=0.7839\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5539 - accuracy: 0.7394 - val_loss: 0.4258 - val_accuracy: 0.7839 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.7560Epoch 8/40: loss=0.5411, accuracy=0.7560, val_loss=0.4470, val_accuracy=0.8038\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5411 - accuracy: 0.7560 - val_loss: 0.4470 - val_accuracy: 0.8038 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5154 - accuracy: 0.7662Epoch 9/40: loss=0.5157, accuracy=0.7661, val_loss=0.4117, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5157 - accuracy: 0.7661 - val_loss: 0.4117 - val_accuracy: 0.8121 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.7737Epoch 10/40: loss=0.5089, accuracy=0.7740, val_loss=0.3600, val_accuracy=0.8493\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5089 - accuracy: 0.7740 - val_loss: 0.3600 - val_accuracy: 0.8493 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.7726Epoch 11/40: loss=0.5128, accuracy=0.7728, val_loss=0.3997, val_accuracy=0.8212\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5128 - accuracy: 0.7728 - val_loss: 0.3997 - val_accuracy: 0.8212 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.7803Epoch 12/40: loss=0.4898, accuracy=0.7804, val_loss=0.4994, val_accuracy=0.7483\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4898 - accuracy: 0.7804 - val_loss: 0.4994 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.7881Epoch 13/40: loss=0.4863, accuracy=0.7879, val_loss=0.4396, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4863 - accuracy: 0.7879 - val_loss: 0.4396 - val_accuracy: 0.7889 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.7736Epoch 14/40: loss=0.4855, accuracy=0.7736, val_loss=0.4744, val_accuracy=0.7947\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4855 - accuracy: 0.7736 - val_loss: 0.4744 - val_accuracy: 0.7947 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.7904\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/40: loss=0.4746, accuracy=0.7904, val_loss=0.5228, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4746 - accuracy: 0.7904 - val_loss: 0.5228 - val_accuracy: 0.7599 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4269 - accuracy: 0.8155Epoch 16/40: loss=0.4267, accuracy=0.8156, val_loss=0.3027, val_accuracy=0.8593\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4267 - accuracy: 0.8156 - val_loss: 0.3027 - val_accuracy: 0.8593 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8218Epoch 17/40: loss=0.4182, accuracy=0.8218, val_loss=0.2839, val_accuracy=0.8841\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4182 - accuracy: 0.8218 - val_loss: 0.2839 - val_accuracy: 0.8841 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8469Epoch 18/40: loss=0.3594, accuracy=0.8469, val_loss=0.3017, val_accuracy=0.8692\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3594 - accuracy: 0.8469 - val_loss: 0.3017 - val_accuracy: 0.8692 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8421Epoch 19/40: loss=0.3658, accuracy=0.8421, val_loss=0.2969, val_accuracy=0.8684\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3658 - accuracy: 0.8421 - val_loss: 0.2969 - val_accuracy: 0.8684 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.8534Epoch 20/40: loss=0.3531, accuracy=0.8537, val_loss=0.3332, val_accuracy=0.8460\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3531 - accuracy: 0.8537 - val_loss: 0.3332 - val_accuracy: 0.8460 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3239 - accuracy: 0.8688Epoch 21/40: loss=0.3237, accuracy=0.8688, val_loss=0.3449, val_accuracy=0.8377\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3237 - accuracy: 0.8688 - val_loss: 0.3449 - val_accuracy: 0.8377 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8721Epoch 22/40: loss=0.3123, accuracy=0.8727, val_loss=0.2643, val_accuracy=0.8957\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3123 - accuracy: 0.8727 - val_loss: 0.2643 - val_accuracy: 0.8957 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.8557Epoch 23/40: loss=0.3268, accuracy=0.8560, val_loss=0.2590, val_accuracy=0.9015\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3268 - accuracy: 0.8560 - val_loss: 0.2590 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8667Epoch 24/40: loss=0.3143, accuracy=0.8667, val_loss=0.2970, val_accuracy=0.8634\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3143 - accuracy: 0.8667 - val_loss: 0.2970 - val_accuracy: 0.8634 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2957 - accuracy: 0.8789Epoch 25/40: loss=0.2951, accuracy=0.8793, val_loss=0.2399, val_accuracy=0.9156\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.2951 - accuracy: 0.8793 - val_loss: 0.2399 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.8764Epoch 26/40: loss=0.3015, accuracy=0.8764, val_loss=0.2520, val_accuracy=0.8990\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3015 - accuracy: 0.8764 - val_loss: 0.2520 - val_accuracy: 0.8990 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.8862Epoch 27/40: loss=0.2848, accuracy=0.8862, val_loss=0.2950, val_accuracy=0.8709\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.2848 - accuracy: 0.8862 - val_loss: 0.2950 - val_accuracy: 0.8709 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.8837Epoch 28/40: loss=0.2826, accuracy=0.8841, val_loss=0.2504, val_accuracy=0.8998\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.2826 - accuracy: 0.8841 - val_loss: 0.2504 - val_accuracy: 0.8998 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.8963Epoch 29/40: loss=0.2604, accuracy=0.8963, val_loss=0.2576, val_accuracy=0.8982\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2604 - accuracy: 0.8963 - val_loss: 0.2576 - val_accuracy: 0.8982 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.8900Epoch 30/40: loss=0.2678, accuracy=0.8903, val_loss=0.2083, val_accuracy=0.9156\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.2678 - accuracy: 0.8903 - val_loss: 0.2083 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9022Epoch 31/40: loss=0.2536, accuracy=0.9019, val_loss=0.2228, val_accuracy=0.9131\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.2536 - accuracy: 0.9019 - val_loss: 0.2228 - val_accuracy: 0.9131 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.8995Epoch 32/40: loss=0.2465, accuracy=0.8996, val_loss=0.2211, val_accuracy=0.9065\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.2465 - accuracy: 0.8996 - val_loss: 0.2211 - val_accuracy: 0.9065 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9008Epoch 33/40: loss=0.2502, accuracy=0.9011, val_loss=0.2355, val_accuracy=0.9114\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2502 - accuracy: 0.9011 - val_loss: 0.2355 - val_accuracy: 0.9114 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9156Epoch 34/40: loss=0.2201, accuracy=0.9156, val_loss=0.1789, val_accuracy=0.9354\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.2201 - accuracy: 0.9156 - val_loss: 0.1789 - val_accuracy: 0.9354 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2370 - accuracy: 0.9107Epoch 35/40: loss=0.2370, accuracy=0.9106, val_loss=0.1932, val_accuracy=0.9263\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2370 - accuracy: 0.9106 - val_loss: 0.1932 - val_accuracy: 0.9263 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9080Epoch 36/40: loss=0.2342, accuracy=0.9083, val_loss=0.1816, val_accuracy=0.9396\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.2342 - accuracy: 0.9083 - val_loss: 0.1816 - val_accuracy: 0.9396 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9056Epoch 37/40: loss=0.2379, accuracy=0.9056, val_loss=0.1783, val_accuracy=0.9247\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.2379 - accuracy: 0.9056 - val_loss: 0.1783 - val_accuracy: 0.9247 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9172Epoch 38/40: loss=0.2117, accuracy=0.9172, val_loss=0.1788, val_accuracy=0.9338\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.2117 - accuracy: 0.9172 - val_loss: 0.1788 - val_accuracy: 0.9338 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9105Epoch 39/40: loss=0.2222, accuracy=0.9106, val_loss=0.1751, val_accuracy=0.9396\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.2222 - accuracy: 0.9106 - val_loss: 0.1751 - val_accuracy: 0.9396 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9184Epoch 40/40: loss=0.2138, accuracy=0.9180, val_loss=0.1737, val_accuracy=0.9346\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.2138 - accuracy: 0.9180 - val_loss: 0.1737 - val_accuracy: 0.9346 - lr: 1.0000e-04\n",
      "Validation accuracy: 0.9395695328712463\n",
      "\n",
      "Refined Training Combination 4/50: num_residual_blocks=8, dropout_rate=0.5, learning_rate=0.0005, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.5, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1914 - accuracy: 0.5704Epoch 1/40: loss=1.1914, accuracy=0.5704, val_loss=0.7326, val_accuracy=0.6507\n",
      "604/604 [==============================] - 16s 22ms/step - loss: 1.1914 - accuracy: 0.5704 - val_loss: 0.7326 - val_accuracy: 0.6507 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6659 - accuracy: 0.6739Epoch 2/40: loss=0.6656, accuracy=0.6740, val_loss=0.7368, val_accuracy=0.7127\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6656 - accuracy: 0.6740 - val_loss: 0.7368 - val_accuracy: 0.7127 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6163 - accuracy: 0.7035Epoch 3/40: loss=0.6160, accuracy=0.7034, val_loss=0.4869, val_accuracy=0.7583\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6160 - accuracy: 0.7034 - val_loss: 0.4869 - val_accuracy: 0.7583 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7161Epoch 4/40: loss=0.5986, accuracy=0.7161, val_loss=0.5637, val_accuracy=0.7384\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5986 - accuracy: 0.7161 - val_loss: 0.5637 - val_accuracy: 0.7384 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.7001Epoch 5/40: loss=0.6089, accuracy=0.7001, val_loss=0.6238, val_accuracy=0.7384\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6089 - accuracy: 0.7001 - val_loss: 0.6238 - val_accuracy: 0.7384 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.7192Epoch 6/40: loss=0.5934, accuracy=0.7192, val_loss=0.4953, val_accuracy=0.7657\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5934 - accuracy: 0.7192 - val_loss: 0.4953 - val_accuracy: 0.7657 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5910 - accuracy: 0.7299Epoch 7/40: loss=0.5911, accuracy=0.7297, val_loss=0.9213, val_accuracy=0.4967\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5911 - accuracy: 0.7297 - val_loss: 0.9213 - val_accuracy: 0.4967 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5885 - accuracy: 0.7243\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/40: loss=0.5884, accuracy=0.7239, val_loss=0.9351, val_accuracy=0.6250\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5884 - accuracy: 0.7239 - val_loss: 0.9351 - val_accuracy: 0.6250 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7473Epoch 9/40: loss=0.5380, accuracy=0.7475, val_loss=0.5248, val_accuracy=0.7657\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5380 - accuracy: 0.7475 - val_loss: 0.5248 - val_accuracy: 0.7657 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7502Epoch 10/40: loss=0.5137, accuracy=0.7504, val_loss=0.5690, val_accuracy=0.7566\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5137 - accuracy: 0.7504 - val_loss: 0.5690 - val_accuracy: 0.7566 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.7705Epoch 11/40: loss=0.4941, accuracy=0.7705, val_loss=0.5810, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4941 - accuracy: 0.7705 - val_loss: 0.5810 - val_accuracy: 0.7318 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.7685Epoch 12/40: loss=0.4868, accuracy=0.7686, val_loss=0.4247, val_accuracy=0.8162\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4868 - accuracy: 0.7686 - val_loss: 0.4247 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.7707Epoch 13/40: loss=0.4750, accuracy=0.7707, val_loss=0.4886, val_accuracy=0.7930\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4750 - accuracy: 0.7707 - val_loss: 0.4886 - val_accuracy: 0.7930 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.7846Epoch 14/40: loss=0.4778, accuracy=0.7846, val_loss=0.4462, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4778 - accuracy: 0.7846 - val_loss: 0.4462 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7853Epoch 15/40: loss=0.4589, accuracy=0.7854, val_loss=0.6185, val_accuracy=0.7459\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4589 - accuracy: 0.7854 - val_loss: 0.6185 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.7794Epoch 16/40: loss=0.4670, accuracy=0.7794, val_loss=0.5378, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4670 - accuracy: 0.7794 - val_loss: 0.5378 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4629 - accuracy: 0.7874\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 17/40: loss=0.4627, accuracy=0.7877, val_loss=0.5284, val_accuracy=0.7848\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4627 - accuracy: 0.7877 - val_loss: 0.5284 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.7961Epoch 18/40: loss=0.4357, accuracy=0.7966, val_loss=0.4789, val_accuracy=0.7906\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4357 - accuracy: 0.7966 - val_loss: 0.4789 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8015Epoch 19/40: loss=0.4403, accuracy=0.8015, val_loss=0.4786, val_accuracy=0.8088\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4403 - accuracy: 0.8015 - val_loss: 0.4786 - val_accuracy: 0.8088 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.7960Epoch 20/40: loss=0.4408, accuracy=0.7962, val_loss=0.4371, val_accuracy=0.8096\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4408 - accuracy: 0.7962 - val_loss: 0.4371 - val_accuracy: 0.8096 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.7978Epoch 21/40: loss=0.4328, accuracy=0.7978, val_loss=0.5009, val_accuracy=0.7864\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4328 - accuracy: 0.7978 - val_loss: 0.5009 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8026\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 22/40: loss=0.4398, accuracy=0.8026, val_loss=0.4681, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4398 - accuracy: 0.8026 - val_loss: 0.4681 - val_accuracy: 0.8113 - lr: 2.0000e-05\n",
      "Epoch 22: early stopping\n",
      "Validation accuracy: 0.8162251710891724\n",
      "\n",
      "Refined Training Combination 5/50: num_residual_blocks=7, dropout_rate=0.5, learning_rate=0.001, filters=64, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.5, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9353 - accuracy: 0.5646Epoch 1/40: loss=0.9355, accuracy=0.5650, val_loss=0.7299, val_accuracy=0.5993\n",
      "604/604 [==============================] - 16s 22ms/step - loss: 0.9355 - accuracy: 0.5650 - val_loss: 0.7299 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.6200Epoch 2/40: loss=0.8033, accuracy=0.6200, val_loss=0.5667, val_accuracy=0.6962\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8033 - accuracy: 0.6200 - val_loss: 0.5667 - val_accuracy: 0.6962 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7615 - accuracy: 0.6470Epoch 3/40: loss=0.7602, accuracy=0.6478, val_loss=0.5890, val_accuracy=0.7028\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7602 - accuracy: 0.6478 - val_loss: 0.5890 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8033 - accuracy: 0.6184Epoch 4/40: loss=0.8032, accuracy=0.6182, val_loss=0.5839, val_accuracy=0.6970\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8032 - accuracy: 0.6182 - val_loss: 0.5839 - val_accuracy: 0.6970 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7633 - accuracy: 0.6466Epoch 5/40: loss=0.7627, accuracy=0.6467, val_loss=0.8752, val_accuracy=0.5488\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7627 - accuracy: 0.6467 - val_loss: 0.8752 - val_accuracy: 0.5488 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7397 - accuracy: 0.6483Epoch 6/40: loss=0.7401, accuracy=0.6482, val_loss=1.0150, val_accuracy=0.4296\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7401 - accuracy: 0.6482 - val_loss: 1.0150 - val_accuracy: 0.4296 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7508 - accuracy: 0.6481\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/40: loss=0.7495, accuracy=0.6486, val_loss=0.6026, val_accuracy=0.6714\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7495 - accuracy: 0.6486 - val_loss: 0.6026 - val_accuracy: 0.6714 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6829 - accuracy: 0.6846Epoch 8/40: loss=0.6825, accuracy=0.6850, val_loss=0.4634, val_accuracy=0.7666\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6825 - accuracy: 0.6850 - val_loss: 0.4634 - val_accuracy: 0.7666 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.7063Epoch 9/40: loss=0.6246, accuracy=0.7063, val_loss=0.4714, val_accuracy=0.7790\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6246 - accuracy: 0.7063 - val_loss: 0.4714 - val_accuracy: 0.7790 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5966 - accuracy: 0.7236Epoch 10/40: loss=0.5955, accuracy=0.7239, val_loss=0.4475, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5955 - accuracy: 0.7239 - val_loss: 0.4475 - val_accuracy: 0.7881 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5826 - accuracy: 0.7184Epoch 11/40: loss=0.5817, accuracy=0.7190, val_loss=0.4962, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5817 - accuracy: 0.7190 - val_loss: 0.4962 - val_accuracy: 0.7641 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5622 - accuracy: 0.7353Epoch 12/40: loss=0.5612, accuracy=0.7357, val_loss=0.4893, val_accuracy=0.7690\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5612 - accuracy: 0.7357 - val_loss: 0.4893 - val_accuracy: 0.7690 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.7512Epoch 13/40: loss=0.5317, accuracy=0.7517, val_loss=0.4299, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5317 - accuracy: 0.7517 - val_loss: 0.4299 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7515Epoch 14/40: loss=0.5284, accuracy=0.7514, val_loss=0.4597, val_accuracy=0.7815\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5284 - accuracy: 0.7514 - val_loss: 0.4597 - val_accuracy: 0.7815 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.7529Epoch 15/40: loss=0.5250, accuracy=0.7527, val_loss=0.4444, val_accuracy=0.7831\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5250 - accuracy: 0.7527 - val_loss: 0.4444 - val_accuracy: 0.7831 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7442Epoch 16/40: loss=0.5215, accuracy=0.7442, val_loss=0.4917, val_accuracy=0.7848\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5215 - accuracy: 0.7442 - val_loss: 0.4917 - val_accuracy: 0.7848 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.7535Epoch 17/40: loss=0.5195, accuracy=0.7537, val_loss=0.4369, val_accuracy=0.8013\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5195 - accuracy: 0.7537 - val_loss: 0.4369 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.7610\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 18/40: loss=0.5054, accuracy=0.7610, val_loss=0.4430, val_accuracy=0.8013\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5054 - accuracy: 0.7610 - val_loss: 0.4430 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.7752Epoch 19/40: loss=0.4888, accuracy=0.7752, val_loss=0.4266, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4888 - accuracy: 0.7752 - val_loss: 0.4266 - val_accuracy: 0.8079 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.7851Epoch 20/40: loss=0.4832, accuracy=0.7852, val_loss=0.4394, val_accuracy=0.8022\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4832 - accuracy: 0.7852 - val_loss: 0.4394 - val_accuracy: 0.8022 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.7879Epoch 21/40: loss=0.4598, accuracy=0.7881, val_loss=0.4072, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4598 - accuracy: 0.7881 - val_loss: 0.4072 - val_accuracy: 0.8179 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.7879Epoch 22/40: loss=0.4677, accuracy=0.7879, val_loss=0.4163, val_accuracy=0.8113\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.4677 - accuracy: 0.7879 - val_loss: 0.4163 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.7864Epoch 23/40: loss=0.4618, accuracy=0.7864, val_loss=0.3988, val_accuracy=0.8212\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4618 - accuracy: 0.7864 - val_loss: 0.3988 - val_accuracy: 0.8212 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.7838Epoch 24/40: loss=0.4673, accuracy=0.7831, val_loss=0.4141, val_accuracy=0.8096\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4673 - accuracy: 0.7831 - val_loss: 0.4141 - val_accuracy: 0.8096 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4565 - accuracy: 0.7886Epoch 25/40: loss=0.4563, accuracy=0.7887, val_loss=0.4055, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4563 - accuracy: 0.7887 - val_loss: 0.4055 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.7883Epoch 26/40: loss=0.4600, accuracy=0.7887, val_loss=0.3908, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4600 - accuracy: 0.7887 - val_loss: 0.3908 - val_accuracy: 0.8137 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.7934Epoch 27/40: loss=0.4426, accuracy=0.7939, val_loss=0.4147, val_accuracy=0.8088\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4426 - accuracy: 0.7939 - val_loss: 0.4147 - val_accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4422 - accuracy: 0.7978Epoch 28/40: loss=0.4419, accuracy=0.7976, val_loss=0.4033, val_accuracy=0.8104\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4419 - accuracy: 0.7976 - val_loss: 0.4033 - val_accuracy: 0.8104 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.8046Epoch 29/40: loss=0.4379, accuracy=0.8050, val_loss=0.4059, val_accuracy=0.8121\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4379 - accuracy: 0.8050 - val_loss: 0.4059 - val_accuracy: 0.8121 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.7934Epoch 30/40: loss=0.4505, accuracy=0.7939, val_loss=0.3937, val_accuracy=0.8195\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4505 - accuracy: 0.7939 - val_loss: 0.3937 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8026\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 31/40: loss=0.4290, accuracy=0.8032, val_loss=0.3931, val_accuracy=0.8162\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4290 - accuracy: 0.8032 - val_loss: 0.3931 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.8052Epoch 32/40: loss=0.4189, accuracy=0.8055, val_loss=0.4038, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4189 - accuracy: 0.8055 - val_loss: 0.4038 - val_accuracy: 0.8113 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8071Epoch 33/40: loss=0.4313, accuracy=0.8071, val_loss=0.3959, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4313 - accuracy: 0.8071 - val_loss: 0.3959 - val_accuracy: 0.8162 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4262 - accuracy: 0.8067Epoch 34/40: loss=0.4261, accuracy=0.8067, val_loss=0.3957, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4261 - accuracy: 0.8067 - val_loss: 0.3957 - val_accuracy: 0.8162 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8035Epoch 35/40: loss=0.4332, accuracy=0.8036, val_loss=0.3995, val_accuracy=0.8137\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.4332 - accuracy: 0.8036 - val_loss: 0.3995 - val_accuracy: 0.8137 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4216 - accuracy: 0.8047\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36/40: loss=0.4216, accuracy=0.8046, val_loss=0.4041, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4216 - accuracy: 0.8046 - val_loss: 0.4041 - val_accuracy: 0.8113 - lr: 8.0000e-06\n",
      "Epoch 36: early stopping\n",
      "Validation accuracy: 0.8211920261383057\n",
      "\n",
      "Refined Training Combination 6/50: num_residual_blocks=8, dropout_rate=0.30000000000000004, learning_rate=0.002, filters=32, kernel_size=5, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.5126 - accuracy: 0.4992Epoch 1/40: loss=1.5116, accuracy=0.4992, val_loss=0.8321, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 24ms/step - loss: 1.5116 - accuracy: 0.4992 - val_loss: 0.8321 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.0473 - accuracy: 0.5004Epoch 2/40: loss=1.0466, accuracy=0.5002, val_loss=0.6733, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 1.0466 - accuracy: 0.5002 - val_loss: 0.6733 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0253 - accuracy: 0.5156Epoch 3/40: loss=1.0241, accuracy=0.5161, val_loss=0.6647, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 1.0241 - accuracy: 0.5161 - val_loss: 0.6647 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9668 - accuracy: 0.5462Epoch 4/40: loss=0.9668, accuracy=0.5462, val_loss=1.2137, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9668 - accuracy: 0.5462 - val_loss: 1.2137 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.6092Epoch 5/40: loss=0.8703, accuracy=0.6097, val_loss=0.8798, val_accuracy=0.6382\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8703 - accuracy: 0.6097 - val_loss: 0.8798 - val_accuracy: 0.6382 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8867 - accuracy: 0.5889Epoch 6/40: loss=0.8862, accuracy=0.5892, val_loss=1.7991, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8862 - accuracy: 0.5892 - val_loss: 1.7991 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8265 - accuracy: 0.6198Epoch 7/40: loss=0.8263, accuracy=0.6196, val_loss=1.4751, val_accuracy=0.4644\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8263 - accuracy: 0.6196 - val_loss: 1.4751 - val_accuracy: 0.4644 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8132 - accuracy: 0.6304Epoch 8/40: loss=0.8148, accuracy=0.6304, val_loss=0.6340, val_accuracy=0.6457\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8148 - accuracy: 0.6304 - val_loss: 0.6340 - val_accuracy: 0.6457 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7922 - accuracy: 0.6430Epoch 9/40: loss=0.7921, accuracy=0.6430, val_loss=0.8756, val_accuracy=0.5265\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7921 - accuracy: 0.6430 - val_loss: 0.8756 - val_accuracy: 0.5265 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7647 - accuracy: 0.6487Epoch 10/40: loss=0.7646, accuracy=0.6486, val_loss=0.8960, val_accuracy=0.4892\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7646 - accuracy: 0.6486 - val_loss: 0.8960 - val_accuracy: 0.4892 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7285 - accuracy: 0.6642Epoch 11/40: loss=0.7279, accuracy=0.6643, val_loss=0.9080, val_accuracy=0.6300\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7279 - accuracy: 0.6643 - val_loss: 0.9080 - val_accuracy: 0.6300 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.6362Epoch 12/40: loss=0.7679, accuracy=0.6362, val_loss=0.9798, val_accuracy=0.6813\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7679 - accuracy: 0.6362 - val_loss: 0.9798 - val_accuracy: 0.6813 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7396 - accuracy: 0.6480\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 13/40: loss=0.7402, accuracy=0.6476, val_loss=1.1763, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7402 - accuracy: 0.6476 - val_loss: 1.1763 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6853 - accuracy: 0.6763Epoch 14/40: loss=0.6844, accuracy=0.6769, val_loss=0.7172, val_accuracy=0.6267\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6844 - accuracy: 0.6769 - val_loss: 0.7172 - val_accuracy: 0.6267 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6400 - accuracy: 0.6971Epoch 15/40: loss=0.6395, accuracy=0.6972, val_loss=0.4882, val_accuracy=0.7715\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6395 - accuracy: 0.6972 - val_loss: 0.4882 - val_accuracy: 0.7715 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.7067Epoch 16/40: loss=0.6124, accuracy=0.7065, val_loss=0.5817, val_accuracy=0.7210\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6124 - accuracy: 0.7065 - val_loss: 0.5817 - val_accuracy: 0.7210 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7183Epoch 17/40: loss=0.5757, accuracy=0.7185, val_loss=0.5309, val_accuracy=0.7467\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5757 - accuracy: 0.7185 - val_loss: 0.5309 - val_accuracy: 0.7467 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5712 - accuracy: 0.7209Epoch 18/40: loss=0.5709, accuracy=0.7210, val_loss=0.4694, val_accuracy=0.7757\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5709 - accuracy: 0.7210 - val_loss: 0.4694 - val_accuracy: 0.7757 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.7132Epoch 19/40: loss=0.5821, accuracy=0.7132, val_loss=0.4980, val_accuracy=0.7773\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5821 - accuracy: 0.7132 - val_loss: 0.4980 - val_accuracy: 0.7773 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5587 - accuracy: 0.7253Epoch 20/40: loss=0.5584, accuracy=0.7254, val_loss=0.4716, val_accuracy=0.7740\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5584 - accuracy: 0.7254 - val_loss: 0.4716 - val_accuracy: 0.7740 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.7239Epoch 21/40: loss=0.5535, accuracy=0.7239, val_loss=0.6185, val_accuracy=0.7070\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5535 - accuracy: 0.7239 - val_loss: 0.6185 - val_accuracy: 0.7070 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7488Epoch 22/40: loss=0.5317, accuracy=0.7488, val_loss=0.4589, val_accuracy=0.7889\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5317 - accuracy: 0.7488 - val_loss: 0.4589 - val_accuracy: 0.7889 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7303Epoch 23/40: loss=0.5460, accuracy=0.7305, val_loss=0.6107, val_accuracy=0.7243\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5460 - accuracy: 0.7305 - val_loss: 0.6107 - val_accuracy: 0.7243 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.7450Epoch 24/40: loss=0.5357, accuracy=0.7452, val_loss=0.4819, val_accuracy=0.7781\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5357 - accuracy: 0.7452 - val_loss: 0.4819 - val_accuracy: 0.7781 - lr: 4.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7372Epoch 25/40: loss=0.5374, accuracy=0.7372, val_loss=0.4692, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5374 - accuracy: 0.7372 - val_loss: 0.4692 - val_accuracy: 0.7806 - lr: 4.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.7498Epoch 26/40: loss=0.5234, accuracy=0.7498, val_loss=0.4491, val_accuracy=0.7897\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5234 - accuracy: 0.7498 - val_loss: 0.4491 - val_accuracy: 0.7897 - lr: 4.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5300 - accuracy: 0.7425Epoch 27/40: loss=0.5297, accuracy=0.7428, val_loss=0.4510, val_accuracy=0.7839\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5297 - accuracy: 0.7428 - val_loss: 0.4510 - val_accuracy: 0.7839 - lr: 4.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.7598Epoch 28/40: loss=0.5124, accuracy=0.7599, val_loss=0.4579, val_accuracy=0.7955\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5124 - accuracy: 0.7599 - val_loss: 0.4579 - val_accuracy: 0.7955 - lr: 4.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.7488Epoch 29/40: loss=0.5192, accuracy=0.7488, val_loss=0.4833, val_accuracy=0.7856\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5192 - accuracy: 0.7488 - val_loss: 0.4833 - val_accuracy: 0.7856 - lr: 4.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.7529Epoch 30/40: loss=0.5200, accuracy=0.7529, val_loss=0.5345, val_accuracy=0.7699\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5200 - accuracy: 0.7529 - val_loss: 0.5345 - val_accuracy: 0.7699 - lr: 4.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5056 - accuracy: 0.7608Epoch 31/40: loss=0.5052, accuracy=0.7610, val_loss=0.4245, val_accuracy=0.8171\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5052 - accuracy: 0.7610 - val_loss: 0.4245 - val_accuracy: 0.8171 - lr: 4.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.7737Epoch 32/40: loss=0.4991, accuracy=0.7736, val_loss=0.4765, val_accuracy=0.8022\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4991 - accuracy: 0.7736 - val_loss: 0.4765 - val_accuracy: 0.8022 - lr: 4.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5070 - accuracy: 0.7627Epoch 33/40: loss=0.5068, accuracy=0.7630, val_loss=0.4201, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5068 - accuracy: 0.7630 - val_loss: 0.4201 - val_accuracy: 0.8113 - lr: 4.0000e-04\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4992 - accuracy: 0.7616Epoch 34/40: loss=0.4993, accuracy=0.7616, val_loss=0.4540, val_accuracy=0.7848\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4993 - accuracy: 0.7616 - val_loss: 0.4540 - val_accuracy: 0.7848 - lr: 4.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.7612Epoch 35/40: loss=0.4996, accuracy=0.7618, val_loss=0.4475, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4996 - accuracy: 0.7618 - val_loss: 0.4475 - val_accuracy: 0.8063 - lr: 4.0000e-04\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.7624Epoch 36/40: loss=0.4985, accuracy=0.7624, val_loss=0.6393, val_accuracy=0.7003\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4985 - accuracy: 0.7624 - val_loss: 0.6393 - val_accuracy: 0.7003 - lr: 4.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.7672Epoch 37/40: loss=0.4953, accuracy=0.7674, val_loss=0.4933, val_accuracy=0.7657\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4953 - accuracy: 0.7674 - val_loss: 0.4933 - val_accuracy: 0.7657 - lr: 4.0000e-04\n",
      "Epoch 38/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4940 - accuracy: 0.7677Epoch 38/40: loss=0.4937, accuracy=0.7680, val_loss=0.4117, val_accuracy=0.8171\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4937 - accuracy: 0.7680 - val_loss: 0.4117 - val_accuracy: 0.8171 - lr: 4.0000e-04\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.7802Epoch 39/40: loss=0.4832, accuracy=0.7802, val_loss=0.5381, val_accuracy=0.7674\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4832 - accuracy: 0.7802 - val_loss: 0.5381 - val_accuracy: 0.7674 - lr: 4.0000e-04\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.7777Epoch 40/40: loss=0.4816, accuracy=0.7777, val_loss=0.4474, val_accuracy=0.8005\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4816 - accuracy: 0.7777 - val_loss: 0.4474 - val_accuracy: 0.8005 - lr: 4.0000e-04\n",
      "Validation accuracy: 0.817052960395813\n",
      "\n",
      "Refined Training Combination 7/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.002, filters=128, kernel_size=5, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.4, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.4491 - accuracy: 0.5043Epoch 1/40: loss=1.4491, accuracy=0.5043, val_loss=0.8337, val_accuracy=0.4007\n",
      "604/604 [==============================] - 23s 34ms/step - loss: 1.4491 - accuracy: 0.5043 - val_loss: 0.8337 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1038 - accuracy: 0.4813Epoch 2/40: loss=1.1040, accuracy=0.4810, val_loss=0.7682, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 1.1040 - accuracy: 0.4810 - val_loss: 0.7682 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1028 - accuracy: 0.5033Epoch 3/40: loss=1.1028, accuracy=0.5035, val_loss=0.7655, val_accuracy=0.5993\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 1.1028 - accuracy: 0.5035 - val_loss: 0.7655 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0658 - accuracy: 0.4965Epoch 4/40: loss=1.0663, accuracy=0.4967, val_loss=0.7164, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 1.0663 - accuracy: 0.4967 - val_loss: 0.7164 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0453 - accuracy: 0.5012Epoch 5/40: loss=1.0448, accuracy=0.5014, val_loss=0.7081, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 1.0448 - accuracy: 0.5014 - val_loss: 0.7081 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0405 - accuracy: 0.4975Epoch 6/40: loss=1.0405, accuracy=0.4975, val_loss=0.6853, val_accuracy=0.5993\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 1.0405 - accuracy: 0.4975 - val_loss: 0.6853 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0210 - accuracy: 0.4934Epoch 7/40: loss=1.0207, accuracy=0.4936, val_loss=0.7235, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 1.0207 - accuracy: 0.4936 - val_loss: 0.7235 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9827 - accuracy: 0.5066Epoch 8/40: loss=0.9830, accuracy=0.5066, val_loss=0.7316, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.9830 - accuracy: 0.5066 - val_loss: 0.7316 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9667 - accuracy: 0.4956Epoch 9/40: loss=0.9663, accuracy=0.4957, val_loss=0.7912, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.9663 - accuracy: 0.4957 - val_loss: 0.7912 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9479 - accuracy: 0.4967Epoch 10/40: loss=0.9469, accuracy=0.4973, val_loss=0.7379, val_accuracy=0.5993\n",
      "604/604 [==============================] - 20s 32ms/step - loss: 0.9469 - accuracy: 0.4973 - val_loss: 0.7379 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9374 - accuracy: 0.4967\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 11/40: loss=0.9372, accuracy=0.4965, val_loss=0.7013, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.9372 - accuracy: 0.4965 - val_loss: 0.7013 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8809 - accuracy: 0.4963Epoch 12/40: loss=0.8809, accuracy=0.4959, val_loss=0.7091, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.8809 - accuracy: 0.4959 - val_loss: 0.7091 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8300 - accuracy: 0.5056Epoch 13/40: loss=0.8301, accuracy=0.5056, val_loss=0.7027, val_accuracy=0.4007\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.8301 - accuracy: 0.5056 - val_loss: 0.7027 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7981 - accuracy: 0.4874Epoch 14/40: loss=0.7983, accuracy=0.4874, val_loss=0.7083, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7983 - accuracy: 0.4874 - val_loss: 0.7083 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7673 - accuracy: 0.4927Epoch 15/40: loss=0.7674, accuracy=0.4930, val_loss=0.6986, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7674 - accuracy: 0.4930 - val_loss: 0.6986 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7513 - accuracy: 0.4963\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 16/40: loss=0.7513, accuracy=0.4961, val_loss=0.6963, val_accuracy=0.4007\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7513 - accuracy: 0.4961 - val_loss: 0.6963 - val_accuracy: 0.4007 - lr: 4.0000e-04\n",
      "Epoch 16: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Refined Training Combination 8/50: num_residual_blocks=7, dropout_rate=0.30000000000000004, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8350 - accuracy: 0.6207Epoch 1/40: loss=0.8350, accuracy=0.6207, val_loss=0.6869, val_accuracy=0.6680\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.8350 - accuracy: 0.6207 - val_loss: 0.6869 - val_accuracy: 0.6680 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6988 - accuracy: 0.6715Epoch 2/40: loss=0.6978, accuracy=0.6720, val_loss=0.5467, val_accuracy=0.6962\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6978 - accuracy: 0.6720 - val_loss: 0.5467 - val_accuracy: 0.6962 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7141Epoch 3/40: loss=0.6190, accuracy=0.7136, val_loss=0.9862, val_accuracy=0.4793\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6190 - accuracy: 0.7136 - val_loss: 0.9862 - val_accuracy: 0.4793 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6079 - accuracy: 0.7104Epoch 4/40: loss=0.6073, accuracy=0.7107, val_loss=0.4546, val_accuracy=0.7798\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6073 - accuracy: 0.7107 - val_loss: 0.4546 - val_accuracy: 0.7798 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5733 - accuracy: 0.7247Epoch 5/40: loss=0.5733, accuracy=0.7248, val_loss=0.4796, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5733 - accuracy: 0.7248 - val_loss: 0.4796 - val_accuracy: 0.7624 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7291Epoch 6/40: loss=0.5759, accuracy=0.7293, val_loss=0.5256, val_accuracy=0.7450\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5759 - accuracy: 0.7293 - val_loss: 0.5256 - val_accuracy: 0.7450 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5684 - accuracy: 0.7313Epoch 7/40: loss=0.5681, accuracy=0.7312, val_loss=0.8146, val_accuracy=0.6084\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5681 - accuracy: 0.7312 - val_loss: 0.8146 - val_accuracy: 0.6084 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5561 - accuracy: 0.7394Epoch 8/40: loss=0.5565, accuracy=0.7392, val_loss=0.5787, val_accuracy=0.6954\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5565 - accuracy: 0.7392 - val_loss: 0.5787 - val_accuracy: 0.6954 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.7405\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.5622, accuracy=0.7405, val_loss=0.5575, val_accuracy=0.6954\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5622 - accuracy: 0.7405 - val_loss: 0.5575 - val_accuracy: 0.6954 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5316 - accuracy: 0.7492Epoch 10/40: loss=0.5312, accuracy=0.7494, val_loss=0.4076, val_accuracy=0.8212\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5312 - accuracy: 0.7494 - val_loss: 0.4076 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7717Epoch 11/40: loss=0.4905, accuracy=0.7717, val_loss=0.4824, val_accuracy=0.7724\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4905 - accuracy: 0.7717 - val_loss: 0.4824 - val_accuracy: 0.7724 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.7963Epoch 12/40: loss=0.4625, accuracy=0.7962, val_loss=0.4850, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4625 - accuracy: 0.7962 - val_loss: 0.4850 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.7790Epoch 13/40: loss=0.4782, accuracy=0.7790, val_loss=0.4758, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4782 - accuracy: 0.7790 - val_loss: 0.4758 - val_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.8014Epoch 14/40: loss=0.4408, accuracy=0.8013, val_loss=0.4639, val_accuracy=0.7765\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4408 - accuracy: 0.8013 - val_loss: 0.4639 - val_accuracy: 0.7765 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8033Epoch 15/40: loss=0.4393, accuracy=0.8032, val_loss=0.4041, val_accuracy=0.8104\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4393 - accuracy: 0.8032 - val_loss: 0.4041 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4326 - accuracy: 0.7965Epoch 16/40: loss=0.4323, accuracy=0.7966, val_loss=0.3904, val_accuracy=0.8154\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4323 - accuracy: 0.7966 - val_loss: 0.3904 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8162Epoch 17/40: loss=0.4143, accuracy=0.8168, val_loss=0.3641, val_accuracy=0.8344\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4143 - accuracy: 0.8168 - val_loss: 0.3641 - val_accuracy: 0.8344 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.8167Epoch 18/40: loss=0.4040, accuracy=0.8160, val_loss=0.3438, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4040 - accuracy: 0.8160 - val_loss: 0.3438 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4156 - accuracy: 0.8115Epoch 19/40: loss=0.4159, accuracy=0.8111, val_loss=0.3415, val_accuracy=0.8427\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4159 - accuracy: 0.8111 - val_loss: 0.3415 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8124Epoch 20/40: loss=0.4048, accuracy=0.8125, val_loss=0.3935, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.3935 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3957 - accuracy: 0.8214Epoch 21/40: loss=0.3950, accuracy=0.8220, val_loss=0.3605, val_accuracy=0.8303\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3950 - accuracy: 0.8220 - val_loss: 0.3605 - val_accuracy: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.8234Epoch 22/40: loss=0.3936, accuracy=0.8235, val_loss=0.4062, val_accuracy=0.8195\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3936 - accuracy: 0.8235 - val_loss: 0.4062 - val_accuracy: 0.8195 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8354Epoch 23/40: loss=0.3762, accuracy=0.8357, val_loss=0.3392, val_accuracy=0.8477\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3762 - accuracy: 0.8357 - val_loss: 0.3392 - val_accuracy: 0.8477 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8232Epoch 24/40: loss=0.3874, accuracy=0.8228, val_loss=0.3464, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3874 - accuracy: 0.8228 - val_loss: 0.3464 - val_accuracy: 0.8411 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8306Epoch 25/40: loss=0.3732, accuracy=0.8309, val_loss=0.3148, val_accuracy=0.8576\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3732 - accuracy: 0.8309 - val_loss: 0.3148 - val_accuracy: 0.8576 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8431Epoch 26/40: loss=0.3643, accuracy=0.8433, val_loss=0.3840, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.3643 - accuracy: 0.8433 - val_loss: 0.3840 - val_accuracy: 0.8204 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8455Epoch 27/40: loss=0.3594, accuracy=0.8452, val_loss=0.3931, val_accuracy=0.8121\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3594 - accuracy: 0.8452 - val_loss: 0.3931 - val_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8451Epoch 28/40: loss=0.3592, accuracy=0.8450, val_loss=0.3929, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3592 - accuracy: 0.8450 - val_loss: 0.3929 - val_accuracy: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8456Epoch 29/40: loss=0.3587, accuracy=0.8456, val_loss=0.3109, val_accuracy=0.8609\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3587 - accuracy: 0.8456 - val_loss: 0.3109 - val_accuracy: 0.8609 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8495Epoch 30/40: loss=0.3520, accuracy=0.8495, val_loss=0.3079, val_accuracy=0.8634\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3520 - accuracy: 0.8495 - val_loss: 0.3079 - val_accuracy: 0.8634 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8449Epoch 31/40: loss=0.3508, accuracy=0.8452, val_loss=0.3847, val_accuracy=0.8154\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3508 - accuracy: 0.8452 - val_loss: 0.3847 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.8599Epoch 32/40: loss=0.3248, accuracy=0.8599, val_loss=0.5462, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3248 - accuracy: 0.8599 - val_loss: 0.5462 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8545Epoch 33/40: loss=0.3429, accuracy=0.8545, val_loss=0.3300, val_accuracy=0.8535\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3429 - accuracy: 0.8545 - val_loss: 0.3300 - val_accuracy: 0.8535 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.8520Epoch 34/40: loss=0.3348, accuracy=0.8520, val_loss=0.4327, val_accuracy=0.8286\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3348 - accuracy: 0.8520 - val_loss: 0.4327 - val_accuracy: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8653Epoch 35/40: loss=0.3207, accuracy=0.8653, val_loss=0.3050, val_accuracy=0.8717\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3207 - accuracy: 0.8653 - val_loss: 0.3050 - val_accuracy: 0.8717 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3134 - accuracy: 0.8677Epoch 36/40: loss=0.3132, accuracy=0.8678, val_loss=0.3330, val_accuracy=0.8626\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3132 - accuracy: 0.8678 - val_loss: 0.3330 - val_accuracy: 0.8626 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8702Epoch 37/40: loss=0.3037, accuracy=0.8704, val_loss=0.3177, val_accuracy=0.8618\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3037 - accuracy: 0.8704 - val_loss: 0.3177 - val_accuracy: 0.8618 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3229 - accuracy: 0.8619Epoch 38/40: loss=0.3233, accuracy=0.8615, val_loss=0.3169, val_accuracy=0.8584\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3233 - accuracy: 0.8615 - val_loss: 0.3169 - val_accuracy: 0.8584 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.8686Epoch 39/40: loss=0.3062, accuracy=0.8690, val_loss=0.3159, val_accuracy=0.8642\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3062 - accuracy: 0.8690 - val_loss: 0.3159 - val_accuracy: 0.8642 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8744\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 40/40: loss=0.2983, accuracy=0.8744, val_loss=0.4004, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.2983 - accuracy: 0.8744 - val_loss: 0.4004 - val_accuracy: 0.8146 - lr: 1.0000e-04\n",
      "Validation accuracy: 0.871688723564148\n",
      "\n",
      "Refined Training Combination 9/50: num_residual_blocks=9, dropout_rate=0.5, learning_rate=0.0005, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8549 - accuracy: 0.6144Epoch 1/40: loss=0.8548, accuracy=0.6140, val_loss=0.7068, val_accuracy=0.6416\n",
      "604/604 [==============================] - 16s 20ms/step - loss: 0.8548 - accuracy: 0.6140 - val_loss: 0.7068 - val_accuracy: 0.6416 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.6784Epoch 2/40: loss=0.6820, accuracy=0.6780, val_loss=0.6000, val_accuracy=0.6978\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6820 - accuracy: 0.6780 - val_loss: 0.6000 - val_accuracy: 0.6978 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.7032Epoch 3/40: loss=0.6299, accuracy=0.7032, val_loss=0.4595, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6299 - accuracy: 0.7032 - val_loss: 0.4595 - val_accuracy: 0.7864 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.7072Epoch 4/40: loss=0.6169, accuracy=0.7072, val_loss=0.5263, val_accuracy=0.7434\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6169 - accuracy: 0.7072 - val_loss: 0.5263 - val_accuracy: 0.7434 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5883 - accuracy: 0.7216Epoch 5/40: loss=0.5884, accuracy=0.7216, val_loss=0.4444, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5884 - accuracy: 0.7216 - val_loss: 0.4444 - val_accuracy: 0.7790 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.7263Epoch 6/40: loss=0.5801, accuracy=0.7262, val_loss=0.4641, val_accuracy=0.7839\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5801 - accuracy: 0.7262 - val_loss: 0.4641 - val_accuracy: 0.7839 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5697 - accuracy: 0.7346Epoch 7/40: loss=0.5692, accuracy=0.7345, val_loss=0.4510, val_accuracy=0.8030\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5692 - accuracy: 0.7345 - val_loss: 0.4510 - val_accuracy: 0.8030 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5812 - accuracy: 0.7251Epoch 8/40: loss=0.5820, accuracy=0.7250, val_loss=0.4646, val_accuracy=0.7674\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5820 - accuracy: 0.7250 - val_loss: 0.4646 - val_accuracy: 0.7674 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.7400Epoch 9/40: loss=0.5512, accuracy=0.7401, val_loss=0.4747, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5512 - accuracy: 0.7401 - val_loss: 0.4747 - val_accuracy: 0.7624 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5858 - accuracy: 0.7253\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/40: loss=0.5859, accuracy=0.7252, val_loss=1.1080, val_accuracy=0.6175\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5859 - accuracy: 0.7252 - val_loss: 1.1080 - val_accuracy: 0.6175 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.7566Epoch 11/40: loss=0.5293, accuracy=0.7566, val_loss=0.4327, val_accuracy=0.7947\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5293 - accuracy: 0.7566 - val_loss: 0.4327 - val_accuracy: 0.7947 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.7608Epoch 12/40: loss=0.5137, accuracy=0.7608, val_loss=0.3680, val_accuracy=0.8270\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5137 - accuracy: 0.7608 - val_loss: 0.3680 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4994 - accuracy: 0.7763Epoch 13/40: loss=0.4992, accuracy=0.7763, val_loss=0.4056, val_accuracy=0.8030\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4992 - accuracy: 0.7763 - val_loss: 0.4056 - val_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.7782Epoch 14/40: loss=0.4785, accuracy=0.7779, val_loss=0.4000, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4785 - accuracy: 0.7779 - val_loss: 0.4000 - val_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.7838Epoch 15/40: loss=0.4756, accuracy=0.7841, val_loss=0.3859, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4756 - accuracy: 0.7841 - val_loss: 0.3859 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7982Epoch 16/40: loss=0.4397, accuracy=0.7982, val_loss=0.3737, val_accuracy=0.8270\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4397 - accuracy: 0.7982 - val_loss: 0.3737 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4436 - accuracy: 0.7961\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 17/40: loss=0.4436, accuracy=0.7957, val_loss=0.3797, val_accuracy=0.8187\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4436 - accuracy: 0.7957 - val_loss: 0.3797 - val_accuracy: 0.8187 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8065Epoch 18/40: loss=0.4271, accuracy=0.8067, val_loss=0.3663, val_accuracy=0.8402\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4271 - accuracy: 0.8067 - val_loss: 0.3663 - val_accuracy: 0.8402 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8168Epoch 19/40: loss=0.4148, accuracy=0.8168, val_loss=0.3624, val_accuracy=0.8419\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4148 - accuracy: 0.8168 - val_loss: 0.3624 - val_accuracy: 0.8419 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8219Epoch 20/40: loss=0.4018, accuracy=0.8220, val_loss=0.3595, val_accuracy=0.8320\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4018 - accuracy: 0.8220 - val_loss: 0.3595 - val_accuracy: 0.8320 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4214 - accuracy: 0.8185Epoch 21/40: loss=0.4219, accuracy=0.8183, val_loss=0.3633, val_accuracy=0.8320\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4219 - accuracy: 0.8183 - val_loss: 0.3633 - val_accuracy: 0.8320 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4128 - accuracy: 0.8151Epoch 22/40: loss=0.4125, accuracy=0.8152, val_loss=0.3670, val_accuracy=0.8344\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4125 - accuracy: 0.8152 - val_loss: 0.3670 - val_accuracy: 0.8344 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8139Epoch 23/40: loss=0.4230, accuracy=0.8139, val_loss=0.3562, val_accuracy=0.8377\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4230 - accuracy: 0.8139 - val_loss: 0.3562 - val_accuracy: 0.8377 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8291Epoch 24/40: loss=0.3988, accuracy=0.8291, val_loss=0.3628, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.3988 - accuracy: 0.8291 - val_loss: 0.3628 - val_accuracy: 0.8328 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4036 - accuracy: 0.8228Epoch 25/40: loss=0.4039, accuracy=0.8222, val_loss=0.3545, val_accuracy=0.8344\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4039 - accuracy: 0.8222 - val_loss: 0.3545 - val_accuracy: 0.8344 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4015 - accuracy: 0.8245Epoch 26/40: loss=0.4011, accuracy=0.8247, val_loss=0.3458, val_accuracy=0.8394\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4011 - accuracy: 0.8247 - val_loss: 0.3458 - val_accuracy: 0.8394 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8272Epoch 27/40: loss=0.4027, accuracy=0.8272, val_loss=0.3493, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4027 - accuracy: 0.8272 - val_loss: 0.3493 - val_accuracy: 0.8377 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3952 - accuracy: 0.8213Epoch 28/40: loss=0.3956, accuracy=0.8210, val_loss=0.3551, val_accuracy=0.8295\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3956 - accuracy: 0.8210 - val_loss: 0.3551 - val_accuracy: 0.8295 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8193Epoch 29/40: loss=0.4008, accuracy=0.8193, val_loss=0.3433, val_accuracy=0.8444\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4008 - accuracy: 0.8193 - val_loss: 0.3433 - val_accuracy: 0.8444 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8230Epoch 30/40: loss=0.3904, accuracy=0.8233, val_loss=0.3415, val_accuracy=0.8477\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3904 - accuracy: 0.8233 - val_loss: 0.3415 - val_accuracy: 0.8477 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8284Epoch 31/40: loss=0.3826, accuracy=0.8280, val_loss=0.3432, val_accuracy=0.8444\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.3826 - accuracy: 0.8280 - val_loss: 0.3432 - val_accuracy: 0.8444 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8188Epoch 32/40: loss=0.3995, accuracy=0.8187, val_loss=0.3374, val_accuracy=0.8460\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3995 - accuracy: 0.8187 - val_loss: 0.3374 - val_accuracy: 0.8460 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.8284Epoch 33/40: loss=0.3774, accuracy=0.8282, val_loss=0.3389, val_accuracy=0.8435\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3774 - accuracy: 0.8282 - val_loss: 0.3389 - val_accuracy: 0.8435 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8346Epoch 34/40: loss=0.3813, accuracy=0.8344, val_loss=0.3327, val_accuracy=0.8510\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3813 - accuracy: 0.8344 - val_loss: 0.3327 - val_accuracy: 0.8510 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8301Epoch 35/40: loss=0.3854, accuracy=0.8299, val_loss=0.3377, val_accuracy=0.8477\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3854 - accuracy: 0.8299 - val_loss: 0.3377 - val_accuracy: 0.8477 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8368Epoch 36/40: loss=0.3739, accuracy=0.8367, val_loss=0.3290, val_accuracy=0.8526\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3739 - accuracy: 0.8367 - val_loss: 0.3290 - val_accuracy: 0.8526 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8349Epoch 37/40: loss=0.3786, accuracy=0.8349, val_loss=0.3303, val_accuracy=0.8493\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.3786 - accuracy: 0.8349 - val_loss: 0.3303 - val_accuracy: 0.8493 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.8462Epoch 38/40: loss=0.3625, accuracy=0.8458, val_loss=0.3319, val_accuracy=0.8510\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3625 - accuracy: 0.8458 - val_loss: 0.3319 - val_accuracy: 0.8510 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8361Epoch 39/40: loss=0.3838, accuracy=0.8359, val_loss=0.3416, val_accuracy=0.8502\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3838 - accuracy: 0.8359 - val_loss: 0.3416 - val_accuracy: 0.8502 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8428Epoch 40/40: loss=0.3639, accuracy=0.8427, val_loss=0.3371, val_accuracy=0.8502\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3639 - accuracy: 0.8427 - val_loss: 0.3371 - val_accuracy: 0.8502 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8526490330696106\n",
      "\n",
      "Refined Training Combination 10/50: num_residual_blocks=8, dropout_rate=0.5, learning_rate=0.001, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.1415 - accuracy: 0.5954Epoch 1/40: loss=1.1415, accuracy=0.5954, val_loss=1.4596, val_accuracy=0.6134\n",
      "604/604 [==============================] - 16s 20ms/step - loss: 1.1415 - accuracy: 0.5954 - val_loss: 1.4596 - val_accuracy: 0.6134 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7686 - accuracy: 0.6399Epoch 2/40: loss=0.7683, accuracy=0.6399, val_loss=0.6481, val_accuracy=0.5762\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7683 - accuracy: 0.6399 - val_loss: 0.6481 - val_accuracy: 0.5762 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7229 - accuracy: 0.6624Epoch 3/40: loss=0.7226, accuracy=0.6623, val_loss=1.2123, val_accuracy=0.6614\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7226 - accuracy: 0.6623 - val_loss: 1.2123 - val_accuracy: 0.6614 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.6606Epoch 4/40: loss=0.7209, accuracy=0.6598, val_loss=0.6570, val_accuracy=0.6672\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7209 - accuracy: 0.6598 - val_loss: 0.6570 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.6811Epoch 5/40: loss=0.6888, accuracy=0.6811, val_loss=0.4669, val_accuracy=0.7707\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6888 - accuracy: 0.6811 - val_loss: 0.4669 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6851 - accuracy: 0.6833Epoch 6/40: loss=0.6851, accuracy=0.6834, val_loss=1.2436, val_accuracy=0.4023\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6851 - accuracy: 0.6834 - val_loss: 1.2436 - val_accuracy: 0.4023 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6566 - accuracy: 0.6923Epoch 7/40: loss=0.6566, accuracy=0.6923, val_loss=1.8081, val_accuracy=0.4180\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6566 - accuracy: 0.6923 - val_loss: 1.8081 - val_accuracy: 0.4180 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.6827Epoch 8/40: loss=0.6820, accuracy=0.6823, val_loss=1.1448, val_accuracy=0.4222\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6820 - accuracy: 0.6823 - val_loss: 1.1448 - val_accuracy: 0.4222 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.6869Epoch 9/40: loss=0.6557, accuracy=0.6869, val_loss=0.5703, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6557 - accuracy: 0.6869 - val_loss: 0.5703 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.6947\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.6482, accuracy=0.6947, val_loss=0.5780, val_accuracy=0.7425\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6482 - accuracy: 0.6947 - val_loss: 0.5780 - val_accuracy: 0.7425 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5764 - accuracy: 0.7255Epoch 11/40: loss=0.5760, accuracy=0.7256, val_loss=0.7177, val_accuracy=0.6382\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5760 - accuracy: 0.7256 - val_loss: 0.7177 - val_accuracy: 0.6382 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7469Epoch 12/40: loss=0.5386, accuracy=0.7469, val_loss=0.4193, val_accuracy=0.8212\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5386 - accuracy: 0.7469 - val_loss: 0.4193 - val_accuracy: 0.8212 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.7610Epoch 13/40: loss=0.5126, accuracy=0.7610, val_loss=0.4990, val_accuracy=0.7632\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5126 - accuracy: 0.7610 - val_loss: 0.4990 - val_accuracy: 0.7632 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.7603Epoch 14/40: loss=0.5065, accuracy=0.7603, val_loss=0.4254, val_accuracy=0.8030\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5065 - accuracy: 0.7603 - val_loss: 0.4254 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5020 - accuracy: 0.7664Epoch 15/40: loss=0.5025, accuracy=0.7661, val_loss=0.4084, val_accuracy=0.8088\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5025 - accuracy: 0.7661 - val_loss: 0.4084 - val_accuracy: 0.8088 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.7772Epoch 16/40: loss=0.4846, accuracy=0.7769, val_loss=0.5364, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4846 - accuracy: 0.7769 - val_loss: 0.5364 - val_accuracy: 0.7641 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.7772Epoch 17/40: loss=0.4846, accuracy=0.7775, val_loss=0.5074, val_accuracy=0.7831\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4846 - accuracy: 0.7775 - val_loss: 0.5074 - val_accuracy: 0.7831 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7827Epoch 18/40: loss=0.4686, accuracy=0.7827, val_loss=0.4712, val_accuracy=0.7897\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4686 - accuracy: 0.7827 - val_loss: 0.4712 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.7724Epoch 19/40: loss=0.4859, accuracy=0.7728, val_loss=0.5398, val_accuracy=0.7533\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4859 - accuracy: 0.7728 - val_loss: 0.5398 - val_accuracy: 0.7533 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.7772\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 20/40: loss=0.4729, accuracy=0.7773, val_loss=0.7665, val_accuracy=0.6656\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4729 - accuracy: 0.7773 - val_loss: 0.7665 - val_accuracy: 0.6656 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7805Epoch 21/40: loss=0.4574, accuracy=0.7806, val_loss=0.4955, val_accuracy=0.7839\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4574 - accuracy: 0.7806 - val_loss: 0.4955 - val_accuracy: 0.7839 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.7861Epoch 22/40: loss=0.4540, accuracy=0.7862, val_loss=0.5870, val_accuracy=0.7475\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4540 - accuracy: 0.7862 - val_loss: 0.5870 - val_accuracy: 0.7475 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.8007Epoch 23/40: loss=0.4468, accuracy=0.8007, val_loss=0.6157, val_accuracy=0.7384\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4468 - accuracy: 0.8007 - val_loss: 0.6157 - val_accuracy: 0.7384 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.7946Epoch 24/40: loss=0.4439, accuracy=0.7945, val_loss=0.5732, val_accuracy=0.7442\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4439 - accuracy: 0.7945 - val_loss: 0.5732 - val_accuracy: 0.7442 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.7955\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 25/40: loss=0.4463, accuracy=0.7955, val_loss=0.6009, val_accuracy=0.7401\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4463 - accuracy: 0.7955 - val_loss: 0.6009 - val_accuracy: 0.7401 - lr: 4.0000e-05\n",
      "Epoch 25: early stopping\n",
      "Validation accuracy: 0.8211920261383057\n",
      "\n",
      "Refined Training Combination 11/50: num_residual_blocks=9, dropout_rate=0.5, learning_rate=0.002, filters=32, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "  6/604 [..............................] - ETA: 23s - loss: 2.7084 - accuracy: 0.3958WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0224s vs `on_train_batch_end` time: 0.0234s). Check your callbacks.\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.3421 - accuracy: 0.5605Epoch 1/40: loss=1.3409, accuracy=0.5604, val_loss=0.7064, val_accuracy=0.6714\n",
      "604/604 [==============================] - 18s 26ms/step - loss: 1.3409 - accuracy: 0.5604 - val_loss: 0.7064 - val_accuracy: 0.6714 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9650 - accuracy: 0.6337Epoch 2/40: loss=0.9645, accuracy=0.6337, val_loss=2.0097, val_accuracy=0.4023\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9645 - accuracy: 0.6337 - val_loss: 2.0097 - val_accuracy: 0.4023 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9126 - accuracy: 0.6250Epoch 3/40: loss=0.9135, accuracy=0.6250, val_loss=1.6368, val_accuracy=0.6175\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.9135 - accuracy: 0.6250 - val_loss: 1.6368 - val_accuracy: 0.6175 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8552 - accuracy: 0.6375Epoch 4/40: loss=0.8544, accuracy=0.6374, val_loss=0.8229, val_accuracy=0.4735\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8544 - accuracy: 0.6374 - val_loss: 0.8229 - val_accuracy: 0.4735 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7912 - accuracy: 0.6524Epoch 5/40: loss=0.7908, accuracy=0.6525, val_loss=0.6026, val_accuracy=0.7310\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7908 - accuracy: 0.6525 - val_loss: 0.6026 - val_accuracy: 0.7310 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7947 - accuracy: 0.6385Epoch 6/40: loss=0.7954, accuracy=0.6385, val_loss=0.7206, val_accuracy=0.5315\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7954 - accuracy: 0.6385 - val_loss: 0.7206 - val_accuracy: 0.5315 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7913 - accuracy: 0.6287Epoch 7/40: loss=0.7906, accuracy=0.6293, val_loss=1.1243, val_accuracy=0.6142\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7906 - accuracy: 0.6293 - val_loss: 1.1243 - val_accuracy: 0.6142 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7825 - accuracy: 0.6420Epoch 8/40: loss=0.7825, accuracy=0.6420, val_loss=0.6387, val_accuracy=0.6680\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7825 - accuracy: 0.6420 - val_loss: 0.6387 - val_accuracy: 0.6680 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7693 - accuracy: 0.6443Epoch 9/40: loss=0.7694, accuracy=0.6442, val_loss=0.6669, val_accuracy=0.6970\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7694 - accuracy: 0.6442 - val_loss: 0.6669 - val_accuracy: 0.6970 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7388 - accuracy: 0.6584\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 10/40: loss=0.7384, accuracy=0.6585, val_loss=1.3348, val_accuracy=0.5298\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7384 - accuracy: 0.6585 - val_loss: 1.3348 - val_accuracy: 0.5298 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.7003Epoch 11/40: loss=0.6641, accuracy=0.7003, val_loss=0.5362, val_accuracy=0.7409\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6641 - accuracy: 0.7003 - val_loss: 0.5362 - val_accuracy: 0.7409 - lr: 4.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.7129Epoch 12/40: loss=0.6111, accuracy=0.7132, val_loss=0.5483, val_accuracy=0.7467\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6111 - accuracy: 0.7132 - val_loss: 0.5483 - val_accuracy: 0.7467 - lr: 4.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.7101Epoch 13/40: loss=0.6024, accuracy=0.7101, val_loss=0.4670, val_accuracy=0.7806\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6024 - accuracy: 0.7101 - val_loss: 0.4670 - val_accuracy: 0.7806 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5666 - accuracy: 0.7353Epoch 14/40: loss=0.5670, accuracy=0.7351, val_loss=0.6567, val_accuracy=0.6829\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5670 - accuracy: 0.7351 - val_loss: 0.6567 - val_accuracy: 0.6829 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5597 - accuracy: 0.7370Epoch 15/40: loss=0.5597, accuracy=0.7370, val_loss=0.4383, val_accuracy=0.7964\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5597 - accuracy: 0.7370 - val_loss: 0.4383 - val_accuracy: 0.7964 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5577 - accuracy: 0.7344Epoch 16/40: loss=0.5577, accuracy=0.7345, val_loss=0.5174, val_accuracy=0.7856\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5577 - accuracy: 0.7345 - val_loss: 0.5174 - val_accuracy: 0.7856 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5388 - accuracy: 0.7415Epoch 17/40: loss=0.5393, accuracy=0.7413, val_loss=0.4781, val_accuracy=0.7930\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5393 - accuracy: 0.7413 - val_loss: 0.4781 - val_accuracy: 0.7930 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.7461Epoch 18/40: loss=0.5309, accuracy=0.7459, val_loss=0.4908, val_accuracy=0.7823\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5309 - accuracy: 0.7459 - val_loss: 0.4908 - val_accuracy: 0.7823 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.7519Epoch 19/40: loss=0.5243, accuracy=0.7517, val_loss=0.7656, val_accuracy=0.6498\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5243 - accuracy: 0.7517 - val_loss: 0.7656 - val_accuracy: 0.6498 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7510\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 20/40: loss=0.5350, accuracy=0.7512, val_loss=0.4961, val_accuracy=0.7939\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5350 - accuracy: 0.7512 - val_loss: 0.4961 - val_accuracy: 0.7939 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5226 - accuracy: 0.7529Epoch 21/40: loss=0.5224, accuracy=0.7527, val_loss=0.5555, val_accuracy=0.7566\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5224 - accuracy: 0.7527 - val_loss: 0.5555 - val_accuracy: 0.7566 - lr: 8.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.7664Epoch 22/40: loss=0.5039, accuracy=0.7659, val_loss=0.4178, val_accuracy=0.8137\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5039 - accuracy: 0.7659 - val_loss: 0.4178 - val_accuracy: 0.8137 - lr: 8.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5117 - accuracy: 0.7620Epoch 23/40: loss=0.5114, accuracy=0.7624, val_loss=0.4132, val_accuracy=0.8195\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5114 - accuracy: 0.7624 - val_loss: 0.4132 - val_accuracy: 0.8195 - lr: 8.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.7724Epoch 24/40: loss=0.4961, accuracy=0.7724, val_loss=0.4916, val_accuracy=0.7980\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4961 - accuracy: 0.7724 - val_loss: 0.4916 - val_accuracy: 0.7980 - lr: 8.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4915 - accuracy: 0.7740Epoch 25/40: loss=0.4916, accuracy=0.7738, val_loss=0.4572, val_accuracy=0.8046\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4916 - accuracy: 0.7738 - val_loss: 0.4572 - val_accuracy: 0.8046 - lr: 8.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.7709Epoch 26/40: loss=0.4979, accuracy=0.7709, val_loss=0.4501, val_accuracy=0.7997\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4979 - accuracy: 0.7709 - val_loss: 0.4501 - val_accuracy: 0.7997 - lr: 8.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.7757Epoch 27/40: loss=0.4868, accuracy=0.7763, val_loss=0.4695, val_accuracy=0.7947\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4868 - accuracy: 0.7763 - val_loss: 0.4695 - val_accuracy: 0.7947 - lr: 8.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.7769\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 28/40: loss=0.4893, accuracy=0.7773, val_loss=0.4716, val_accuracy=0.7922\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4893 - accuracy: 0.7773 - val_loss: 0.4716 - val_accuracy: 0.7922 - lr: 8.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.7826Epoch 29/40: loss=0.4774, accuracy=0.7825, val_loss=0.4399, val_accuracy=0.8038\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4774 - accuracy: 0.7825 - val_loss: 0.4399 - val_accuracy: 0.8038 - lr: 1.6000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4829 - accuracy: 0.7747Epoch 30/40: loss=0.4829, accuracy=0.7746, val_loss=0.4482, val_accuracy=0.8046\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4829 - accuracy: 0.7746 - val_loss: 0.4482 - val_accuracy: 0.8046 - lr: 1.6000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.7784Epoch 31/40: loss=0.4739, accuracy=0.7784, val_loss=0.4370, val_accuracy=0.8022\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4739 - accuracy: 0.7784 - val_loss: 0.4370 - val_accuracy: 0.8022 - lr: 1.6000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7745Epoch 32/40: loss=0.4949, accuracy=0.7740, val_loss=0.4417, val_accuracy=0.8022\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4949 - accuracy: 0.7740 - val_loss: 0.4417 - val_accuracy: 0.8022 - lr: 1.6000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.7766\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 33/40: loss=0.4782, accuracy=0.7767, val_loss=0.4357, val_accuracy=0.8038\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4782 - accuracy: 0.7767 - val_loss: 0.4357 - val_accuracy: 0.8038 - lr: 1.6000e-05\n",
      "Epoch 33: early stopping\n",
      "Validation accuracy: 0.8195364475250244\n",
      "\n",
      "Refined Training Combination 12/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=64, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2612 - accuracy: 0.5832Epoch 1/40: loss=1.2612, accuracy=0.5832, val_loss=0.5259, val_accuracy=0.7616\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 1.2612 - accuracy: 0.5832 - val_loss: 0.5259 - val_accuracy: 0.7616 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6376 - accuracy: 0.6825Epoch 2/40: loss=0.6383, accuracy=0.6825, val_loss=1.1564, val_accuracy=0.5298\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.6383 - accuracy: 0.6825 - val_loss: 1.1564 - val_accuracy: 0.5298 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.6931Epoch 3/40: loss=0.6260, accuracy=0.6931, val_loss=0.8642, val_accuracy=0.5960\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6260 - accuracy: 0.6931 - val_loss: 0.8642 - val_accuracy: 0.5960 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.7088Epoch 4/40: loss=0.5984, accuracy=0.7088, val_loss=0.4875, val_accuracy=0.7939\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5984 - accuracy: 0.7088 - val_loss: 0.4875 - val_accuracy: 0.7939 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6112 - accuracy: 0.7025Epoch 5/40: loss=0.6114, accuracy=0.7024, val_loss=1.0025, val_accuracy=0.6142\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6114 - accuracy: 0.7024 - val_loss: 1.0025 - val_accuracy: 0.6142 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.7125Epoch 6/40: loss=0.5972, accuracy=0.7127, val_loss=0.8938, val_accuracy=0.6788\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5972 - accuracy: 0.7127 - val_loss: 0.8938 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5889 - accuracy: 0.7187Epoch 7/40: loss=0.5882, accuracy=0.7192, val_loss=1.2123, val_accuracy=0.5381\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5882 - accuracy: 0.7192 - val_loss: 1.2123 - val_accuracy: 0.5381 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.7200Epoch 8/40: loss=0.5825, accuracy=0.7200, val_loss=0.6700, val_accuracy=0.7235\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5825 - accuracy: 0.7200 - val_loss: 0.6700 - val_accuracy: 0.7235 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5737 - accuracy: 0.7266\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.5736, accuracy=0.7268, val_loss=0.9694, val_accuracy=0.4859\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5736 - accuracy: 0.7268 - val_loss: 0.9694 - val_accuracy: 0.4859 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7659Epoch 10/40: loss=0.5104, accuracy=0.7659, val_loss=0.5202, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5104 - accuracy: 0.7659 - val_loss: 0.5202 - val_accuracy: 0.7748 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7842Epoch 11/40: loss=0.4754, accuracy=0.7844, val_loss=0.6011, val_accuracy=0.7492\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.4754 - accuracy: 0.7844 - val_loss: 0.6011 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.7780Epoch 12/40: loss=0.4741, accuracy=0.7779, val_loss=0.4578, val_accuracy=0.8104\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4741 - accuracy: 0.7779 - val_loss: 0.4578 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.7811Epoch 13/40: loss=0.4639, accuracy=0.7806, val_loss=0.4646, val_accuracy=0.8038\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4639 - accuracy: 0.7806 - val_loss: 0.4646 - val_accuracy: 0.8038 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.7869Epoch 14/40: loss=0.4599, accuracy=0.7870, val_loss=0.4538, val_accuracy=0.7980\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4599 - accuracy: 0.7870 - val_loss: 0.4538 - val_accuracy: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.7841Epoch 15/40: loss=0.4552, accuracy=0.7841, val_loss=0.4119, val_accuracy=0.8245\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4552 - accuracy: 0.7841 - val_loss: 0.4119 - val_accuracy: 0.8245 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8049Epoch 16/40: loss=0.4384, accuracy=0.8044, val_loss=0.5617, val_accuracy=0.7467\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4384 - accuracy: 0.8044 - val_loss: 0.5617 - val_accuracy: 0.7467 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.8034Epoch 17/40: loss=0.4317, accuracy=0.8034, val_loss=0.5461, val_accuracy=0.7599\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4317 - accuracy: 0.8034 - val_loss: 0.5461 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4323 - accuracy: 0.7981Epoch 18/40: loss=0.4322, accuracy=0.7980, val_loss=0.4067, val_accuracy=0.8228\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.4322 - accuracy: 0.7980 - val_loss: 0.4067 - val_accuracy: 0.8228 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4260 - accuracy: 0.8068Epoch 19/40: loss=0.4257, accuracy=0.8069, val_loss=0.5693, val_accuracy=0.7343\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4257 - accuracy: 0.8069 - val_loss: 0.5693 - val_accuracy: 0.7343 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8037Epoch 20/40: loss=0.4294, accuracy=0.8038, val_loss=0.5120, val_accuracy=0.7616\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4294 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.8167Epoch 21/40: loss=0.4089, accuracy=0.8168, val_loss=0.4556, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4089 - accuracy: 0.8168 - val_loss: 0.4556 - val_accuracy: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3989 - accuracy: 0.8149Epoch 22/40: loss=0.3989, accuracy=0.8148, val_loss=0.6281, val_accuracy=0.7550\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.3989 - accuracy: 0.8148 - val_loss: 0.6281 - val_accuracy: 0.7550 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8293\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 23/40: loss=0.3926, accuracy=0.8293, val_loss=0.4800, val_accuracy=0.8104\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3926 - accuracy: 0.8293 - val_loss: 0.4800 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8373Epoch 24/40: loss=0.3715, accuracy=0.8373, val_loss=0.4637, val_accuracy=0.8063\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3715 - accuracy: 0.8373 - val_loss: 0.4637 - val_accuracy: 0.8063 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3659 - accuracy: 0.8426Epoch 25/40: loss=0.3664, accuracy=0.8425, val_loss=0.4177, val_accuracy=0.8237\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3664 - accuracy: 0.8425 - val_loss: 0.4177 - val_accuracy: 0.8237 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8439Epoch 26/40: loss=0.3667, accuracy=0.8438, val_loss=0.5199, val_accuracy=0.7873\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.3667 - accuracy: 0.8438 - val_loss: 0.5199 - val_accuracy: 0.7873 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8435Epoch 27/40: loss=0.3578, accuracy=0.8435, val_loss=0.4580, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3578 - accuracy: 0.8435 - val_loss: 0.4580 - val_accuracy: 0.8063 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.8414\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28/40: loss=0.3579, accuracy=0.8415, val_loss=0.4552, val_accuracy=0.8104\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.3579 - accuracy: 0.8415 - val_loss: 0.4552 - val_accuracy: 0.8104 - lr: 2.0000e-05\n",
      "Epoch 28: early stopping\n",
      "Validation accuracy: 0.8245033025741577\n",
      "\n",
      "Refined Training Combination 13/50: num_residual_blocks=8, dropout_rate=0.5, learning_rate=0.002, filters=128, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1246 - accuracy: 0.5536Epoch 1/40: loss=1.1229, accuracy=0.5538, val_loss=0.7326, val_accuracy=0.5993\n",
      "604/604 [==============================] - 17s 24ms/step - loss: 1.1229 - accuracy: 0.5538 - val_loss: 0.7326 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1212 - accuracy: 0.5701Epoch 2/40: loss=1.1211, accuracy=0.5697, val_loss=0.6673, val_accuracy=0.6656\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.1211 - accuracy: 0.5697 - val_loss: 0.6673 - val_accuracy: 0.6656 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.5776Epoch 3/40: loss=1.0842, accuracy=0.5776, val_loss=0.6627, val_accuracy=0.5621\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 1.0842 - accuracy: 0.5776 - val_loss: 0.6627 - val_accuracy: 0.5621 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.1040 - accuracy: 0.5579Epoch 4/40: loss=1.1020, accuracy=0.5588, val_loss=0.6576, val_accuracy=0.5323\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.1020 - accuracy: 0.5588 - val_loss: 0.6576 - val_accuracy: 0.5323 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0297 - accuracy: 0.5750Epoch 5/40: loss=1.0298, accuracy=0.5747, val_loss=0.9257, val_accuracy=0.4164\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 1.0298 - accuracy: 0.5747 - val_loss: 0.9257 - val_accuracy: 0.4164 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.5712Epoch 6/40: loss=1.0298, accuracy=0.5712, val_loss=0.6294, val_accuracy=0.6829\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 1.0298 - accuracy: 0.5712 - val_loss: 0.6294 - val_accuracy: 0.6829 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9512 - accuracy: 0.6026Epoch 7/40: loss=0.9510, accuracy=0.6022, val_loss=0.5692, val_accuracy=0.7061\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.9510 - accuracy: 0.6022 - val_loss: 0.5692 - val_accuracy: 0.7061 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.5904Epoch 8/40: loss=0.9369, accuracy=0.5904, val_loss=0.9064, val_accuracy=0.4851\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9369 - accuracy: 0.5904 - val_loss: 0.9064 - val_accuracy: 0.4851 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9074 - accuracy: 0.6088Epoch 9/40: loss=0.9086, accuracy=0.6087, val_loss=0.7430, val_accuracy=0.4917\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.9086 - accuracy: 0.6087 - val_loss: 0.7430 - val_accuracy: 0.4917 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8998 - accuracy: 0.5999Epoch 10/40: loss=0.8987, accuracy=0.6004, val_loss=0.7375, val_accuracy=0.6697\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8987 - accuracy: 0.6004 - val_loss: 0.7375 - val_accuracy: 0.6697 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8848 - accuracy: 0.5974Epoch 11/40: loss=0.8843, accuracy=0.5975, val_loss=0.6992, val_accuracy=0.6449\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8843 - accuracy: 0.5975 - val_loss: 0.6992 - val_accuracy: 0.6449 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8765 - accuracy: 0.5958\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 12/40: loss=0.8757, accuracy=0.5962, val_loss=0.5790, val_accuracy=0.6937\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.8757 - accuracy: 0.5962 - val_loss: 0.5790 - val_accuracy: 0.6937 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.6008Epoch 13/40: loss=0.8302, accuracy=0.6008, val_loss=0.6015, val_accuracy=0.6407\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.8302 - accuracy: 0.6008 - val_loss: 0.6015 - val_accuracy: 0.6407 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.6331Epoch 14/40: loss=0.7450, accuracy=0.6331, val_loss=0.5806, val_accuracy=0.6805\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.7450 - accuracy: 0.6331 - val_loss: 0.5806 - val_accuracy: 0.6805 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.6527Epoch 15/40: loss=0.6957, accuracy=0.6527, val_loss=0.5945, val_accuracy=0.6730\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6957 - accuracy: 0.6527 - val_loss: 0.5945 - val_accuracy: 0.6730 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.6734Epoch 16/40: loss=0.6527, accuracy=0.6734, val_loss=0.5274, val_accuracy=0.7417\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6527 - accuracy: 0.6734 - val_loss: 0.5274 - val_accuracy: 0.7417 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.6783Epoch 17/40: loss=0.6324, accuracy=0.6782, val_loss=0.7056, val_accuracy=0.5654\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6324 - accuracy: 0.6782 - val_loss: 0.7056 - val_accuracy: 0.5654 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6128 - accuracy: 0.6931Epoch 18/40: loss=0.6132, accuracy=0.6927, val_loss=0.6261, val_accuracy=0.6573\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6132 - accuracy: 0.6927 - val_loss: 0.6261 - val_accuracy: 0.6573 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.6934Epoch 19/40: loss=0.6078, accuracy=0.6939, val_loss=0.4899, val_accuracy=0.7575\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6078 - accuracy: 0.6939 - val_loss: 0.4899 - val_accuracy: 0.7575 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5939 - accuracy: 0.7068Epoch 20/40: loss=0.5938, accuracy=0.7072, val_loss=0.6051, val_accuracy=0.6755\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5938 - accuracy: 0.7072 - val_loss: 0.6051 - val_accuracy: 0.6755 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.7181Epoch 21/40: loss=0.5798, accuracy=0.7179, val_loss=0.5827, val_accuracy=0.7111\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5798 - accuracy: 0.7179 - val_loss: 0.5827 - val_accuracy: 0.7111 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.7137Epoch 22/40: loss=0.5881, accuracy=0.7130, val_loss=0.6061, val_accuracy=0.7070\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5881 - accuracy: 0.7130 - val_loss: 0.6061 - val_accuracy: 0.7070 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.7243Epoch 23/40: loss=0.5733, accuracy=0.7243, val_loss=0.4860, val_accuracy=0.7715\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5733 - accuracy: 0.7243 - val_loss: 0.4860 - val_accuracy: 0.7715 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5760 - accuracy: 0.7266Epoch 24/40: loss=0.5758, accuracy=0.7264, val_loss=0.4823, val_accuracy=0.7715\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5758 - accuracy: 0.7264 - val_loss: 0.4823 - val_accuracy: 0.7715 - lr: 4.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.7281Epoch 25/40: loss=0.5755, accuracy=0.7281, val_loss=0.5585, val_accuracy=0.7351\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5755 - accuracy: 0.7281 - val_loss: 0.5585 - val_accuracy: 0.7351 - lr: 4.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5843 - accuracy: 0.7160Epoch 26/40: loss=0.5847, accuracy=0.7156, val_loss=0.5383, val_accuracy=0.7459\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5847 - accuracy: 0.7156 - val_loss: 0.5383 - val_accuracy: 0.7459 - lr: 4.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7192Epoch 27/40: loss=0.5670, accuracy=0.7192, val_loss=0.5321, val_accuracy=0.7351\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5670 - accuracy: 0.7192 - val_loss: 0.5321 - val_accuracy: 0.7351 - lr: 4.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5714 - accuracy: 0.7322Epoch 28/40: loss=0.5709, accuracy=0.7326, val_loss=0.4923, val_accuracy=0.7699\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5709 - accuracy: 0.7326 - val_loss: 0.4923 - val_accuracy: 0.7699 - lr: 4.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5543 - accuracy: 0.7390\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 29/40: loss=0.5538, accuracy=0.7394, val_loss=0.5028, val_accuracy=0.7508\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5538 - accuracy: 0.7394 - val_loss: 0.5028 - val_accuracy: 0.7508 - lr: 4.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5558 - accuracy: 0.7338Epoch 30/40: loss=0.5559, accuracy=0.7339, val_loss=0.4947, val_accuracy=0.7839\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5559 - accuracy: 0.7339 - val_loss: 0.4947 - val_accuracy: 0.7839 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.7442Epoch 31/40: loss=0.5443, accuracy=0.7442, val_loss=0.4681, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5443 - accuracy: 0.7442 - val_loss: 0.4681 - val_accuracy: 0.7815 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.7326Epoch 32/40: loss=0.5533, accuracy=0.7330, val_loss=0.4657, val_accuracy=0.7790\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5533 - accuracy: 0.7330 - val_loss: 0.4657 - val_accuracy: 0.7790 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7456Epoch 33/40: loss=0.5379, accuracy=0.7457, val_loss=0.4804, val_accuracy=0.7798\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5379 - accuracy: 0.7457 - val_loss: 0.4804 - val_accuracy: 0.7798 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.7359Epoch 34/40: loss=0.5467, accuracy=0.7359, val_loss=0.4799, val_accuracy=0.7773\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5467 - accuracy: 0.7359 - val_loss: 0.4799 - val_accuracy: 0.7773 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.7444Epoch 35/40: loss=0.5414, accuracy=0.7444, val_loss=0.4627, val_accuracy=0.7831\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5414 - accuracy: 0.7444 - val_loss: 0.4627 - val_accuracy: 0.7831 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7388Epoch 36/40: loss=0.5405, accuracy=0.7388, val_loss=0.4676, val_accuracy=0.7815\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5405 - accuracy: 0.7388 - val_loss: 0.4676 - val_accuracy: 0.7815 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5346 - accuracy: 0.7494Epoch 37/40: loss=0.5342, accuracy=0.7496, val_loss=0.4701, val_accuracy=0.7823\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5342 - accuracy: 0.7496 - val_loss: 0.4701 - val_accuracy: 0.7823 - lr: 8.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.7456Epoch 38/40: loss=0.5308, accuracy=0.7457, val_loss=0.4676, val_accuracy=0.7831\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5308 - accuracy: 0.7457 - val_loss: 0.4676 - val_accuracy: 0.7831 - lr: 8.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5322 - accuracy: 0.7400Epoch 39/40: loss=0.5320, accuracy=0.7399, val_loss=0.4755, val_accuracy=0.7873\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5320 - accuracy: 0.7399 - val_loss: 0.4755 - val_accuracy: 0.7873 - lr: 8.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7494\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 40/40: loss=0.5259, accuracy=0.7494, val_loss=0.4655, val_accuracy=0.7839\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5259 - accuracy: 0.7494 - val_loss: 0.4655 - val_accuracy: 0.7839 - lr: 8.0000e-05\n",
      "Validation accuracy: 0.7872516512870789\n",
      "\n",
      "Refined Training Combination 14/50: num_residual_blocks=7, dropout_rate=0.30000000000000004, learning_rate=0.001, filters=128, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.0, height_shift_range=0.2, shear_range=0.30000000000000004, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.5906Epoch 1/40: loss=0.8961, accuracy=0.5906, val_loss=2.0614, val_accuracy=0.5993\n",
      "604/604 [==============================] - 22s 31ms/step - loss: 0.8961 - accuracy: 0.5906 - val_loss: 2.0614 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8055 - accuracy: 0.6179Epoch 2/40: loss=0.8055, accuracy=0.6186, val_loss=0.9328, val_accuracy=0.6457\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.8055 - accuracy: 0.6186 - val_loss: 0.9328 - val_accuracy: 0.6457 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7551 - accuracy: 0.6476Epoch 3/40: loss=0.7551, accuracy=0.6476, val_loss=0.5672, val_accuracy=0.7194\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7551 - accuracy: 0.6476 - val_loss: 0.5672 - val_accuracy: 0.7194 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7575 - accuracy: 0.6449Epoch 4/40: loss=0.7576, accuracy=0.6447, val_loss=1.0462, val_accuracy=0.6035\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7576 - accuracy: 0.6447 - val_loss: 1.0462 - val_accuracy: 0.6035 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.6562Epoch 5/40: loss=0.7465, accuracy=0.6562, val_loss=0.7742, val_accuracy=0.5579\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7465 - accuracy: 0.6562 - val_loss: 0.7742 - val_accuracy: 0.5579 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.6674Epoch 6/40: loss=0.7280, accuracy=0.6674, val_loss=0.6266, val_accuracy=0.6714\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.7280 - accuracy: 0.6674 - val_loss: 0.6266 - val_accuracy: 0.6714 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7643 - accuracy: 0.6341Epoch 7/40: loss=0.7648, accuracy=0.6341, val_loss=0.7516, val_accuracy=0.7028\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7648 - accuracy: 0.6341 - val_loss: 0.7516 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7917 - accuracy: 0.6148Epoch 8/40: loss=0.7916, accuracy=0.6153, val_loss=0.5371, val_accuracy=0.7260\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7916 - accuracy: 0.6153 - val_loss: 0.5371 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.6466Epoch 9/40: loss=0.7582, accuracy=0.6461, val_loss=1.1560, val_accuracy=0.4487\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7582 - accuracy: 0.6461 - val_loss: 1.1560 - val_accuracy: 0.4487 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7305 - accuracy: 0.6507Epoch 10/40: loss=0.7300, accuracy=0.6507, val_loss=0.5375, val_accuracy=0.7161\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.7300 - accuracy: 0.6507 - val_loss: 0.5375 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.6544Epoch 11/40: loss=0.7396, accuracy=0.6544, val_loss=1.0380, val_accuracy=0.4147\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7396 - accuracy: 0.6544 - val_loss: 1.0380 - val_accuracy: 0.4147 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7404 - accuracy: 0.6501Epoch 12/40: loss=0.7406, accuracy=0.6500, val_loss=0.6306, val_accuracy=0.6788\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7406 - accuracy: 0.6500 - val_loss: 0.6306 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7114 - accuracy: 0.6592\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40: loss=0.7117, accuracy=0.6594, val_loss=0.7776, val_accuracy=0.6581\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7117 - accuracy: 0.6594 - val_loss: 0.7776 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6651 - accuracy: 0.6748Epoch 14/40: loss=0.6648, accuracy=0.6751, val_loss=0.5622, val_accuracy=0.7351\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.6648 - accuracy: 0.6751 - val_loss: 0.5622 - val_accuracy: 0.7351 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6099 - accuracy: 0.7210Epoch 15/40: loss=0.6094, accuracy=0.7212, val_loss=0.5095, val_accuracy=0.7459\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.6094 - accuracy: 0.7212 - val_loss: 0.5095 - val_accuracy: 0.7459 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.7112Epoch 16/40: loss=0.5960, accuracy=0.7113, val_loss=0.4948, val_accuracy=0.7434\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5960 - accuracy: 0.7113 - val_loss: 0.4948 - val_accuracy: 0.7434 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5646 - accuracy: 0.7307Epoch 17/40: loss=0.5650, accuracy=0.7301, val_loss=0.5140, val_accuracy=0.7459\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5650 - accuracy: 0.7301 - val_loss: 0.5140 - val_accuracy: 0.7459 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5785 - accuracy: 0.7231Epoch 18/40: loss=0.5787, accuracy=0.7233, val_loss=0.4619, val_accuracy=0.7955\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5787 - accuracy: 0.7233 - val_loss: 0.4619 - val_accuracy: 0.7955 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7253Epoch 19/40: loss=0.5681, accuracy=0.7252, val_loss=0.6314, val_accuracy=0.6705\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5681 - accuracy: 0.7252 - val_loss: 0.6314 - val_accuracy: 0.6705 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7326Epoch 20/40: loss=0.5485, accuracy=0.7326, val_loss=0.5148, val_accuracy=0.7566\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5485 - accuracy: 0.7326 - val_loss: 0.5148 - val_accuracy: 0.7566 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7446Epoch 21/40: loss=0.5352, accuracy=0.7444, val_loss=0.4736, val_accuracy=0.7608\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5352 - accuracy: 0.7444 - val_loss: 0.4736 - val_accuracy: 0.7608 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.7457Epoch 22/40: loss=0.5220, accuracy=0.7457, val_loss=0.4455, val_accuracy=0.7848\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5220 - accuracy: 0.7457 - val_loss: 0.4455 - val_accuracy: 0.7848 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.7334Epoch 23/40: loss=0.5397, accuracy=0.7332, val_loss=0.4429, val_accuracy=0.7955\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5397 - accuracy: 0.7332 - val_loss: 0.4429 - val_accuracy: 0.7955 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5202 - accuracy: 0.7494Epoch 24/40: loss=0.5203, accuracy=0.7492, val_loss=0.4425, val_accuracy=0.7914\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5203 - accuracy: 0.7492 - val_loss: 0.4425 - val_accuracy: 0.7914 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.7523Epoch 25/40: loss=0.5138, accuracy=0.7523, val_loss=0.4990, val_accuracy=0.7608\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5138 - accuracy: 0.7523 - val_loss: 0.4990 - val_accuracy: 0.7608 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.7539Epoch 26/40: loss=0.5275, accuracy=0.7539, val_loss=0.4915, val_accuracy=0.7641\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5275 - accuracy: 0.7539 - val_loss: 0.4915 - val_accuracy: 0.7641 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5196 - accuracy: 0.7533Epoch 27/40: loss=0.5191, accuracy=0.7537, val_loss=0.4782, val_accuracy=0.7806\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5191 - accuracy: 0.7537 - val_loss: 0.4782 - val_accuracy: 0.7806 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.7604Epoch 28/40: loss=0.5129, accuracy=0.7599, val_loss=0.4498, val_accuracy=0.7815\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5129 - accuracy: 0.7599 - val_loss: 0.4498 - val_accuracy: 0.7815 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.7583\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 29/40: loss=0.5080, accuracy=0.7583, val_loss=0.5035, val_accuracy=0.7566\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5080 - accuracy: 0.7583 - val_loss: 0.5035 - val_accuracy: 0.7566 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5015 - accuracy: 0.7624Epoch 30/40: loss=0.5014, accuracy=0.7624, val_loss=0.4333, val_accuracy=0.7997\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5014 - accuracy: 0.7624 - val_loss: 0.4333 - val_accuracy: 0.7997 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5011 - accuracy: 0.7589Epoch 31/40: loss=0.5010, accuracy=0.7591, val_loss=0.4531, val_accuracy=0.7856\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.5010 - accuracy: 0.7591 - val_loss: 0.4531 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.7684Epoch 32/40: loss=0.4833, accuracy=0.7684, val_loss=0.4135, val_accuracy=0.8113\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.4833 - accuracy: 0.7684 - val_loss: 0.4135 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4827 - accuracy: 0.7716Epoch 33/40: loss=0.4835, accuracy=0.7715, val_loss=0.4414, val_accuracy=0.7980\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.4835 - accuracy: 0.7715 - val_loss: 0.4414 - val_accuracy: 0.7980 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.7693Epoch 34/40: loss=0.4815, accuracy=0.7695, val_loss=0.4148, val_accuracy=0.8121\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.4815 - accuracy: 0.7695 - val_loss: 0.4148 - val_accuracy: 0.8121 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4778 - accuracy: 0.7693Epoch 35/40: loss=0.4780, accuracy=0.7692, val_loss=0.4243, val_accuracy=0.8104\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.4780 - accuracy: 0.7692 - val_loss: 0.4243 - val_accuracy: 0.8104 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.7682Epoch 36/40: loss=0.4875, accuracy=0.7678, val_loss=0.4355, val_accuracy=0.7972\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.4875 - accuracy: 0.7678 - val_loss: 0.4355 - val_accuracy: 0.7972 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.7841\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 37/40: loss=0.4669, accuracy=0.7841, val_loss=0.4142, val_accuracy=0.8146\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.4669 - accuracy: 0.7841 - val_loss: 0.4142 - val_accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7779Epoch 38/40: loss=0.4784, accuracy=0.7779, val_loss=0.4292, val_accuracy=0.8063\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.4784 - accuracy: 0.7779 - val_loss: 0.4292 - val_accuracy: 0.8063 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.7752Epoch 39/40: loss=0.4762, accuracy=0.7752, val_loss=0.4211, val_accuracy=0.8088\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.4762 - accuracy: 0.7752 - val_loss: 0.4211 - val_accuracy: 0.8088 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.7811Epoch 40/40: loss=0.4634, accuracy=0.7810, val_loss=0.4268, val_accuracy=0.8063\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.4634 - accuracy: 0.7810 - val_loss: 0.4268 - val_accuracy: 0.8063 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.8145695328712463\n",
      "\n",
      "Refined Training Combination 15/50: num_residual_blocks=7, dropout_rate=0.4, learning_rate=0.001, filters=128, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.4, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0159 - accuracy: 0.5019Epoch 1/40: loss=1.0159, accuracy=0.5019, val_loss=0.6868, val_accuracy=0.5993\n",
      "604/604 [==============================] - 21s 30ms/step - loss: 1.0159 - accuracy: 0.5019 - val_loss: 0.6868 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8978 - accuracy: 0.5439Epoch 2/40: loss=0.8972, accuracy=0.5441, val_loss=0.8701, val_accuracy=0.4462\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.8972 - accuracy: 0.5441 - val_loss: 0.8701 - val_accuracy: 0.4462 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8239 - accuracy: 0.6037Epoch 3/40: loss=0.8239, accuracy=0.6037, val_loss=0.6066, val_accuracy=0.7111\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.8239 - accuracy: 0.6037 - val_loss: 0.6066 - val_accuracy: 0.7111 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7673 - accuracy: 0.6310Epoch 4/40: loss=0.7673, accuracy=0.6310, val_loss=1.0136, val_accuracy=0.6060\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.7673 - accuracy: 0.6310 - val_loss: 1.0136 - val_accuracy: 0.6060 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.6343Epoch 5/40: loss=0.7569, accuracy=0.6343, val_loss=0.8042, val_accuracy=0.4561\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.7569 - accuracy: 0.6343 - val_loss: 0.8042 - val_accuracy: 0.4561 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7714 - accuracy: 0.6430Epoch 6/40: loss=0.7707, accuracy=0.6434, val_loss=0.6918, val_accuracy=0.7185\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7707 - accuracy: 0.6434 - val_loss: 0.6918 - val_accuracy: 0.7185 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7361 - accuracy: 0.6615Epoch 7/40: loss=0.7365, accuracy=0.6612, val_loss=0.8860, val_accuracy=0.6043\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.7365 - accuracy: 0.6612 - val_loss: 0.8860 - val_accuracy: 0.6043 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7427 - accuracy: 0.6560\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.7427, accuracy=0.6560, val_loss=0.8263, val_accuracy=0.5977\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.7427 - accuracy: 0.6560 - val_loss: 0.8263 - val_accuracy: 0.5977 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.6788Epoch 9/40: loss=0.6872, accuracy=0.6788, val_loss=0.5679, val_accuracy=0.7376\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.6872 - accuracy: 0.6788 - val_loss: 0.5679 - val_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.7000Epoch 10/40: loss=0.6526, accuracy=0.6997, val_loss=0.6844, val_accuracy=0.6349\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.6526 - accuracy: 0.6997 - val_loss: 0.6844 - val_accuracy: 0.6349 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.6987Epoch 11/40: loss=0.6272, accuracy=0.6987, val_loss=0.5036, val_accuracy=0.7550\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.6272 - accuracy: 0.6987 - val_loss: 0.5036 - val_accuracy: 0.7550 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.7177Epoch 12/40: loss=0.5959, accuracy=0.7177, val_loss=0.5314, val_accuracy=0.7575\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5959 - accuracy: 0.7177 - val_loss: 0.5314 - val_accuracy: 0.7575 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.7170Epoch 13/40: loss=0.5918, accuracy=0.7171, val_loss=0.4656, val_accuracy=0.7897\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5918 - accuracy: 0.7171 - val_loss: 0.4656 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.7212Epoch 14/40: loss=0.5742, accuracy=0.7212, val_loss=0.5529, val_accuracy=0.7202\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5742 - accuracy: 0.7212 - val_loss: 0.5529 - val_accuracy: 0.7202 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.7295Epoch 15/40: loss=0.5644, accuracy=0.7295, val_loss=0.5560, val_accuracy=0.7343\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5644 - accuracy: 0.7295 - val_loss: 0.5560 - val_accuracy: 0.7343 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7457Epoch 16/40: loss=0.5412, accuracy=0.7457, val_loss=0.5169, val_accuracy=0.7583\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5412 - accuracy: 0.7457 - val_loss: 0.5169 - val_accuracy: 0.7583 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7320Epoch 17/40: loss=0.5610, accuracy=0.7320, val_loss=0.4811, val_accuracy=0.7748\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5610 - accuracy: 0.7320 - val_loss: 0.4811 - val_accuracy: 0.7748 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5528 - accuracy: 0.7345\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 18/40: loss=0.5530, accuracy=0.7341, val_loss=0.6681, val_accuracy=0.6432\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5530 - accuracy: 0.7341 - val_loss: 0.6681 - val_accuracy: 0.6432 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7442Epoch 19/40: loss=0.5407, accuracy=0.7442, val_loss=0.4375, val_accuracy=0.8104\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5407 - accuracy: 0.7442 - val_loss: 0.4375 - val_accuracy: 0.8104 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.7523Epoch 20/40: loss=0.5273, accuracy=0.7523, val_loss=0.4368, val_accuracy=0.8046\n",
      "604/604 [==============================] - 18s 31ms/step - loss: 0.5273 - accuracy: 0.7523 - val_loss: 0.4368 - val_accuracy: 0.8046 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.7456Epoch 21/40: loss=0.5318, accuracy=0.7459, val_loss=0.4701, val_accuracy=0.7897\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5318 - accuracy: 0.7459 - val_loss: 0.4701 - val_accuracy: 0.7897 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.7544Epoch 22/40: loss=0.5163, accuracy=0.7548, val_loss=0.4528, val_accuracy=0.7955\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5163 - accuracy: 0.7548 - val_loss: 0.4528 - val_accuracy: 0.7955 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.7560Epoch 23/40: loss=0.5173, accuracy=0.7560, val_loss=0.4335, val_accuracy=0.8071\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5173 - accuracy: 0.7560 - val_loss: 0.4335 - val_accuracy: 0.8071 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.7533Epoch 24/40: loss=0.5196, accuracy=0.7529, val_loss=0.4602, val_accuracy=0.7930\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5196 - accuracy: 0.7529 - val_loss: 0.4602 - val_accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.7552Epoch 25/40: loss=0.5207, accuracy=0.7552, val_loss=0.4275, val_accuracy=0.8079\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.5207 - accuracy: 0.7552 - val_loss: 0.4275 - val_accuracy: 0.8079 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5038 - accuracy: 0.7624Epoch 26/40: loss=0.5034, accuracy=0.7626, val_loss=0.4243, val_accuracy=0.8013\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5034 - accuracy: 0.7626 - val_loss: 0.4243 - val_accuracy: 0.8013 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5106 - accuracy: 0.7614Epoch 27/40: loss=0.5103, accuracy=0.7614, val_loss=0.4470, val_accuracy=0.7980\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5103 - accuracy: 0.7614 - val_loss: 0.4470 - val_accuracy: 0.7980 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5151 - accuracy: 0.7583Epoch 28/40: loss=0.5150, accuracy=0.7585, val_loss=0.4351, val_accuracy=0.8079\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5150 - accuracy: 0.7585 - val_loss: 0.4351 - val_accuracy: 0.8079 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7628Epoch 29/40: loss=0.5080, accuracy=0.7628, val_loss=0.4565, val_accuracy=0.7939\n",
      "604/604 [==============================] - 18s 30ms/step - loss: 0.5080 - accuracy: 0.7628 - val_loss: 0.4565 - val_accuracy: 0.7939 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.7587Epoch 30/40: loss=0.5098, accuracy=0.7581, val_loss=0.4723, val_accuracy=0.7798\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.5098 - accuracy: 0.7581 - val_loss: 0.4723 - val_accuracy: 0.7798 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.7672\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 31/40: loss=0.4964, accuracy=0.7672, val_loss=0.4412, val_accuracy=0.7988\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.4964 - accuracy: 0.7672 - val_loss: 0.4412 - val_accuracy: 0.7988 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.7628Epoch 32/40: loss=0.5054, accuracy=0.7628, val_loss=0.4415, val_accuracy=0.8013\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5054 - accuracy: 0.7628 - val_loss: 0.4415 - val_accuracy: 0.8013 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.7608Epoch 33/40: loss=0.5058, accuracy=0.7610, val_loss=0.4445, val_accuracy=0.7947\n",
      "604/604 [==============================] - 19s 31ms/step - loss: 0.5058 - accuracy: 0.7610 - val_loss: 0.4445 - val_accuracy: 0.7947 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.7647Epoch 34/40: loss=0.4955, accuracy=0.7647, val_loss=0.4336, val_accuracy=0.8055\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.4955 - accuracy: 0.7647 - val_loss: 0.4336 - val_accuracy: 0.8055 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.7622Epoch 35/40: loss=0.5008, accuracy=0.7622, val_loss=0.4401, val_accuracy=0.7988\n",
      "604/604 [==============================] - 19s 32ms/step - loss: 0.5008 - accuracy: 0.7622 - val_loss: 0.4401 - val_accuracy: 0.7988 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.7672\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36/40: loss=0.5001, accuracy=0.7674, val_loss=0.4401, val_accuracy=0.7988\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.5001 - accuracy: 0.7674 - val_loss: 0.4401 - val_accuracy: 0.7988 - lr: 8.0000e-06\n",
      "Epoch 36: early stopping\n",
      "Validation accuracy: 0.8104304671287537\n",
      "\n",
      "Refined Training Combination 16/50: num_residual_blocks=7, dropout_rate=0.5, learning_rate=0.002, filters=64, kernel_size=3, num_dense_layers=2, activation_function=tanh, rotation_range=20, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.3559 - accuracy: 0.5628Epoch 1/40: loss=1.3529, accuracy=0.5629, val_loss=0.8573, val_accuracy=0.6896\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 1.3529 - accuracy: 0.5629 - val_loss: 0.8573 - val_accuracy: 0.6896 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0235 - accuracy: 0.5933Epoch 2/40: loss=1.0227, accuracy=0.5935, val_loss=0.8833, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 1.0227 - accuracy: 0.5935 - val_loss: 0.8833 - val_accuracy: 0.7318 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9486 - accuracy: 0.6103Epoch 3/40: loss=0.9486, accuracy=0.6103, val_loss=0.9447, val_accuracy=0.4214\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9486 - accuracy: 0.6103 - val_loss: 0.9447 - val_accuracy: 0.4214 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.5615Epoch 4/40: loss=0.9603, accuracy=0.5611, val_loss=0.9285, val_accuracy=0.6308\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.9603 - accuracy: 0.5611 - val_loss: 0.9285 - val_accuracy: 0.6308 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8513 - accuracy: 0.6159Epoch 5/40: loss=0.8513, accuracy=0.6159, val_loss=0.5193, val_accuracy=0.7525\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8513 - accuracy: 0.6159 - val_loss: 0.5193 - val_accuracy: 0.7525 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8307 - accuracy: 0.6252Epoch 6/40: loss=0.8306, accuracy=0.6252, val_loss=1.5101, val_accuracy=0.4065\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.8306 - accuracy: 0.6252 - val_loss: 1.5101 - val_accuracy: 0.4065 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7502 - accuracy: 0.6551Epoch 7/40: loss=0.7509, accuracy=0.6550, val_loss=0.6499, val_accuracy=0.6242\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.7509 - accuracy: 0.6550 - val_loss: 0.6499 - val_accuracy: 0.6242 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7988 - accuracy: 0.6461Epoch 8/40: loss=0.7983, accuracy=0.6463, val_loss=0.5852, val_accuracy=0.7094\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7983 - accuracy: 0.6463 - val_loss: 0.5852 - val_accuracy: 0.7094 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.6554Epoch 9/40: loss=0.7605, accuracy=0.6554, val_loss=0.6167, val_accuracy=0.6796\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7605 - accuracy: 0.6554 - val_loss: 0.6167 - val_accuracy: 0.6796 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.6572\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 10/40: loss=0.7444, accuracy=0.6567, val_loss=1.0347, val_accuracy=0.5373\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7444 - accuracy: 0.6567 - val_loss: 1.0347 - val_accuracy: 0.5373 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6968 - accuracy: 0.6715Epoch 11/40: loss=0.6957, accuracy=0.6724, val_loss=0.5523, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6957 - accuracy: 0.6724 - val_loss: 0.5523 - val_accuracy: 0.7641 - lr: 4.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.7074Epoch 12/40: loss=0.6451, accuracy=0.7078, val_loss=0.5011, val_accuracy=0.7831\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6451 - accuracy: 0.7078 - val_loss: 0.5011 - val_accuracy: 0.7831 - lr: 4.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6050 - accuracy: 0.7120Epoch 13/40: loss=0.6056, accuracy=0.7121, val_loss=0.8570, val_accuracy=0.6200\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6056 - accuracy: 0.7121 - val_loss: 0.8570 - val_accuracy: 0.6200 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5827 - accuracy: 0.7270Epoch 14/40: loss=0.5838, accuracy=0.7262, val_loss=0.5026, val_accuracy=0.7798\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5838 - accuracy: 0.7262 - val_loss: 0.5026 - val_accuracy: 0.7798 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5657 - accuracy: 0.7363Epoch 15/40: loss=0.5651, accuracy=0.7365, val_loss=0.5502, val_accuracy=0.7541\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5651 - accuracy: 0.7365 - val_loss: 0.5502 - val_accuracy: 0.7541 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5650 - accuracy: 0.7403Epoch 16/40: loss=0.5645, accuracy=0.7405, val_loss=0.6124, val_accuracy=0.6987\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5645 - accuracy: 0.7405 - val_loss: 0.6124 - val_accuracy: 0.6987 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.7440Epoch 17/40: loss=0.5473, accuracy=0.7444, val_loss=0.4532, val_accuracy=0.8055\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5473 - accuracy: 0.7444 - val_loss: 0.4532 - val_accuracy: 0.8055 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5363 - accuracy: 0.7577Epoch 18/40: loss=0.5371, accuracy=0.7570, val_loss=0.5062, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5371 - accuracy: 0.7570 - val_loss: 0.5062 - val_accuracy: 0.7790 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.7459Epoch 19/40: loss=0.5392, accuracy=0.7463, val_loss=0.4767, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5392 - accuracy: 0.7463 - val_loss: 0.4767 - val_accuracy: 0.7947 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7442Epoch 20/40: loss=0.5387, accuracy=0.7440, val_loss=0.4578, val_accuracy=0.8104\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5387 - accuracy: 0.7440 - val_loss: 0.4578 - val_accuracy: 0.8104 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7571Epoch 21/40: loss=0.5349, accuracy=0.7566, val_loss=0.5014, val_accuracy=0.7823\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5349 - accuracy: 0.7566 - val_loss: 0.5014 - val_accuracy: 0.7823 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7421\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 22/40: loss=0.5355, accuracy=0.7421, val_loss=0.5184, val_accuracy=0.7483\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5355 - accuracy: 0.7421 - val_loss: 0.5184 - val_accuracy: 0.7483 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.7535Epoch 23/40: loss=0.5181, accuracy=0.7535, val_loss=0.4925, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5181 - accuracy: 0.7535 - val_loss: 0.4925 - val_accuracy: 0.7641 - lr: 8.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.7620Epoch 24/40: loss=0.5175, accuracy=0.7620, val_loss=0.4338, val_accuracy=0.8030\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5175 - accuracy: 0.7620 - val_loss: 0.4338 - val_accuracy: 0.8030 - lr: 8.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5133 - accuracy: 0.7662Epoch 25/40: loss=0.5124, accuracy=0.7666, val_loss=0.4435, val_accuracy=0.8013\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5124 - accuracy: 0.7666 - val_loss: 0.4435 - val_accuracy: 0.8013 - lr: 8.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.7641Epoch 26/40: loss=0.5066, accuracy=0.7645, val_loss=0.4696, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5066 - accuracy: 0.7645 - val_loss: 0.4696 - val_accuracy: 0.7815 - lr: 8.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7606Epoch 27/40: loss=0.5096, accuracy=0.7606, val_loss=0.4314, val_accuracy=0.8063\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5096 - accuracy: 0.7606 - val_loss: 0.4314 - val_accuracy: 0.8063 - lr: 8.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.7705Epoch 28/40: loss=0.4946, accuracy=0.7705, val_loss=0.4400, val_accuracy=0.7997\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4946 - accuracy: 0.7705 - val_loss: 0.4400 - val_accuracy: 0.7997 - lr: 8.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.7631Epoch 29/40: loss=0.5022, accuracy=0.7630, val_loss=0.4340, val_accuracy=0.8038\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5022 - accuracy: 0.7630 - val_loss: 0.4340 - val_accuracy: 0.8038 - lr: 8.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7736Epoch 30/40: loss=0.5020, accuracy=0.7736, val_loss=0.4611, val_accuracy=0.7864\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5020 - accuracy: 0.7736 - val_loss: 0.4611 - val_accuracy: 0.7864 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7761Epoch 31/40: loss=0.4951, accuracy=0.7761, val_loss=0.4284, val_accuracy=0.8104\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.4951 - accuracy: 0.7761 - val_loss: 0.4284 - val_accuracy: 0.8104 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.7702Epoch 32/40: loss=0.4963, accuracy=0.7703, val_loss=0.4380, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4963 - accuracy: 0.7703 - val_loss: 0.4380 - val_accuracy: 0.8030 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.7815Epoch 33/40: loss=0.4837, accuracy=0.7812, val_loss=0.4314, val_accuracy=0.8113\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4837 - accuracy: 0.7812 - val_loss: 0.4314 - val_accuracy: 0.8113 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7821Epoch 34/40: loss=0.4744, accuracy=0.7821, val_loss=0.4469, val_accuracy=0.8005\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4744 - accuracy: 0.7821 - val_loss: 0.4469 - val_accuracy: 0.8005 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.7825Epoch 35/40: loss=0.4813, accuracy=0.7825, val_loss=0.4650, val_accuracy=0.7839\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4813 - accuracy: 0.7825 - val_loss: 0.4650 - val_accuracy: 0.7839 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.7794Epoch 36/40: loss=0.4748, accuracy=0.7794, val_loss=0.4087, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4748 - accuracy: 0.7794 - val_loss: 0.4087 - val_accuracy: 0.8146 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.7805Epoch 37/40: loss=0.4759, accuracy=0.7806, val_loss=0.4275, val_accuracy=0.8055\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4759 - accuracy: 0.7806 - val_loss: 0.4275 - val_accuracy: 0.8055 - lr: 8.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.7763Epoch 38/40: loss=0.4884, accuracy=0.7763, val_loss=0.4375, val_accuracy=0.7947\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4884 - accuracy: 0.7763 - val_loss: 0.4375 - val_accuracy: 0.7947 - lr: 8.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.7796Epoch 39/40: loss=0.4741, accuracy=0.7796, val_loss=0.4150, val_accuracy=0.8071\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4741 - accuracy: 0.7796 - val_loss: 0.4150 - val_accuracy: 0.8071 - lr: 8.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7854Epoch 40/40: loss=0.4659, accuracy=0.7854, val_loss=0.4218, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4659 - accuracy: 0.7854 - val_loss: 0.4218 - val_accuracy: 0.8030 - lr: 8.0000e-05\n",
      "Validation accuracy: 0.8145695328712463\n",
      "\n",
      "Refined Training Combination 17/50: num_residual_blocks=7, dropout_rate=0.4, learning_rate=0.001, filters=32, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.6005Epoch 1/40: loss=0.8966, accuracy=0.6008, val_loss=0.5682, val_accuracy=0.7020\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.8966 - accuracy: 0.6008 - val_loss: 0.5682 - val_accuracy: 0.7020 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7795 - accuracy: 0.6449Epoch 2/40: loss=0.7790, accuracy=0.6449, val_loss=0.5430, val_accuracy=0.7310\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7790 - accuracy: 0.6449 - val_loss: 0.5430 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7210 - accuracy: 0.6684Epoch 3/40: loss=0.7237, accuracy=0.6674, val_loss=1.0266, val_accuracy=0.6200\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7237 - accuracy: 0.6674 - val_loss: 1.0266 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7000 - accuracy: 0.6798Epoch 4/40: loss=0.6985, accuracy=0.6803, val_loss=0.5469, val_accuracy=0.6987\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6985 - accuracy: 0.6803 - val_loss: 0.5469 - val_accuracy: 0.6987 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.6806Epoch 5/40: loss=0.7219, accuracy=0.6807, val_loss=0.7646, val_accuracy=0.6507\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7219 - accuracy: 0.6807 - val_loss: 0.7646 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7029 - accuracy: 0.6889Epoch 6/40: loss=0.7029, accuracy=0.6889, val_loss=0.5427, val_accuracy=0.7003\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7029 - accuracy: 0.6889 - val_loss: 0.5427 - val_accuracy: 0.7003 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6889 - accuracy: 0.6884Epoch 7/40: loss=0.6887, accuracy=0.6883, val_loss=0.5018, val_accuracy=0.7608\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6887 - accuracy: 0.6883 - val_loss: 0.5018 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.7011Epoch 8/40: loss=0.6702, accuracy=0.7012, val_loss=0.5599, val_accuracy=0.7326\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6702 - accuracy: 0.7012 - val_loss: 0.5599 - val_accuracy: 0.7326 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6757 - accuracy: 0.7012Epoch 9/40: loss=0.6757, accuracy=0.7012, val_loss=0.5310, val_accuracy=0.7500\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6757 - accuracy: 0.7012 - val_loss: 0.5310 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.7090Epoch 10/40: loss=0.6526, accuracy=0.7092, val_loss=0.5769, val_accuracy=0.7119\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6526 - accuracy: 0.7092 - val_loss: 0.5769 - val_accuracy: 0.7119 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6576 - accuracy: 0.7029Epoch 11/40: loss=0.6573, accuracy=0.7030, val_loss=0.7504, val_accuracy=0.6416\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6573 - accuracy: 0.7030 - val_loss: 0.7504 - val_accuracy: 0.6416 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6404 - accuracy: 0.7168\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.6398, accuracy=0.7171, val_loss=0.6690, val_accuracy=0.7053\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6398 - accuracy: 0.7171 - val_loss: 0.6690 - val_accuracy: 0.7053 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6083 - accuracy: 0.7365Epoch 13/40: loss=0.6085, accuracy=0.7359, val_loss=0.4663, val_accuracy=0.7914\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6085 - accuracy: 0.7359 - val_loss: 0.4663 - val_accuracy: 0.7914 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5591 - accuracy: 0.7496Epoch 14/40: loss=0.5589, accuracy=0.7496, val_loss=0.4617, val_accuracy=0.7798\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5589 - accuracy: 0.7496 - val_loss: 0.4617 - val_accuracy: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.7646Epoch 15/40: loss=0.5245, accuracy=0.7649, val_loss=0.4529, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5245 - accuracy: 0.7649 - val_loss: 0.4529 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.7604Epoch 16/40: loss=0.5206, accuracy=0.7599, val_loss=0.4395, val_accuracy=0.7939\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5206 - accuracy: 0.7599 - val_loss: 0.4395 - val_accuracy: 0.7939 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.7658Epoch 17/40: loss=0.5198, accuracy=0.7663, val_loss=0.4657, val_accuracy=0.7724\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5198 - accuracy: 0.7663 - val_loss: 0.4657 - val_accuracy: 0.7724 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.7674Epoch 18/40: loss=0.5023, accuracy=0.7670, val_loss=0.4622, val_accuracy=0.7732\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5023 - accuracy: 0.7670 - val_loss: 0.4622 - val_accuracy: 0.7732 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.7732Epoch 19/40: loss=0.4995, accuracy=0.7732, val_loss=0.4787, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4995 - accuracy: 0.7732 - val_loss: 0.4787 - val_accuracy: 0.7823 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4724 - accuracy: 0.7795Epoch 20/40: loss=0.4722, accuracy=0.7798, val_loss=0.4426, val_accuracy=0.7930\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4722 - accuracy: 0.7798 - val_loss: 0.4426 - val_accuracy: 0.7930 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.7695\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 21/40: loss=0.4833, accuracy=0.7686, val_loss=0.4939, val_accuracy=0.7583\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4833 - accuracy: 0.7686 - val_loss: 0.4939 - val_accuracy: 0.7583 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7883Epoch 22/40: loss=0.4685, accuracy=0.7883, val_loss=0.4497, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4685 - accuracy: 0.7883 - val_loss: 0.4497 - val_accuracy: 0.7864 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7910Epoch 23/40: loss=0.4537, accuracy=0.7910, val_loss=0.4615, val_accuracy=0.7773\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4537 - accuracy: 0.7910 - val_loss: 0.4615 - val_accuracy: 0.7773 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.7799Epoch 24/40: loss=0.4754, accuracy=0.7798, val_loss=0.4658, val_accuracy=0.7765\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4754 - accuracy: 0.7798 - val_loss: 0.4658 - val_accuracy: 0.7765 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7823Epoch 25/40: loss=0.4690, accuracy=0.7823, val_loss=0.4726, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.4690 - accuracy: 0.7823 - val_loss: 0.4726 - val_accuracy: 0.7707 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.7896\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 26/40: loss=0.4647, accuracy=0.7899, val_loss=0.4828, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4647 - accuracy: 0.7899 - val_loss: 0.4828 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 26: early stopping\n",
      "Validation accuracy: 0.7938741445541382\n",
      "\n",
      "Refined Training Combination 18/50: num_residual_blocks=8, dropout_rate=0.30000000000000004, learning_rate=0.0005, filters=64, kernel_size=3, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.5, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8532 - accuracy: 0.6250Epoch 1/40: loss=0.8532, accuracy=0.6250, val_loss=0.5481, val_accuracy=0.7293\n",
      "604/604 [==============================] - 16s 21ms/step - loss: 0.8532 - accuracy: 0.6250 - val_loss: 0.5481 - val_accuracy: 0.7293 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7047 - accuracy: 0.6619Epoch 2/40: loss=0.7047, accuracy=0.6616, val_loss=0.4936, val_accuracy=0.7657\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7047 - accuracy: 0.6616 - val_loss: 0.4936 - val_accuracy: 0.7657 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.6883Epoch 3/40: loss=0.6426, accuracy=0.6883, val_loss=0.7620, val_accuracy=0.6581\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6426 - accuracy: 0.6883 - val_loss: 0.7620 - val_accuracy: 0.6581 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6215 - accuracy: 0.6922Epoch 4/40: loss=0.6214, accuracy=0.6921, val_loss=0.7562, val_accuracy=0.5877\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6214 - accuracy: 0.6921 - val_loss: 0.7562 - val_accuracy: 0.5877 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6138 - accuracy: 0.7060Epoch 5/40: loss=0.6127, accuracy=0.7067, val_loss=0.5931, val_accuracy=0.6970\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6127 - accuracy: 0.7067 - val_loss: 0.5931 - val_accuracy: 0.6970 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.7160Epoch 6/40: loss=0.5916, accuracy=0.7163, val_loss=1.0997, val_accuracy=0.4512\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5916 - accuracy: 0.7163 - val_loss: 1.0997 - val_accuracy: 0.4512 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5905 - accuracy: 0.7177\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/40: loss=0.5905, accuracy=0.7177, val_loss=0.5490, val_accuracy=0.7301\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5905 - accuracy: 0.7177 - val_loss: 0.5490 - val_accuracy: 0.7301 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7430Epoch 8/40: loss=0.5471, accuracy=0.7430, val_loss=0.4746, val_accuracy=0.7781\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5471 - accuracy: 0.7430 - val_loss: 0.4746 - val_accuracy: 0.7781 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5221 - accuracy: 0.7502Epoch 9/40: loss=0.5219, accuracy=0.7502, val_loss=0.4456, val_accuracy=0.7997\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5219 - accuracy: 0.7502 - val_loss: 0.4456 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5043 - accuracy: 0.7711Epoch 10/40: loss=0.5044, accuracy=0.7709, val_loss=0.4069, val_accuracy=0.8063\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5044 - accuracy: 0.7709 - val_loss: 0.4069 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4851 - accuracy: 0.7759Epoch 11/40: loss=0.4851, accuracy=0.7759, val_loss=0.5772, val_accuracy=0.7177\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4851 - accuracy: 0.7759 - val_loss: 0.5772 - val_accuracy: 0.7177 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7722Epoch 12/40: loss=0.4800, accuracy=0.7719, val_loss=0.4064, val_accuracy=0.8104\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4800 - accuracy: 0.7719 - val_loss: 0.4064 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.7863Epoch 13/40: loss=0.4646, accuracy=0.7870, val_loss=0.5904, val_accuracy=0.7169\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4646 - accuracy: 0.7870 - val_loss: 0.5904 - val_accuracy: 0.7169 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7928Epoch 14/40: loss=0.4604, accuracy=0.7928, val_loss=0.3901, val_accuracy=0.8162\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4604 - accuracy: 0.7928 - val_loss: 0.3901 - val_accuracy: 0.8162 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8010Epoch 15/40: loss=0.4427, accuracy=0.8007, val_loss=0.4257, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4427 - accuracy: 0.8007 - val_loss: 0.4257 - val_accuracy: 0.8113 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.7906Epoch 16/40: loss=0.4562, accuracy=0.7906, val_loss=0.4583, val_accuracy=0.7848\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4562 - accuracy: 0.7906 - val_loss: 0.4583 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.7927Epoch 17/40: loss=0.4441, accuracy=0.7928, val_loss=0.4089, val_accuracy=0.8179\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4441 - accuracy: 0.7928 - val_loss: 0.4089 - val_accuracy: 0.8179 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8009Epoch 18/40: loss=0.4369, accuracy=0.8009, val_loss=0.4325, val_accuracy=0.8063\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4369 - accuracy: 0.8009 - val_loss: 0.4325 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8126\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.4157, accuracy=0.8123, val_loss=0.4022, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4157 - accuracy: 0.8123 - val_loss: 0.4022 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8154Epoch 20/40: loss=0.4081, accuracy=0.8154, val_loss=0.3900, val_accuracy=0.8295\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4081 - accuracy: 0.8154 - val_loss: 0.3900 - val_accuracy: 0.8295 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4133 - accuracy: 0.8127Epoch 21/40: loss=0.4133, accuracy=0.8127, val_loss=0.3737, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4133 - accuracy: 0.8127 - val_loss: 0.3737 - val_accuracy: 0.8336 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8396Epoch 22/40: loss=0.3743, accuracy=0.8392, val_loss=0.3764, val_accuracy=0.8344\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3743 - accuracy: 0.8392 - val_loss: 0.3764 - val_accuracy: 0.8344 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8279Epoch 23/40: loss=0.3838, accuracy=0.8280, val_loss=0.3862, val_accuracy=0.8278\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3838 - accuracy: 0.8280 - val_loss: 0.3862 - val_accuracy: 0.8278 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8252Epoch 24/40: loss=0.3858, accuracy=0.8251, val_loss=0.3838, val_accuracy=0.8344\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3858 - accuracy: 0.8251 - val_loss: 0.3838 - val_accuracy: 0.8344 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8308Epoch 25/40: loss=0.3836, accuracy=0.8311, val_loss=0.3710, val_accuracy=0.8344\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3836 - accuracy: 0.8311 - val_loss: 0.3710 - val_accuracy: 0.8344 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302Epoch 26/40: loss=0.3811, accuracy=0.8303, val_loss=0.3605, val_accuracy=0.8419\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3811 - accuracy: 0.8303 - val_loss: 0.3605 - val_accuracy: 0.8419 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.8344Epoch 27/40: loss=0.3650, accuracy=0.8344, val_loss=0.3515, val_accuracy=0.8427\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3650 - accuracy: 0.8344 - val_loss: 0.3515 - val_accuracy: 0.8427 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3735 - accuracy: 0.8362Epoch 28/40: loss=0.3731, accuracy=0.8365, val_loss=0.3558, val_accuracy=0.8386\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3731 - accuracy: 0.8365 - val_loss: 0.3558 - val_accuracy: 0.8386 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3693 - accuracy: 0.8397Epoch 29/40: loss=0.3685, accuracy=0.8400, val_loss=0.3593, val_accuracy=0.8394\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3685 - accuracy: 0.8400 - val_loss: 0.3593 - val_accuracy: 0.8394 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8472Epoch 30/40: loss=0.3513, accuracy=0.8473, val_loss=0.3744, val_accuracy=0.8311\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3513 - accuracy: 0.8473 - val_loss: 0.3744 - val_accuracy: 0.8311 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.8382Epoch 31/40: loss=0.3555, accuracy=0.8382, val_loss=0.3513, val_accuracy=0.8444\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3555 - accuracy: 0.8382 - val_loss: 0.3513 - val_accuracy: 0.8444 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.8495Epoch 32/40: loss=0.3540, accuracy=0.8493, val_loss=0.3773, val_accuracy=0.8204\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3540 - accuracy: 0.8493 - val_loss: 0.3773 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8466Epoch 33/40: loss=0.3517, accuracy=0.8471, val_loss=0.3817, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3517 - accuracy: 0.8471 - val_loss: 0.3817 - val_accuracy: 0.8270 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8444Epoch 34/40: loss=0.3511, accuracy=0.8444, val_loss=0.3596, val_accuracy=0.8361\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3511 - accuracy: 0.8444 - val_loss: 0.3596 - val_accuracy: 0.8361 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.8555Epoch 35/40: loss=0.3451, accuracy=0.8555, val_loss=0.3584, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3451 - accuracy: 0.8555 - val_loss: 0.3584 - val_accuracy: 0.8320 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8534\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 36/40: loss=0.3384, accuracy=0.8537, val_loss=0.3656, val_accuracy=0.8262\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3384 - accuracy: 0.8537 - val_loss: 0.3656 - val_accuracy: 0.8262 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.8469Epoch 37/40: loss=0.3515, accuracy=0.8469, val_loss=0.3532, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3515 - accuracy: 0.8469 - val_loss: 0.3532 - val_accuracy: 0.8485 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3411 - accuracy: 0.8528Epoch 38/40: loss=0.3408, accuracy=0.8529, val_loss=0.3608, val_accuracy=0.8344\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3408 - accuracy: 0.8529 - val_loss: 0.3608 - val_accuracy: 0.8344 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8555Epoch 39/40: loss=0.3326, accuracy=0.8555, val_loss=0.3561, val_accuracy=0.8361\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3326 - accuracy: 0.8555 - val_loss: 0.3561 - val_accuracy: 0.8361 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.8488Epoch 40/40: loss=0.3414, accuracy=0.8489, val_loss=0.3602, val_accuracy=0.8311\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3414 - accuracy: 0.8489 - val_loss: 0.3602 - val_accuracy: 0.8311 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.8485099077224731\n",
      "\n",
      "Refined Training Combination 19/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.001, filters=64, kernel_size=5, num_dense_layers=2, activation_function=tanh, rotation_range=30, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.30000000000000004, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.2462 - accuracy: 0.5100Epoch 1/40: loss=1.2450, accuracy=0.5101, val_loss=0.7569, val_accuracy=0.6275\n",
      "604/604 [==============================] - 21s 23ms/step - loss: 1.2450 - accuracy: 0.5101 - val_loss: 0.7569 - val_accuracy: 0.6275 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8065 - accuracy: 0.6039Epoch 2/40: loss=0.8057, accuracy=0.6043, val_loss=2.8459, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8057 - accuracy: 0.6043 - val_loss: 2.8459 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7456 - accuracy: 0.6480Epoch 3/40: loss=0.7466, accuracy=0.6476, val_loss=0.8175, val_accuracy=0.7583\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7466 - accuracy: 0.6476 - val_loss: 0.8175 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.6803Epoch 4/40: loss=0.7076, accuracy=0.6803, val_loss=0.5575, val_accuracy=0.7500\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7076 - accuracy: 0.6803 - val_loss: 0.5575 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.6830Epoch 5/40: loss=0.6951, accuracy=0.6836, val_loss=1.3625, val_accuracy=0.6283\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6951 - accuracy: 0.6836 - val_loss: 1.3625 - val_accuracy: 0.6283 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.6697Epoch 6/40: loss=0.6898, accuracy=0.6697, val_loss=0.8582, val_accuracy=0.6507\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6898 - accuracy: 0.6697 - val_loss: 0.8582 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.6523Epoch 7/40: loss=0.7195, accuracy=0.6523, val_loss=1.0396, val_accuracy=0.4901\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7195 - accuracy: 0.6523 - val_loss: 1.0396 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.6927Epoch 8/40: loss=0.6561, accuracy=0.6927, val_loss=1.3536, val_accuracy=0.4329\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6561 - accuracy: 0.6927 - val_loss: 1.3536 - val_accuracy: 0.4329 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.6736\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/40: loss=0.6704, accuracy=0.6736, val_loss=1.0609, val_accuracy=0.4719\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6704 - accuracy: 0.6736 - val_loss: 1.0609 - val_accuracy: 0.4719 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7288Epoch 10/40: loss=0.5682, accuracy=0.7289, val_loss=0.4566, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5682 - accuracy: 0.7289 - val_loss: 0.4566 - val_accuracy: 0.7790 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.7427Epoch 11/40: loss=0.5396, accuracy=0.7428, val_loss=0.4463, val_accuracy=0.8030\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5396 - accuracy: 0.7428 - val_loss: 0.4463 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.7506Epoch 12/40: loss=0.5201, accuracy=0.7506, val_loss=0.4763, val_accuracy=0.7690\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5201 - accuracy: 0.7506 - val_loss: 0.4763 - val_accuracy: 0.7690 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.7521Epoch 13/40: loss=0.5194, accuracy=0.7514, val_loss=0.5335, val_accuracy=0.7326\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5194 - accuracy: 0.7514 - val_loss: 0.5335 - val_accuracy: 0.7326 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.7645Epoch 14/40: loss=0.4984, accuracy=0.7645, val_loss=0.4636, val_accuracy=0.7873\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4984 - accuracy: 0.7645 - val_loss: 0.4636 - val_accuracy: 0.7873 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7697Epoch 15/40: loss=0.4951, accuracy=0.7697, val_loss=0.4923, val_accuracy=0.7972\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4951 - accuracy: 0.7697 - val_loss: 0.4923 - val_accuracy: 0.7972 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.7684Epoch 16/40: loss=0.4950, accuracy=0.7686, val_loss=0.4160, val_accuracy=0.8113\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.4950 - accuracy: 0.7686 - val_loss: 0.4160 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.7726Epoch 17/40: loss=0.4898, accuracy=0.7726, val_loss=0.4996, val_accuracy=0.7558\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4898 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7558 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.7751Epoch 18/40: loss=0.4830, accuracy=0.7750, val_loss=0.4756, val_accuracy=0.7897\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4830 - accuracy: 0.7750 - val_loss: 0.4756 - val_accuracy: 0.7897 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7770Epoch 19/40: loss=0.4804, accuracy=0.7771, val_loss=0.4286, val_accuracy=0.8088\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4804 - accuracy: 0.7771 - val_loss: 0.4286 - val_accuracy: 0.8088 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.7773Epoch 20/40: loss=0.4653, accuracy=0.7773, val_loss=0.4926, val_accuracy=0.7699\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4653 - accuracy: 0.7773 - val_loss: 0.4926 - val_accuracy: 0.7699 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.7926\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 21/40: loss=0.4626, accuracy=0.7926, val_loss=0.4608, val_accuracy=0.7964\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4626 - accuracy: 0.7926 - val_loss: 0.4608 - val_accuracy: 0.7964 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8054Epoch 22/40: loss=0.4420, accuracy=0.8061, val_loss=0.4021, val_accuracy=0.8171\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4420 - accuracy: 0.8061 - val_loss: 0.4021 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8046Epoch 23/40: loss=0.4344, accuracy=0.8046, val_loss=0.4166, val_accuracy=0.8096\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.4344 - accuracy: 0.8046 - val_loss: 0.4166 - val_accuracy: 0.8096 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4266 - accuracy: 0.8034Epoch 24/40: loss=0.4265, accuracy=0.8034, val_loss=0.4132, val_accuracy=0.8096\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4265 - accuracy: 0.8034 - val_loss: 0.4132 - val_accuracy: 0.8096 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8156Epoch 25/40: loss=0.4113, accuracy=0.8156, val_loss=0.4281, val_accuracy=0.8022\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4113 - accuracy: 0.8156 - val_loss: 0.4281 - val_accuracy: 0.8022 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8060Epoch 26/40: loss=0.4208, accuracy=0.8063, val_loss=0.3910, val_accuracy=0.8245\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4208 - accuracy: 0.8063 - val_loss: 0.3910 - val_accuracy: 0.8245 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4072 - accuracy: 0.8118Epoch 27/40: loss=0.4083, accuracy=0.8115, val_loss=0.3958, val_accuracy=0.8270\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4083 - accuracy: 0.8115 - val_loss: 0.3958 - val_accuracy: 0.8270 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4027 - accuracy: 0.8178Epoch 28/40: loss=0.4028, accuracy=0.8179, val_loss=0.4274, val_accuracy=0.8104\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4028 - accuracy: 0.8179 - val_loss: 0.4274 - val_accuracy: 0.8104 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8305Epoch 29/40: loss=0.3924, accuracy=0.8305, val_loss=0.3803, val_accuracy=0.8220\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.3924 - accuracy: 0.8305 - val_loss: 0.3803 - val_accuracy: 0.8220 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.8221Epoch 30/40: loss=0.3995, accuracy=0.8222, val_loss=0.3801, val_accuracy=0.8195\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3995 - accuracy: 0.8222 - val_loss: 0.3801 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8295Epoch 31/40: loss=0.3906, accuracy=0.8295, val_loss=0.3820, val_accuracy=0.8295\n",
      "604/604 [==============================] - 15s 26ms/step - loss: 0.3906 - accuracy: 0.8295 - val_loss: 0.3820 - val_accuracy: 0.8295 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8306Epoch 32/40: loss=0.3858, accuracy=0.8305, val_loss=0.4251, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3858 - accuracy: 0.8305 - val_loss: 0.4251 - val_accuracy: 0.8187 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3948 - accuracy: 0.8299Epoch 33/40: loss=0.3945, accuracy=0.8301, val_loss=0.4680, val_accuracy=0.7930\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3945 - accuracy: 0.8301 - val_loss: 0.4680 - val_accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8307Epoch 34/40: loss=0.3854, accuracy=0.8307, val_loss=0.4172, val_accuracy=0.8146\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3854 - accuracy: 0.8307 - val_loss: 0.4172 - val_accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8431\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 35/40: loss=0.3706, accuracy=0.8431, val_loss=0.3949, val_accuracy=0.8245\n",
      "604/604 [==============================] - 17s 29ms/step - loss: 0.3706 - accuracy: 0.8431 - val_loss: 0.3949 - val_accuracy: 0.8245 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.8450Epoch 36/40: loss=0.3619, accuracy=0.8450, val_loss=0.4113, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3619 - accuracy: 0.8450 - val_loss: 0.4113 - val_accuracy: 0.8113 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.8410Epoch 37/40: loss=0.3559, accuracy=0.8411, val_loss=0.4061, val_accuracy=0.8179\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.3559 - accuracy: 0.8411 - val_loss: 0.4061 - val_accuracy: 0.8179 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.8385Epoch 38/40: loss=0.3695, accuracy=0.8382, val_loss=0.4126, val_accuracy=0.8162\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3695 - accuracy: 0.8382 - val_loss: 0.4126 - val_accuracy: 0.8162 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3629 - accuracy: 0.8412Epoch 39/40: loss=0.3630, accuracy=0.8413, val_loss=0.4050, val_accuracy=0.8195\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.3630 - accuracy: 0.8413 - val_loss: 0.4050 - val_accuracy: 0.8195 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8393\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40/40: loss=0.3671, accuracy=0.8396, val_loss=0.4138, val_accuracy=0.8162\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3671 - accuracy: 0.8396 - val_loss: 0.4138 - val_accuracy: 0.8162 - lr: 8.0000e-06\n",
      "Epoch 40: early stopping\n",
      "Validation accuracy: 0.8294702172279358\n",
      "\n",
      "Refined Training Combination 20/50: num_residual_blocks=9, dropout_rate=0.4, learning_rate=0.0005, filters=64, kernel_size=5, num_dense_layers=2, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.4, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.2876 - accuracy: 0.5445Epoch 1/40: loss=1.2876, accuracy=0.5445, val_loss=0.5693, val_accuracy=0.6954\n",
      "604/604 [==============================] - 21s 27ms/step - loss: 1.2876 - accuracy: 0.5445 - val_loss: 0.5693 - val_accuracy: 0.6954 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6620 - accuracy: 0.6617Epoch 2/40: loss=0.6618, accuracy=0.6620, val_loss=0.8615, val_accuracy=0.6507\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6618 - accuracy: 0.6620 - val_loss: 0.8615 - val_accuracy: 0.6507 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6177 - accuracy: 0.6870Epoch 3/40: loss=0.6173, accuracy=0.6871, val_loss=1.0356, val_accuracy=0.6134\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6173 - accuracy: 0.6871 - val_loss: 1.0356 - val_accuracy: 0.6134 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6070 - accuracy: 0.7031Epoch 4/40: loss=0.6065, accuracy=0.7032, val_loss=0.6376, val_accuracy=0.6945\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.6065 - accuracy: 0.7032 - val_loss: 0.6376 - val_accuracy: 0.6945 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5848 - accuracy: 0.7289Epoch 5/40: loss=0.5856, accuracy=0.7285, val_loss=1.4791, val_accuracy=0.4048\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5856 - accuracy: 0.7285 - val_loss: 1.4791 - val_accuracy: 0.4048 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7090\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/40: loss=0.5914, accuracy=0.7090, val_loss=1.1147, val_accuracy=0.6233\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5914 - accuracy: 0.7090 - val_loss: 1.1147 - val_accuracy: 0.6233 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7591Epoch 7/40: loss=0.5233, accuracy=0.7593, val_loss=0.4759, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5233 - accuracy: 0.7593 - val_loss: 0.4759 - val_accuracy: 0.8088 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.7774Epoch 8/40: loss=0.4831, accuracy=0.7775, val_loss=0.4461, val_accuracy=0.7997\n",
      "604/604 [==============================] - 15s 26ms/step - loss: 0.4831 - accuracy: 0.7775 - val_loss: 0.4461 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7868Epoch 9/40: loss=0.4752, accuracy=0.7868, val_loss=0.5541, val_accuracy=0.7806\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4752 - accuracy: 0.7868 - val_loss: 0.5541 - val_accuracy: 0.7806 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.7781Epoch 10/40: loss=0.4694, accuracy=0.7781, val_loss=0.4308, val_accuracy=0.8088\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4694 - accuracy: 0.7781 - val_loss: 0.4308 - val_accuracy: 0.8088 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.7930Epoch 11/40: loss=0.4495, accuracy=0.7930, val_loss=0.4481, val_accuracy=0.8212\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.4495 - accuracy: 0.7930 - val_loss: 0.4481 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.7973Epoch 12/40: loss=0.4493, accuracy=0.7976, val_loss=0.5688, val_accuracy=0.7392\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4493 - accuracy: 0.7976 - val_loss: 0.5688 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8050Epoch 13/40: loss=0.4389, accuracy=0.8050, val_loss=0.4898, val_accuracy=0.7864\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.4389 - accuracy: 0.8050 - val_loss: 0.4898 - val_accuracy: 0.7864 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8050Epoch 14/40: loss=0.4261, accuracy=0.8050, val_loss=0.4942, val_accuracy=0.7988\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4261 - accuracy: 0.8050 - val_loss: 0.4942 - val_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4138 - accuracy: 0.8116\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 15/40: loss=0.4138, accuracy=0.8115, val_loss=0.4911, val_accuracy=0.7947\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4138 - accuracy: 0.8115 - val_loss: 0.4911 - val_accuracy: 0.7947 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8421Epoch 16/40: loss=0.3676, accuracy=0.8421, val_loss=0.4404, val_accuracy=0.8262\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3676 - accuracy: 0.8421 - val_loss: 0.4404 - val_accuracy: 0.8262 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3463 - accuracy: 0.8515Epoch 17/40: loss=0.3461, accuracy=0.8516, val_loss=0.4695, val_accuracy=0.8187\n",
      "604/604 [==============================] - 18s 29ms/step - loss: 0.3461 - accuracy: 0.8516 - val_loss: 0.4695 - val_accuracy: 0.8187 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8526Epoch 18/40: loss=0.3400, accuracy=0.8529, val_loss=0.4691, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3400 - accuracy: 0.8529 - val_loss: 0.4691 - val_accuracy: 0.8278 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8725Epoch 19/40: loss=0.2991, accuracy=0.8727, val_loss=0.4924, val_accuracy=0.8179\n",
      "604/604 [==============================] - 17s 28ms/step - loss: 0.2991 - accuracy: 0.8727 - val_loss: 0.4924 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8694\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 20/40: loss=0.3097, accuracy=0.8690, val_loss=0.5822, val_accuracy=0.8038\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3097 - accuracy: 0.8690 - val_loss: 0.5822 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 20: early stopping\n",
      "Validation accuracy: 0.8278145790100098\n",
      "\n",
      "Refined Training Combination 21/50: num_residual_blocks=8, dropout_rate=0.30000000000000004, learning_rate=0.002, filters=32, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.5, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0930 - accuracy: 0.5433Epoch 1/40: loss=1.0930, accuracy=0.5433, val_loss=0.8342, val_accuracy=0.5993\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 1.0930 - accuracy: 0.5433 - val_loss: 0.8342 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0341 - accuracy: 0.6074Epoch 2/40: loss=1.0341, accuracy=0.6074, val_loss=0.8647, val_accuracy=0.6192\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 1.0341 - accuracy: 0.6074 - val_loss: 0.8647 - val_accuracy: 0.6192 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9707 - accuracy: 0.6179Epoch 3/40: loss=0.9710, accuracy=0.6178, val_loss=0.5665, val_accuracy=0.6954\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.9710 - accuracy: 0.6178 - val_loss: 0.5665 - val_accuracy: 0.6954 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0076 - accuracy: 0.6043Epoch 4/40: loss=1.0069, accuracy=0.6045, val_loss=0.9655, val_accuracy=0.4040\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.0069 - accuracy: 0.6045 - val_loss: 0.9655 - val_accuracy: 0.4040 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9570 - accuracy: 0.6144Epoch 5/40: loss=0.9570, accuracy=0.6144, val_loss=0.5576, val_accuracy=0.7409\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.9570 - accuracy: 0.6144 - val_loss: 0.5576 - val_accuracy: 0.7409 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9245 - accuracy: 0.6345Epoch 6/40: loss=0.9245, accuracy=0.6345, val_loss=0.9801, val_accuracy=0.4255\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.9245 - accuracy: 0.6345 - val_loss: 0.9801 - val_accuracy: 0.4255 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8989 - accuracy: 0.6308Epoch 7/40: loss=0.8982, accuracy=0.6304, val_loss=0.6070, val_accuracy=0.6325\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8982 - accuracy: 0.6304 - val_loss: 0.6070 - val_accuracy: 0.6325 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.6455Epoch 8/40: loss=0.8508, accuracy=0.6455, val_loss=0.5421, val_accuracy=0.7392\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8508 - accuracy: 0.6455 - val_loss: 0.5421 - val_accuracy: 0.7392 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8703 - accuracy: 0.6318Epoch 9/40: loss=0.8702, accuracy=0.6318, val_loss=0.9007, val_accuracy=0.6200\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.8702 - accuracy: 0.6318 - val_loss: 0.9007 - val_accuracy: 0.6200 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8151 - accuracy: 0.6640Epoch 10/40: loss=0.8194, accuracy=0.6635, val_loss=0.5471, val_accuracy=0.7094\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8194 - accuracy: 0.6635 - val_loss: 0.5471 - val_accuracy: 0.7094 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8251 - accuracy: 0.6455Epoch 11/40: loss=0.8251, accuracy=0.6455, val_loss=1.0781, val_accuracy=0.4321\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8251 - accuracy: 0.6455 - val_loss: 1.0781 - val_accuracy: 0.4321 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.6591Epoch 12/40: loss=0.7824, accuracy=0.6591, val_loss=0.9822, val_accuracy=0.4363\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7824 - accuracy: 0.6591 - val_loss: 0.9822 - val_accuracy: 0.4363 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7562 - accuracy: 0.6689\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 13/40: loss=0.7562, accuracy=0.6691, val_loss=0.8290, val_accuracy=0.6051\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7562 - accuracy: 0.6691 - val_loss: 0.8290 - val_accuracy: 0.6051 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.6864Epoch 14/40: loss=0.6857, accuracy=0.6865, val_loss=0.4766, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6857 - accuracy: 0.6865 - val_loss: 0.4766 - val_accuracy: 0.7765 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.6869Epoch 15/40: loss=0.6587, accuracy=0.6869, val_loss=0.4651, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6587 - accuracy: 0.6869 - val_loss: 0.4651 - val_accuracy: 0.7740 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5964 - accuracy: 0.7081Epoch 16/40: loss=0.5964, accuracy=0.7082, val_loss=0.4907, val_accuracy=0.7624\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5964 - accuracy: 0.7082 - val_loss: 0.4907 - val_accuracy: 0.7624 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5710 - accuracy: 0.7289Epoch 17/40: loss=0.5712, accuracy=0.7285, val_loss=0.4407, val_accuracy=0.7856\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5712 - accuracy: 0.7285 - val_loss: 0.4407 - val_accuracy: 0.7856 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.7249Epoch 18/40: loss=0.5670, accuracy=0.7245, val_loss=0.4446, val_accuracy=0.7848\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5670 - accuracy: 0.7245 - val_loss: 0.4446 - val_accuracy: 0.7848 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.7311Epoch 19/40: loss=0.5534, accuracy=0.7314, val_loss=0.4290, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5534 - accuracy: 0.7314 - val_loss: 0.4290 - val_accuracy: 0.7955 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7425Epoch 20/40: loss=0.5288, accuracy=0.7425, val_loss=0.4760, val_accuracy=0.7616\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5288 - accuracy: 0.7425 - val_loss: 0.4760 - val_accuracy: 0.7616 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.7317Epoch 21/40: loss=0.5327, accuracy=0.7320, val_loss=0.8204, val_accuracy=0.6722\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5327 - accuracy: 0.7320 - val_loss: 0.8204 - val_accuracy: 0.6722 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7473Epoch 22/40: loss=0.5309, accuracy=0.7473, val_loss=0.4458, val_accuracy=0.7881\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5309 - accuracy: 0.7473 - val_loss: 0.4458 - val_accuracy: 0.7881 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7434Epoch 23/40: loss=0.5236, accuracy=0.7434, val_loss=0.4183, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5236 - accuracy: 0.7434 - val_loss: 0.4183 - val_accuracy: 0.7964 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5290 - accuracy: 0.7432Epoch 24/40: loss=0.5290, accuracy=0.7432, val_loss=0.4240, val_accuracy=0.7922\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5290 - accuracy: 0.7432 - val_loss: 0.4240 - val_accuracy: 0.7922 - lr: 4.0000e-04\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.7488Epoch 25/40: loss=0.5143, accuracy=0.7483, val_loss=0.4426, val_accuracy=0.7997\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5143 - accuracy: 0.7483 - val_loss: 0.4426 - val_accuracy: 0.7997 - lr: 4.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5134 - accuracy: 0.7564Epoch 26/40: loss=0.5137, accuracy=0.7564, val_loss=0.4541, val_accuracy=0.8005\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5137 - accuracy: 0.7564 - val_loss: 0.4541 - val_accuracy: 0.8005 - lr: 4.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.7620Epoch 27/40: loss=0.5027, accuracy=0.7620, val_loss=0.4409, val_accuracy=0.7823\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5027 - accuracy: 0.7620 - val_loss: 0.4409 - val_accuracy: 0.7823 - lr: 4.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.7658\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 28/40: loss=0.5018, accuracy=0.7659, val_loss=0.5228, val_accuracy=0.7450\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5018 - accuracy: 0.7659 - val_loss: 0.5228 - val_accuracy: 0.7450 - lr: 4.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4927 - accuracy: 0.7633Epoch 29/40: loss=0.4922, accuracy=0.7637, val_loss=0.4018, val_accuracy=0.8096\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4922 - accuracy: 0.7637 - val_loss: 0.4018 - val_accuracy: 0.8096 - lr: 8.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7772Epoch 30/40: loss=0.4944, accuracy=0.7773, val_loss=0.4135, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4944 - accuracy: 0.7773 - val_loss: 0.4135 - val_accuracy: 0.8137 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.7647Epoch 31/40: loss=0.4940, accuracy=0.7643, val_loss=0.4071, val_accuracy=0.8022\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4940 - accuracy: 0.7643 - val_loss: 0.4071 - val_accuracy: 0.8022 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.7728Epoch 32/40: loss=0.4771, accuracy=0.7728, val_loss=0.4037, val_accuracy=0.8113\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4771 - accuracy: 0.7728 - val_loss: 0.4037 - val_accuracy: 0.8113 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.7797Epoch 33/40: loss=0.4760, accuracy=0.7798, val_loss=0.4005, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4760 - accuracy: 0.7798 - val_loss: 0.4005 - val_accuracy: 0.8137 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.7815Epoch 34/40: loss=0.4708, accuracy=0.7815, val_loss=0.3930, val_accuracy=0.8245\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4708 - accuracy: 0.7815 - val_loss: 0.3930 - val_accuracy: 0.8245 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.7767Epoch 35/40: loss=0.4735, accuracy=0.7767, val_loss=0.3925, val_accuracy=0.8270\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4735 - accuracy: 0.7767 - val_loss: 0.3925 - val_accuracy: 0.8270 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.7865Epoch 36/40: loss=0.4556, accuracy=0.7862, val_loss=0.4381, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4556 - accuracy: 0.7862 - val_loss: 0.4381 - val_accuracy: 0.8079 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4498 - accuracy: 0.7931Epoch 37/40: loss=0.4502, accuracy=0.7928, val_loss=0.3925, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4502 - accuracy: 0.7928 - val_loss: 0.3925 - val_accuracy: 0.8113 - lr: 8.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.7823Epoch 38/40: loss=0.4632, accuracy=0.7823, val_loss=0.3970, val_accuracy=0.8096\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4632 - accuracy: 0.7823 - val_loss: 0.3970 - val_accuracy: 0.8096 - lr: 8.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.7812Epoch 39/40: loss=0.4609, accuracy=0.7812, val_loss=0.4040, val_accuracy=0.8121\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4040 - val_accuracy: 0.8121 - lr: 8.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.7854\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 40/40: loss=0.4596, accuracy=0.7854, val_loss=0.3960, val_accuracy=0.8171\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4596 - accuracy: 0.7854 - val_loss: 0.3960 - val_accuracy: 0.8171 - lr: 8.0000e-05\n",
      "Validation accuracy: 0.8269867300987244\n",
      "\n",
      "Refined Training Combination 22/50: num_residual_blocks=9, dropout_rate=0.30000000000000004, learning_rate=0.002, filters=128, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.5, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0835 - accuracy: 0.5612Epoch 1/40: loss=1.0851, accuracy=0.5606, val_loss=1.0748, val_accuracy=0.5993\n",
      "604/604 [==============================] - 29s 42ms/step - loss: 1.0851 - accuracy: 0.5606 - val_loss: 1.0748 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1212 - accuracy: 0.5653Epoch 2/40: loss=1.1201, accuracy=0.5656, val_loss=0.5772, val_accuracy=0.7169\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 1.1201 - accuracy: 0.5656 - val_loss: 0.5772 - val_accuracy: 0.7169 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.5933Epoch 3/40: loss=1.0341, accuracy=0.5935, val_loss=0.9583, val_accuracy=0.4031\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 1.0341 - accuracy: 0.5935 - val_loss: 0.9583 - val_accuracy: 0.4031 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9946 - accuracy: 0.6031Epoch 4/40: loss=0.9946, accuracy=0.6031, val_loss=0.5970, val_accuracy=0.7028\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.9946 - accuracy: 0.6031 - val_loss: 0.5970 - val_accuracy: 0.7028 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0291 - accuracy: 0.5782Epoch 5/40: loss=1.0291, accuracy=0.5782, val_loss=1.1611, val_accuracy=0.4056\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 1.0291 - accuracy: 0.5782 - val_loss: 1.1611 - val_accuracy: 0.4056 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9898 - accuracy: 0.5821Epoch 6/40: loss=0.9897, accuracy=0.5820, val_loss=0.6325, val_accuracy=0.6846\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.9897 - accuracy: 0.5820 - val_loss: 0.6325 - val_accuracy: 0.6846 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9428 - accuracy: 0.6010\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 7/40: loss=0.9421, accuracy=0.6010, val_loss=0.6158, val_accuracy=0.7111\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.9421 - accuracy: 0.6010 - val_loss: 0.6158 - val_accuracy: 0.7111 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8218 - accuracy: 0.6403Epoch 8/40: loss=0.8215, accuracy=0.6405, val_loss=0.6274, val_accuracy=0.6573\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.8215 - accuracy: 0.6405 - val_loss: 0.6274 - val_accuracy: 0.6573 - lr: 4.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7495 - accuracy: 0.6497Epoch 9/40: loss=0.7494, accuracy=0.6496, val_loss=0.5541, val_accuracy=0.7202\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7494 - accuracy: 0.6496 - val_loss: 0.5541 - val_accuracy: 0.7202 - lr: 4.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6835 - accuracy: 0.6598Epoch 10/40: loss=0.6835, accuracy=0.6598, val_loss=0.5703, val_accuracy=0.7144\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.6835 - accuracy: 0.6598 - val_loss: 0.5703 - val_accuracy: 0.7144 - lr: 4.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.6704Epoch 11/40: loss=0.6539, accuracy=0.6707, val_loss=0.6217, val_accuracy=0.7086\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.6539 - accuracy: 0.6707 - val_loss: 0.6217 - val_accuracy: 0.7086 - lr: 4.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6289 - accuracy: 0.6886Epoch 12/40: loss=0.6288, accuracy=0.6883, val_loss=0.5878, val_accuracy=0.7268\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.6288 - accuracy: 0.6883 - val_loss: 0.5878 - val_accuracy: 0.7268 - lr: 4.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.6908Epoch 13/40: loss=0.6165, accuracy=0.6908, val_loss=0.5379, val_accuracy=0.7210\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.6165 - accuracy: 0.6908 - val_loss: 0.5379 - val_accuracy: 0.7210 - lr: 4.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6010 - accuracy: 0.6909Epoch 14/40: loss=0.6012, accuracy=0.6908, val_loss=0.5132, val_accuracy=0.7318\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.6012 - accuracy: 0.6908 - val_loss: 0.5132 - val_accuracy: 0.7318 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.6901Epoch 15/40: loss=0.6123, accuracy=0.6896, val_loss=0.6924, val_accuracy=0.5430\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.6123 - accuracy: 0.6896 - val_loss: 0.6924 - val_accuracy: 0.5430 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6028 - accuracy: 0.6789Epoch 16/40: loss=0.6027, accuracy=0.6790, val_loss=0.6300, val_accuracy=0.6010\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.6027 - accuracy: 0.6790 - val_loss: 0.6300 - val_accuracy: 0.6010 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6082 - accuracy: 0.6859Epoch 17/40: loss=0.6084, accuracy=0.6861, val_loss=0.4781, val_accuracy=0.7599\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.6084 - accuracy: 0.6861 - val_loss: 0.4781 - val_accuracy: 0.7599 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5957 - accuracy: 0.6969Epoch 18/40: loss=0.5957, accuracy=0.6968, val_loss=0.7328, val_accuracy=0.5232\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.5957 - accuracy: 0.6968 - val_loss: 0.7328 - val_accuracy: 0.5232 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5745 - accuracy: 0.7133Epoch 19/40: loss=0.5740, accuracy=0.7136, val_loss=0.7066, val_accuracy=0.5993\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5740 - accuracy: 0.7136 - val_loss: 0.7066 - val_accuracy: 0.5993 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.7077Epoch 20/40: loss=0.5818, accuracy=0.7080, val_loss=0.8870, val_accuracy=0.6490\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5818 - accuracy: 0.7080 - val_loss: 0.8870 - val_accuracy: 0.6490 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.7117Epoch 21/40: loss=0.5865, accuracy=0.7115, val_loss=0.6035, val_accuracy=0.6614\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.5865 - accuracy: 0.7115 - val_loss: 0.6035 - val_accuracy: 0.6614 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7183\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 22/40: loss=0.5708, accuracy=0.7183, val_loss=0.5038, val_accuracy=0.7517\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.5708 - accuracy: 0.7183 - val_loss: 0.5038 - val_accuracy: 0.7517 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5618 - accuracy: 0.7199Epoch 23/40: loss=0.5616, accuracy=0.7200, val_loss=0.5033, val_accuracy=0.7707\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5616 - accuracy: 0.7200 - val_loss: 0.5033 - val_accuracy: 0.7707 - lr: 8.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5508 - accuracy: 0.7293Epoch 24/40: loss=0.5504, accuracy=0.7297, val_loss=0.4653, val_accuracy=0.7823\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5504 - accuracy: 0.7297 - val_loss: 0.4653 - val_accuracy: 0.7823 - lr: 8.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.7281Epoch 25/40: loss=0.5554, accuracy=0.7281, val_loss=0.4804, val_accuracy=0.7790\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5554 - accuracy: 0.7281 - val_loss: 0.4804 - val_accuracy: 0.7790 - lr: 8.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.7454Epoch 26/40: loss=0.5325, accuracy=0.7454, val_loss=0.4962, val_accuracy=0.7674\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5325 - accuracy: 0.7454 - val_loss: 0.4962 - val_accuracy: 0.7674 - lr: 8.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5346 - accuracy: 0.7398Epoch 27/40: loss=0.5346, accuracy=0.7401, val_loss=0.4572, val_accuracy=0.7806\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.5346 - accuracy: 0.7401 - val_loss: 0.4572 - val_accuracy: 0.7806 - lr: 8.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5186 - accuracy: 0.7500Epoch 28/40: loss=0.5183, accuracy=0.7502, val_loss=0.4420, val_accuracy=0.7831\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.5183 - accuracy: 0.7502 - val_loss: 0.4420 - val_accuracy: 0.7831 - lr: 8.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.7585Epoch 29/40: loss=0.5174, accuracy=0.7583, val_loss=0.4583, val_accuracy=0.7823\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.5174 - accuracy: 0.7583 - val_loss: 0.4583 - val_accuracy: 0.7823 - lr: 8.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7469Epoch 30/40: loss=0.5290, accuracy=0.7469, val_loss=0.5974, val_accuracy=0.7070\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5290 - accuracy: 0.7469 - val_loss: 0.5974 - val_accuracy: 0.7070 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7423Epoch 31/40: loss=0.5236, accuracy=0.7423, val_loss=0.4352, val_accuracy=0.7922\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.5236 - accuracy: 0.7423 - val_loss: 0.4352 - val_accuracy: 0.7922 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.7471Epoch 32/40: loss=0.5229, accuracy=0.7471, val_loss=0.4431, val_accuracy=0.7939\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5229 - accuracy: 0.7471 - val_loss: 0.4431 - val_accuracy: 0.7939 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5106 - accuracy: 0.7541Epoch 33/40: loss=0.5104, accuracy=0.7543, val_loss=0.5051, val_accuracy=0.7724\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5104 - accuracy: 0.7543 - val_loss: 0.5051 - val_accuracy: 0.7724 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.7606Epoch 34/40: loss=0.5017, accuracy=0.7606, val_loss=0.4866, val_accuracy=0.7773\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5017 - accuracy: 0.7606 - val_loss: 0.4866 - val_accuracy: 0.7773 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.7486Epoch 35/40: loss=0.5141, accuracy=0.7486, val_loss=0.4382, val_accuracy=0.7930\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5141 - accuracy: 0.7486 - val_loss: 0.4382 - val_accuracy: 0.7930 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5086 - accuracy: 0.7566\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 36/40: loss=0.5087, accuracy=0.7564, val_loss=0.5106, val_accuracy=0.7773\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5087 - accuracy: 0.7564 - val_loss: 0.5106 - val_accuracy: 0.7773 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7589Epoch 37/40: loss=0.5061, accuracy=0.7589, val_loss=0.4549, val_accuracy=0.7955\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5061 - accuracy: 0.7589 - val_loss: 0.4549 - val_accuracy: 0.7955 - lr: 1.6000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4992 - accuracy: 0.7633Epoch 38/40: loss=0.4994, accuracy=0.7628, val_loss=0.4716, val_accuracy=0.7790\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.4994 - accuracy: 0.7628 - val_loss: 0.4716 - val_accuracy: 0.7790 - lr: 1.6000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4885 - accuracy: 0.7657Epoch 39/40: loss=0.4885, accuracy=0.7657, val_loss=0.4349, val_accuracy=0.7930\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.4885 - accuracy: 0.7657 - val_loss: 0.4349 - val_accuracy: 0.7930 - lr: 1.6000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.7548Epoch 40/40: loss=0.5029, accuracy=0.7548, val_loss=0.4789, val_accuracy=0.7765\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5029 - accuracy: 0.7548 - val_loss: 0.4789 - val_accuracy: 0.7765 - lr: 1.6000e-05\n",
      "Validation accuracy: 0.7955297827720642\n",
      "\n",
      "Refined Training Combination 23/50: num_residual_blocks=9, dropout_rate=0.30000000000000004, learning_rate=0.001, filters=128, kernel_size=5, num_dense_layers=1, activation_function=tanh, rotation_range=30, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.5, zoom_range=0.0, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9265 - accuracy: 0.5606Epoch 1/40: loss=0.9265, accuracy=0.5606, val_loss=0.6808, val_accuracy=0.6680\n",
      "604/604 [==============================] - 24s 35ms/step - loss: 0.9265 - accuracy: 0.5606 - val_loss: 0.6808 - val_accuracy: 0.6680 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.6325Epoch 2/40: loss=0.7871, accuracy=0.6329, val_loss=1.5454, val_accuracy=0.4015\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.7871 - accuracy: 0.6329 - val_loss: 1.5454 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7761 - accuracy: 0.6407Epoch 3/40: loss=0.7761, accuracy=0.6407, val_loss=0.7687, val_accuracy=0.5919\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7761 - accuracy: 0.6407 - val_loss: 0.7687 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.5929Epoch 4/40: loss=0.8344, accuracy=0.5929, val_loss=0.8282, val_accuracy=0.4387\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.8344 - accuracy: 0.5929 - val_loss: 0.8282 - val_accuracy: 0.4387 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7896 - accuracy: 0.6173Epoch 5/40: loss=0.7896, accuracy=0.6173, val_loss=0.7156, val_accuracy=0.6134\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7896 - accuracy: 0.6173 - val_loss: 0.7156 - val_accuracy: 0.6134 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8148 - accuracy: 0.6022Epoch 6/40: loss=0.8158, accuracy=0.6018, val_loss=0.6537, val_accuracy=0.5993\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.8158 - accuracy: 0.6018 - val_loss: 0.6537 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7769 - accuracy: 0.6190Epoch 7/40: loss=0.7762, accuracy=0.6194, val_loss=0.6400, val_accuracy=0.6854\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7762 - accuracy: 0.6194 - val_loss: 0.6400 - val_accuracy: 0.6854 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.6339Epoch 8/40: loss=0.7710, accuracy=0.6339, val_loss=1.1347, val_accuracy=0.4007\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.7710 - accuracy: 0.6339 - val_loss: 1.1347 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.6337Epoch 9/40: loss=0.7570, accuracy=0.6337, val_loss=0.9266, val_accuracy=0.4967\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.7570 - accuracy: 0.6337 - val_loss: 0.9266 - val_accuracy: 0.4967 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7729 - accuracy: 0.6150Epoch 10/40: loss=0.7738, accuracy=0.6144, val_loss=0.9390, val_accuracy=0.4015\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.7738 - accuracy: 0.6144 - val_loss: 0.9390 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.6093Epoch 11/40: loss=0.7849, accuracy=0.6093, val_loss=0.5764, val_accuracy=0.5993\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.7849 - accuracy: 0.6093 - val_loss: 0.5764 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7565 - accuracy: 0.6277Epoch 12/40: loss=0.7555, accuracy=0.6283, val_loss=0.6732, val_accuracy=0.6838\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7555 - accuracy: 0.6283 - val_loss: 0.6732 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7706 - accuracy: 0.6190Epoch 13/40: loss=0.7707, accuracy=0.6190, val_loss=0.5593, val_accuracy=0.7450\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7707 - accuracy: 0.6190 - val_loss: 0.5593 - val_accuracy: 0.7450 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7707 - accuracy: 0.6066Epoch 14/40: loss=0.7712, accuracy=0.6064, val_loss=0.6989, val_accuracy=0.6507\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7712 - accuracy: 0.6064 - val_loss: 0.6989 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7417 - accuracy: 0.6318Epoch 15/40: loss=0.7417, accuracy=0.6314, val_loss=0.7443, val_accuracy=0.5679\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7417 - accuracy: 0.6314 - val_loss: 0.7443 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.6459Epoch 16/40: loss=0.7356, accuracy=0.6457, val_loss=0.7304, val_accuracy=0.6126\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.7356 - accuracy: 0.6457 - val_loss: 0.7304 - val_accuracy: 0.6126 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7519 - accuracy: 0.6269Epoch 17/40: loss=0.7519, accuracy=0.6269, val_loss=0.5416, val_accuracy=0.7252\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7519 - accuracy: 0.6269 - val_loss: 0.5416 - val_accuracy: 0.7252 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7194 - accuracy: 0.6517Epoch 18/40: loss=0.7193, accuracy=0.6519, val_loss=0.8732, val_accuracy=0.4545\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7193 - accuracy: 0.6519 - val_loss: 0.8732 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7127 - accuracy: 0.6420Epoch 19/40: loss=0.7130, accuracy=0.6416, val_loss=1.0600, val_accuracy=0.4031\n",
      "604/604 [==============================] - 22s 36ms/step - loss: 0.7130 - accuracy: 0.6416 - val_loss: 1.0600 - val_accuracy: 0.4031 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7626 - accuracy: 0.6036Epoch 20/40: loss=0.7628, accuracy=0.6037, val_loss=0.7146, val_accuracy=0.6275\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7628 - accuracy: 0.6037 - val_loss: 0.7146 - val_accuracy: 0.6275 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7255 - accuracy: 0.6345Epoch 21/40: loss=0.7255, accuracy=0.6345, val_loss=0.9094, val_accuracy=0.5099\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.7255 - accuracy: 0.6345 - val_loss: 0.9094 - val_accuracy: 0.5099 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7983 - accuracy: 0.5837\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 22/40: loss=0.7986, accuracy=0.5836, val_loss=0.6006, val_accuracy=0.6978\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.7986 - accuracy: 0.5836 - val_loss: 0.6006 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.6149Epoch 23/40: loss=0.7193, accuracy=0.6149, val_loss=0.5402, val_accuracy=0.7376\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.7193 - accuracy: 0.6149 - val_loss: 0.5402 - val_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6743 - accuracy: 0.6509Epoch 24/40: loss=0.6742, accuracy=0.6511, val_loss=0.5198, val_accuracy=0.7533\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.6742 - accuracy: 0.6511 - val_loss: 0.5198 - val_accuracy: 0.7533 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.6700Epoch 25/40: loss=0.6384, accuracy=0.6701, val_loss=0.5953, val_accuracy=0.6540\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.6384 - accuracy: 0.6701 - val_loss: 0.5953 - val_accuracy: 0.6540 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7005Epoch 26/40: loss=0.6088, accuracy=0.6999, val_loss=0.5126, val_accuracy=0.7376\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.6088 - accuracy: 0.6999 - val_loss: 0.5126 - val_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.7044Epoch 27/40: loss=0.6024, accuracy=0.7045, val_loss=0.5367, val_accuracy=0.7608\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.6024 - accuracy: 0.7045 - val_loss: 0.5367 - val_accuracy: 0.7608 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.7142Epoch 28/40: loss=0.5805, accuracy=0.7142, val_loss=0.5307, val_accuracy=0.7334\n",
      "604/604 [==============================] - 21s 34ms/step - loss: 0.5805 - accuracy: 0.7142 - val_loss: 0.5307 - val_accuracy: 0.7334 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.7190Epoch 29/40: loss=0.5747, accuracy=0.7190, val_loss=0.4950, val_accuracy=0.7599\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.5747 - accuracy: 0.7190 - val_loss: 0.4950 - val_accuracy: 0.7599 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7088Epoch 30/40: loss=0.5857, accuracy=0.7088, val_loss=0.5851, val_accuracy=0.7334\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5857 - accuracy: 0.7088 - val_loss: 0.5851 - val_accuracy: 0.7334 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.7208Epoch 31/40: loss=0.5634, accuracy=0.7208, val_loss=0.5027, val_accuracy=0.7674\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5634 - accuracy: 0.7208 - val_loss: 0.5027 - val_accuracy: 0.7674 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.7268Epoch 32/40: loss=0.5633, accuracy=0.7268, val_loss=0.5273, val_accuracy=0.7657\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5633 - accuracy: 0.7268 - val_loss: 0.5273 - val_accuracy: 0.7657 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.7254Epoch 33/40: loss=0.5600, accuracy=0.7254, val_loss=0.5078, val_accuracy=0.7666\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5600 - accuracy: 0.7254 - val_loss: 0.5078 - val_accuracy: 0.7666 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.7187\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 34/40: loss=0.5530, accuracy=0.7192, val_loss=0.4983, val_accuracy=0.7699\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5530 - accuracy: 0.7192 - val_loss: 0.4983 - val_accuracy: 0.7699 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5479 - accuracy: 0.7282Epoch 35/40: loss=0.5479, accuracy=0.7281, val_loss=0.4896, val_accuracy=0.7773\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5479 - accuracy: 0.7281 - val_loss: 0.4896 - val_accuracy: 0.7773 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5572 - accuracy: 0.7185Epoch 36/40: loss=0.5569, accuracy=0.7190, val_loss=0.5181, val_accuracy=0.7641\n",
      "604/604 [==============================] - 20s 34ms/step - loss: 0.5569 - accuracy: 0.7190 - val_loss: 0.5181 - val_accuracy: 0.7641 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7301Epoch 37/40: loss=0.5498, accuracy=0.7301, val_loss=0.4961, val_accuracy=0.7715\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5498 - accuracy: 0.7301 - val_loss: 0.4961 - val_accuracy: 0.7715 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.7396Epoch 38/40: loss=0.5417, accuracy=0.7397, val_loss=0.4944, val_accuracy=0.7690\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5417 - accuracy: 0.7397 - val_loss: 0.4944 - val_accuracy: 0.7690 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.7407Epoch 39/40: loss=0.5436, accuracy=0.7407, val_loss=0.4875, val_accuracy=0.7707\n",
      "604/604 [==============================] - 20s 33ms/step - loss: 0.5436 - accuracy: 0.7407 - val_loss: 0.4875 - val_accuracy: 0.7707 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5414 - accuracy: 0.7396Epoch 40/40: loss=0.5410, accuracy=0.7401, val_loss=0.4935, val_accuracy=0.7715\n",
      "604/604 [==============================] - 21s 35ms/step - loss: 0.5410 - accuracy: 0.7401 - val_loss: 0.4935 - val_accuracy: 0.7715 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.7773178815841675\n",
      "\n",
      "Refined Training Combination 24/50: num_residual_blocks=9, dropout_rate=0.30000000000000004, learning_rate=0.002, filters=128, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=20, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.5, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0281 - accuracy: 0.5891Epoch 1/40: loss=1.0290, accuracy=0.5890, val_loss=1.1729, val_accuracy=0.6051\n",
      "604/604 [==============================] - 17s 24ms/step - loss: 1.0290 - accuracy: 0.5890 - val_loss: 1.1729 - val_accuracy: 0.6051 - lr: 0.0020\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.1123 - accuracy: 0.5769Epoch 2/40: loss=1.1111, accuracy=0.5774, val_loss=0.9814, val_accuracy=0.4379\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 1.1111 - accuracy: 0.5774 - val_loss: 0.9814 - val_accuracy: 0.4379 - lr: 0.0020\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0634 - accuracy: 0.5782Epoch 3/40: loss=1.0644, accuracy=0.5780, val_loss=1.1057, val_accuracy=0.6060\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 1.0644 - accuracy: 0.5780 - val_loss: 1.1057 - val_accuracy: 0.6060 - lr: 0.0020\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.5697Epoch 4/40: loss=1.0747, accuracy=0.5697, val_loss=0.7957, val_accuracy=0.6233\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 1.0747 - accuracy: 0.5697 - val_loss: 0.7957 - val_accuracy: 0.6233 - lr: 0.0020\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9838 - accuracy: 0.6010Epoch 5/40: loss=0.9837, accuracy=0.6006, val_loss=0.6655, val_accuracy=0.6440\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9837 - accuracy: 0.6006 - val_loss: 0.6655 - val_accuracy: 0.6440 - lr: 0.0020\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0235 - accuracy: 0.5752Epoch 6/40: loss=1.0223, accuracy=0.5757, val_loss=0.5355, val_accuracy=0.7219\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 1.0223 - accuracy: 0.5757 - val_loss: 0.5355 - val_accuracy: 0.7219 - lr: 0.0020\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9966 - accuracy: 0.5647Epoch 7/40: loss=0.9957, accuracy=0.5650, val_loss=0.5833, val_accuracy=0.6970\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9957 - accuracy: 0.5650 - val_loss: 0.5833 - val_accuracy: 0.6970 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9212 - accuracy: 0.6012Epoch 8/40: loss=0.9219, accuracy=0.6010, val_loss=0.5342, val_accuracy=0.7541\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9219 - accuracy: 0.6010 - val_loss: 0.5342 - val_accuracy: 0.7541 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8902 - accuracy: 0.6045Epoch 9/40: loss=0.8898, accuracy=0.6047, val_loss=0.8298, val_accuracy=0.6043\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8898 - accuracy: 0.6047 - val_loss: 0.8298 - val_accuracy: 0.6043 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.5381Epoch 10/40: loss=0.9852, accuracy=0.5381, val_loss=0.9262, val_accuracy=0.4354\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9852 - accuracy: 0.5381 - val_loss: 0.9262 - val_accuracy: 0.4354 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8725 - accuracy: 0.5955Epoch 11/40: loss=0.8743, accuracy=0.5946, val_loss=0.6727, val_accuracy=0.6796\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8743 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6796 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.5293Epoch 12/40: loss=0.9698, accuracy=0.5290, val_loss=0.6660, val_accuracy=0.5853\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9698 - accuracy: 0.5290 - val_loss: 0.6660 - val_accuracy: 0.5853 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8747 - accuracy: 0.5755\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 13/40: loss=0.8755, accuracy=0.5747, val_loss=0.8493, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.8755 - accuracy: 0.5747 - val_loss: 0.8493 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7960 - accuracy: 0.5945Epoch 14/40: loss=0.7958, accuracy=0.5944, val_loss=0.5411, val_accuracy=0.7293\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7958 - accuracy: 0.5944 - val_loss: 0.5411 - val_accuracy: 0.7293 - lr: 4.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.6442Epoch 15/40: loss=0.7014, accuracy=0.6442, val_loss=0.5105, val_accuracy=0.7525\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7014 - accuracy: 0.6442 - val_loss: 0.5105 - val_accuracy: 0.7525 - lr: 4.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6603 - accuracy: 0.6737Epoch 16/40: loss=0.6605, accuracy=0.6736, val_loss=0.5401, val_accuracy=0.7425\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6605 - accuracy: 0.6736 - val_loss: 0.5401 - val_accuracy: 0.7425 - lr: 4.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.6821Epoch 17/40: loss=0.6364, accuracy=0.6821, val_loss=0.5667, val_accuracy=0.7276\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6364 - accuracy: 0.6821 - val_loss: 0.5667 - val_accuracy: 0.7276 - lr: 4.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6076 - accuracy: 0.7011Epoch 18/40: loss=0.6081, accuracy=0.7007, val_loss=0.5095, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6081 - accuracy: 0.7007 - val_loss: 0.5095 - val_accuracy: 0.7699 - lr: 4.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.7131Epoch 19/40: loss=0.5929, accuracy=0.7130, val_loss=0.5075, val_accuracy=0.7525\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5929 - accuracy: 0.7130 - val_loss: 0.5075 - val_accuracy: 0.7525 - lr: 4.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5824 - accuracy: 0.7261Epoch 20/40: loss=0.5835, accuracy=0.7258, val_loss=0.4950, val_accuracy=0.7848\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5835 - accuracy: 0.7258 - val_loss: 0.4950 - val_accuracy: 0.7848 - lr: 4.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.7074Epoch 21/40: loss=0.5930, accuracy=0.7074, val_loss=0.5284, val_accuracy=0.7243\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5930 - accuracy: 0.7074 - val_loss: 0.5284 - val_accuracy: 0.7243 - lr: 4.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.6966Epoch 22/40: loss=0.5943, accuracy=0.6966, val_loss=0.5326, val_accuracy=0.7757\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5943 - accuracy: 0.6966 - val_loss: 0.5326 - val_accuracy: 0.7757 - lr: 4.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7109Epoch 23/40: loss=0.5863, accuracy=0.7109, val_loss=0.4960, val_accuracy=0.7873\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5863 - accuracy: 0.7109 - val_loss: 0.4960 - val_accuracy: 0.7873 - lr: 4.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5776 - accuracy: 0.7195Epoch 24/40: loss=0.5777, accuracy=0.7196, val_loss=0.5113, val_accuracy=0.7674\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5777 - accuracy: 0.7196 - val_loss: 0.5113 - val_accuracy: 0.7674 - lr: 4.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.7165\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 25/40: loss=0.5775, accuracy=0.7165, val_loss=0.5125, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5775 - accuracy: 0.7165 - val_loss: 0.5125 - val_accuracy: 0.7210 - lr: 4.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5730 - accuracy: 0.7135Epoch 26/40: loss=0.5728, accuracy=0.7134, val_loss=0.5190, val_accuracy=0.7533\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5728 - accuracy: 0.7134 - val_loss: 0.5190 - val_accuracy: 0.7533 - lr: 8.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7205Epoch 27/40: loss=0.5637, accuracy=0.7206, val_loss=0.5058, val_accuracy=0.7674\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5637 - accuracy: 0.7206 - val_loss: 0.5058 - val_accuracy: 0.7674 - lr: 8.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7266Epoch 28/40: loss=0.5625, accuracy=0.7266, val_loss=0.5027, val_accuracy=0.7641\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5625 - accuracy: 0.7266 - val_loss: 0.5027 - val_accuracy: 0.7641 - lr: 8.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7212Epoch 29/40: loss=0.5686, accuracy=0.7214, val_loss=0.4887, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5686 - accuracy: 0.7214 - val_loss: 0.4887 - val_accuracy: 0.7839 - lr: 8.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.7394Epoch 30/40: loss=0.5503, accuracy=0.7394, val_loss=0.4972, val_accuracy=0.7815\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5503 - accuracy: 0.7394 - val_loss: 0.4972 - val_accuracy: 0.7815 - lr: 8.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.7326Epoch 31/40: loss=0.5568, accuracy=0.7326, val_loss=0.4839, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5568 - accuracy: 0.7326 - val_loss: 0.4839 - val_accuracy: 0.7964 - lr: 8.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5489 - accuracy: 0.7321Epoch 32/40: loss=0.5497, accuracy=0.7322, val_loss=0.4980, val_accuracy=0.7674\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5497 - accuracy: 0.7322 - val_loss: 0.4980 - val_accuracy: 0.7674 - lr: 8.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7438Epoch 33/40: loss=0.5384, accuracy=0.7430, val_loss=0.5059, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5384 - accuracy: 0.7430 - val_loss: 0.5059 - val_accuracy: 0.7641 - lr: 8.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5458 - accuracy: 0.7440Epoch 34/40: loss=0.5461, accuracy=0.7438, val_loss=0.4943, val_accuracy=0.7765\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5461 - accuracy: 0.7438 - val_loss: 0.4943 - val_accuracy: 0.7765 - lr: 8.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.7486Epoch 35/40: loss=0.5341, accuracy=0.7486, val_loss=0.4865, val_accuracy=0.7839\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5341 - accuracy: 0.7486 - val_loss: 0.4865 - val_accuracy: 0.7839 - lr: 8.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5480 - accuracy: 0.7375\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 36/40: loss=0.5487, accuracy=0.7372, val_loss=0.4947, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5487 - accuracy: 0.7372 - val_loss: 0.4947 - val_accuracy: 0.7740 - lr: 8.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.7407Epoch 37/40: loss=0.5403, accuracy=0.7407, val_loss=0.4933, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5403 - accuracy: 0.7407 - val_loss: 0.4933 - val_accuracy: 0.7765 - lr: 1.6000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7421Epoch 38/40: loss=0.5372, accuracy=0.7421, val_loss=0.4948, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5372 - accuracy: 0.7421 - val_loss: 0.4948 - val_accuracy: 0.7740 - lr: 1.6000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.7423Epoch 39/40: loss=0.5398, accuracy=0.7423, val_loss=0.4973, val_accuracy=0.7740\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5398 - accuracy: 0.7423 - val_loss: 0.4973 - val_accuracy: 0.7740 - lr: 1.6000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7523Epoch 40/40: loss=0.5305, accuracy=0.7523, val_loss=0.4969, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5305 - accuracy: 0.7523 - val_loss: 0.4969 - val_accuracy: 0.7740 - lr: 1.6000e-05\n",
      "Validation accuracy: 0.7963576316833496\n",
      "\n",
      "Refined Training Combination 25/50: num_residual_blocks=8, dropout_rate=0.4, learning_rate=0.0005, filters=64, kernel_size=1, num_dense_layers=1, activation_function=tanh, rotation_range=10, width_shift_range=0.0, height_shift_range=0.1, shear_range=0.30000000000000004, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8737 - accuracy: 0.5999Epoch 1/40: loss=0.8734, accuracy=0.6002, val_loss=0.5900, val_accuracy=0.7161\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.8734 - accuracy: 0.6002 - val_loss: 0.5900 - val_accuracy: 0.7161 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7100 - accuracy: 0.6642Epoch 2/40: loss=0.7097, accuracy=0.6637, val_loss=0.4842, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7097 - accuracy: 0.6637 - val_loss: 0.4842 - val_accuracy: 0.7864 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.6904Epoch 3/40: loss=0.6516, accuracy=0.6902, val_loss=0.4876, val_accuracy=0.7690\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6516 - accuracy: 0.6902 - val_loss: 0.4876 - val_accuracy: 0.7690 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.7007Epoch 4/40: loss=0.6112, accuracy=0.7007, val_loss=0.5173, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6112 - accuracy: 0.7007 - val_loss: 0.5173 - val_accuracy: 0.7210 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5818 - accuracy: 0.7243Epoch 5/40: loss=0.5818, accuracy=0.7241, val_loss=0.4381, val_accuracy=0.8055\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5818 - accuracy: 0.7241 - val_loss: 0.4381 - val_accuracy: 0.8055 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5856 - accuracy: 0.7226Epoch 6/40: loss=0.5857, accuracy=0.7227, val_loss=0.4812, val_accuracy=0.7575\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5857 - accuracy: 0.7227 - val_loss: 0.4812 - val_accuracy: 0.7575 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5724 - accuracy: 0.7342Epoch 7/40: loss=0.5718, accuracy=0.7343, val_loss=0.6424, val_accuracy=0.6763\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5718 - accuracy: 0.7343 - val_loss: 0.6424 - val_accuracy: 0.6763 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7440Epoch 8/40: loss=0.5531, accuracy=0.7440, val_loss=0.4244, val_accuracy=0.8046\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5531 - accuracy: 0.7440 - val_loss: 0.4244 - val_accuracy: 0.8046 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7496Epoch 9/40: loss=0.5465, accuracy=0.7496, val_loss=0.4241, val_accuracy=0.7972\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5465 - accuracy: 0.7496 - val_loss: 0.4241 - val_accuracy: 0.7972 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7535Epoch 10/40: loss=0.5500, accuracy=0.7535, val_loss=0.4914, val_accuracy=0.7773\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5500 - accuracy: 0.7535 - val_loss: 0.4914 - val_accuracy: 0.7773 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5224 - accuracy: 0.7587Epoch 11/40: loss=0.5236, accuracy=0.7579, val_loss=0.6689, val_accuracy=0.6606\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5236 - accuracy: 0.7579 - val_loss: 0.6689 - val_accuracy: 0.6606 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.7604Epoch 12/40: loss=0.5291, accuracy=0.7597, val_loss=0.7681, val_accuracy=0.5695\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5291 - accuracy: 0.7597 - val_loss: 0.7681 - val_accuracy: 0.5695 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      " 74/604 [==>...........................] - ETA: 11s - loss: 0.5325 - accuracy: 0.7382"
     ]
    }
   ],
   "source": [
    "# Define data augmentation\n",
    "def create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip):\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=rotation_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "def residual_block(x, filters, kernel_size):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function):\n",
    "    # Input layer for combined images\n",
    "    combined_input = Input(shape=(input_shape[1], input_shape[2], input_shape[3]), name='combined_input')\n",
    "    \n",
    "    # Convolutional base\n",
    "    x = Conv2D(filters, (kernel_size, kernel_size), activation=activation_function, padding='same')(combined_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, filters, kernel_size)\n",
    "        if x.shape[1] >= 2 and x.shape[2] >= 2:\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    for _ in range(num_dense_layers):\n",
    "        x = Dense(2048, activation=activation_function)(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# Expanded grid search parameters\n",
    "num_residual_blocks_options = [4, 5 ,6 ,7, 8]\n",
    "dropout_rate_options = [0.3, 0.25, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "learning_rate_options = [1e-2, 5e-2, 1e-3, 5e-3, 5e-4, 1e-4, 5e-5, 1e-5, 1e-6]\n",
    "filters_options = [32, 64, 128]\n",
    "kernel_size_options = [3, 5, 7]\n",
    "num_dense_layers_options = [1, 2, 3]\n",
    "activation_function_options = ['relu', 'tanh']\n",
    "rotation_range_options = [10, 20, 30, 40]\n",
    "width_shift_range_options = [0.1, 0.2, 0.3, 0.4]\n",
    "height_shift_range_options = [0.1, 0.2, 0.3, 0.4]\n",
    "shear_range_options = [0.1, 0.2, 0.3, 0.4]\n",
    "zoom_range_options = [0.1, 0.2, 0.3, 0.4]\n",
    "horizontal_flip_options = [True, False]\n",
    "\n",
    "# Create grid search parameter combinations\n",
    "parameter_combinations = list(product(num_residual_blocks_options, dropout_rate_options, learning_rate_options,\n",
    "                                      filters_options, kernel_size_options, num_dense_layers_options,\n",
    "                                      activation_function_options, rotation_range_options, width_shift_range_options,\n",
    "                                      height_shift_range_options, shear_range_options, zoom_range_options, horizontal_flip_options))\n",
    "\n",
    "# Select 50 unique combinations\n",
    "np.random.seed(42)\n",
    "selected_combinations = np.random.choice(len(parameter_combinations), 50, replace=False)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Callbacks for training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Custom callback to print epoch details\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']}: loss={logs['loss']:.4f}, accuracy={logs['accuracy']:.4f}, val_loss={logs['val_loss']:.4f}, val_accuracy={logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Perform grid search\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for idx, combination_idx in enumerate(selected_combinations):\n",
    "    num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip = parameter_combinations[combination_idx]\n",
    "    print(f\"\\nInitial Training Combination {idx + 1}/50: num_residual_blocks={num_residual_blocks}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, filters={filters}, kernel_size={kernel_size}, num_dense_layers={num_dense_layers}, activation_function={activation_function}, rotation_range={rotation_range}, width_shift_range={width_shift_range}, height_shift_range={height_shift_range}, shear_range={shear_range}, zoom_range={zoom_range}, horizontal_flip={horizontal_flip}\")\n",
    "    \n",
    "    datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "    datagen.fit(X_train)\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "            epochs=40,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = (num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "\n",
    "print(f\"\\nBest parameters found in initial grid search: num_residual_blocks={best_params[0]}, dropout_rate={best_params[1]}, learning_rate={best_params[2]}, filters={best_params[3]}, kernel_size={best_params[4]}, num_dense_layers={best_params[5]}, activation_function={best_params[6]}, rotation_range={best_params[7]}, width_shift_range={best_params[8]}, height_shift_range={best_params[9]}, shear_range={best_params[10]}, zoom_range={best_params[11]}, horizontal_flip={best_params[12]}\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
    "\n",
    "# Refine grid search around best parameters\n",
    "refined_num_residual_blocks_options = [max(1, best_params[0] - 1), best_params[0], best_params[0] + 1]\n",
    "refined_dropout_rate_options = [max(0.0, best_params[1] - 0.1), best_params[1], min(1.0, best_params[1] + 0.1)]\n",
    "refined_learning_rate_options = [best_params[2] * 0.5, best_params[2], best_params[2] * 2]\n",
    "refined_filters_options = [max(32, best_params[3] // 2), best_params[3], min(256, best_params[3] * 2)]\n",
    "refined_kernel_size_options = [max(1, best_params[4] - 2), best_params[4], min(7, best_params[4] + 2)]\n",
    "refined_num_dense_layers_options = [max(1, best_params[5] - 1), best_params[5], best_params[5] + 1]\n",
    "refined_activation_function_options = [best_params[6]]\n",
    "refined_rotation_range_options = [max(0, best_params[7] - 10), best_params[7], best_params[7] + 10]\n",
    "refined_width_shift_range_options = [max(0.0, best_params[8] - 0.1), best_params[8], min(1.0, best_params[8] + 0.1)]\n",
    "refined_height_shift_range_options = [max(0.0, best_params[9] - 0.1), best_params[9], min(1.0, best_params[9] + 0.1)]\n",
    "refined_shear_range_options = [max(0.0, best_params[10] - 0.1), best_params[10], min(1.0, best_params[10] + 0.1)]\n",
    "refined_zoom_range_options = [max(0.0, best_params[11] - 0.1), best_params[11], min(1.0, best_params[11] + 0.1)]\n",
    "refined_horizontal_flip_options = [best_params[12]]\n",
    "\n",
    "refined_parameter_combinations = list(product(refined_num_residual_blocks_options, refined_dropout_rate_options, refined_learning_rate_options,\n",
    "                                              refined_filters_options, refined_kernel_size_options, refined_num_dense_layers_options,\n",
    "                                              refined_activation_function_options, refined_rotation_range_options, refined_width_shift_range_options,\n",
    "                                              refined_height_shift_range_options, refined_shear_range_options, refined_zoom_range_options, refined_horizontal_flip_options))\n",
    "\n",
    "# Select 50 unique combinations for refined search\n",
    "np.random.seed(42)\n",
    "selected_refined_combinations = np.random.choice(len(refined_parameter_combinations), 50, replace=False)\n",
    "\n",
    "# Perform refined grid search\n",
    "best_val_accuracy_refined = 0\n",
    "best_params_refined = None\n",
    "\n",
    "for idx, combination_idx in enumerate(selected_refined_combinations):\n",
    "    num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip = refined_parameter_combinations[combination_idx]\n",
    "    print(f\"\\nRefined Training Combination {idx + 1}/50: num_residual_blocks={num_residual_blocks}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, filters={filters}, kernel_size={kernel_size}, num_dense_layers={num_dense_layers}, activation_function={activation_function}, rotation_range={rotation_range}, width_shift_range={width_shift_range}, height_shift_range={height_shift_range}, shear_range={shear_range}, zoom_range={zoom_range}, horizontal_flip={horizontal_flip}\")\n",
    "    \n",
    "    datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "    datagen.fit(X_train)\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "            epochs=40,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy_refined:\n",
    "        best_val_accuracy_refined = val_accuracy\n",
    "        best_params_refined = (num_residual_blocks, dropout_rate, learning_rate, filters, kernel_size, num_dense_layers, activation_function, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "\n",
    "print(f\"\\nRefined best parameters found: num_residual_blocks={best_params_refined[0]}, dropout_rate={best_params_refined[1]}, learning_rate={best_params_refined[2]}, filters={best_params_refined[3]}, kernel_size={best_params_refined[4]}, num_dense_layers={best_params_refined[5]}, activation_function={best_params_refined[6]}, rotation_range={best_params_refined[7]}, width_shift_range={best_params_refined[8]}, height_shift_range={best_params_refined[9]}, shear_range={best_params_refined[10]}, zoom_range={best_params_refined[11]}, horizontal_flip={best_params_refined[12]}\")\n",
    "print(f\"Refined best validation accuracy: {best_val_accuracy_refined}\")\n",
    "\n",
    "# Train the final model with the refined best parameters found\n",
    "final_model = build_complex_model(input_shape, best_params_refined[0], best_params_refined[1], best_params_refined[2])\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    final_history = final_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Save the best model to a local directory\n",
    "model_save_path = 'best_model.h5'\n",
    "final_model.save(model_save_path)\n",
    "print(f\"Best model saved to {model_save_path}\")\n",
    "\n",
    "# Make predictions\n",
    "with tf.device('/GPU:0'):\n",
    "    val_predictions = final_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_val_true, y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d279d1-f936-4fdc-8a6a-5269b80f00ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_model\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccaedc-7b0a-4b5b-bfbc-07151a969d53",
   "metadata": {},
   "source": [
    "# Save the Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e850d4-bf71-485c-8d5d-f5bead9b3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the best model to a local directory\n",
    "#model_save_path = 'best_model.h5'\n",
    "#final_model.save(model_save_path)\n",
    "#print(f\"Best model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis Thanasis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

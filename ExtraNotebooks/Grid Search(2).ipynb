{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e8bc41-db65-478d-ab65-dfffe6ca71ee",
   "metadata": {},
   "source": [
    "# Inserting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5ac207-a84f-49fb-bd7b-bd152d45c08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  1\n",
      "Training data shape: (4832, 64, 64, 6)\n",
      "Validation data shape: (1208, 64, 64, 6)\n",
      "Training labels shape: (4832, 2)\n",
      "Validation labels shape: (1208, 2)\n",
      "Class weights: {0: 0.8640915593705293, 1: 1.18664047151277}\n",
      "\n",
      "Initial Training Combination 1/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.001, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:2094: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n",
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.6215Epoch 1/40: loss=0.7710, accuracy=0.6215, val_loss=1.6062, val_accuracy=0.4007\n",
      "604/604 [==============================] - 18s 19ms/step - loss: 0.7710 - accuracy: 0.6215 - val_loss: 1.6062 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.6892Epoch 2/40: loss=0.6081, accuracy=0.6892, val_loss=0.6777, val_accuracy=0.6846\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6081 - accuracy: 0.6892 - val_loss: 0.6777 - val_accuracy: 0.6846 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.7066Epoch 3/40: loss=0.5818, accuracy=0.7067, val_loss=0.7988, val_accuracy=0.4669\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5818 - accuracy: 0.7067 - val_loss: 0.7988 - val_accuracy: 0.4669 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.7235Epoch 4/40: loss=0.5694, accuracy=0.7235, val_loss=0.6836, val_accuracy=0.5877\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5694 - accuracy: 0.7235 - val_loss: 0.6836 - val_accuracy: 0.5877 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7276Epoch 5/40: loss=0.5682, accuracy=0.7276, val_loss=0.5165, val_accuracy=0.7334\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5682 - accuracy: 0.7276 - val_loss: 0.5165 - val_accuracy: 0.7334 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5648 - accuracy: 0.7147Epoch 6/40: loss=0.5644, accuracy=0.7146, val_loss=4.1128, val_accuracy=0.6026\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5644 - accuracy: 0.7146 - val_loss: 4.1128 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5629 - accuracy: 0.7313Epoch 7/40: loss=0.5635, accuracy=0.7312, val_loss=0.7684, val_accuracy=0.7185\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5635 - accuracy: 0.7312 - val_loss: 0.7684 - val_accuracy: 0.7185 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5624 - accuracy: 0.7346Epoch 8/40: loss=0.5632, accuracy=0.7345, val_loss=0.6062, val_accuracy=0.7384\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5632 - accuracy: 0.7345 - val_loss: 0.6062 - val_accuracy: 0.7384 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7332Epoch 9/40: loss=0.5534, accuracy=0.7332, val_loss=0.9116, val_accuracy=0.6118\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5534 - accuracy: 0.7332 - val_loss: 0.9116 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.7353\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.5541, accuracy=0.7351, val_loss=0.7393, val_accuracy=0.7185\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5541 - accuracy: 0.7351 - val_loss: 0.7393 - val_accuracy: 0.7185 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.7610Epoch 11/40: loss=0.5160, accuracy=0.7610, val_loss=0.4550, val_accuracy=0.7781\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5160 - accuracy: 0.7610 - val_loss: 0.4550 - val_accuracy: 0.7781 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4989 - accuracy: 0.7714Epoch 12/40: loss=0.4990, accuracy=0.7711, val_loss=0.4610, val_accuracy=0.8022\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4990 - accuracy: 0.7711 - val_loss: 0.4610 - val_accuracy: 0.8022 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.7739Epoch 13/40: loss=0.4860, accuracy=0.7734, val_loss=0.4273, val_accuracy=0.8171\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4860 - accuracy: 0.7734 - val_loss: 0.4273 - val_accuracy: 0.8171 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7683Epoch 14/40: loss=0.4980, accuracy=0.7690, val_loss=0.4414, val_accuracy=0.8154\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4980 - accuracy: 0.7690 - val_loss: 0.4414 - val_accuracy: 0.8154 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.7660Epoch 15/40: loss=0.4949, accuracy=0.7659, val_loss=0.4824, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4949 - accuracy: 0.7659 - val_loss: 0.4824 - val_accuracy: 0.8079 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7902Epoch 16/40: loss=0.4692, accuracy=0.7901, val_loss=0.5896, val_accuracy=0.7376\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4692 - accuracy: 0.7901 - val_loss: 0.5896 - val_accuracy: 0.7376 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7804Epoch 17/40: loss=0.4744, accuracy=0.7804, val_loss=0.4150, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4744 - accuracy: 0.7804 - val_loss: 0.4150 - val_accuracy: 0.8270 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4752 - accuracy: 0.7803Epoch 18/40: loss=0.4751, accuracy=0.7804, val_loss=0.4450, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4751 - accuracy: 0.7804 - val_loss: 0.4450 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.7821Epoch 19/40: loss=0.4787, accuracy=0.7821, val_loss=0.4308, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4787 - accuracy: 0.7821 - val_loss: 0.4308 - val_accuracy: 0.8179 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4794 - accuracy: 0.7749Epoch 20/40: loss=0.4793, accuracy=0.7750, val_loss=0.4380, val_accuracy=0.8253\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4793 - accuracy: 0.7750 - val_loss: 0.4380 - val_accuracy: 0.8253 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4504 - accuracy: 0.7950Epoch 21/40: loss=0.4504, accuracy=0.7949, val_loss=0.4140, val_accuracy=0.8353\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4504 - accuracy: 0.7949 - val_loss: 0.4140 - val_accuracy: 0.8353 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.7868Epoch 22/40: loss=0.4672, accuracy=0.7868, val_loss=0.4596, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4672 - accuracy: 0.7868 - val_loss: 0.4596 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8028Epoch 23/40: loss=0.4461, accuracy=0.8028, val_loss=0.3954, val_accuracy=0.8353\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4461 - accuracy: 0.8028 - val_loss: 0.3954 - val_accuracy: 0.8353 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.7887Epoch 24/40: loss=0.4656, accuracy=0.7887, val_loss=0.4239, val_accuracy=0.8187\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4656 - accuracy: 0.7887 - val_loss: 0.4239 - val_accuracy: 0.8187 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.7904Epoch 25/40: loss=0.4567, accuracy=0.7906, val_loss=0.4149, val_accuracy=0.8344\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4567 - accuracy: 0.7906 - val_loss: 0.4149 - val_accuracy: 0.8344 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.7957Epoch 26/40: loss=0.4412, accuracy=0.7955, val_loss=0.5305, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4412 - accuracy: 0.7955 - val_loss: 0.5305 - val_accuracy: 0.7914 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.7989Epoch 27/40: loss=0.4442, accuracy=0.7988, val_loss=0.4268, val_accuracy=0.8005\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4442 - accuracy: 0.7988 - val_loss: 0.4268 - val_accuracy: 0.8005 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4403 - accuracy: 0.7992\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 28/40: loss=0.4402, accuracy=0.7990, val_loss=0.4064, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4402 - accuracy: 0.7990 - val_loss: 0.4064 - val_accuracy: 0.8377 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4139 - accuracy: 0.8177Epoch 29/40: loss=0.4142, accuracy=0.8177, val_loss=0.4122, val_accuracy=0.8427\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.4122 - val_accuracy: 0.8427 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8164Epoch 30/40: loss=0.4155, accuracy=0.8164, val_loss=0.3896, val_accuracy=0.8444\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4155 - accuracy: 0.8164 - val_loss: 0.3896 - val_accuracy: 0.8444 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.8162Epoch 31/40: loss=0.4143, accuracy=0.8164, val_loss=0.4169, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4143 - accuracy: 0.8164 - val_loss: 0.4169 - val_accuracy: 0.8328 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4111 - accuracy: 0.8185Epoch 32/40: loss=0.4116, accuracy=0.8181, val_loss=0.3924, val_accuracy=0.8419\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4116 - accuracy: 0.8181 - val_loss: 0.3924 - val_accuracy: 0.8419 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8203Epoch 33/40: loss=0.3972, accuracy=0.8206, val_loss=0.3844, val_accuracy=0.8394\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3972 - accuracy: 0.8206 - val_loss: 0.3844 - val_accuracy: 0.8394 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8214Epoch 34/40: loss=0.4078, accuracy=0.8214, val_loss=0.3992, val_accuracy=0.8386\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4078 - accuracy: 0.8214 - val_loss: 0.3992 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.8220Epoch 35/40: loss=0.3986, accuracy=0.8220, val_loss=0.4377, val_accuracy=0.7972\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3986 - accuracy: 0.8220 - val_loss: 0.4377 - val_accuracy: 0.7972 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3927 - accuracy: 0.8263Epoch 36/40: loss=0.3924, accuracy=0.8264, val_loss=0.3978, val_accuracy=0.8386\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3924 - accuracy: 0.8264 - val_loss: 0.3978 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3961 - accuracy: 0.8286Epoch 37/40: loss=0.3961, accuracy=0.8286, val_loss=0.3742, val_accuracy=0.8435\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3961 - accuracy: 0.8286 - val_loss: 0.3742 - val_accuracy: 0.8435 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4028 - accuracy: 0.8195Epoch 38/40: loss=0.4023, accuracy=0.8195, val_loss=0.4477, val_accuracy=0.8096\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4023 - accuracy: 0.8195 - val_loss: 0.4477 - val_accuracy: 0.8096 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.8329Epoch 39/40: loss=0.3938, accuracy=0.8330, val_loss=0.4109, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3938 - accuracy: 0.8330 - val_loss: 0.4109 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8204Epoch 40/40: loss=0.3930, accuracy=0.8204, val_loss=0.3971, val_accuracy=0.8369\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3930 - accuracy: 0.8204 - val_loss: 0.3971 - val_accuracy: 0.8369 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.8443708419799805\n",
      "\n",
      "Initial Training Combination 2/50: num_residual_blocks=4, dropout_rate=0.5, learning_rate=0.0001, rotation_range=10, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.5006Epoch 1/40: loss=0.9907, accuracy=0.5006, val_loss=0.6662, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.9907 - accuracy: 0.5006 - val_loss: 0.6662 - val_accuracy: 0.5993 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9402 - accuracy: 0.4948Epoch 2/40: loss=0.9398, accuracy=0.4950, val_loss=0.6938, val_accuracy=0.5273\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9398 - accuracy: 0.4950 - val_loss: 0.6938 - val_accuracy: 0.5273 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8914 - accuracy: 0.4954Epoch 3/40: loss=0.8914, accuracy=0.4957, val_loss=0.6886, val_accuracy=0.5356\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8914 - accuracy: 0.4957 - val_loss: 0.6886 - val_accuracy: 0.5356 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8457 - accuracy: 0.5031Epoch 4/40: loss=0.8457, accuracy=0.5031, val_loss=0.6814, val_accuracy=0.5753\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8457 - accuracy: 0.5031 - val_loss: 0.6814 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8078 - accuracy: 0.5162Epoch 5/40: loss=0.8085, accuracy=0.5157, val_loss=0.6778, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8085 - accuracy: 0.5157 - val_loss: 0.6778 - val_accuracy: 0.5985 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.5062\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/40: loss=0.7976, accuracy=0.5062, val_loss=0.6741, val_accuracy=0.6134\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7976 - accuracy: 0.5062 - val_loss: 0.6741 - val_accuracy: 0.6134 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7755 - accuracy: 0.5143Epoch 7/40: loss=0.7757, accuracy=0.5139, val_loss=0.6641, val_accuracy=0.6175\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7757 - accuracy: 0.5139 - val_loss: 0.6641 - val_accuracy: 0.6175 - lr: 2.0000e-05\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7734 - accuracy: 0.5185Epoch 8/40: loss=0.7728, accuracy=0.5192, val_loss=0.6653, val_accuracy=0.6258\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7728 - accuracy: 0.5192 - val_loss: 0.6653 - val_accuracy: 0.6258 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7661 - accuracy: 0.5204Epoch 9/40: loss=0.7667, accuracy=0.5203, val_loss=0.6784, val_accuracy=0.6349\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7667 - accuracy: 0.5203 - val_loss: 0.6784 - val_accuracy: 0.6349 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.5308Epoch 10/40: loss=0.7574, accuracy=0.5308, val_loss=0.6802, val_accuracy=0.6515\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7574 - accuracy: 0.5308 - val_loss: 0.6802 - val_accuracy: 0.6515 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.5313Epoch 11/40: loss=0.7479, accuracy=0.5312, val_loss=0.6835, val_accuracy=0.6639\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7479 - accuracy: 0.5312 - val_loss: 0.6835 - val_accuracy: 0.6639 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.5453\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 12/40: loss=0.7436, accuracy=0.5453, val_loss=0.6799, val_accuracy=0.6614\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7436 - accuracy: 0.5453 - val_loss: 0.6799 - val_accuracy: 0.6614 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7414 - accuracy: 0.5375Epoch 13/40: loss=0.7420, accuracy=0.5368, val_loss=0.6749, val_accuracy=0.6639\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7420 - accuracy: 0.5368 - val_loss: 0.6749 - val_accuracy: 0.6639 - lr: 4.0000e-06\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7375 - accuracy: 0.5401Epoch 14/40: loss=0.7373, accuracy=0.5399, val_loss=0.6727, val_accuracy=0.6680\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7373 - accuracy: 0.5399 - val_loss: 0.6727 - val_accuracy: 0.6680 - lr: 4.0000e-06\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7339 - accuracy: 0.5457Epoch 15/40: loss=0.7346, accuracy=0.5451, val_loss=0.6685, val_accuracy=0.6656\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7346 - accuracy: 0.5451 - val_loss: 0.6685 - val_accuracy: 0.6656 - lr: 4.0000e-06\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7457 - accuracy: 0.5408Epoch 16/40: loss=0.7457, accuracy=0.5408, val_loss=0.6747, val_accuracy=0.6697\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7457 - accuracy: 0.5408 - val_loss: 0.6747 - val_accuracy: 0.6697 - lr: 4.0000e-06\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7210 - accuracy: 0.5592\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 17/40: loss=0.7211, accuracy=0.5586, val_loss=0.6825, val_accuracy=0.6714\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7211 - accuracy: 0.5586 - val_loss: 0.6825 - val_accuracy: 0.6714 - lr: 4.0000e-06\n",
      "Epoch 17: early stopping\n",
      "Validation accuracy: 0.6713576316833496\n",
      "\n",
      "Initial Training Combination 3/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.0001, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8737 - accuracy: 0.5483Epoch 1/40: loss=0.8738, accuracy=0.5482, val_loss=0.6271, val_accuracy=0.6697\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.8738 - accuracy: 0.5482 - val_loss: 0.6271 - val_accuracy: 0.6697 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7539 - accuracy: 0.6196Epoch 2/40: loss=0.7533, accuracy=0.6200, val_loss=1.3731, val_accuracy=0.6275\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7533 - accuracy: 0.6200 - val_loss: 1.3731 - val_accuracy: 0.6275 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.6643Epoch 3/40: loss=0.6832, accuracy=0.6643, val_loss=0.7387, val_accuracy=0.7086\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6832 - accuracy: 0.6643 - val_loss: 0.7387 - val_accuracy: 0.7086 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6560 - accuracy: 0.6679Epoch 4/40: loss=0.6563, accuracy=0.6674, val_loss=0.6044, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6563 - accuracy: 0.6674 - val_loss: 0.6044 - val_accuracy: 0.7219 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6323 - accuracy: 0.6845Epoch 5/40: loss=0.6322, accuracy=0.6844, val_loss=1.0484, val_accuracy=0.4462\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6322 - accuracy: 0.6844 - val_loss: 1.0484 - val_accuracy: 0.4462 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6111 - accuracy: 0.7022Epoch 6/40: loss=0.6107, accuracy=0.7024, val_loss=0.6552, val_accuracy=0.6507\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6107 - accuracy: 0.7024 - val_loss: 0.6552 - val_accuracy: 0.6507 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5941 - accuracy: 0.7078Epoch 7/40: loss=0.5945, accuracy=0.7076, val_loss=1.0782, val_accuracy=0.6449\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5945 - accuracy: 0.7076 - val_loss: 1.0782 - val_accuracy: 0.6449 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5881 - accuracy: 0.7067Epoch 8/40: loss=0.5885, accuracy=0.7067, val_loss=0.5079, val_accuracy=0.7425\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5885 - accuracy: 0.7067 - val_loss: 0.5079 - val_accuracy: 0.7425 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7208Epoch 9/40: loss=0.5672, accuracy=0.7208, val_loss=0.5591, val_accuracy=0.7070\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5672 - accuracy: 0.7208 - val_loss: 0.5591 - val_accuracy: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7246Epoch 10/40: loss=0.5533, accuracy=0.7250, val_loss=0.4981, val_accuracy=0.7674\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5533 - accuracy: 0.7250 - val_loss: 0.4981 - val_accuracy: 0.7674 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5559 - accuracy: 0.7297Epoch 11/40: loss=0.5555, accuracy=0.7297, val_loss=0.4796, val_accuracy=0.7409\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5555 - accuracy: 0.7297 - val_loss: 0.4796 - val_accuracy: 0.7409 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7299Epoch 12/40: loss=0.5501, accuracy=0.7299, val_loss=0.6981, val_accuracy=0.5894\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5501 - accuracy: 0.7299 - val_loss: 0.6981 - val_accuracy: 0.5894 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.7357Epoch 13/40: loss=0.5345, accuracy=0.7357, val_loss=0.7811, val_accuracy=0.5811\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5345 - accuracy: 0.7357 - val_loss: 0.7811 - val_accuracy: 0.5811 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5196 - accuracy: 0.7438Epoch 14/40: loss=0.5197, accuracy=0.7434, val_loss=0.8278, val_accuracy=0.5935\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5197 - accuracy: 0.7434 - val_loss: 0.8278 - val_accuracy: 0.5935 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7550Epoch 15/40: loss=0.5138, accuracy=0.7548, val_loss=0.8248, val_accuracy=0.6647\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5138 - accuracy: 0.7548 - val_loss: 0.8248 - val_accuracy: 0.6647 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.7510Epoch 16/40: loss=0.5142, accuracy=0.7510, val_loss=0.4669, val_accuracy=0.7773\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5142 - accuracy: 0.7510 - val_loss: 0.4669 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5015 - accuracy: 0.7585Epoch 17/40: loss=0.5010, accuracy=0.7587, val_loss=0.4330, val_accuracy=0.7947\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5010 - accuracy: 0.7587 - val_loss: 0.4330 - val_accuracy: 0.7947 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.7722Epoch 18/40: loss=0.4932, accuracy=0.7719, val_loss=0.4305, val_accuracy=0.8038\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4932 - accuracy: 0.7719 - val_loss: 0.4305 - val_accuracy: 0.8038 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.7606Epoch 19/40: loss=0.4900, accuracy=0.7608, val_loss=0.4774, val_accuracy=0.7368\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4900 - accuracy: 0.7608 - val_loss: 0.4774 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.7676Epoch 20/40: loss=0.4912, accuracy=0.7672, val_loss=0.5208, val_accuracy=0.7053\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4912 - accuracy: 0.7672 - val_loss: 0.5208 - val_accuracy: 0.7053 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.7668Epoch 21/40: loss=0.4819, accuracy=0.7668, val_loss=0.4863, val_accuracy=0.7699\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4819 - accuracy: 0.7668 - val_loss: 0.4863 - val_accuracy: 0.7699 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.7686Epoch 22/40: loss=0.4787, accuracy=0.7686, val_loss=0.4631, val_accuracy=0.7682\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4787 - accuracy: 0.7686 - val_loss: 0.4631 - val_accuracy: 0.7682 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7688\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 23/40: loss=0.4766, accuracy=0.7688, val_loss=0.5778, val_accuracy=0.7492\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4766 - accuracy: 0.7688 - val_loss: 0.5778 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.7791Epoch 24/40: loss=0.4584, accuracy=0.7788, val_loss=0.5587, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4584 - accuracy: 0.7788 - val_loss: 0.5587 - val_accuracy: 0.7641 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4493 - accuracy: 0.7923Epoch 25/40: loss=0.4496, accuracy=0.7922, val_loss=0.4203, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4496 - accuracy: 0.7922 - val_loss: 0.4203 - val_accuracy: 0.8079 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.7965Epoch 26/40: loss=0.4448, accuracy=0.7964, val_loss=0.5024, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4448 - accuracy: 0.7964 - val_loss: 0.5024 - val_accuracy: 0.7823 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.7959Epoch 27/40: loss=0.4410, accuracy=0.7959, val_loss=0.4198, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4410 - accuracy: 0.7959 - val_loss: 0.4198 - val_accuracy: 0.8195 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.8014Epoch 28/40: loss=0.4326, accuracy=0.8009, val_loss=0.4214, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4326 - accuracy: 0.8009 - val_loss: 0.4214 - val_accuracy: 0.8096 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8040Epoch 29/40: loss=0.4366, accuracy=0.8040, val_loss=0.4725, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4366 - accuracy: 0.8040 - val_loss: 0.4725 - val_accuracy: 0.8030 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8117Epoch 30/40: loss=0.4232, accuracy=0.8115, val_loss=0.4258, val_accuracy=0.7964\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4232 - accuracy: 0.8115 - val_loss: 0.4258 - val_accuracy: 0.7964 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8019Epoch 31/40: loss=0.4350, accuracy=0.8013, val_loss=0.4124, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4350 - accuracy: 0.8013 - val_loss: 0.4124 - val_accuracy: 0.8237 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4348 - accuracy: 0.8007Epoch 32/40: loss=0.4340, accuracy=0.8013, val_loss=0.4346, val_accuracy=0.8038\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4340 - accuracy: 0.8013 - val_loss: 0.4346 - val_accuracy: 0.8038 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8060Epoch 33/40: loss=0.4257, accuracy=0.8059, val_loss=0.4776, val_accuracy=0.7972\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4257 - accuracy: 0.8059 - val_loss: 0.4776 - val_accuracy: 0.7972 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.7989Epoch 34/40: loss=0.4288, accuracy=0.7993, val_loss=0.4915, val_accuracy=0.7773\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4288 - accuracy: 0.7993 - val_loss: 0.4915 - val_accuracy: 0.7773 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8046Epoch 35/40: loss=0.4268, accuracy=0.8046, val_loss=0.4218, val_accuracy=0.8088\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4268 - accuracy: 0.8046 - val_loss: 0.4218 - val_accuracy: 0.8088 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8027Epoch 36/40: loss=0.4333, accuracy=0.8026, val_loss=0.4120, val_accuracy=0.8228\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4333 - accuracy: 0.8026 - val_loss: 0.4120 - val_accuracy: 0.8228 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4162 - accuracy: 0.8093Epoch 37/40: loss=0.4163, accuracy=0.8092, val_loss=0.3984, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4163 - accuracy: 0.8092 - val_loss: 0.3984 - val_accuracy: 0.8187 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8086Epoch 38/40: loss=0.4197, accuracy=0.8088, val_loss=0.3839, val_accuracy=0.8320\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4197 - accuracy: 0.8088 - val_loss: 0.3839 - val_accuracy: 0.8320 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8106Epoch 39/40: loss=0.4140, accuracy=0.8106, val_loss=0.4581, val_accuracy=0.8005\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4140 - accuracy: 0.8106 - val_loss: 0.4581 - val_accuracy: 0.8005 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8133Epoch 40/40: loss=0.4213, accuracy=0.8133, val_loss=0.3941, val_accuracy=0.8278\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4213 - accuracy: 0.8133 - val_loss: 0.3941 - val_accuracy: 0.8278 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8319536447525024\n",
      "\n",
      "Initial Training Combination 4/50: num_residual_blocks=2, dropout_rate=0.5, learning_rate=0.0005, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.3, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.5062Epoch 1/40: loss=0.9738, accuracy=0.5066, val_loss=1.2064, val_accuracy=0.4015\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 0.9738 - accuracy: 0.5066 - val_loss: 1.2064 - val_accuracy: 0.4015 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.5623Epoch 2/40: loss=0.7739, accuracy=0.5623, val_loss=0.7645, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7739 - accuracy: 0.5623 - val_loss: 0.7645 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.6298Epoch 3/40: loss=0.6717, accuracy=0.6298, val_loss=0.6190, val_accuracy=0.7061\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6717 - accuracy: 0.6298 - val_loss: 0.6190 - val_accuracy: 0.7061 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6238 - accuracy: 0.6597Epoch 4/40: loss=0.6239, accuracy=0.6596, val_loss=0.7716, val_accuracy=0.6863\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6239 - accuracy: 0.6596 - val_loss: 0.7716 - val_accuracy: 0.6863 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.6838Epoch 5/40: loss=0.5992, accuracy=0.6838, val_loss=0.5080, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5992 - accuracy: 0.6838 - val_loss: 0.5080 - val_accuracy: 0.7608 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7051Epoch 6/40: loss=0.5765, accuracy=0.7051, val_loss=2.8217, val_accuracy=0.4040\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5765 - accuracy: 0.7051 - val_loss: 2.8217 - val_accuracy: 0.4040 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.6921Epoch 7/40: loss=0.5852, accuracy=0.6921, val_loss=0.5635, val_accuracy=0.7301\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5852 - accuracy: 0.6921 - val_loss: 0.5635 - val_accuracy: 0.7301 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5796 - accuracy: 0.7038Epoch 8/40: loss=0.5797, accuracy=0.7038, val_loss=0.4911, val_accuracy=0.7806\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5797 - accuracy: 0.7038 - val_loss: 0.4911 - val_accuracy: 0.7806 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.7119Epoch 9/40: loss=0.5608, accuracy=0.7119, val_loss=1.5820, val_accuracy=0.4338\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5608 - accuracy: 0.7119 - val_loss: 1.5820 - val_accuracy: 0.4338 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.7088Epoch 10/40: loss=0.5695, accuracy=0.7088, val_loss=0.8838, val_accuracy=0.6656\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5695 - accuracy: 0.7088 - val_loss: 0.8838 - val_accuracy: 0.6656 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.7150Epoch 11/40: loss=0.5711, accuracy=0.7154, val_loss=0.6654, val_accuracy=0.6863\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5711 - accuracy: 0.7154 - val_loss: 0.6654 - val_accuracy: 0.6863 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.7153Epoch 12/40: loss=0.5579, accuracy=0.7159, val_loss=1.5751, val_accuracy=0.4404\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5579 - accuracy: 0.7159 - val_loss: 1.5751 - val_accuracy: 0.4404 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5566 - accuracy: 0.7203Epoch 13/40: loss=0.5568, accuracy=0.7198, val_loss=0.4720, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5568 - accuracy: 0.7198 - val_loss: 0.4720 - val_accuracy: 0.7856 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.7251Epoch 14/40: loss=0.5519, accuracy=0.7252, val_loss=0.7137, val_accuracy=0.7425\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5519 - accuracy: 0.7252 - val_loss: 0.7137 - val_accuracy: 0.7425 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.7126Epoch 15/40: loss=0.5541, accuracy=0.7130, val_loss=0.7063, val_accuracy=0.6482\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5541 - accuracy: 0.7130 - val_loss: 0.7063 - val_accuracy: 0.6482 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7176Epoch 16/40: loss=0.5517, accuracy=0.7169, val_loss=0.5071, val_accuracy=0.7475\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5517 - accuracy: 0.7169 - val_loss: 0.5071 - val_accuracy: 0.7475 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.7154Epoch 17/40: loss=0.5530, accuracy=0.7154, val_loss=0.4998, val_accuracy=0.7649\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5530 - accuracy: 0.7154 - val_loss: 0.4998 - val_accuracy: 0.7649 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.7190\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 18/40: loss=0.5530, accuracy=0.7190, val_loss=0.6252, val_accuracy=0.7724\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5530 - accuracy: 0.7190 - val_loss: 0.6252 - val_accuracy: 0.7724 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7384Epoch 19/40: loss=0.5269, accuracy=0.7388, val_loss=0.4889, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5269 - accuracy: 0.7388 - val_loss: 0.4889 - val_accuracy: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7488Epoch 20/40: loss=0.5191, accuracy=0.7488, val_loss=0.4987, val_accuracy=0.7972\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5191 - accuracy: 0.7488 - val_loss: 0.4987 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.7496Epoch 21/40: loss=0.5177, accuracy=0.7494, val_loss=0.4556, val_accuracy=0.7980\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5177 - accuracy: 0.7494 - val_loss: 0.4556 - val_accuracy: 0.7980 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.7421Epoch 22/40: loss=0.5212, accuracy=0.7421, val_loss=0.4999, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5212 - accuracy: 0.7421 - val_loss: 0.4999 - val_accuracy: 0.7707 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.7471Epoch 23/40: loss=0.5173, accuracy=0.7471, val_loss=0.4582, val_accuracy=0.7881\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5173 - accuracy: 0.7471 - val_loss: 0.4582 - val_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.7541Epoch 24/40: loss=0.5075, accuracy=0.7541, val_loss=0.5078, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5075 - accuracy: 0.7541 - val_loss: 0.5078 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5027 - accuracy: 0.7479Epoch 25/40: loss=0.5027, accuracy=0.7477, val_loss=0.7330, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5027 - accuracy: 0.7477 - val_loss: 0.7330 - val_accuracy: 0.7301 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.7537\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 26/40: loss=0.5065, accuracy=0.7539, val_loss=0.5493, val_accuracy=0.7715\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5065 - accuracy: 0.7539 - val_loss: 0.5493 - val_accuracy: 0.7715 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7626Epoch 27/40: loss=0.4972, accuracy=0.7626, val_loss=0.4989, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4972 - accuracy: 0.7626 - val_loss: 0.4989 - val_accuracy: 0.7881 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5020 - accuracy: 0.7506Epoch 28/40: loss=0.5025, accuracy=0.7506, val_loss=0.5136, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5025 - accuracy: 0.7506 - val_loss: 0.5136 - val_accuracy: 0.7831 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4964 - accuracy: 0.7629Epoch 29/40: loss=0.4962, accuracy=0.7632, val_loss=0.4733, val_accuracy=0.8046\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4962 - accuracy: 0.7632 - val_loss: 0.4733 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5006 - accuracy: 0.7529Epoch 30/40: loss=0.5008, accuracy=0.7529, val_loss=0.4821, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5008 - accuracy: 0.7529 - val_loss: 0.4821 - val_accuracy: 0.7997 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4947 - accuracy: 0.7600\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 31/40: loss=0.4944, accuracy=0.7601, val_loss=0.5190, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.4944 - accuracy: 0.7601 - val_loss: 0.5190 - val_accuracy: 0.7839 - lr: 2.0000e-05\n",
      "Epoch 31: early stopping\n",
      "Validation accuracy: 0.804635763168335\n",
      "\n",
      "Initial Training Combination 5/50: num_residual_blocks=4, dropout_rate=0.5, learning_rate=0.001, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8957 - accuracy: 0.5205Epoch 1/40: loss=0.8957, accuracy=0.5205, val_loss=0.6786, val_accuracy=0.5745\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.8957 - accuracy: 0.5205 - val_loss: 0.6786 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.5445Epoch 2/40: loss=0.7150, accuracy=0.5445, val_loss=0.7677, val_accuracy=0.5149\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7150 - accuracy: 0.5445 - val_loss: 0.7677 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5711Epoch 3/40: loss=0.6934, accuracy=0.5716, val_loss=0.6391, val_accuracy=0.6631\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6934 - accuracy: 0.5716 - val_loss: 0.6391 - val_accuracy: 0.6631 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.5782Epoch 4/40: loss=0.6810, accuracy=0.5782, val_loss=0.5711, val_accuracy=0.7202\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6810 - accuracy: 0.5782 - val_loss: 0.5711 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6333 - accuracy: 0.6526Epoch 5/40: loss=0.6332, accuracy=0.6529, val_loss=0.9159, val_accuracy=0.5124\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6332 - accuracy: 0.6529 - val_loss: 0.9159 - val_accuracy: 0.5124 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.6515Epoch 6/40: loss=0.6314, accuracy=0.6515, val_loss=0.5445, val_accuracy=0.7467\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6314 - accuracy: 0.6515 - val_loss: 0.5445 - val_accuracy: 0.7467 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6556Epoch 7/40: loss=0.6177, accuracy=0.6556, val_loss=0.5964, val_accuracy=0.7326\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6177 - accuracy: 0.6556 - val_loss: 0.5964 - val_accuracy: 0.7326 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.6932Epoch 8/40: loss=0.5950, accuracy=0.6935, val_loss=1.4113, val_accuracy=0.5596\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5950 - accuracy: 0.6935 - val_loss: 1.4113 - val_accuracy: 0.5596 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5980 - accuracy: 0.6870Epoch 9/40: loss=0.5980, accuracy=0.6869, val_loss=0.6142, val_accuracy=0.7690\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5980 - accuracy: 0.6869 - val_loss: 0.6142 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7051Epoch 10/40: loss=0.5869, accuracy=0.7051, val_loss=0.7325, val_accuracy=0.6871\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5869 - accuracy: 0.7051 - val_loss: 0.7325 - val_accuracy: 0.6871 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.7025\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 11/40: loss=0.5890, accuracy=0.7022, val_loss=0.6874, val_accuracy=0.6829\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5890 - accuracy: 0.7022 - val_loss: 0.6874 - val_accuracy: 0.6829 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7221Epoch 12/40: loss=0.5549, accuracy=0.7221, val_loss=0.7080, val_accuracy=0.6788\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5549 - accuracy: 0.7221 - val_loss: 0.7080 - val_accuracy: 0.6788 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.7322Epoch 13/40: loss=0.5496, accuracy=0.7322, val_loss=0.5589, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5496 - accuracy: 0.7322 - val_loss: 0.5589 - val_accuracy: 0.7765 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7301Epoch 14/40: loss=0.5430, accuracy=0.7303, val_loss=0.5851, val_accuracy=0.7781\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5430 - accuracy: 0.7303 - val_loss: 0.5851 - val_accuracy: 0.7781 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7349Epoch 15/40: loss=0.5461, accuracy=0.7351, val_loss=0.5083, val_accuracy=0.7798\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5461 - accuracy: 0.7351 - val_loss: 0.5083 - val_accuracy: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.7281Epoch 16/40: loss=0.5442, accuracy=0.7281, val_loss=0.4763, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5442 - accuracy: 0.7281 - val_loss: 0.4763 - val_accuracy: 0.7955 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7301Epoch 17/40: loss=0.5461, accuracy=0.7301, val_loss=0.4993, val_accuracy=0.7525\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5461 - accuracy: 0.7301 - val_loss: 0.4993 - val_accuracy: 0.7525 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7334Epoch 18/40: loss=0.5417, accuracy=0.7328, val_loss=0.6707, val_accuracy=0.7136\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5417 - accuracy: 0.7328 - val_loss: 0.6707 - val_accuracy: 0.7136 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.7467Epoch 19/40: loss=0.5270, accuracy=0.7471, val_loss=0.5928, val_accuracy=0.7715\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5270 - accuracy: 0.7471 - val_loss: 0.5928 - val_accuracy: 0.7715 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.7452Epoch 20/40: loss=0.5256, accuracy=0.7450, val_loss=0.4995, val_accuracy=0.7997\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5256 - accuracy: 0.7450 - val_loss: 0.4995 - val_accuracy: 0.7997 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5342 - accuracy: 0.7402Epoch 21/40: loss=0.5343, accuracy=0.7401, val_loss=0.4610, val_accuracy=0.7939\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5343 - accuracy: 0.7401 - val_loss: 0.4610 - val_accuracy: 0.7939 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7454Epoch 22/40: loss=0.5292, accuracy=0.7448, val_loss=0.4424, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5292 - accuracy: 0.7448 - val_loss: 0.4424 - val_accuracy: 0.7947 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.7483Epoch 23/40: loss=0.5184, accuracy=0.7486, val_loss=0.4726, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5184 - accuracy: 0.7486 - val_loss: 0.4726 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.7548Epoch 24/40: loss=0.5135, accuracy=0.7550, val_loss=0.5878, val_accuracy=0.7798\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5135 - accuracy: 0.7550 - val_loss: 0.5878 - val_accuracy: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.7610Epoch 25/40: loss=0.5122, accuracy=0.7610, val_loss=0.5733, val_accuracy=0.8005\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5122 - accuracy: 0.7610 - val_loss: 0.5733 - val_accuracy: 0.8005 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.7539Epoch 26/40: loss=0.5182, accuracy=0.7539, val_loss=0.5766, val_accuracy=0.7161\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5182 - accuracy: 0.7539 - val_loss: 0.5766 - val_accuracy: 0.7161 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.7508\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 27/40: loss=0.5106, accuracy=0.7508, val_loss=0.4767, val_accuracy=0.7997\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5106 - accuracy: 0.7508 - val_loss: 0.4767 - val_accuracy: 0.7997 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5136 - accuracy: 0.7535Epoch 28/40: loss=0.5131, accuracy=0.7537, val_loss=0.4885, val_accuracy=0.8171\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5131 - accuracy: 0.7537 - val_loss: 0.4885 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4922 - accuracy: 0.7653Epoch 29/40: loss=0.4919, accuracy=0.7657, val_loss=0.4744, val_accuracy=0.8187\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4919 - accuracy: 0.7657 - val_loss: 0.4744 - val_accuracy: 0.8187 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4977 - accuracy: 0.7587Epoch 30/40: loss=0.4977, accuracy=0.7587, val_loss=0.4692, val_accuracy=0.8154\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.4692 - val_accuracy: 0.8154 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.7649Epoch 31/40: loss=0.4952, accuracy=0.7649, val_loss=0.4671, val_accuracy=0.8162\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4952 - accuracy: 0.7649 - val_loss: 0.4671 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4885 - accuracy: 0.7720\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.4882, accuracy=0.7724, val_loss=0.4780, val_accuracy=0.8204\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4882 - accuracy: 0.7724 - val_loss: 0.4780 - val_accuracy: 0.8204 - lr: 4.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.820364236831665\n",
      "\n",
      "Initial Training Combination 6/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.001, rotation_range=10, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.5871Epoch 1/40: loss=0.8360, accuracy=0.5871, val_loss=0.8373, val_accuracy=0.6242\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.8360 - accuracy: 0.5871 - val_loss: 0.8373 - val_accuracy: 0.6242 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6230 - accuracy: 0.6786Epoch 2/40: loss=0.6227, accuracy=0.6786, val_loss=0.5364, val_accuracy=0.7401\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6227 - accuracy: 0.6786 - val_loss: 0.5364 - val_accuracy: 0.7401 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5916 - accuracy: 0.6917Epoch 3/40: loss=0.5911, accuracy=0.6923, val_loss=0.9294, val_accuracy=0.5000\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5911 - accuracy: 0.6923 - val_loss: 0.9294 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5704 - accuracy: 0.7183Epoch 4/40: loss=0.5703, accuracy=0.7183, val_loss=0.5802, val_accuracy=0.7401\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5703 - accuracy: 0.7183 - val_loss: 0.5802 - val_accuracy: 0.7401 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5734 - accuracy: 0.7141Epoch 5/40: loss=0.5733, accuracy=0.7140, val_loss=0.6117, val_accuracy=0.7202\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5733 - accuracy: 0.7140 - val_loss: 0.6117 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5747 - accuracy: 0.7048Epoch 6/40: loss=0.5748, accuracy=0.7047, val_loss=1.0779, val_accuracy=0.4214\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5748 - accuracy: 0.7047 - val_loss: 1.0779 - val_accuracy: 0.4214 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.7067Epoch 7/40: loss=0.5817, accuracy=0.7067, val_loss=0.5299, val_accuracy=0.7359\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5817 - accuracy: 0.7067 - val_loss: 0.5299 - val_accuracy: 0.7359 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5667 - accuracy: 0.7201Epoch 8/40: loss=0.5667, accuracy=0.7202, val_loss=0.5135, val_accuracy=0.7550\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5667 - accuracy: 0.7202 - val_loss: 0.5135 - val_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7267Epoch 9/40: loss=0.5652, accuracy=0.7264, val_loss=0.7287, val_accuracy=0.5861\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5652 - accuracy: 0.7264 - val_loss: 0.7287 - val_accuracy: 0.5861 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7237Epoch 10/40: loss=0.5588, accuracy=0.7237, val_loss=0.6690, val_accuracy=0.6995\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5588 - accuracy: 0.7237 - val_loss: 0.6690 - val_accuracy: 0.6995 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.7332Epoch 11/40: loss=0.5548, accuracy=0.7334, val_loss=0.5347, val_accuracy=0.7558\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5548 - accuracy: 0.7334 - val_loss: 0.5347 - val_accuracy: 0.7558 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7346Epoch 12/40: loss=0.5553, accuracy=0.7341, val_loss=1.0958, val_accuracy=0.6333\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5553 - accuracy: 0.7341 - val_loss: 1.0958 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7359Epoch 13/40: loss=0.5536, accuracy=0.7359, val_loss=0.5076, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5536 - accuracy: 0.7359 - val_loss: 0.5076 - val_accuracy: 0.7748 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.7324Epoch 14/40: loss=0.5547, accuracy=0.7324, val_loss=0.5696, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5547 - accuracy: 0.7324 - val_loss: 0.5696 - val_accuracy: 0.7599 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.7392Epoch 15/40: loss=0.5367, accuracy=0.7392, val_loss=1.0948, val_accuracy=0.4536\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5367 - accuracy: 0.7392 - val_loss: 1.0948 - val_accuracy: 0.4536 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7303Epoch 16/40: loss=0.5473, accuracy=0.7305, val_loss=0.5201, val_accuracy=0.7467\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5473 - accuracy: 0.7305 - val_loss: 0.5201 - val_accuracy: 0.7467 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.7467Epoch 17/40: loss=0.5300, accuracy=0.7469, val_loss=0.4334, val_accuracy=0.8046\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5300 - accuracy: 0.7469 - val_loss: 0.4334 - val_accuracy: 0.8046 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5298 - accuracy: 0.7471Epoch 18/40: loss=0.5289, accuracy=0.7475, val_loss=0.5323, val_accuracy=0.7326\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5289 - accuracy: 0.7475 - val_loss: 0.5323 - val_accuracy: 0.7326 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.7556Epoch 19/40: loss=0.5164, accuracy=0.7556, val_loss=0.4993, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5164 - accuracy: 0.7556 - val_loss: 0.4993 - val_accuracy: 0.7848 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.7562Epoch 20/40: loss=0.5156, accuracy=0.7566, val_loss=0.5211, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5156 - accuracy: 0.7566 - val_loss: 0.5211 - val_accuracy: 0.7856 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5071 - accuracy: 0.7620Epoch 21/40: loss=0.5060, accuracy=0.7628, val_loss=0.6026, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5060 - accuracy: 0.7628 - val_loss: 0.6026 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5251 - accuracy: 0.7525\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 22/40: loss=0.5249, accuracy=0.7527, val_loss=0.6077, val_accuracy=0.7127\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5249 - accuracy: 0.7527 - val_loss: 0.6077 - val_accuracy: 0.7127 - lr: 0.0010\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.7788Epoch 23/40: loss=0.4754, accuracy=0.7790, val_loss=0.4047, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4754 - accuracy: 0.7790 - val_loss: 0.4047 - val_accuracy: 0.8146 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.7803Epoch 24/40: loss=0.4763, accuracy=0.7804, val_loss=0.4048, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4763 - accuracy: 0.7804 - val_loss: 0.4048 - val_accuracy: 0.8137 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4660 - accuracy: 0.7832Epoch 25/40: loss=0.4660, accuracy=0.7831, val_loss=0.4151, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4660 - accuracy: 0.7831 - val_loss: 0.4151 - val_accuracy: 0.8179 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7853Epoch 26/40: loss=0.4583, accuracy=0.7844, val_loss=0.4178, val_accuracy=0.8113\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4583 - accuracy: 0.7844 - val_loss: 0.4178 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.7795Epoch 27/40: loss=0.4671, accuracy=0.7794, val_loss=0.4891, val_accuracy=0.7798\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4671 - accuracy: 0.7794 - val_loss: 0.4891 - val_accuracy: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.7895\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 28/40: loss=0.4556, accuracy=0.7893, val_loss=0.4149, val_accuracy=0.8096\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4556 - accuracy: 0.7893 - val_loss: 0.4149 - val_accuracy: 0.8096 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.7877Epoch 29/40: loss=0.4527, accuracy=0.7877, val_loss=0.4193, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4527 - accuracy: 0.7877 - val_loss: 0.4193 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.7933Epoch 30/40: loss=0.4498, accuracy=0.7933, val_loss=0.4091, val_accuracy=0.8096\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4498 - accuracy: 0.7933 - val_loss: 0.4091 - val_accuracy: 0.8096 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8057Epoch 31/40: loss=0.4373, accuracy=0.8057, val_loss=0.4259, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4373 - accuracy: 0.8057 - val_loss: 0.4259 - val_accuracy: 0.8079 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8035Epoch 32/40: loss=0.4366, accuracy=0.8034, val_loss=0.3917, val_accuracy=0.8212\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4366 - accuracy: 0.8034 - val_loss: 0.3917 - val_accuracy: 0.8212 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8040Epoch 33/40: loss=0.4371, accuracy=0.8040, val_loss=0.4118, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4371 - accuracy: 0.8040 - val_loss: 0.4118 - val_accuracy: 0.8137 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4486 - accuracy: 0.7964Epoch 34/40: loss=0.4487, accuracy=0.7964, val_loss=0.4281, val_accuracy=0.8113\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4487 - accuracy: 0.7964 - val_loss: 0.4281 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.8065Epoch 35/40: loss=0.4381, accuracy=0.8065, val_loss=0.4182, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4381 - accuracy: 0.8065 - val_loss: 0.4182 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.8087Epoch 36/40: loss=0.4197, accuracy=0.8086, val_loss=0.4109, val_accuracy=0.8162\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4197 - accuracy: 0.8086 - val_loss: 0.4109 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.8005\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 37/40: loss=0.4299, accuracy=0.8003, val_loss=0.4263, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4263 - val_accuracy: 0.8079 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.7990Epoch 38/40: loss=0.4357, accuracy=0.7990, val_loss=0.4100, val_accuracy=0.8137\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4357 - accuracy: 0.7990 - val_loss: 0.4100 - val_accuracy: 0.8137 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4238 - accuracy: 0.8075Epoch 39/40: loss=0.4240, accuracy=0.8073, val_loss=0.4145, val_accuracy=0.8137\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4240 - accuracy: 0.8073 - val_loss: 0.4145 - val_accuracy: 0.8137 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.8030Epoch 40/40: loss=0.4244, accuracy=0.8030, val_loss=0.4175, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4244 - accuracy: 0.8030 - val_loss: 0.4175 - val_accuracy: 0.8137 - lr: 8.0000e-06\n",
      "Validation accuracy: 0.8211920261383057\n",
      "\n",
      "Initial Training Combination 7/50: num_residual_blocks=1, dropout_rate=0.6, learning_rate=0.001, rotation_range=10, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.2, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9268 - accuracy: 0.5101Epoch 1/40: loss=0.9268, accuracy=0.5101, val_loss=0.6496, val_accuracy=0.6407\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9268 - accuracy: 0.5101 - val_loss: 0.6496 - val_accuracy: 0.6407 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7277 - accuracy: 0.5336Epoch 2/40: loss=0.7274, accuracy=0.5341, val_loss=1.0677, val_accuracy=0.4015\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7274 - accuracy: 0.5341 - val_loss: 1.0677 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6904 - accuracy: 0.5610Epoch 3/40: loss=0.6896, accuracy=0.5623, val_loss=0.6128, val_accuracy=0.6763\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6896 - accuracy: 0.5623 - val_loss: 0.6128 - val_accuracy: 0.6763 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.6178Epoch 4/40: loss=0.6665, accuracy=0.6178, val_loss=3.3977, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6665 - accuracy: 0.6178 - val_loss: 3.3977 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.6151Epoch 5/40: loss=0.6602, accuracy=0.6151, val_loss=0.7181, val_accuracy=0.5902\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6602 - accuracy: 0.6151 - val_loss: 0.7181 - val_accuracy: 0.5902 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.6008Epoch 6/40: loss=0.6662, accuracy=0.6008, val_loss=0.6447, val_accuracy=0.6912\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6662 - accuracy: 0.6008 - val_loss: 0.6447 - val_accuracy: 0.6912 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6275Epoch 7/40: loss=0.6512, accuracy=0.6275, val_loss=2.0362, val_accuracy=0.4023\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6512 - accuracy: 0.6275 - val_loss: 2.0362 - val_accuracy: 0.4023 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6506 - accuracy: 0.6175\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.6505, accuracy=0.6173, val_loss=0.7275, val_accuracy=0.6465\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6505 - accuracy: 0.6173 - val_loss: 0.7275 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.6138Epoch 9/40: loss=0.6543, accuracy=0.6128, val_loss=0.9358, val_accuracy=0.4652\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6543 - accuracy: 0.6128 - val_loss: 0.9358 - val_accuracy: 0.4652 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6334 - accuracy: 0.6300Epoch 10/40: loss=0.6335, accuracy=0.6298, val_loss=0.6982, val_accuracy=0.6432\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6335 - accuracy: 0.6298 - val_loss: 0.6982 - val_accuracy: 0.6432 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.6430Epoch 11/40: loss=0.6316, accuracy=0.6428, val_loss=0.6657, val_accuracy=0.6598\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6316 - accuracy: 0.6428 - val_loss: 0.6657 - val_accuracy: 0.6598 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6440Epoch 12/40: loss=0.6335, accuracy=0.6440, val_loss=0.6979, val_accuracy=0.6407\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6335 - accuracy: 0.6440 - val_loss: 0.6979 - val_accuracy: 0.6407 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.6575\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 13/40: loss=0.6213, accuracy=0.6575, val_loss=0.6549, val_accuracy=0.7053\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6213 - accuracy: 0.6575 - val_loss: 0.6549 - val_accuracy: 0.7053 - lr: 2.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Validation accuracy: 0.7052980065345764\n",
      "\n",
      "Initial Training Combination 8/50: num_residual_blocks=4, dropout_rate=0.6, learning_rate=0.0005, rotation_range=20, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.2, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.4911Epoch 1/40: loss=1.0132, accuracy=0.4909, val_loss=0.8403, val_accuracy=0.4189\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 1.0132 - accuracy: 0.4909 - val_loss: 0.8403 - val_accuracy: 0.4189 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8176 - accuracy: 0.4998Epoch 2/40: loss=0.8175, accuracy=0.4998, val_loss=0.7292, val_accuracy=0.4089\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8175 - accuracy: 0.4998 - val_loss: 0.7292 - val_accuracy: 0.4089 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7388 - accuracy: 0.5079Epoch 3/40: loss=0.7388, accuracy=0.5079, val_loss=0.7271, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7388 - accuracy: 0.5079 - val_loss: 0.7271 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.4900Epoch 4/40: loss=0.7198, accuracy=0.4905, val_loss=0.7127, val_accuracy=0.4752\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7198 - accuracy: 0.4905 - val_loss: 0.7127 - val_accuracy: 0.4752 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7111 - accuracy: 0.4789Epoch 5/40: loss=0.7111, accuracy=0.4789, val_loss=0.6950, val_accuracy=0.5356\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7111 - accuracy: 0.4789 - val_loss: 0.6950 - val_accuracy: 0.5356 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7045 - accuracy: 0.4911Epoch 6/40: loss=0.7045, accuracy=0.4913, val_loss=0.6850, val_accuracy=0.5770\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7045 - accuracy: 0.4913 - val_loss: 0.6850 - val_accuracy: 0.5770 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.5087Epoch 7/40: loss=0.7048, accuracy=0.5087, val_loss=0.6810, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7048 - accuracy: 0.5087 - val_loss: 0.6810 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7030 - accuracy: 0.5058Epoch 8/40: loss=0.7026, accuracy=0.5058, val_loss=0.8544, val_accuracy=0.5886\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.7026 - accuracy: 0.5058 - val_loss: 0.8544 - val_accuracy: 0.5886 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7003 - accuracy: 0.5214Epoch 9/40: loss=0.7003, accuracy=0.5213, val_loss=1.1711, val_accuracy=0.6002\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7003 - accuracy: 0.5213 - val_loss: 1.1711 - val_accuracy: 0.6002 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7052 - accuracy: 0.5025Epoch 10/40: loss=0.7050, accuracy=0.5031, val_loss=0.7083, val_accuracy=0.4015\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7050 - accuracy: 0.5031 - val_loss: 0.7083 - val_accuracy: 0.4015 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.5130Epoch 11/40: loss=0.6994, accuracy=0.5130, val_loss=0.7176, val_accuracy=0.4015\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6994 - accuracy: 0.5130 - val_loss: 0.7176 - val_accuracy: 0.4015 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7019 - accuracy: 0.5066\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/40: loss=0.7020, accuracy=0.5066, val_loss=0.6960, val_accuracy=0.4950\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7020 - accuracy: 0.5066 - val_loss: 0.6960 - val_accuracy: 0.4950 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6966 - accuracy: 0.5141Epoch 13/40: loss=0.6968, accuracy=0.5137, val_loss=0.6905, val_accuracy=0.4892\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6968 - accuracy: 0.5137 - val_loss: 0.6905 - val_accuracy: 0.4892 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.5422Epoch 14/40: loss=0.6878, accuracy=0.5424, val_loss=0.6599, val_accuracy=0.5795\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6878 - accuracy: 0.5424 - val_loss: 0.6599 - val_accuracy: 0.5795 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5841Epoch 15/40: loss=0.6715, accuracy=0.5844, val_loss=0.5642, val_accuracy=0.6945\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6715 - accuracy: 0.5844 - val_loss: 0.5642 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6278 - accuracy: 0.6591Epoch 16/40: loss=0.6285, accuracy=0.6587, val_loss=0.5863, val_accuracy=0.7045\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6285 - accuracy: 0.6587 - val_loss: 0.5863 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6040 - accuracy: 0.6710Epoch 17/40: loss=0.6041, accuracy=0.6714, val_loss=0.5547, val_accuracy=0.6730\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6041 - accuracy: 0.6714 - val_loss: 0.5547 - val_accuracy: 0.6730 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.6846Epoch 18/40: loss=0.5981, accuracy=0.6846, val_loss=0.7562, val_accuracy=0.4859\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5981 - accuracy: 0.6846 - val_loss: 0.7562 - val_accuracy: 0.4859 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5761 - accuracy: 0.7029Epoch 19/40: loss=0.5761, accuracy=0.7030, val_loss=1.3312, val_accuracy=0.3965\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5761 - accuracy: 0.7030 - val_loss: 1.3312 - val_accuracy: 0.3965 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5838 - accuracy: 0.6983Epoch 20/40: loss=0.5839, accuracy=0.6985, val_loss=0.8421, val_accuracy=0.4950\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5839 - accuracy: 0.6985 - val_loss: 0.8421 - val_accuracy: 0.4950 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5726 - accuracy: 0.7035Epoch 21/40: loss=0.5724, accuracy=0.7034, val_loss=0.9457, val_accuracy=0.7351\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5724 - accuracy: 0.7034 - val_loss: 0.9457 - val_accuracy: 0.7351 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7112\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 22/40: loss=0.5688, accuracy=0.7109, val_loss=0.9941, val_accuracy=0.4553\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5688 - accuracy: 0.7109 - val_loss: 0.9941 - val_accuracy: 0.4553 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.7143Epoch 23/40: loss=0.5654, accuracy=0.7142, val_loss=0.6809, val_accuracy=0.5877\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5654 - accuracy: 0.7142 - val_loss: 0.6809 - val_accuracy: 0.5877 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7140Epoch 24/40: loss=0.5658, accuracy=0.7140, val_loss=0.7048, val_accuracy=0.5762\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5658 - accuracy: 0.7140 - val_loss: 0.7048 - val_accuracy: 0.5762 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7203Epoch 25/40: loss=0.5634, accuracy=0.7208, val_loss=0.8946, val_accuracy=0.4743\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5634 - accuracy: 0.7208 - val_loss: 0.8946 - val_accuracy: 0.4743 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.7116Epoch 26/40: loss=0.5671, accuracy=0.7121, val_loss=0.7141, val_accuracy=0.5654\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5671 - accuracy: 0.7121 - val_loss: 0.7141 - val_accuracy: 0.5654 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7121\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5575, accuracy=0.7121, val_loss=0.7572, val_accuracy=0.5430\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5575 - accuracy: 0.7121 - val_loss: 0.7572 - val_accuracy: 0.5430 - lr: 2.0000e-05\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7350993156433105\n",
      "\n",
      "Initial Training Combination 9/50: num_residual_blocks=3, dropout_rate=0.5, learning_rate=0.0001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0357 - accuracy: 0.5176Epoch 1/40: loss=1.0357, accuracy=0.5176, val_loss=0.7206, val_accuracy=0.4536\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0357 - accuracy: 0.5176 - val_loss: 0.7206 - val_accuracy: 0.4536 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9659 - accuracy: 0.4998Epoch 2/40: loss=0.9647, accuracy=0.5004, val_loss=0.7427, val_accuracy=0.4346\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9647 - accuracy: 0.5004 - val_loss: 0.7427 - val_accuracy: 0.4346 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9457 - accuracy: 0.4888Epoch 3/40: loss=0.9449, accuracy=0.4894, val_loss=0.7228, val_accuracy=0.4495\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.9449 - accuracy: 0.4894 - val_loss: 0.7228 - val_accuracy: 0.4495 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.5087Epoch 4/40: loss=0.8879, accuracy=0.5087, val_loss=0.7390, val_accuracy=0.4139\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8879 - accuracy: 0.5087 - val_loss: 0.7390 - val_accuracy: 0.4139 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.5130Epoch 5/40: loss=0.8537, accuracy=0.5130, val_loss=0.7175, val_accuracy=0.4379\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8537 - accuracy: 0.5130 - val_loss: 0.7175 - val_accuracy: 0.4379 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8334 - accuracy: 0.5098Epoch 6/40: loss=0.8332, accuracy=0.5097, val_loss=0.7128, val_accuracy=0.5199\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8332 - accuracy: 0.5097 - val_loss: 0.7128 - val_accuracy: 0.5199 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7920 - accuracy: 0.5373Epoch 7/40: loss=0.7920, accuracy=0.5373, val_loss=0.6718, val_accuracy=0.6391\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7920 - accuracy: 0.5373 - val_loss: 0.6718 - val_accuracy: 0.6391 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7465 - accuracy: 0.5638Epoch 8/40: loss=0.7460, accuracy=0.5644, val_loss=0.5839, val_accuracy=0.7136\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7460 - accuracy: 0.5644 - val_loss: 0.5839 - val_accuracy: 0.7136 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7070 - accuracy: 0.6008Epoch 9/40: loss=0.7070, accuracy=0.6008, val_loss=0.7851, val_accuracy=0.5919\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7070 - accuracy: 0.6008 - val_loss: 0.7851 - val_accuracy: 0.5919 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.6358Epoch 10/40: loss=0.6714, accuracy=0.6358, val_loss=1.5007, val_accuracy=0.4023\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6714 - accuracy: 0.6358 - val_loss: 1.5007 - val_accuracy: 0.4023 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6466 - accuracy: 0.6500Epoch 11/40: loss=0.6464, accuracy=0.6500, val_loss=0.6569, val_accuracy=0.6772\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6464 - accuracy: 0.6500 - val_loss: 0.6569 - val_accuracy: 0.6772 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6346 - accuracy: 0.6642Epoch 12/40: loss=0.6351, accuracy=0.6639, val_loss=0.5227, val_accuracy=0.7508\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6351 - accuracy: 0.6639 - val_loss: 0.5227 - val_accuracy: 0.7508 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.6778Epoch 13/40: loss=0.6188, accuracy=0.6778, val_loss=0.4663, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6188 - accuracy: 0.6778 - val_loss: 0.4663 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.6794Epoch 14/40: loss=0.6149, accuracy=0.6792, val_loss=0.7247, val_accuracy=0.5778\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6149 - accuracy: 0.6792 - val_loss: 0.7247 - val_accuracy: 0.5778 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5947 - accuracy: 0.6908Epoch 15/40: loss=0.5950, accuracy=0.6910, val_loss=0.4912, val_accuracy=0.7632\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5950 - accuracy: 0.6910 - val_loss: 0.4912 - val_accuracy: 0.7632 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.6869Epoch 16/40: loss=0.5897, accuracy=0.6867, val_loss=0.7137, val_accuracy=0.5704\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5897 - accuracy: 0.6867 - val_loss: 0.7137 - val_accuracy: 0.5704 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7036Epoch 17/40: loss=0.5754, accuracy=0.7034, val_loss=1.0938, val_accuracy=0.6705\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5754 - accuracy: 0.7034 - val_loss: 1.0938 - val_accuracy: 0.6705 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5758 - accuracy: 0.7095Epoch 18/40: loss=0.5757, accuracy=0.7096, val_loss=0.4627, val_accuracy=0.7732\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5757 - accuracy: 0.7096 - val_loss: 0.4627 - val_accuracy: 0.7732 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7161Epoch 19/40: loss=0.5641, accuracy=0.7161, val_loss=1.0704, val_accuracy=0.4992\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5641 - accuracy: 0.7161 - val_loss: 1.0704 - val_accuracy: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7319Epoch 20/40: loss=0.5442, accuracy=0.7314, val_loss=0.4703, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5442 - accuracy: 0.7314 - val_loss: 0.4703 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.7237Epoch 21/40: loss=0.5600, accuracy=0.7237, val_loss=0.6670, val_accuracy=0.6192\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5600 - accuracy: 0.7237 - val_loss: 0.6670 - val_accuracy: 0.6192 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7164Epoch 22/40: loss=0.5499, accuracy=0.7171, val_loss=0.5568, val_accuracy=0.7616\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5499 - accuracy: 0.7171 - val_loss: 0.5568 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5554 - accuracy: 0.7206\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 23/40: loss=0.5553, accuracy=0.7208, val_loss=0.4751, val_accuracy=0.7657\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5553 - accuracy: 0.7208 - val_loss: 0.4751 - val_accuracy: 0.7657 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.7402Epoch 24/40: loss=0.5249, accuracy=0.7407, val_loss=0.4362, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5249 - accuracy: 0.7407 - val_loss: 0.4362 - val_accuracy: 0.7988 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5197 - accuracy: 0.7427Epoch 25/40: loss=0.5193, accuracy=0.7430, val_loss=0.4416, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5193 - accuracy: 0.7430 - val_loss: 0.4416 - val_accuracy: 0.7856 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.7473Epoch 26/40: loss=0.5210, accuracy=0.7473, val_loss=0.4472, val_accuracy=0.8005\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5210 - accuracy: 0.7473 - val_loss: 0.4472 - val_accuracy: 0.8005 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.7475Epoch 27/40: loss=0.5181, accuracy=0.7475, val_loss=0.4737, val_accuracy=0.7459\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5181 - accuracy: 0.7475 - val_loss: 0.4737 - val_accuracy: 0.7459 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.7488Epoch 28/40: loss=0.5138, accuracy=0.7492, val_loss=0.4375, val_accuracy=0.7748\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5138 - accuracy: 0.7492 - val_loss: 0.4375 - val_accuracy: 0.7748 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.7560\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 29/40: loss=0.5111, accuracy=0.7560, val_loss=0.4691, val_accuracy=0.7798\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5111 - accuracy: 0.7560 - val_loss: 0.4691 - val_accuracy: 0.7798 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.7463Epoch 30/40: loss=0.5081, accuracy=0.7463, val_loss=0.4395, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5081 - accuracy: 0.7463 - val_loss: 0.4395 - val_accuracy: 0.7815 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.7568Epoch 31/40: loss=0.5066, accuracy=0.7568, val_loss=0.4402, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5066 - accuracy: 0.7568 - val_loss: 0.4402 - val_accuracy: 0.7873 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.7583Epoch 32/40: loss=0.5029, accuracy=0.7583, val_loss=0.4376, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5029 - accuracy: 0.7583 - val_loss: 0.4376 - val_accuracy: 0.7873 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5027 - accuracy: 0.7515Epoch 33/40: loss=0.5024, accuracy=0.7517, val_loss=0.4399, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5024 - accuracy: 0.7517 - val_loss: 0.4399 - val_accuracy: 0.7864 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.7600\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 34/40: loss=0.5003, accuracy=0.7606, val_loss=0.4441, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5003 - accuracy: 0.7606 - val_loss: 0.4441 - val_accuracy: 0.7781 - lr: 4.0000e-06\n",
      "Epoch 34: early stopping\n",
      "Validation accuracy: 0.8004966974258423\n",
      "\n",
      "Initial Training Combination 10/50: num_residual_blocks=1, dropout_rate=0.3, learning_rate=0.0001, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.5519Epoch 1/40: loss=0.8860, accuracy=0.5519, val_loss=0.8783, val_accuracy=0.5058\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.8860 - accuracy: 0.5519 - val_loss: 0.8783 - val_accuracy: 0.5058 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7755 - accuracy: 0.6042Epoch 2/40: loss=0.7749, accuracy=0.6041, val_loss=0.9482, val_accuracy=0.5215\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7749 - accuracy: 0.6041 - val_loss: 0.9482 - val_accuracy: 0.5215 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.6325Epoch 3/40: loss=0.7294, accuracy=0.6325, val_loss=0.7416, val_accuracy=0.5869\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7294 - accuracy: 0.6325 - val_loss: 0.7416 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7235 - accuracy: 0.6244Epoch 4/40: loss=0.7235, accuracy=0.6244, val_loss=0.5506, val_accuracy=0.7483\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7235 - accuracy: 0.6244 - val_loss: 0.5506 - val_accuracy: 0.7483 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6834 - accuracy: 0.6364Epoch 5/40: loss=0.6829, accuracy=0.6366, val_loss=1.1831, val_accuracy=0.6523\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6829 - accuracy: 0.6366 - val_loss: 1.1831 - val_accuracy: 0.6523 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.6482Epoch 6/40: loss=0.6798, accuracy=0.6482, val_loss=1.0904, val_accuracy=0.6490\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6798 - accuracy: 0.6482 - val_loss: 1.0904 - val_accuracy: 0.6490 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.6470Epoch 7/40: loss=0.6674, accuracy=0.6471, val_loss=0.8897, val_accuracy=0.5033\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6674 - accuracy: 0.6471 - val_loss: 0.8897 - val_accuracy: 0.5033 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6428 - accuracy: 0.6575Epoch 8/40: loss=0.6428, accuracy=0.6575, val_loss=0.7568, val_accuracy=0.5439\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6428 - accuracy: 0.6575 - val_loss: 0.7568 - val_accuracy: 0.5439 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.6600\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 9/40: loss=0.6502, accuracy=0.6604, val_loss=0.6312, val_accuracy=0.7012\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6502 - accuracy: 0.6604 - val_loss: 0.6312 - val_accuracy: 0.7012 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6230 - accuracy: 0.6689Epoch 10/40: loss=0.6229, accuracy=0.6691, val_loss=0.5455, val_accuracy=0.7028\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6229 - accuracy: 0.6691 - val_loss: 0.5455 - val_accuracy: 0.7028 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6140 - accuracy: 0.6709Epoch 11/40: loss=0.6146, accuracy=0.6707, val_loss=0.4898, val_accuracy=0.7417\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6146 - accuracy: 0.6707 - val_loss: 0.4898 - val_accuracy: 0.7417 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.6851Epoch 12/40: loss=0.6113, accuracy=0.6854, val_loss=0.5157, val_accuracy=0.7276\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6113 - accuracy: 0.6854 - val_loss: 0.5157 - val_accuracy: 0.7276 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.6853Epoch 13/40: loss=0.6059, accuracy=0.6854, val_loss=0.5640, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6059 - accuracy: 0.6854 - val_loss: 0.5640 - val_accuracy: 0.6879 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 0.6854Epoch 14/40: loss=0.6074, accuracy=0.6854, val_loss=0.4682, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6074 - accuracy: 0.6854 - val_loss: 0.4682 - val_accuracy: 0.7699 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.6782Epoch 15/40: loss=0.6069, accuracy=0.6778, val_loss=0.4957, val_accuracy=0.7657\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6069 - accuracy: 0.6778 - val_loss: 0.4957 - val_accuracy: 0.7657 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6774Epoch 16/40: loss=0.6076, accuracy=0.6774, val_loss=0.5012, val_accuracy=0.7343\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6076 - accuracy: 0.6774 - val_loss: 0.5012 - val_accuracy: 0.7343 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5962 - accuracy: 0.6892Epoch 17/40: loss=0.5966, accuracy=0.6885, val_loss=0.5646, val_accuracy=0.6846\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5966 - accuracy: 0.6885 - val_loss: 0.5646 - val_accuracy: 0.6846 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5821 - accuracy: 0.6965Epoch 18/40: loss=0.5821, accuracy=0.6966, val_loss=0.4988, val_accuracy=0.7185\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5821 - accuracy: 0.6966 - val_loss: 0.4988 - val_accuracy: 0.7185 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5827 - accuracy: 0.6951\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 19/40: loss=0.5828, accuracy=0.6950, val_loss=0.4859, val_accuracy=0.7707\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5828 - accuracy: 0.6950 - val_loss: 0.4859 - val_accuracy: 0.7707 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5825 - accuracy: 0.6983Epoch 20/40: loss=0.5825, accuracy=0.6983, val_loss=0.4736, val_accuracy=0.7392\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5825 - accuracy: 0.6983 - val_loss: 0.4736 - val_accuracy: 0.7392 - lr: 4.0000e-06\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.6949Epoch 21/40: loss=0.5839, accuracy=0.6954, val_loss=0.4776, val_accuracy=0.7409\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5839 - accuracy: 0.6954 - val_loss: 0.4776 - val_accuracy: 0.7409 - lr: 4.0000e-06\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.6906Epoch 22/40: loss=0.5909, accuracy=0.6906, val_loss=0.4699, val_accuracy=0.7525\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5909 - accuracy: 0.6906 - val_loss: 0.4699 - val_accuracy: 0.7525 - lr: 4.0000e-06\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7072Epoch 23/40: loss=0.5728, accuracy=0.7072, val_loss=0.4728, val_accuracy=0.7459\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5728 - accuracy: 0.7072 - val_loss: 0.4728 - val_accuracy: 0.7459 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7016\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.5745, accuracy=0.7016, val_loss=0.4733, val_accuracy=0.7459\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5745 - accuracy: 0.7016 - val_loss: 0.4733 - val_accuracy: 0.7459 - lr: 4.0000e-06\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.7706953883171082\n",
      "\n",
      "Initial Training Combination 11/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.0001, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.5370Epoch 1/40: loss=0.9070, accuracy=0.5370, val_loss=0.7730, val_accuracy=0.5149\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9070 - accuracy: 0.5370 - val_loss: 0.7730 - val_accuracy: 0.5149 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.6198Epoch 2/40: loss=0.7581, accuracy=0.6209, val_loss=0.8778, val_accuracy=0.5869\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7581 - accuracy: 0.6209 - val_loss: 0.8778 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.6492Epoch 3/40: loss=0.7048, accuracy=0.6492, val_loss=0.6608, val_accuracy=0.7310\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7048 - accuracy: 0.6492 - val_loss: 0.6608 - val_accuracy: 0.7310 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.6705Epoch 4/40: loss=0.6766, accuracy=0.6705, val_loss=0.5778, val_accuracy=0.7119\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6766 - accuracy: 0.6705 - val_loss: 0.5778 - val_accuracy: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.6828Epoch 5/40: loss=0.6519, accuracy=0.6825, val_loss=1.0381, val_accuracy=0.6482\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6519 - accuracy: 0.6825 - val_loss: 1.0381 - val_accuracy: 0.6482 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6351 - accuracy: 0.6884Epoch 6/40: loss=0.6342, accuracy=0.6889, val_loss=1.0192, val_accuracy=0.4859\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6342 - accuracy: 0.6889 - val_loss: 1.0192 - val_accuracy: 0.4859 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.6805Epoch 7/40: loss=0.6229, accuracy=0.6805, val_loss=0.6676, val_accuracy=0.6747\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6229 - accuracy: 0.6805 - val_loss: 0.6676 - val_accuracy: 0.6747 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6251 - accuracy: 0.6866Epoch 8/40: loss=0.6249, accuracy=0.6867, val_loss=0.5813, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6249 - accuracy: 0.6867 - val_loss: 0.5813 - val_accuracy: 0.7301 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5971 - accuracy: 0.6970\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 9/40: loss=0.5976, accuracy=0.6968, val_loss=0.6951, val_accuracy=0.6035\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5976 - accuracy: 0.6968 - val_loss: 0.6951 - val_accuracy: 0.6035 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.7026Epoch 10/40: loss=0.5894, accuracy=0.7026, val_loss=0.5527, val_accuracy=0.6887\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5894 - accuracy: 0.7026 - val_loss: 0.5527 - val_accuracy: 0.6887 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.7213Epoch 11/40: loss=0.5734, accuracy=0.7206, val_loss=0.7131, val_accuracy=0.6002\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5734 - accuracy: 0.7206 - val_loss: 0.7131 - val_accuracy: 0.6002 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7191Epoch 12/40: loss=0.5652, accuracy=0.7194, val_loss=0.5186, val_accuracy=0.7202\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5652 - accuracy: 0.7194 - val_loss: 0.5186 - val_accuracy: 0.7202 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5568 - accuracy: 0.7221Epoch 13/40: loss=0.5568, accuracy=0.7214, val_loss=0.7516, val_accuracy=0.5637\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5568 - accuracy: 0.7214 - val_loss: 0.7516 - val_accuracy: 0.5637 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7309Epoch 14/40: loss=0.5510, accuracy=0.7308, val_loss=0.7090, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5510 - accuracy: 0.7308 - val_loss: 0.7090 - val_accuracy: 0.5960 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.7293Epoch 15/40: loss=0.5506, accuracy=0.7293, val_loss=0.4430, val_accuracy=0.7848\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5506 - accuracy: 0.7293 - val_loss: 0.4430 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.7202Epoch 16/40: loss=0.5551, accuracy=0.7202, val_loss=0.7594, val_accuracy=0.5770\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5551 - accuracy: 0.7202 - val_loss: 0.7594 - val_accuracy: 0.5770 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.7369Epoch 17/40: loss=0.5359, accuracy=0.7372, val_loss=0.5102, val_accuracy=0.7285\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5359 - accuracy: 0.7372 - val_loss: 0.5102 - val_accuracy: 0.7285 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.7461Epoch 18/40: loss=0.5287, accuracy=0.7461, val_loss=0.4239, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5287 - accuracy: 0.7461 - val_loss: 0.4239 - val_accuracy: 0.7997 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7444Epoch 19/40: loss=0.5262, accuracy=0.7438, val_loss=0.4468, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5262 - accuracy: 0.7438 - val_loss: 0.4468 - val_accuracy: 0.7839 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.7361Epoch 20/40: loss=0.5394, accuracy=0.7361, val_loss=0.4646, val_accuracy=0.7674\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5394 - accuracy: 0.7361 - val_loss: 0.4646 - val_accuracy: 0.7674 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5298 - accuracy: 0.7363Epoch 21/40: loss=0.5287, accuracy=0.7372, val_loss=0.6266, val_accuracy=0.6474\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5287 - accuracy: 0.7372 - val_loss: 0.6266 - val_accuracy: 0.6474 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.7427Epoch 22/40: loss=0.5215, accuracy=0.7428, val_loss=0.6097, val_accuracy=0.6672\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5215 - accuracy: 0.7428 - val_loss: 0.6097 - val_accuracy: 0.6672 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.7442\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 23/40: loss=0.5221, accuracy=0.7442, val_loss=0.4826, val_accuracy=0.7492\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5221 - accuracy: 0.7442 - val_loss: 0.4826 - val_accuracy: 0.7492 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7566Epoch 24/40: loss=0.5096, accuracy=0.7566, val_loss=0.4539, val_accuracy=0.7699\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5096 - accuracy: 0.7566 - val_loss: 0.4539 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.7521Epoch 25/40: loss=0.5077, accuracy=0.7523, val_loss=0.4650, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5077 - accuracy: 0.7523 - val_loss: 0.4650 - val_accuracy: 0.7599 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7562Epoch 26/40: loss=0.5048, accuracy=0.7562, val_loss=0.4824, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5048 - accuracy: 0.7562 - val_loss: 0.4824 - val_accuracy: 0.7483 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.7566Epoch 27/40: loss=0.4995, accuracy=0.7566, val_loss=0.4472, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4995 - accuracy: 0.7566 - val_loss: 0.4472 - val_accuracy: 0.7781 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5040 - accuracy: 0.7575\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28/40: loss=0.5033, accuracy=0.7577, val_loss=0.5014, val_accuracy=0.7301\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5033 - accuracy: 0.7577 - val_loss: 0.5014 - val_accuracy: 0.7301 - lr: 4.0000e-06\n",
      "Epoch 28: early stopping\n",
      "Validation accuracy: 0.7996688485145569\n",
      "\n",
      "Initial Training Combination 12/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.001, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9018 - accuracy: 0.5058Epoch 1/40: loss=0.9013, accuracy=0.5058, val_loss=1.2530, val_accuracy=0.3990\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9013 - accuracy: 0.5058 - val_loss: 1.2530 - val_accuracy: 0.3990 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.5039Epoch 2/40: loss=0.7343, accuracy=0.5037, val_loss=0.8221, val_accuracy=0.4123\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7343 - accuracy: 0.5037 - val_loss: 0.8221 - val_accuracy: 0.4123 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6999 - accuracy: 0.5473Epoch 3/40: loss=0.6999, accuracy=0.5470, val_loss=0.6668, val_accuracy=0.6730\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6999 - accuracy: 0.5470 - val_loss: 0.6668 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6906 - accuracy: 0.5769Epoch 4/40: loss=0.6910, accuracy=0.5766, val_loss=0.6475, val_accuracy=0.6912\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6910 - accuracy: 0.5766 - val_loss: 0.6475 - val_accuracy: 0.6912 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5714Epoch 5/40: loss=0.6915, accuracy=0.5714, val_loss=0.6438, val_accuracy=0.6118\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6915 - accuracy: 0.5714 - val_loss: 0.6438 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.5495Epoch 6/40: loss=0.6958, accuracy=0.5495, val_loss=4.0435, val_accuracy=0.4015\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6958 - accuracy: 0.5495 - val_loss: 4.0435 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.5190Epoch 7/40: loss=0.7064, accuracy=0.5190, val_loss=0.6916, val_accuracy=0.5538\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7064 - accuracy: 0.5190 - val_loss: 0.6916 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.5720Epoch 8/40: loss=0.6816, accuracy=0.5718, val_loss=0.9863, val_accuracy=0.5207\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6816 - accuracy: 0.5718 - val_loss: 0.9863 - val_accuracy: 0.5207 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5859Epoch 9/40: loss=0.6703, accuracy=0.5859, val_loss=2.2818, val_accuracy=0.4247\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6703 - accuracy: 0.5859 - val_loss: 2.2818 - val_accuracy: 0.4247 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.6003\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.6629, accuracy=0.6002, val_loss=0.8549, val_accuracy=0.5646\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6629 - accuracy: 0.6002 - val_loss: 0.8549 - val_accuracy: 0.5646 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6335 - accuracy: 0.6310Epoch 11/40: loss=0.6335, accuracy=0.6316, val_loss=0.7870, val_accuracy=0.6209\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6335 - accuracy: 0.6316 - val_loss: 0.7870 - val_accuracy: 0.6209 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6327 - accuracy: 0.6333Epoch 12/40: loss=0.6326, accuracy=0.6335, val_loss=0.6259, val_accuracy=0.7061\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6326 - accuracy: 0.6335 - val_loss: 0.6259 - val_accuracy: 0.7061 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6174 - accuracy: 0.6507Epoch 13/40: loss=0.6170, accuracy=0.6509, val_loss=0.6651, val_accuracy=0.6995\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6170 - accuracy: 0.6509 - val_loss: 0.6651 - val_accuracy: 0.6995 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6080 - accuracy: 0.6588Epoch 14/40: loss=0.6080, accuracy=0.6587, val_loss=0.6258, val_accuracy=0.7442\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6080 - accuracy: 0.6587 - val_loss: 0.6258 - val_accuracy: 0.7442 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.6513Epoch 15/40: loss=0.6164, accuracy=0.6513, val_loss=0.6690, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6164 - accuracy: 0.6513 - val_loss: 0.6690 - val_accuracy: 0.6879 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5961 - accuracy: 0.6725Epoch 16/40: loss=0.5959, accuracy=0.6726, val_loss=1.3433, val_accuracy=0.5315\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5959 - accuracy: 0.6726 - val_loss: 1.3433 - val_accuracy: 0.5315 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.6663Epoch 17/40: loss=0.5931, accuracy=0.6662, val_loss=1.4840, val_accuracy=0.6523\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5931 - accuracy: 0.6662 - val_loss: 1.4840 - val_accuracy: 0.6523 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5959 - accuracy: 0.6681Epoch 18/40: loss=0.5959, accuracy=0.6678, val_loss=0.6102, val_accuracy=0.7425\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5959 - accuracy: 0.6678 - val_loss: 0.6102 - val_accuracy: 0.7425 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5918 - accuracy: 0.6711Epoch 19/40: loss=0.5920, accuracy=0.6709, val_loss=0.6237, val_accuracy=0.6738\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5920 - accuracy: 0.6709 - val_loss: 0.6237 - val_accuracy: 0.6738 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5900 - accuracy: 0.6704Epoch 20/40: loss=0.5901, accuracy=0.6703, val_loss=0.6297, val_accuracy=0.7260\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5901 - accuracy: 0.6703 - val_loss: 0.6297 - val_accuracy: 0.7260 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5919 - accuracy: 0.6764Epoch 21/40: loss=0.5926, accuracy=0.6757, val_loss=0.8185, val_accuracy=0.7012\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5926 - accuracy: 0.6757 - val_loss: 0.8185 - val_accuracy: 0.7012 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.6896Epoch 22/40: loss=0.5841, accuracy=0.6896, val_loss=0.7788, val_accuracy=0.6407\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5841 - accuracy: 0.6896 - val_loss: 0.7788 - val_accuracy: 0.6407 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.6860\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/40: loss=0.5761, accuracy=0.6861, val_loss=0.6109, val_accuracy=0.7467\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5761 - accuracy: 0.6861 - val_loss: 0.6109 - val_accuracy: 0.7467 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5797 - accuracy: 0.6863Epoch 24/40: loss=0.5798, accuracy=0.6865, val_loss=0.7089, val_accuracy=0.6995\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5798 - accuracy: 0.6865 - val_loss: 0.7089 - val_accuracy: 0.6995 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.6995Epoch 25/40: loss=0.5700, accuracy=0.6995, val_loss=0.6899, val_accuracy=0.6854\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5700 - accuracy: 0.6995 - val_loss: 0.6899 - val_accuracy: 0.6854 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5744 - accuracy: 0.6945Epoch 26/40: loss=0.5743, accuracy=0.6943, val_loss=0.6333, val_accuracy=0.7368\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5743 - accuracy: 0.6943 - val_loss: 0.6333 - val_accuracy: 0.7368 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.7007Epoch 27/40: loss=0.5654, accuracy=0.7012, val_loss=0.6631, val_accuracy=0.7227\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5654 - accuracy: 0.7012 - val_loss: 0.6631 - val_accuracy: 0.7227 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7132\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28/40: loss=0.5550, accuracy=0.7132, val_loss=0.6601, val_accuracy=0.7376\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5550 - accuracy: 0.7132 - val_loss: 0.6601 - val_accuracy: 0.7376 - lr: 4.0000e-05\n",
      "Epoch 28: early stopping\n",
      "Validation accuracy: 0.746688723564148\n",
      "\n",
      "Initial Training Combination 13/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.0005, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8105 - accuracy: 0.6013Epoch 1/40: loss=0.8096, accuracy=0.6016, val_loss=1.6667, val_accuracy=0.6159\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.8096 - accuracy: 0.6016 - val_loss: 1.6667 - val_accuracy: 0.6159 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.6694Epoch 2/40: loss=0.6510, accuracy=0.6689, val_loss=0.5859, val_accuracy=0.7359\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6510 - accuracy: 0.6689 - val_loss: 0.5859 - val_accuracy: 0.7359 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.6962Epoch 3/40: loss=0.5956, accuracy=0.6962, val_loss=0.6994, val_accuracy=0.7070\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5956 - accuracy: 0.6962 - val_loss: 0.6994 - val_accuracy: 0.7070 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5590 - accuracy: 0.7191Epoch 4/40: loss=0.5591, accuracy=0.7188, val_loss=0.8362, val_accuracy=0.6507\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5591 - accuracy: 0.7188 - val_loss: 0.8362 - val_accuracy: 0.6507 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5566 - accuracy: 0.7239Epoch 5/40: loss=0.5562, accuracy=0.7241, val_loss=0.7726, val_accuracy=0.6358\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5562 - accuracy: 0.7241 - val_loss: 0.7726 - val_accuracy: 0.6358 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.7413Epoch 6/40: loss=0.5403, accuracy=0.7413, val_loss=0.5186, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5403 - accuracy: 0.7413 - val_loss: 0.5186 - val_accuracy: 0.7790 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7378Epoch 7/40: loss=0.5375, accuracy=0.7378, val_loss=0.5203, val_accuracy=0.7185\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5375 - accuracy: 0.7378 - val_loss: 0.5203 - val_accuracy: 0.7185 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7430Epoch 8/40: loss=0.5374, accuracy=0.7428, val_loss=0.5244, val_accuracy=0.7020\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5374 - accuracy: 0.7428 - val_loss: 0.5244 - val_accuracy: 0.7020 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5276 - accuracy: 0.7502Epoch 9/40: loss=0.5271, accuracy=0.7504, val_loss=0.5208, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5271 - accuracy: 0.7504 - val_loss: 0.5208 - val_accuracy: 0.7219 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7531Epoch 10/40: loss=0.5193, accuracy=0.7531, val_loss=0.4674, val_accuracy=0.7434\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5193 - accuracy: 0.7531 - val_loss: 0.4674 - val_accuracy: 0.7434 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7593Epoch 11/40: loss=0.5185, accuracy=0.7595, val_loss=0.4482, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5185 - accuracy: 0.7595 - val_loss: 0.4482 - val_accuracy: 0.7641 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.7564Epoch 12/40: loss=0.5198, accuracy=0.7564, val_loss=0.4560, val_accuracy=0.7939\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5198 - accuracy: 0.7564 - val_loss: 0.4560 - val_accuracy: 0.7939 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5124 - accuracy: 0.7596Epoch 13/40: loss=0.5123, accuracy=0.7595, val_loss=0.5367, val_accuracy=0.7285\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5123 - accuracy: 0.7595 - val_loss: 0.5367 - val_accuracy: 0.7285 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4945 - accuracy: 0.7645Epoch 14/40: loss=0.4940, accuracy=0.7647, val_loss=0.5660, val_accuracy=0.7334\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4940 - accuracy: 0.7647 - val_loss: 0.5660 - val_accuracy: 0.7334 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.7635Epoch 15/40: loss=0.5022, accuracy=0.7635, val_loss=0.4346, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5022 - accuracy: 0.7635 - val_loss: 0.4346 - val_accuracy: 0.8212 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.7614Epoch 16/40: loss=0.5031, accuracy=0.7616, val_loss=0.4573, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5031 - accuracy: 0.7616 - val_loss: 0.4573 - val_accuracy: 0.8113 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.7664Epoch 17/40: loss=0.4896, accuracy=0.7663, val_loss=0.4167, val_accuracy=0.8022\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4896 - accuracy: 0.7663 - val_loss: 0.4167 - val_accuracy: 0.8022 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.7618Epoch 18/40: loss=0.4904, accuracy=0.7618, val_loss=0.8159, val_accuracy=0.6366\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4904 - accuracy: 0.7618 - val_loss: 0.8159 - val_accuracy: 0.6366 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7635Epoch 19/40: loss=0.4942, accuracy=0.7632, val_loss=0.4364, val_accuracy=0.7972\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4942 - accuracy: 0.7632 - val_loss: 0.4364 - val_accuracy: 0.7972 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.7662Epoch 20/40: loss=0.4833, accuracy=0.7668, val_loss=0.8246, val_accuracy=0.7078\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4833 - accuracy: 0.7668 - val_loss: 0.8246 - val_accuracy: 0.7078 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.7676Epoch 21/40: loss=0.4916, accuracy=0.7672, val_loss=0.4953, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4916 - accuracy: 0.7672 - val_loss: 0.4953 - val_accuracy: 0.7219 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7886\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 22/40: loss=0.4654, accuracy=0.7891, val_loss=0.5401, val_accuracy=0.7765\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4654 - accuracy: 0.7891 - val_loss: 0.5401 - val_accuracy: 0.7765 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.8000Epoch 23/40: loss=0.4411, accuracy=0.8003, val_loss=0.3860, val_accuracy=0.8369\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.3860 - val_accuracy: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8142Epoch 24/40: loss=0.4214, accuracy=0.8142, val_loss=0.3842, val_accuracy=0.8088\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4214 - accuracy: 0.8142 - val_loss: 0.3842 - val_accuracy: 0.8088 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8021Epoch 25/40: loss=0.4294, accuracy=0.8022, val_loss=0.3834, val_accuracy=0.8361\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4294 - accuracy: 0.8022 - val_loss: 0.3834 - val_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.7990Epoch 26/40: loss=0.4352, accuracy=0.7990, val_loss=0.3780, val_accuracy=0.8502\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4352 - accuracy: 0.7990 - val_loss: 0.3780 - val_accuracy: 0.8502 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.8152Epoch 27/40: loss=0.4182, accuracy=0.8152, val_loss=0.3822, val_accuracy=0.8427\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4182 - accuracy: 0.8152 - val_loss: 0.3822 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4083 - accuracy: 0.8211Epoch 28/40: loss=0.4081, accuracy=0.8212, val_loss=0.3660, val_accuracy=0.8435\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4081 - accuracy: 0.8212 - val_loss: 0.3660 - val_accuracy: 0.8435 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.8078Epoch 29/40: loss=0.4254, accuracy=0.8077, val_loss=0.3809, val_accuracy=0.8369\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4254 - accuracy: 0.8077 - val_loss: 0.3809 - val_accuracy: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8147Epoch 30/40: loss=0.4185, accuracy=0.8142, val_loss=0.3649, val_accuracy=0.8551\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4185 - accuracy: 0.8142 - val_loss: 0.3649 - val_accuracy: 0.8551 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3983 - accuracy: 0.8214Epoch 31/40: loss=0.3977, accuracy=0.8218, val_loss=0.3474, val_accuracy=0.8642\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3977 - accuracy: 0.8218 - val_loss: 0.3474 - val_accuracy: 0.8642 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8321Epoch 32/40: loss=0.3906, accuracy=0.8320, val_loss=0.3796, val_accuracy=0.8394\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3906 - accuracy: 0.8320 - val_loss: 0.3796 - val_accuracy: 0.8394 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8283Epoch 33/40: loss=0.3889, accuracy=0.8280, val_loss=0.3516, val_accuracy=0.8386\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3889 - accuracy: 0.8280 - val_loss: 0.3516 - val_accuracy: 0.8386 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3947 - accuracy: 0.8253Epoch 34/40: loss=0.3947, accuracy=0.8253, val_loss=0.3429, val_accuracy=0.8485\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3947 - accuracy: 0.8253 - val_loss: 0.3429 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8292Epoch 35/40: loss=0.3855, accuracy=0.8293, val_loss=0.4205, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3855 - accuracy: 0.8293 - val_loss: 0.4205 - val_accuracy: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8273Epoch 36/40: loss=0.3881, accuracy=0.8276, val_loss=0.3913, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3881 - accuracy: 0.8276 - val_loss: 0.3913 - val_accuracy: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3993 - accuracy: 0.8161Epoch 37/40: loss=0.3996, accuracy=0.8158, val_loss=0.3692, val_accuracy=0.8411\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3996 - accuracy: 0.8158 - val_loss: 0.3692 - val_accuracy: 0.8411 - lr: 1.0000e-04\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8277Epoch 38/40: loss=0.3812, accuracy=0.8282, val_loss=0.4267, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3812 - accuracy: 0.8282 - val_loss: 0.4267 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8311\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 39/40: loss=0.3706, accuracy=0.8309, val_loss=0.3580, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3706 - accuracy: 0.8309 - val_loss: 0.3580 - val_accuracy: 0.8336 - lr: 1.0000e-04\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8407Epoch 40/40: loss=0.3607, accuracy=0.8404, val_loss=0.3569, val_accuracy=0.8502\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3607 - accuracy: 0.8404 - val_loss: 0.3569 - val_accuracy: 0.8502 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8642383813858032\n",
      "\n",
      "Initial Training Combination 14/50: num_residual_blocks=2, dropout_rate=0.4, learning_rate=0.0001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9969 - accuracy: 0.4946Epoch 1/40: loss=0.9961, accuracy=0.4944, val_loss=0.6432, val_accuracy=0.6142\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.9961 - accuracy: 0.4944 - val_loss: 0.6432 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8638 - accuracy: 0.5500Epoch 2/40: loss=0.8640, accuracy=0.5499, val_loss=0.7539, val_accuracy=0.6283\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8640 - accuracy: 0.5499 - val_loss: 0.7539 - val_accuracy: 0.6283 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7823 - accuracy: 0.5888Epoch 3/40: loss=0.7835, accuracy=0.5884, val_loss=0.7430, val_accuracy=0.6755\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7835 - accuracy: 0.5884 - val_loss: 0.7430 - val_accuracy: 0.6755 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7272 - accuracy: 0.6258Epoch 4/40: loss=0.7272, accuracy=0.6260, val_loss=1.3431, val_accuracy=0.4685\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7272 - accuracy: 0.6260 - val_loss: 1.3431 - val_accuracy: 0.4685 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.6393Epoch 5/40: loss=0.7007, accuracy=0.6393, val_loss=0.6505, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7007 - accuracy: 0.6393 - val_loss: 0.6505 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6984 - accuracy: 0.6420\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/40: loss=0.6978, accuracy=0.6426, val_loss=1.1892, val_accuracy=0.4901\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6978 - accuracy: 0.6426 - val_loss: 1.1892 - val_accuracy: 0.4901 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.6629Epoch 7/40: loss=0.6630, accuracy=0.6629, val_loss=0.7147, val_accuracy=0.6515\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6630 - accuracy: 0.6629 - val_loss: 0.7147 - val_accuracy: 0.6515 - lr: 2.0000e-05\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6468 - accuracy: 0.6724Epoch 8/40: loss=0.6468, accuracy=0.6724, val_loss=0.8024, val_accuracy=0.6142\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6468 - accuracy: 0.6724 - val_loss: 0.8024 - val_accuracy: 0.6142 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6697Epoch 9/40: loss=0.6429, accuracy=0.6697, val_loss=0.5410, val_accuracy=0.7401\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6429 - accuracy: 0.6697 - val_loss: 0.5410 - val_accuracy: 0.7401 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6529 - accuracy: 0.6671Epoch 10/40: loss=0.6526, accuracy=0.6674, val_loss=0.6539, val_accuracy=0.6656\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6526 - accuracy: 0.6674 - val_loss: 0.6539 - val_accuracy: 0.6656 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6350 - accuracy: 0.6741Epoch 11/40: loss=0.6353, accuracy=0.6743, val_loss=0.7367, val_accuracy=0.6300\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6353 - accuracy: 0.6743 - val_loss: 0.7367 - val_accuracy: 0.6300 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6297 - accuracy: 0.6851Epoch 12/40: loss=0.6297, accuracy=0.6850, val_loss=0.5529, val_accuracy=0.7268\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6297 - accuracy: 0.6850 - val_loss: 0.5529 - val_accuracy: 0.7268 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6259 - accuracy: 0.6748Epoch 13/40: loss=0.6255, accuracy=0.6745, val_loss=0.5637, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6255 - accuracy: 0.6745 - val_loss: 0.5637 - val_accuracy: 0.7219 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.6846\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 14/40: loss=0.6148, accuracy=0.6846, val_loss=0.5438, val_accuracy=0.7210\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6148 - accuracy: 0.6846 - val_loss: 0.5438 - val_accuracy: 0.7210 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6071 - accuracy: 0.6926Epoch 15/40: loss=0.6081, accuracy=0.6923, val_loss=0.7186, val_accuracy=0.6382\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6081 - accuracy: 0.6923 - val_loss: 0.7186 - val_accuracy: 0.6382 - lr: 4.0000e-06\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.6848Epoch 16/40: loss=0.6138, accuracy=0.6848, val_loss=0.6607, val_accuracy=0.6631\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6138 - accuracy: 0.6848 - val_loss: 0.6607 - val_accuracy: 0.6631 - lr: 4.0000e-06\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6026 - accuracy: 0.6999Epoch 17/40: loss=0.6048, accuracy=0.6995, val_loss=0.6281, val_accuracy=0.6813\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6048 - accuracy: 0.6995 - val_loss: 0.6281 - val_accuracy: 0.6813 - lr: 4.0000e-06\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6107 - accuracy: 0.6883Epoch 18/40: loss=0.6103, accuracy=0.6885, val_loss=0.7247, val_accuracy=0.6457\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6103 - accuracy: 0.6885 - val_loss: 0.7247 - val_accuracy: 0.6457 - lr: 4.0000e-06\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6079 - accuracy: 0.6864\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 19/40: loss=0.6084, accuracy=0.6858, val_loss=0.5631, val_accuracy=0.7111\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6084 - accuracy: 0.6858 - val_loss: 0.5631 - val_accuracy: 0.7111 - lr: 4.0000e-06\n",
      "Epoch 19: early stopping\n",
      "Validation accuracy: 0.7400662302970886\n",
      "\n",
      "Initial Training Combination 15/50: num_residual_blocks=3, dropout_rate=0.6, learning_rate=0.01, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0140 - accuracy: 0.5098Epoch 1/40: loss=1.0128, accuracy=0.5106, val_loss=0.6866, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 18ms/step - loss: 1.0128 - accuracy: 0.5106 - val_loss: 0.6866 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.5232Epoch 2/40: loss=0.7023, accuracy=0.5232, val_loss=0.6910, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7023 - accuracy: 0.5232 - val_loss: 0.6910 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6979 - accuracy: 0.4921Epoch 3/40: loss=0.6980, accuracy=0.4923, val_loss=0.6834, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6980 - accuracy: 0.4923 - val_loss: 0.6834 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6970 - accuracy: 0.4933Epoch 4/40: loss=0.6972, accuracy=0.4934, val_loss=0.6785, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6972 - accuracy: 0.4934 - val_loss: 0.6785 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6970 - accuracy: 0.5104Epoch 5/40: loss=0.6970, accuracy=0.5103, val_loss=0.6976, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6970 - accuracy: 0.5103 - val_loss: 0.6976 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.4868Epoch 6/40: loss=0.6953, accuracy=0.4868, val_loss=0.6853, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6953 - accuracy: 0.4868 - val_loss: 0.6853 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6973 - accuracy: 0.4817Epoch 7/40: loss=0.6972, accuracy=0.4812, val_loss=4.0916, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6972 - accuracy: 0.4812 - val_loss: 4.0916 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6953 - accuracy: 0.4827Epoch 8/40: loss=0.6952, accuracy=0.4820, val_loss=0.6935, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6952 - accuracy: 0.4820 - val_loss: 0.6935 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.4981\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 9/40: loss=0.6958, accuracy=0.4981, val_loss=0.7090, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6958 - accuracy: 0.4981 - val_loss: 0.7090 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.4492Epoch 10/40: loss=0.6937, accuracy=0.4497, val_loss=0.6926, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6937 - accuracy: 0.4497 - val_loss: 0.6926 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5314Epoch 11/40: loss=0.6934, accuracy=0.5315, val_loss=1.0721, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6934 - accuracy: 0.5315 - val_loss: 1.0721 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4650Epoch 12/40: loss=0.6934, accuracy=0.4648, val_loss=0.6899, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6934 - accuracy: 0.4648 - val_loss: 0.6899 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5356Epoch 13/40: loss=0.6934, accuracy=0.5356, val_loss=0.6943, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6934 - accuracy: 0.5356 - val_loss: 0.6943 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.4386\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 14/40: loss=0.6936, accuracy=0.4389, val_loss=0.6917, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6936 - accuracy: 0.4389 - val_loss: 0.6917 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 14: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 16/50: num_residual_blocks=3, dropout_rate=0.5, learning_rate=0.0005, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9452 - accuracy: 0.5052Epoch 1/40: loss=0.9457, accuracy=0.5050, val_loss=0.6560, val_accuracy=0.6109\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 0.9457 - accuracy: 0.5050 - val_loss: 0.6560 - val_accuracy: 0.6109 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7683 - accuracy: 0.5503Epoch 2/40: loss=0.7675, accuracy=0.5511, val_loss=0.6816, val_accuracy=0.6763\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7675 - accuracy: 0.5511 - val_loss: 0.6816 - val_accuracy: 0.6763 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.6300Epoch 3/40: loss=0.6653, accuracy=0.6298, val_loss=0.6932, val_accuracy=0.6482\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6653 - accuracy: 0.6298 - val_loss: 0.6932 - val_accuracy: 0.6482 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6197 - accuracy: 0.6648Epoch 4/40: loss=0.6196, accuracy=0.6647, val_loss=0.5258, val_accuracy=0.7450\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6196 - accuracy: 0.6647 - val_loss: 0.5258 - val_accuracy: 0.7450 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.6882Epoch 5/40: loss=0.5952, accuracy=0.6881, val_loss=0.7858, val_accuracy=0.6904\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5952 - accuracy: 0.6881 - val_loss: 0.7858 - val_accuracy: 0.6904 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.6943Epoch 6/40: loss=0.5817, accuracy=0.6947, val_loss=0.5685, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5817 - accuracy: 0.6947 - val_loss: 0.5685 - val_accuracy: 0.7442 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5790 - accuracy: 0.7013Epoch 7/40: loss=0.5791, accuracy=0.7001, val_loss=0.6088, val_accuracy=0.7343\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5791 - accuracy: 0.7001 - val_loss: 0.6088 - val_accuracy: 0.7343 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7084Epoch 8/40: loss=0.5759, accuracy=0.7084, val_loss=0.6728, val_accuracy=0.7467\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5759 - accuracy: 0.7084 - val_loss: 0.6728 - val_accuracy: 0.7467 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5811 - accuracy: 0.7070\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.5813, accuracy=0.7070, val_loss=0.5649, val_accuracy=0.7583\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5813 - accuracy: 0.7070 - val_loss: 0.5649 - val_accuracy: 0.7583 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5610 - accuracy: 0.7206Epoch 10/40: loss=0.5613, accuracy=0.7202, val_loss=0.6857, val_accuracy=0.7061\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5613 - accuracy: 0.7202 - val_loss: 0.6857 - val_accuracy: 0.7061 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.7289Epoch 11/40: loss=0.5467, accuracy=0.7289, val_loss=0.5683, val_accuracy=0.7608\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5467 - accuracy: 0.7289 - val_loss: 0.5683 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.7289Epoch 12/40: loss=0.5457, accuracy=0.7285, val_loss=0.4963, val_accuracy=0.7856\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5457 - accuracy: 0.7285 - val_loss: 0.4963 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5389 - accuracy: 0.7354Epoch 13/40: loss=0.5382, accuracy=0.7359, val_loss=0.6968, val_accuracy=0.6912\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5382 - accuracy: 0.7359 - val_loss: 0.6968 - val_accuracy: 0.6912 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.7394Epoch 14/40: loss=0.5319, accuracy=0.7394, val_loss=0.5473, val_accuracy=0.7781\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5319 - accuracy: 0.7394 - val_loss: 0.5473 - val_accuracy: 0.7781 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7469Epoch 15/40: loss=0.5261, accuracy=0.7469, val_loss=0.4846, val_accuracy=0.8022\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5261 - accuracy: 0.7469 - val_loss: 0.4846 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.7369Epoch 16/40: loss=0.5326, accuracy=0.7368, val_loss=0.5910, val_accuracy=0.7517\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5326 - accuracy: 0.7368 - val_loss: 0.5910 - val_accuracy: 0.7517 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5134 - accuracy: 0.7568Epoch 17/40: loss=0.5131, accuracy=0.7570, val_loss=0.6580, val_accuracy=0.7599\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5131 - accuracy: 0.7570 - val_loss: 0.6580 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7440Epoch 18/40: loss=0.5196, accuracy=0.7440, val_loss=0.4703, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5196 - accuracy: 0.7440 - val_loss: 0.4703 - val_accuracy: 0.8129 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5118 - accuracy: 0.7569Epoch 19/40: loss=0.5118, accuracy=0.7564, val_loss=0.7230, val_accuracy=0.6738\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5118 - accuracy: 0.7564 - val_loss: 0.7230 - val_accuracy: 0.6738 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5064 - accuracy: 0.7614Epoch 20/40: loss=0.5075, accuracy=0.7606, val_loss=0.4594, val_accuracy=0.8022\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5075 - accuracy: 0.7606 - val_loss: 0.4594 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.7494Epoch 21/40: loss=0.5136, accuracy=0.7496, val_loss=0.7535, val_accuracy=0.6871\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5136 - accuracy: 0.7496 - val_loss: 0.7535 - val_accuracy: 0.6871 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7620Epoch 22/40: loss=0.5072, accuracy=0.7620, val_loss=0.6209, val_accuracy=0.7467\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5072 - accuracy: 0.7620 - val_loss: 0.6209 - val_accuracy: 0.7467 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7558Epoch 23/40: loss=0.5079, accuracy=0.7558, val_loss=0.7662, val_accuracy=0.6796\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5079 - accuracy: 0.7558 - val_loss: 0.7662 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.7606Epoch 24/40: loss=0.5043, accuracy=0.7606, val_loss=0.4435, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5043 - accuracy: 0.7606 - val_loss: 0.4435 - val_accuracy: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.7577Epoch 25/40: loss=0.5003, accuracy=0.7577, val_loss=0.6069, val_accuracy=0.7260\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5003 - accuracy: 0.7577 - val_loss: 0.6069 - val_accuracy: 0.7260 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.7496Epoch 26/40: loss=0.5142, accuracy=0.7496, val_loss=0.5324, val_accuracy=0.7599\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5142 - accuracy: 0.7496 - val_loss: 0.5324 - val_accuracy: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4944 - accuracy: 0.7639Epoch 27/40: loss=0.4943, accuracy=0.7639, val_loss=0.6503, val_accuracy=0.6921\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4943 - accuracy: 0.7639 - val_loss: 0.6503 - val_accuracy: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.7662Epoch 28/40: loss=0.4900, accuracy=0.7657, val_loss=0.4768, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4900 - accuracy: 0.7657 - val_loss: 0.4768 - val_accuracy: 0.7856 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.7713\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 29/40: loss=0.4871, accuracy=0.7713, val_loss=0.5219, val_accuracy=0.7798\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4871 - accuracy: 0.7713 - val_loss: 0.5219 - val_accuracy: 0.7798 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7761Epoch 30/40: loss=0.4834, accuracy=0.7761, val_loss=0.4896, val_accuracy=0.7930\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4834 - accuracy: 0.7761 - val_loss: 0.4896 - val_accuracy: 0.7930 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.7806Epoch 31/40: loss=0.4757, accuracy=0.7798, val_loss=0.5030, val_accuracy=0.7823\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4757 - accuracy: 0.7798 - val_loss: 0.5030 - val_accuracy: 0.7823 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.7811Epoch 32/40: loss=0.4650, accuracy=0.7808, val_loss=0.6908, val_accuracy=0.7045\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4650 - accuracy: 0.7808 - val_loss: 0.6908 - val_accuracy: 0.7045 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.7835Epoch 33/40: loss=0.4584, accuracy=0.7835, val_loss=0.5557, val_accuracy=0.7558\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4584 - accuracy: 0.7835 - val_loss: 0.5557 - val_accuracy: 0.7558 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.7825\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 34/40: loss=0.4710, accuracy=0.7825, val_loss=0.4955, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4710 - accuracy: 0.7825 - val_loss: 0.4955 - val_accuracy: 0.7881 - lr: 2.0000e-05\n",
      "Epoch 34: early stopping\n",
      "Validation accuracy: 0.8129138946533203\n",
      "\n",
      "Initial Training Combination 17/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.001, rotation_range=30, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9180 - accuracy: 0.4853Epoch 1/40: loss=0.9176, accuracy=0.4855, val_loss=0.7500, val_accuracy=0.5588\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9176 - accuracy: 0.4855 - val_loss: 0.7500 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.5014Epoch 2/40: loss=0.7313, accuracy=0.5014, val_loss=0.6848, val_accuracy=0.6449\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7313 - accuracy: 0.5014 - val_loss: 0.6848 - val_accuracy: 0.6449 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7208 - accuracy: 0.4981Epoch 3/40: loss=0.7207, accuracy=0.4983, val_loss=0.7045, val_accuracy=0.6391\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7207 - accuracy: 0.4983 - val_loss: 0.7045 - val_accuracy: 0.6391 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7065 - accuracy: 0.5320Epoch 4/40: loss=0.7065, accuracy=0.5321, val_loss=0.7971, val_accuracy=0.5257\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7065 - accuracy: 0.5321 - val_loss: 0.7971 - val_accuracy: 0.5257 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5668Epoch 5/40: loss=0.6929, accuracy=0.5671, val_loss=15.2675, val_accuracy=0.4015\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6929 - accuracy: 0.5671 - val_loss: 15.2675 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6632 - accuracy: 0.6163Epoch 6/40: loss=0.6633, accuracy=0.6161, val_loss=0.7213, val_accuracy=0.6291\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6633 - accuracy: 0.6161 - val_loss: 0.7213 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.6339\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/40: loss=0.6445, accuracy=0.6339, val_loss=1.0023, val_accuracy=0.6780\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6445 - accuracy: 0.6339 - val_loss: 1.0023 - val_accuracy: 0.6780 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6207 - accuracy: 0.6584Epoch 8/40: loss=0.6207, accuracy=0.6591, val_loss=0.5650, val_accuracy=0.7500\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6207 - accuracy: 0.6591 - val_loss: 0.5650 - val_accuracy: 0.7500 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.6634Epoch 9/40: loss=0.6120, accuracy=0.6629, val_loss=0.5476, val_accuracy=0.7508\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6120 - accuracy: 0.6629 - val_loss: 0.5476 - val_accuracy: 0.7508 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.6730Epoch 10/40: loss=0.5929, accuracy=0.6730, val_loss=0.6543, val_accuracy=0.7144\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5929 - accuracy: 0.6730 - val_loss: 0.6543 - val_accuracy: 0.7144 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5940 - accuracy: 0.6782Epoch 11/40: loss=0.5934, accuracy=0.6788, val_loss=0.5784, val_accuracy=0.7541\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5934 - accuracy: 0.6788 - val_loss: 0.5784 - val_accuracy: 0.7541 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.6829Epoch 12/40: loss=0.5902, accuracy=0.6829, val_loss=0.6618, val_accuracy=0.7219\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5902 - accuracy: 0.6829 - val_loss: 0.6618 - val_accuracy: 0.7219 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5830 - accuracy: 0.6867Epoch 13/40: loss=0.5841, accuracy=0.6861, val_loss=0.5854, val_accuracy=0.7425\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5841 - accuracy: 0.6861 - val_loss: 0.5854 - val_accuracy: 0.7425 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5815 - accuracy: 0.6896\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 14/40: loss=0.5806, accuracy=0.6904, val_loss=0.5622, val_accuracy=0.7682\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5806 - accuracy: 0.6904 - val_loss: 0.5622 - val_accuracy: 0.7682 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.7025Epoch 15/40: loss=0.5659, accuracy=0.7024, val_loss=0.5203, val_accuracy=0.7765\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5659 - accuracy: 0.7024 - val_loss: 0.5203 - val_accuracy: 0.7765 - lr: 4.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.6994Epoch 16/40: loss=0.5616, accuracy=0.6993, val_loss=0.5107, val_accuracy=0.7724\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5616 - accuracy: 0.6993 - val_loss: 0.5107 - val_accuracy: 0.7724 - lr: 4.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7041Epoch 17/40: loss=0.5653, accuracy=0.7041, val_loss=0.5268, val_accuracy=0.7831\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5653 - accuracy: 0.7041 - val_loss: 0.5268 - val_accuracy: 0.7831 - lr: 4.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5625 - accuracy: 0.7076Epoch 18/40: loss=0.5631, accuracy=0.7074, val_loss=0.5276, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5631 - accuracy: 0.7074 - val_loss: 0.5276 - val_accuracy: 0.7790 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.7080Epoch 19/40: loss=0.5530, accuracy=0.7080, val_loss=0.5255, val_accuracy=0.7856\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5530 - accuracy: 0.7080 - val_loss: 0.5255 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.6990Epoch 20/40: loss=0.5658, accuracy=0.6987, val_loss=0.5065, val_accuracy=0.7856\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5658 - accuracy: 0.6987 - val_loss: 0.5065 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.7110Epoch 21/40: loss=0.5508, accuracy=0.7105, val_loss=0.5050, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5508 - accuracy: 0.7105 - val_loss: 0.5050 - val_accuracy: 0.7897 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5517 - accuracy: 0.7113Epoch 22/40: loss=0.5515, accuracy=0.7117, val_loss=0.5294, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5515 - accuracy: 0.7117 - val_loss: 0.5294 - val_accuracy: 0.7889 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5542 - accuracy: 0.7146Epoch 23/40: loss=0.5544, accuracy=0.7142, val_loss=0.5026, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5544 - accuracy: 0.7142 - val_loss: 0.5026 - val_accuracy: 0.7856 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5657 - accuracy: 0.7077Epoch 24/40: loss=0.5654, accuracy=0.7080, val_loss=0.5146, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5654 - accuracy: 0.7080 - val_loss: 0.5146 - val_accuracy: 0.7873 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7126Epoch 25/40: loss=0.5508, accuracy=0.7130, val_loss=0.4869, val_accuracy=0.7873\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5508 - accuracy: 0.7130 - val_loss: 0.4869 - val_accuracy: 0.7873 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5579 - accuracy: 0.7087Epoch 26/40: loss=0.5576, accuracy=0.7092, val_loss=0.5295, val_accuracy=0.7889\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5576 - accuracy: 0.7092 - val_loss: 0.5295 - val_accuracy: 0.7889 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7199Epoch 27/40: loss=0.5503, accuracy=0.7204, val_loss=0.5330, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5503 - accuracy: 0.7204 - val_loss: 0.5330 - val_accuracy: 0.7889 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.7223Epoch 28/40: loss=0.5405, accuracy=0.7223, val_loss=0.4907, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5405 - accuracy: 0.7223 - val_loss: 0.4907 - val_accuracy: 0.7997 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.7210Epoch 29/40: loss=0.5401, accuracy=0.7210, val_loss=0.4775, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5401 - accuracy: 0.7210 - val_loss: 0.4775 - val_accuracy: 0.7922 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.7113Epoch 30/40: loss=0.5559, accuracy=0.7113, val_loss=0.4928, val_accuracy=0.7881\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5559 - accuracy: 0.7113 - val_loss: 0.4928 - val_accuracy: 0.7881 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7165Epoch 31/40: loss=0.5470, accuracy=0.7165, val_loss=0.5063, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5470 - accuracy: 0.7165 - val_loss: 0.5063 - val_accuracy: 0.7922 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.7220Epoch 32/40: loss=0.5427, accuracy=0.7216, val_loss=0.5011, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5427 - accuracy: 0.7216 - val_loss: 0.5011 - val_accuracy: 0.7988 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.7282Epoch 33/40: loss=0.5409, accuracy=0.7276, val_loss=0.4954, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5409 - accuracy: 0.7276 - val_loss: 0.4954 - val_accuracy: 0.7848 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.7194\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 34/40: loss=0.5451, accuracy=0.7194, val_loss=0.4996, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5451 - accuracy: 0.7194 - val_loss: 0.4996 - val_accuracy: 0.7831 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.7216Epoch 35/40: loss=0.5466, accuracy=0.7216, val_loss=0.5173, val_accuracy=0.7988\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5466 - accuracy: 0.7216 - val_loss: 0.5173 - val_accuracy: 0.7988 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.7199Epoch 36/40: loss=0.5411, accuracy=0.7202, val_loss=0.4942, val_accuracy=0.8013\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5411 - accuracy: 0.7202 - val_loss: 0.4942 - val_accuracy: 0.8013 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5395 - accuracy: 0.7184Epoch 37/40: loss=0.5401, accuracy=0.7181, val_loss=0.4850, val_accuracy=0.7997\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5401 - accuracy: 0.7181 - val_loss: 0.4850 - val_accuracy: 0.7997 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7202Epoch 38/40: loss=0.5386, accuracy=0.7202, val_loss=0.4980, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5386 - accuracy: 0.7202 - val_loss: 0.4980 - val_accuracy: 0.7988 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.7322\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.5375, accuracy=0.7322, val_loss=0.4869, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5375 - accuracy: 0.7322 - val_loss: 0.4869 - val_accuracy: 0.7980 - lr: 8.0000e-06\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.8013244867324829\n",
      "\n",
      "Initial Training Combination 18/50: num_residual_blocks=4, dropout_rate=0.6, learning_rate=0.0005, rotation_range=10, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.1, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9864 - accuracy: 0.5108Epoch 1/40: loss=0.9869, accuracy=0.5106, val_loss=0.6911, val_accuracy=0.5762\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.9869 - accuracy: 0.5106 - val_loss: 0.6911 - val_accuracy: 0.5762 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7949 - accuracy: 0.5234Epoch 2/40: loss=0.7952, accuracy=0.5228, val_loss=0.7811, val_accuracy=0.5762\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7952 - accuracy: 0.5228 - val_loss: 0.7811 - val_accuracy: 0.5762 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7052 - accuracy: 0.5576Epoch 3/40: loss=0.7051, accuracy=0.5577, val_loss=0.7283, val_accuracy=0.6904\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7051 - accuracy: 0.5577 - val_loss: 0.7283 - val_accuracy: 0.6904 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6565 - accuracy: 0.6126Epoch 4/40: loss=0.6564, accuracy=0.6126, val_loss=1.2822, val_accuracy=0.4354\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6564 - accuracy: 0.6126 - val_loss: 1.2822 - val_accuracy: 0.4354 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6382 - accuracy: 0.6362Epoch 5/40: loss=0.6383, accuracy=0.6362, val_loss=0.6880, val_accuracy=0.6623\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6383 - accuracy: 0.6362 - val_loss: 0.6880 - val_accuracy: 0.6623 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.6572Epoch 6/40: loss=0.6141, accuracy=0.6573, val_loss=1.1758, val_accuracy=0.6043\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6141 - accuracy: 0.6573 - val_loss: 1.1758 - val_accuracy: 0.6043 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.6596Epoch 7/40: loss=0.6263, accuracy=0.6596, val_loss=0.7061, val_accuracy=0.6631\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6263 - accuracy: 0.6596 - val_loss: 0.7061 - val_accuracy: 0.6631 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6018 - accuracy: 0.6799Epoch 8/40: loss=0.6017, accuracy=0.6798, val_loss=0.7716, val_accuracy=0.6325\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6017 - accuracy: 0.6798 - val_loss: 0.7716 - val_accuracy: 0.6325 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5995 - accuracy: 0.6815Epoch 9/40: loss=0.5998, accuracy=0.6815, val_loss=0.7755, val_accuracy=0.6581\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5998 - accuracy: 0.6815 - val_loss: 0.7755 - val_accuracy: 0.6581 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.6715\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/40: loss=0.6046, accuracy=0.6718, val_loss=1.0637, val_accuracy=0.5886\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6046 - accuracy: 0.6718 - val_loss: 1.0637 - val_accuracy: 0.5886 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5723 - accuracy: 0.7087Epoch 11/40: loss=0.5720, accuracy=0.7090, val_loss=0.5365, val_accuracy=0.7815\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5720 - accuracy: 0.7090 - val_loss: 0.5365 - val_accuracy: 0.7815 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.7141Epoch 12/40: loss=0.5654, accuracy=0.7138, val_loss=1.0810, val_accuracy=0.5944\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5654 - accuracy: 0.7138 - val_loss: 1.0810 - val_accuracy: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7224Epoch 13/40: loss=0.5527, accuracy=0.7227, val_loss=0.7590, val_accuracy=0.6581\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5527 - accuracy: 0.7227 - val_loss: 0.7590 - val_accuracy: 0.6581 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.7162Epoch 14/40: loss=0.5613, accuracy=0.7159, val_loss=0.4831, val_accuracy=0.7922\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5613 - accuracy: 0.7159 - val_loss: 0.4831 - val_accuracy: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.7185Epoch 15/40: loss=0.5499, accuracy=0.7185, val_loss=0.5069, val_accuracy=0.7897\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5499 - accuracy: 0.7185 - val_loss: 0.5069 - val_accuracy: 0.7897 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.7332Epoch 16/40: loss=0.5418, accuracy=0.7332, val_loss=0.6066, val_accuracy=0.7558\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5418 - accuracy: 0.7332 - val_loss: 0.6066 - val_accuracy: 0.7558 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7313Epoch 17/40: loss=0.5399, accuracy=0.7308, val_loss=1.1513, val_accuracy=0.6192\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5399 - accuracy: 0.7308 - val_loss: 1.1513 - val_accuracy: 0.6192 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7307Epoch 18/40: loss=0.5377, accuracy=0.7310, val_loss=0.4935, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5377 - accuracy: 0.7310 - val_loss: 0.4935 - val_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5303 - accuracy: 0.7427\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.5310, accuracy=0.7428, val_loss=0.5321, val_accuracy=0.7839\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5310 - accuracy: 0.7428 - val_loss: 0.5321 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7390Epoch 20/40: loss=0.5322, accuracy=0.7392, val_loss=0.4825, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5322 - accuracy: 0.7392 - val_loss: 0.4825 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5267 - accuracy: 0.7452Epoch 21/40: loss=0.5265, accuracy=0.7454, val_loss=0.5117, val_accuracy=0.7988\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5265 - accuracy: 0.7454 - val_loss: 0.5117 - val_accuracy: 0.7988 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5246 - accuracy: 0.7351Epoch 22/40: loss=0.5243, accuracy=0.7355, val_loss=0.5232, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5243 - accuracy: 0.7355 - val_loss: 0.5232 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.7448Epoch 23/40: loss=0.5205, accuracy=0.7448, val_loss=0.4684, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5205 - accuracy: 0.7448 - val_loss: 0.4684 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7461Epoch 24/40: loss=0.5241, accuracy=0.7461, val_loss=0.5610, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5241 - accuracy: 0.7461 - val_loss: 0.5610 - val_accuracy: 0.7790 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7539Epoch 25/40: loss=0.5134, accuracy=0.7539, val_loss=0.5342, val_accuracy=0.7914\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5134 - accuracy: 0.7539 - val_loss: 0.5342 - val_accuracy: 0.7914 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.7471Epoch 26/40: loss=0.5157, accuracy=0.7475, val_loss=0.4914, val_accuracy=0.8046\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5157 - accuracy: 0.7475 - val_loss: 0.4914 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.7541Epoch 27/40: loss=0.5096, accuracy=0.7543, val_loss=0.5621, val_accuracy=0.7848\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5096 - accuracy: 0.7543 - val_loss: 0.5621 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.7488\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 28/40: loss=0.5161, accuracy=0.7490, val_loss=0.4871, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5161 - accuracy: 0.7490 - val_loss: 0.4871 - val_accuracy: 0.8146 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.7546Epoch 29/40: loss=0.5056, accuracy=0.7546, val_loss=0.5108, val_accuracy=0.8022\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5056 - accuracy: 0.7546 - val_loss: 0.5108 - val_accuracy: 0.8022 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.7546Epoch 30/40: loss=0.5189, accuracy=0.7546, val_loss=0.5144, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5189 - accuracy: 0.7546 - val_loss: 0.5144 - val_accuracy: 0.7980 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5070 - accuracy: 0.7554Epoch 31/40: loss=0.5070, accuracy=0.7556, val_loss=0.5218, val_accuracy=0.7964\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5070 - accuracy: 0.7556 - val_loss: 0.5218 - val_accuracy: 0.7964 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.7485Epoch 32/40: loss=0.5076, accuracy=0.7490, val_loss=0.4939, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5076 - accuracy: 0.7490 - val_loss: 0.4939 - val_accuracy: 0.8071 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.7606\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 33/40: loss=0.5042, accuracy=0.7606, val_loss=0.4994, val_accuracy=0.8030\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5042 - accuracy: 0.7606 - val_loss: 0.4994 - val_accuracy: 0.8030 - lr: 4.0000e-06\n",
      "Epoch 33: early stopping\n",
      "Validation accuracy: 0.8178808093070984\n",
      "\n",
      "Initial Training Combination 19/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.001, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5081Epoch 1/40: loss=0.9329, accuracy=0.5081, val_loss=0.6839, val_accuracy=0.5480\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.9329 - accuracy: 0.5081 - val_loss: 0.6839 - val_accuracy: 0.5480 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7359 - accuracy: 0.5083Epoch 2/40: loss=0.7360, accuracy=0.5081, val_loss=0.6928, val_accuracy=0.5058\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7360 - accuracy: 0.5081 - val_loss: 0.6928 - val_accuracy: 0.5058 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7175 - accuracy: 0.5102Epoch 3/40: loss=0.7176, accuracy=0.5101, val_loss=0.6920, val_accuracy=0.4992\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7176 - accuracy: 0.5101 - val_loss: 0.6920 - val_accuracy: 0.4992 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7144 - accuracy: 0.5199Epoch 4/40: loss=0.7143, accuracy=0.5201, val_loss=0.6958, val_accuracy=0.4487\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7143 - accuracy: 0.5201 - val_loss: 0.6958 - val_accuracy: 0.4487 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7115 - accuracy: 0.5235Epoch 5/40: loss=0.7118, accuracy=0.5226, val_loss=0.6769, val_accuracy=0.5579\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7118 - accuracy: 0.5226 - val_loss: 0.6769 - val_accuracy: 0.5579 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7051 - accuracy: 0.5143Epoch 6/40: loss=0.7050, accuracy=0.5143, val_loss=0.8891, val_accuracy=0.5969\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7050 - accuracy: 0.5143 - val_loss: 0.8891 - val_accuracy: 0.5969 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7050 - accuracy: 0.5135Epoch 7/40: loss=0.7048, accuracy=0.5145, val_loss=0.6599, val_accuracy=0.6109\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7048 - accuracy: 0.5145 - val_loss: 0.6599 - val_accuracy: 0.6109 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7011 - accuracy: 0.5309Epoch 8/40: loss=0.7011, accuracy=0.5312, val_loss=0.6781, val_accuracy=0.6507\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7011 - accuracy: 0.5312 - val_loss: 0.6781 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7012 - accuracy: 0.5214Epoch 9/40: loss=0.7012, accuracy=0.5213, val_loss=0.6905, val_accuracy=0.5273\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7012 - accuracy: 0.5213 - val_loss: 0.6905 - val_accuracy: 0.5273 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.5228Epoch 10/40: loss=0.6966, accuracy=0.5232, val_loss=0.7003, val_accuracy=0.4189\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6966 - accuracy: 0.5232 - val_loss: 0.7003 - val_accuracy: 0.4189 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6988 - accuracy: 0.5110Epoch 11/40: loss=0.6988, accuracy=0.5114, val_loss=0.6911, val_accuracy=0.4222\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6988 - accuracy: 0.5114 - val_loss: 0.6911 - val_accuracy: 0.4222 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.5112\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.6982, accuracy=0.5112, val_loss=0.6911, val_accuracy=0.4288\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6982 - accuracy: 0.5112 - val_loss: 0.6911 - val_accuracy: 0.4288 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5221Epoch 13/40: loss=0.6949, accuracy=0.5221, val_loss=0.6948, val_accuracy=0.4156\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6949 - accuracy: 0.5221 - val_loss: 0.6948 - val_accuracy: 0.4156 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5162Epoch 14/40: loss=0.6916, accuracy=0.5163, val_loss=0.6781, val_accuracy=0.5075\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6916 - accuracy: 0.5163 - val_loss: 0.6781 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6851 - accuracy: 0.5441Epoch 15/40: loss=0.6854, accuracy=0.5439, val_loss=0.6632, val_accuracy=0.5290\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6854 - accuracy: 0.5439 - val_loss: 0.6632 - val_accuracy: 0.5290 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5833Epoch 16/40: loss=0.6709, accuracy=0.5834, val_loss=0.6422, val_accuracy=0.5869\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6709 - accuracy: 0.5834 - val_loss: 0.6422 - val_accuracy: 0.5869 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.6482Epoch 17/40: loss=0.6305, accuracy=0.6482, val_loss=0.9846, val_accuracy=0.4073\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6305 - accuracy: 0.6482 - val_loss: 0.9846 - val_accuracy: 0.4073 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6200 - accuracy: 0.6627Epoch 18/40: loss=0.6199, accuracy=0.6629, val_loss=0.6458, val_accuracy=0.5836\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6199 - accuracy: 0.6629 - val_loss: 0.6458 - val_accuracy: 0.5836 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.6904Epoch 19/40: loss=0.5937, accuracy=0.6904, val_loss=0.8207, val_accuracy=0.5141\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5937 - accuracy: 0.6904 - val_loss: 0.8207 - val_accuracy: 0.5141 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5955 - accuracy: 0.6893Epoch 20/40: loss=0.5954, accuracy=0.6894, val_loss=0.5311, val_accuracy=0.7235\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5954 - accuracy: 0.6894 - val_loss: 0.5311 - val_accuracy: 0.7235 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5910 - accuracy: 0.6856Epoch 21/40: loss=0.5908, accuracy=0.6861, val_loss=0.5779, val_accuracy=0.7558\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5908 - accuracy: 0.6861 - val_loss: 0.5779 - val_accuracy: 0.7558 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5892 - accuracy: 0.6926Epoch 22/40: loss=0.5899, accuracy=0.6921, val_loss=0.9698, val_accuracy=0.4661\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5899 - accuracy: 0.6921 - val_loss: 0.9698 - val_accuracy: 0.4661 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7099Epoch 23/40: loss=0.5746, accuracy=0.7099, val_loss=0.7743, val_accuracy=0.5820\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.5746 - accuracy: 0.7099 - val_loss: 0.7743 - val_accuracy: 0.5820 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5814 - accuracy: 0.7045Epoch 24/40: loss=0.5821, accuracy=0.7038, val_loss=0.5464, val_accuracy=0.7500\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5821 - accuracy: 0.7038 - val_loss: 0.5464 - val_accuracy: 0.7500 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7070\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/40: loss=0.5679, accuracy=0.7070, val_loss=0.5358, val_accuracy=0.7583\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5679 - accuracy: 0.7070 - val_loss: 0.5358 - val_accuracy: 0.7583 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7115Epoch 26/40: loss=0.5645, accuracy=0.7115, val_loss=0.5649, val_accuracy=0.7227\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5645 - accuracy: 0.7115 - val_loss: 0.5649 - val_accuracy: 0.7227 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5717 - accuracy: 0.7130Epoch 27/40: loss=0.5720, accuracy=0.7130, val_loss=0.5529, val_accuracy=0.7376\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5720 - accuracy: 0.7130 - val_loss: 0.5529 - val_accuracy: 0.7376 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.7201Epoch 28/40: loss=0.5571, accuracy=0.7206, val_loss=0.5695, val_accuracy=0.7219\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5571 - accuracy: 0.7206 - val_loss: 0.5695 - val_accuracy: 0.7219 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7130Epoch 29/40: loss=0.5658, accuracy=0.7130, val_loss=0.5999, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5658 - accuracy: 0.7130 - val_loss: 0.5999 - val_accuracy: 0.7012 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7205\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 30/40: loss=0.5679, accuracy=0.7210, val_loss=0.6970, val_accuracy=0.6374\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5679 - accuracy: 0.7210 - val_loss: 0.6970 - val_accuracy: 0.6374 - lr: 4.0000e-05\n",
      "Epoch 30: early stopping\n",
      "Validation accuracy: 0.7582781314849854\n",
      "\n",
      "Initial Training Combination 20/50: num_residual_blocks=4, dropout_rate=0.4, learning_rate=0.0005, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8880 - accuracy: 0.5476Epoch 1/40: loss=0.8880, accuracy=0.5476, val_loss=0.9519, val_accuracy=0.4892\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.8880 - accuracy: 0.5476 - val_loss: 0.9519 - val_accuracy: 0.4892 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.6575Epoch 2/40: loss=0.6709, accuracy=0.6575, val_loss=1.8828, val_accuracy=0.6184\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6709 - accuracy: 0.6575 - val_loss: 1.8828 - val_accuracy: 0.6184 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6002 - accuracy: 0.6915Epoch 3/40: loss=0.6002, accuracy=0.6916, val_loss=0.4751, val_accuracy=0.7765\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6002 - accuracy: 0.6916 - val_loss: 0.4751 - val_accuracy: 0.7765 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5700 - accuracy: 0.7116Epoch 4/40: loss=0.5698, accuracy=0.7115, val_loss=0.4472, val_accuracy=0.7889\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5698 - accuracy: 0.7115 - val_loss: 0.4472 - val_accuracy: 0.7889 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5559 - accuracy: 0.7170Epoch 5/40: loss=0.5555, accuracy=0.7173, val_loss=0.7123, val_accuracy=0.6225\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5555 - accuracy: 0.7173 - val_loss: 0.7123 - val_accuracy: 0.6225 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.7382Epoch 6/40: loss=0.5330, accuracy=0.7382, val_loss=0.9335, val_accuracy=0.5952\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5330 - accuracy: 0.7382 - val_loss: 0.9335 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.7425Epoch 7/40: loss=0.5342, accuracy=0.7425, val_loss=0.4422, val_accuracy=0.7972\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5342 - accuracy: 0.7425 - val_loss: 0.4422 - val_accuracy: 0.7972 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5316 - accuracy: 0.7460Epoch 8/40: loss=0.5318, accuracy=0.7457, val_loss=0.6128, val_accuracy=0.7003\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5318 - accuracy: 0.7457 - val_loss: 0.6128 - val_accuracy: 0.7003 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7318Epoch 9/40: loss=0.5374, accuracy=0.7318, val_loss=0.4639, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5374 - accuracy: 0.7318 - val_loss: 0.4639 - val_accuracy: 0.7641 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.7521Epoch 10/40: loss=0.5151, accuracy=0.7521, val_loss=1.6082, val_accuracy=0.6101\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5151 - accuracy: 0.7521 - val_loss: 1.6082 - val_accuracy: 0.6101 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5211 - accuracy: 0.7488Epoch 11/40: loss=0.5208, accuracy=0.7492, val_loss=0.7282, val_accuracy=0.6440\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5208 - accuracy: 0.7492 - val_loss: 0.7282 - val_accuracy: 0.6440 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.7612\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/40: loss=0.5115, accuracy=0.7612, val_loss=0.5787, val_accuracy=0.7078\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5115 - accuracy: 0.7612 - val_loss: 0.5787 - val_accuracy: 0.7078 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.7755Epoch 13/40: loss=0.4764, accuracy=0.7746, val_loss=0.4632, val_accuracy=0.7823\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4764 - accuracy: 0.7746 - val_loss: 0.4632 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.7728Epoch 14/40: loss=0.4747, accuracy=0.7730, val_loss=0.4326, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4747 - accuracy: 0.7730 - val_loss: 0.4326 - val_accuracy: 0.8328 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.7884Epoch 15/40: loss=0.4644, accuracy=0.7879, val_loss=0.4192, val_accuracy=0.7823\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4644 - accuracy: 0.7879 - val_loss: 0.4192 - val_accuracy: 0.7823 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.7883Epoch 16/40: loss=0.4624, accuracy=0.7883, val_loss=0.4479, val_accuracy=0.8344\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4624 - accuracy: 0.7883 - val_loss: 0.4479 - val_accuracy: 0.8344 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.7823Epoch 17/40: loss=0.4633, accuracy=0.7825, val_loss=0.4165, val_accuracy=0.8286\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4633 - accuracy: 0.7825 - val_loss: 0.4165 - val_accuracy: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4485 - accuracy: 0.7917Epoch 18/40: loss=0.4485, accuracy=0.7918, val_loss=0.4970, val_accuracy=0.7864\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4485 - accuracy: 0.7918 - val_loss: 0.4970 - val_accuracy: 0.7864 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.7974Epoch 19/40: loss=0.4475, accuracy=0.7974, val_loss=0.4552, val_accuracy=0.8245\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4475 - accuracy: 0.7974 - val_loss: 0.4552 - val_accuracy: 0.8245 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.7941Epoch 20/40: loss=0.4444, accuracy=0.7941, val_loss=0.4196, val_accuracy=0.8228\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4444 - accuracy: 0.7941 - val_loss: 0.4196 - val_accuracy: 0.8228 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8059Epoch 21/40: loss=0.4330, accuracy=0.8059, val_loss=0.4126, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4330 - accuracy: 0.8059 - val_loss: 0.4126 - val_accuracy: 0.8411 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8083Epoch 22/40: loss=0.4240, accuracy=0.8082, val_loss=0.3719, val_accuracy=0.8543\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4240 - accuracy: 0.8082 - val_loss: 0.3719 - val_accuracy: 0.8543 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.8001Epoch 23/40: loss=0.4379, accuracy=0.8001, val_loss=0.3857, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4379 - accuracy: 0.8001 - val_loss: 0.3857 - val_accuracy: 0.8328 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.8022Epoch 24/40: loss=0.4248, accuracy=0.8022, val_loss=0.4607, val_accuracy=0.7525\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4248 - accuracy: 0.8022 - val_loss: 0.4607 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4169 - accuracy: 0.8075Epoch 25/40: loss=0.4172, accuracy=0.8075, val_loss=0.3976, val_accuracy=0.8303\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4172 - accuracy: 0.8075 - val_loss: 0.3976 - val_accuracy: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4114 - accuracy: 0.8152Epoch 26/40: loss=0.4111, accuracy=0.8156, val_loss=0.4169, val_accuracy=0.8286\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4111 - accuracy: 0.8156 - val_loss: 0.4169 - val_accuracy: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8090\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 27/40: loss=0.4172, accuracy=0.8090, val_loss=0.4454, val_accuracy=0.8154\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.4454 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8226Epoch 28/40: loss=0.3943, accuracy=0.8228, val_loss=0.4027, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3943 - accuracy: 0.8228 - val_loss: 0.4027 - val_accuracy: 0.8411 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8236Epoch 29/40: loss=0.3859, accuracy=0.8235, val_loss=0.4161, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3859 - accuracy: 0.8235 - val_loss: 0.4161 - val_accuracy: 0.8162 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8249Epoch 30/40: loss=0.3902, accuracy=0.8249, val_loss=0.4217, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3902 - accuracy: 0.8249 - val_loss: 0.4217 - val_accuracy: 0.8113 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8317Epoch 31/40: loss=0.3780, accuracy=0.8317, val_loss=0.4139, val_accuracy=0.8303\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3780 - accuracy: 0.8317 - val_loss: 0.4139 - val_accuracy: 0.8303 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8324\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.3717, accuracy=0.8326, val_loss=0.4273, val_accuracy=0.8195\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3717 - accuracy: 0.8326 - val_loss: 0.4273 - val_accuracy: 0.8195 - lr: 2.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.8543046116828918\n",
      "\n",
      "Initial Training Combination 21/50: num_residual_blocks=5, dropout_rate=0.6, learning_rate=0.001, rotation_range=10, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.1, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9540 - accuracy: 0.4869Epoch 1/40: loss=0.9537, accuracy=0.4870, val_loss=0.7125, val_accuracy=0.4040\n",
      "604/604 [==============================] - 16s 22ms/step - loss: 0.9537 - accuracy: 0.4870 - val_loss: 0.7125 - val_accuracy: 0.4040 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7374 - accuracy: 0.5006Epoch 2/40: loss=0.7376, accuracy=0.5004, val_loss=0.6991, val_accuracy=0.4172\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7376 - accuracy: 0.5004 - val_loss: 0.6991 - val_accuracy: 0.4172 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.5058Epoch 3/40: loss=0.7191, accuracy=0.5062, val_loss=0.7221, val_accuracy=0.4031\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7191 - accuracy: 0.5062 - val_loss: 0.7221 - val_accuracy: 0.4031 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.5170Epoch 4/40: loss=0.7115, accuracy=0.5170, val_loss=0.6770, val_accuracy=0.5753\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7115 - accuracy: 0.5170 - val_loss: 0.6770 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7132 - accuracy: 0.5087Epoch 5/40: loss=0.7132, accuracy=0.5089, val_loss=0.9292, val_accuracy=0.5869\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7132 - accuracy: 0.5089 - val_loss: 0.9292 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5151Epoch 6/40: loss=0.7059, accuracy=0.5151, val_loss=2.4106, val_accuracy=0.5911\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7059 - accuracy: 0.5151 - val_loss: 2.4106 - val_accuracy: 0.5911 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7096 - accuracy: 0.5066Epoch 7/40: loss=0.7096, accuracy=0.5066, val_loss=0.7935, val_accuracy=0.5679\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7096 - accuracy: 0.5066 - val_loss: 0.7935 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7066 - accuracy: 0.4946Epoch 8/40: loss=0.7065, accuracy=0.4944, val_loss=1.2546, val_accuracy=0.5919\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7065 - accuracy: 0.4944 - val_loss: 1.2546 - val_accuracy: 0.5919 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.5122\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/40: loss=0.6991, accuracy=0.5122, val_loss=0.7415, val_accuracy=0.5596\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6991 - accuracy: 0.5122 - val_loss: 0.7415 - val_accuracy: 0.5596 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5213Epoch 10/40: loss=0.6958, accuracy=0.5213, val_loss=0.6921, val_accuracy=0.5488\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6958 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5488 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5133Epoch 11/40: loss=0.6926, accuracy=0.5126, val_loss=0.7288, val_accuracy=0.5629\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6926 - accuracy: 0.5126 - val_loss: 0.7288 - val_accuracy: 0.5629 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6893 - accuracy: 0.5502Epoch 12/40: loss=0.6894, accuracy=0.5495, val_loss=0.8054, val_accuracy=0.5588\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6894 - accuracy: 0.5495 - val_loss: 0.8054 - val_accuracy: 0.5588 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5238Epoch 13/40: loss=0.6911, accuracy=0.5238, val_loss=0.6996, val_accuracy=0.5141\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6911 - accuracy: 0.5238 - val_loss: 0.6996 - val_accuracy: 0.5141 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.5393Epoch 14/40: loss=0.6871, accuracy=0.5393, val_loss=0.6728, val_accuracy=0.5712\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6871 - accuracy: 0.5393 - val_loss: 0.6728 - val_accuracy: 0.5712 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.5522Epoch 15/40: loss=0.6844, accuracy=0.5522, val_loss=0.7069, val_accuracy=0.5919\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6844 - accuracy: 0.5522 - val_loss: 0.7069 - val_accuracy: 0.5919 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6801 - accuracy: 0.5650Epoch 16/40: loss=0.6801, accuracy=0.5646, val_loss=0.7310, val_accuracy=0.6225\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6801 - accuracy: 0.5646 - val_loss: 0.7310 - val_accuracy: 0.6225 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6617 - accuracy: 0.5987Epoch 17/40: loss=0.6615, accuracy=0.5991, val_loss=0.7474, val_accuracy=0.5041\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6615 - accuracy: 0.5991 - val_loss: 0.7474 - val_accuracy: 0.5041 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6369 - accuracy: 0.6358Epoch 18/40: loss=0.6370, accuracy=0.6360, val_loss=2.4359, val_accuracy=0.6267\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6370 - accuracy: 0.6360 - val_loss: 2.4359 - val_accuracy: 0.6267 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6199 - accuracy: 0.6593\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/40: loss=0.6198, accuracy=0.6596, val_loss=1.2074, val_accuracy=0.7020\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6198 - accuracy: 0.6596 - val_loss: 1.2074 - val_accuracy: 0.7020 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5956 - accuracy: 0.6873Epoch 20/40: loss=0.5956, accuracy=0.6873, val_loss=0.5889, val_accuracy=0.6747\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5956 - accuracy: 0.6873 - val_loss: 0.5889 - val_accuracy: 0.6747 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.6913Epoch 21/40: loss=0.5926, accuracy=0.6910, val_loss=0.7936, val_accuracy=0.5728\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5926 - accuracy: 0.6910 - val_loss: 0.7936 - val_accuracy: 0.5728 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.7001Epoch 22/40: loss=0.5768, accuracy=0.7001, val_loss=1.1325, val_accuracy=0.4437\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5768 - accuracy: 0.7001 - val_loss: 1.1325 - val_accuracy: 0.4437 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5782 - accuracy: 0.7065Epoch 23/40: loss=0.5780, accuracy=0.7065, val_loss=0.7993, val_accuracy=0.5538\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5780 - accuracy: 0.7065 - val_loss: 0.7993 - val_accuracy: 0.5538 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.6981Epoch 24/40: loss=0.5845, accuracy=0.6981, val_loss=0.6985, val_accuracy=0.6109\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5845 - accuracy: 0.6981 - val_loss: 0.6985 - val_accuracy: 0.6109 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5838 - accuracy: 0.7035Epoch 25/40: loss=0.5841, accuracy=0.7034, val_loss=0.5861, val_accuracy=0.7169\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5841 - accuracy: 0.7034 - val_loss: 0.5861 - val_accuracy: 0.7169 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7049Epoch 26/40: loss=0.5769, accuracy=0.7049, val_loss=0.8495, val_accuracy=0.5497\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5769 - accuracy: 0.7049 - val_loss: 0.8495 - val_accuracy: 0.5497 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.7108Epoch 27/40: loss=0.5768, accuracy=0.7103, val_loss=0.7428, val_accuracy=0.6010\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5768 - accuracy: 0.7103 - val_loss: 0.7428 - val_accuracy: 0.6010 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5782 - accuracy: 0.7019Epoch 28/40: loss=0.5787, accuracy=0.7020, val_loss=0.6254, val_accuracy=0.6672\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5787 - accuracy: 0.7020 - val_loss: 0.6254 - val_accuracy: 0.6672 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7076Epoch 29/40: loss=0.5687, accuracy=0.7076, val_loss=0.6766, val_accuracy=0.6399\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5687 - accuracy: 0.7076 - val_loss: 0.6766 - val_accuracy: 0.6399 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5782 - accuracy: 0.7070\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 30/40: loss=0.5776, accuracy=0.7076, val_loss=1.0769, val_accuracy=0.4719\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5776 - accuracy: 0.7076 - val_loss: 1.0769 - val_accuracy: 0.4719 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7070Epoch 31/40: loss=0.5774, accuracy=0.7067, val_loss=0.7121, val_accuracy=0.6291\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5774 - accuracy: 0.7067 - val_loss: 0.7121 - val_accuracy: 0.6291 - lr: 8.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.7078Epoch 32/40: loss=0.5708, accuracy=0.7082, val_loss=0.7530, val_accuracy=0.6101\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5708 - accuracy: 0.7082 - val_loss: 0.7530 - val_accuracy: 0.6101 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5652 - accuracy: 0.7145Epoch 33/40: loss=0.5651, accuracy=0.7144, val_loss=0.7569, val_accuracy=0.6175\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5651 - accuracy: 0.7144 - val_loss: 0.7569 - val_accuracy: 0.6175 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5727 - accuracy: 0.7128Epoch 34/40: loss=0.5726, accuracy=0.7125, val_loss=0.7453, val_accuracy=0.6167\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5726 - accuracy: 0.7125 - val_loss: 0.7453 - val_accuracy: 0.6167 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7023\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 35/40: loss=0.5769, accuracy=0.7024, val_loss=0.8023, val_accuracy=0.5877\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5769 - accuracy: 0.7024 - val_loss: 0.8023 - val_accuracy: 0.5877 - lr: 8.0000e-06\n",
      "Epoch 35: early stopping\n",
      "Validation accuracy: 0.7168874144554138\n",
      "\n",
      "Initial Training Combination 22/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.0005, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7692 - accuracy: 0.6138Epoch 1/40: loss=0.7688, accuracy=0.6142, val_loss=0.8651, val_accuracy=0.7185\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.7688 - accuracy: 0.6142 - val_loss: 0.8651 - val_accuracy: 0.7185 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6283 - accuracy: 0.6759Epoch 2/40: loss=0.6306, accuracy=0.6751, val_loss=0.6405, val_accuracy=0.5960\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6306 - accuracy: 0.6751 - val_loss: 0.6405 - val_accuracy: 0.5960 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7074Epoch 3/40: loss=0.5730, accuracy=0.7074, val_loss=0.8263, val_accuracy=0.5530\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5730 - accuracy: 0.7074 - val_loss: 0.8263 - val_accuracy: 0.5530 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5491 - accuracy: 0.7307Epoch 4/40: loss=0.5488, accuracy=0.7310, val_loss=0.8335, val_accuracy=0.6167\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5488 - accuracy: 0.7310 - val_loss: 0.8335 - val_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7411Epoch 5/40: loss=0.5283, accuracy=0.7415, val_loss=0.6013, val_accuracy=0.7219\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5283 - accuracy: 0.7415 - val_loss: 0.6013 - val_accuracy: 0.7219 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.7434Epoch 6/40: loss=0.5316, accuracy=0.7434, val_loss=0.6847, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5316 - accuracy: 0.7434 - val_loss: 0.6847 - val_accuracy: 0.7210 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.7525Epoch 7/40: loss=0.5198, accuracy=0.7525, val_loss=0.6212, val_accuracy=0.7533\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5198 - accuracy: 0.7525 - val_loss: 0.6212 - val_accuracy: 0.7533 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.7438Epoch 8/40: loss=0.5276, accuracy=0.7438, val_loss=0.6991, val_accuracy=0.6308\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5276 - accuracy: 0.7438 - val_loss: 0.6991 - val_accuracy: 0.6308 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7490Epoch 9/40: loss=0.5261, accuracy=0.7490, val_loss=1.3677, val_accuracy=0.4752\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5261 - accuracy: 0.7490 - val_loss: 1.3677 - val_accuracy: 0.4752 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.7496Epoch 10/40: loss=0.5100, accuracy=0.7494, val_loss=0.4722, val_accuracy=0.8038\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5100 - accuracy: 0.7494 - val_loss: 0.4722 - val_accuracy: 0.8038 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.7637Epoch 11/40: loss=0.5078, accuracy=0.7635, val_loss=0.5310, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5078 - accuracy: 0.7635 - val_loss: 0.5310 - val_accuracy: 0.7608 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7604Epoch 12/40: loss=0.4999, accuracy=0.7603, val_loss=0.5959, val_accuracy=0.7053\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4999 - accuracy: 0.7603 - val_loss: 0.5959 - val_accuracy: 0.7053 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.7666Epoch 13/40: loss=0.5032, accuracy=0.7663, val_loss=0.5138, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5032 - accuracy: 0.7663 - val_loss: 0.5138 - val_accuracy: 0.7641 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7626Epoch 14/40: loss=0.4948, accuracy=0.7626, val_loss=0.7944, val_accuracy=0.5364\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4948 - accuracy: 0.7626 - val_loss: 0.7944 - val_accuracy: 0.5364 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.7691\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/40: loss=0.4953, accuracy=0.7695, val_loss=0.5287, val_accuracy=0.7467\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4953 - accuracy: 0.7695 - val_loss: 0.5287 - val_accuracy: 0.7467 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7874Epoch 16/40: loss=0.4680, accuracy=0.7883, val_loss=0.4077, val_accuracy=0.8311\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4680 - accuracy: 0.7883 - val_loss: 0.4077 - val_accuracy: 0.8311 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.7885Epoch 17/40: loss=0.4580, accuracy=0.7885, val_loss=0.3864, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4580 - accuracy: 0.7885 - val_loss: 0.3864 - val_accuracy: 0.8411 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.7927Epoch 18/40: loss=0.4466, accuracy=0.7928, val_loss=0.4184, val_accuracy=0.8353\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4466 - accuracy: 0.7928 - val_loss: 0.4184 - val_accuracy: 0.8353 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.7973Epoch 19/40: loss=0.4378, accuracy=0.7976, val_loss=0.3894, val_accuracy=0.8444\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4378 - accuracy: 0.7976 - val_loss: 0.3894 - val_accuracy: 0.8444 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8022Epoch 20/40: loss=0.4367, accuracy=0.8022, val_loss=0.4187, val_accuracy=0.8535\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4367 - accuracy: 0.8022 - val_loss: 0.4187 - val_accuracy: 0.8535 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4216 - accuracy: 0.8042Epoch 21/40: loss=0.4223, accuracy=0.8040, val_loss=0.3829, val_accuracy=0.8427\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4223 - accuracy: 0.8040 - val_loss: 0.3829 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8038Epoch 22/40: loss=0.4252, accuracy=0.8038, val_loss=0.4152, val_accuracy=0.8477\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4152 - val_accuracy: 0.8477 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.8040Epoch 23/40: loss=0.4231, accuracy=0.8040, val_loss=0.3865, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4231 - accuracy: 0.8040 - val_loss: 0.3865 - val_accuracy: 0.8212 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8088Epoch 24/40: loss=0.4140, accuracy=0.8088, val_loss=0.3938, val_accuracy=0.8253\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4140 - accuracy: 0.8088 - val_loss: 0.3938 - val_accuracy: 0.8253 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8158Epoch 25/40: loss=0.4115, accuracy=0.8158, val_loss=0.4054, val_accuracy=0.8477\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4115 - accuracy: 0.8158 - val_loss: 0.4054 - val_accuracy: 0.8477 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.8109\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 26/40: loss=0.4109, accuracy=0.8113, val_loss=0.4002, val_accuracy=0.8104\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4109 - accuracy: 0.8113 - val_loss: 0.4002 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4019 - accuracy: 0.8170Epoch 27/40: loss=0.4018, accuracy=0.8171, val_loss=0.3981, val_accuracy=0.8336\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4018 - accuracy: 0.8171 - val_loss: 0.3981 - val_accuracy: 0.8336 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8201Epoch 28/40: loss=0.3909, accuracy=0.8200, val_loss=0.4054, val_accuracy=0.8253\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3909 - accuracy: 0.8200 - val_loss: 0.4054 - val_accuracy: 0.8253 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.8370Epoch 29/40: loss=0.3675, accuracy=0.8375, val_loss=0.3700, val_accuracy=0.8435\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3675 - accuracy: 0.8375 - val_loss: 0.3700 - val_accuracy: 0.8435 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8275Epoch 30/40: loss=0.3805, accuracy=0.8276, val_loss=0.3723, val_accuracy=0.8328\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3805 - accuracy: 0.8276 - val_loss: 0.3723 - val_accuracy: 0.8328 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8250Epoch 31/40: loss=0.3897, accuracy=0.8247, val_loss=0.3787, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3897 - accuracy: 0.8247 - val_loss: 0.3787 - val_accuracy: 0.8220 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8260Epoch 32/40: loss=0.3831, accuracy=0.8264, val_loss=0.3740, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3831 - accuracy: 0.8264 - val_loss: 0.3740 - val_accuracy: 0.8270 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.8366Epoch 33/40: loss=0.3633, accuracy=0.8367, val_loss=0.3706, val_accuracy=0.8303\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3633 - accuracy: 0.8367 - val_loss: 0.3706 - val_accuracy: 0.8303 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8286\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 34/40: loss=0.3722, accuracy=0.8286, val_loss=0.3764, val_accuracy=0.8212\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3722 - accuracy: 0.8286 - val_loss: 0.3764 - val_accuracy: 0.8212 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8261Epoch 35/40: loss=0.3841, accuracy=0.8264, val_loss=0.3857, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3841 - accuracy: 0.8264 - val_loss: 0.3857 - val_accuracy: 0.8187 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.8291Epoch 36/40: loss=0.3698, accuracy=0.8293, val_loss=0.3831, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3698 - accuracy: 0.8293 - val_loss: 0.3831 - val_accuracy: 0.8204 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8276Epoch 37/40: loss=0.3869, accuracy=0.8276, val_loss=0.3932, val_accuracy=0.8088\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3869 - accuracy: 0.8276 - val_loss: 0.3932 - val_accuracy: 0.8088 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8375Epoch 38/40: loss=0.3721, accuracy=0.8375, val_loss=0.3878, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.3721 - accuracy: 0.8375 - val_loss: 0.3878 - val_accuracy: 0.8204 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8344\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.3791, accuracy=0.8340, val_loss=0.3911, val_accuracy=0.8171\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3791 - accuracy: 0.8340 - val_loss: 0.3911 - val_accuracy: 0.8171 - lr: 4.0000e-06\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.8534768223762512\n",
      "\n",
      "Initial Training Combination 23/50: num_residual_blocks=4, dropout_rate=0.4, learning_rate=0.0005, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.5259Epoch 1/40: loss=0.9079, accuracy=0.5259, val_loss=1.5447, val_accuracy=0.4065\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.9079 - accuracy: 0.5259 - val_loss: 1.5447 - val_accuracy: 0.4065 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.6277Epoch 2/40: loss=0.6935, accuracy=0.6279, val_loss=0.6310, val_accuracy=0.7202\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6935 - accuracy: 0.6279 - val_loss: 0.6310 - val_accuracy: 0.7202 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.6608Epoch 3/40: loss=0.6282, accuracy=0.6608, val_loss=0.7912, val_accuracy=0.5944\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6282 - accuracy: 0.6608 - val_loss: 0.7912 - val_accuracy: 0.5944 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5736 - accuracy: 0.7054Epoch 4/40: loss=0.5734, accuracy=0.7055, val_loss=0.8252, val_accuracy=0.6192\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5734 - accuracy: 0.7055 - val_loss: 0.8252 - val_accuracy: 0.6192 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5684 - accuracy: 0.7145Epoch 5/40: loss=0.5680, accuracy=0.7148, val_loss=0.9141, val_accuracy=0.5149\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5680 - accuracy: 0.7148 - val_loss: 0.9141 - val_accuracy: 0.5149 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.7125Epoch 6/40: loss=0.5612, accuracy=0.7125, val_loss=0.9777, val_accuracy=0.4478\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5612 - accuracy: 0.7125 - val_loss: 0.9777 - val_accuracy: 0.4478 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.7243\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/40: loss=0.5577, accuracy=0.7250, val_loss=1.1590, val_accuracy=0.6440\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5577 - accuracy: 0.7250 - val_loss: 1.1590 - val_accuracy: 0.6440 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5314 - accuracy: 0.7402Epoch 8/40: loss=0.5316, accuracy=0.7401, val_loss=0.4683, val_accuracy=0.7889\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5316 - accuracy: 0.7401 - val_loss: 0.4683 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.7427Epoch 9/40: loss=0.5226, accuracy=0.7432, val_loss=0.4435, val_accuracy=0.8154\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5226 - accuracy: 0.7432 - val_loss: 0.4435 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.7552Epoch 10/40: loss=0.5215, accuracy=0.7550, val_loss=0.4468, val_accuracy=0.8063\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5215 - accuracy: 0.7550 - val_loss: 0.4468 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.7589Epoch 11/40: loss=0.5077, accuracy=0.7593, val_loss=0.5439, val_accuracy=0.7475\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5077 - accuracy: 0.7593 - val_loss: 0.5439 - val_accuracy: 0.7475 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.7542Epoch 12/40: loss=0.5075, accuracy=0.7539, val_loss=0.7110, val_accuracy=0.6382\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5075 - accuracy: 0.7539 - val_loss: 0.7110 - val_accuracy: 0.6382 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4979 - accuracy: 0.7552Epoch 13/40: loss=0.4985, accuracy=0.7550, val_loss=0.5737, val_accuracy=0.7368\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4985 - accuracy: 0.7550 - val_loss: 0.5737 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4913 - accuracy: 0.7625Epoch 14/40: loss=0.4917, accuracy=0.7620, val_loss=0.4265, val_accuracy=0.8303\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4917 - accuracy: 0.7620 - val_loss: 0.4265 - val_accuracy: 0.8303 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.7566Epoch 15/40: loss=0.4848, accuracy=0.7566, val_loss=0.5653, val_accuracy=0.7508\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4848 - accuracy: 0.7566 - val_loss: 0.5653 - val_accuracy: 0.7508 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4882 - accuracy: 0.7639Epoch 16/40: loss=0.4878, accuracy=0.7645, val_loss=0.4671, val_accuracy=0.7988\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4878 - accuracy: 0.7645 - val_loss: 0.4671 - val_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7753Epoch 17/40: loss=0.4749, accuracy=0.7757, val_loss=0.4229, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4749 - accuracy: 0.7757 - val_loss: 0.4229 - val_accuracy: 0.8146 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.7819Epoch 18/40: loss=0.4641, accuracy=0.7815, val_loss=0.4923, val_accuracy=0.7922\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4641 - accuracy: 0.7815 - val_loss: 0.4923 - val_accuracy: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7746Epoch 19/40: loss=0.4690, accuracy=0.7746, val_loss=0.4541, val_accuracy=0.7649\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4690 - accuracy: 0.7746 - val_loss: 0.4541 - val_accuracy: 0.7649 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7765Epoch 20/40: loss=0.4766, accuracy=0.7765, val_loss=0.4315, val_accuracy=0.8154\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4766 - accuracy: 0.7765 - val_loss: 0.4315 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.7753Epoch 21/40: loss=0.4647, accuracy=0.7755, val_loss=0.5526, val_accuracy=0.7525\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4647 - accuracy: 0.7755 - val_loss: 0.5526 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4657 - accuracy: 0.7853\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 22/40: loss=0.4653, accuracy=0.7854, val_loss=0.6323, val_accuracy=0.7210\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4653 - accuracy: 0.7854 - val_loss: 0.6323 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.7814Epoch 23/40: loss=0.4573, accuracy=0.7815, val_loss=0.4535, val_accuracy=0.8154\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4573 - accuracy: 0.7815 - val_loss: 0.4535 - val_accuracy: 0.8154 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.7994Epoch 24/40: loss=0.4333, accuracy=0.7999, val_loss=0.4148, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4333 - accuracy: 0.7999 - val_loss: 0.4148 - val_accuracy: 0.8278 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4500 - accuracy: 0.7986Epoch 25/40: loss=0.4499, accuracy=0.7986, val_loss=0.4176, val_accuracy=0.8303\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4499 - accuracy: 0.7986 - val_loss: 0.4176 - val_accuracy: 0.8303 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.8031Epoch 26/40: loss=0.4296, accuracy=0.8032, val_loss=0.4220, val_accuracy=0.8253\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4296 - accuracy: 0.8032 - val_loss: 0.4220 - val_accuracy: 0.8253 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.7979Epoch 27/40: loss=0.4322, accuracy=0.7982, val_loss=0.4603, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4322 - accuracy: 0.7982 - val_loss: 0.4603 - val_accuracy: 0.8220 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4358 - accuracy: 0.8002Epoch 28/40: loss=0.4355, accuracy=0.8003, val_loss=0.4630, val_accuracy=0.8129\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4630 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.8067Epoch 29/40: loss=0.4267, accuracy=0.8065, val_loss=0.4009, val_accuracy=0.8427\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4267 - accuracy: 0.8065 - val_loss: 0.4009 - val_accuracy: 0.8427 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.8114Epoch 30/40: loss=0.4190, accuracy=0.8113, val_loss=0.4885, val_accuracy=0.8005\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4190 - accuracy: 0.8113 - val_loss: 0.4885 - val_accuracy: 0.8005 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8100Epoch 31/40: loss=0.4180, accuracy=0.8100, val_loss=0.4119, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4180 - accuracy: 0.8100 - val_loss: 0.4119 - val_accuracy: 0.8237 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4280 - accuracy: 0.8000Epoch 32/40: loss=0.4278, accuracy=0.8001, val_loss=0.4602, val_accuracy=0.8129\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4278 - accuracy: 0.8001 - val_loss: 0.4602 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8025Epoch 33/40: loss=0.4256, accuracy=0.8022, val_loss=0.4241, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4256 - accuracy: 0.8022 - val_loss: 0.4241 - val_accuracy: 0.8195 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.8131\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 34/40: loss=0.4174, accuracy=0.8131, val_loss=0.4306, val_accuracy=0.8253\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4174 - accuracy: 0.8131 - val_loss: 0.4306 - val_accuracy: 0.8253 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8057Epoch 35/40: loss=0.4191, accuracy=0.8057, val_loss=0.4117, val_accuracy=0.8278\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4191 - accuracy: 0.8057 - val_loss: 0.4117 - val_accuracy: 0.8278 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4169 - accuracy: 0.8094Epoch 36/40: loss=0.4176, accuracy=0.8088, val_loss=0.4373, val_accuracy=0.8187\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4176 - accuracy: 0.8088 - val_loss: 0.4373 - val_accuracy: 0.8187 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.8053Epoch 37/40: loss=0.4289, accuracy=0.8053, val_loss=0.4212, val_accuracy=0.8212\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4289 - accuracy: 0.8053 - val_loss: 0.4212 - val_accuracy: 0.8212 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4152 - accuracy: 0.8140Epoch 38/40: loss=0.4148, accuracy=0.8139, val_loss=0.4208, val_accuracy=0.8262\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4148 - accuracy: 0.8139 - val_loss: 0.4208 - val_accuracy: 0.8262 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8150\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.4158, accuracy=0.8150, val_loss=0.4276, val_accuracy=0.8245\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4158 - accuracy: 0.8150 - val_loss: 0.4276 - val_accuracy: 0.8245 - lr: 4.0000e-06\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.8427152037620544\n",
      "\n",
      "Initial Training Combination 24/50: num_residual_blocks=2, dropout_rate=0.4, learning_rate=0.0001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.1, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9674 - accuracy: 0.5188Epoch 1/40: loss=0.9674, accuracy=0.5188, val_loss=0.6898, val_accuracy=0.5795\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.9674 - accuracy: 0.5188 - val_loss: 0.6898 - val_accuracy: 0.5795 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8768 - accuracy: 0.5290Epoch 2/40: loss=0.8768, accuracy=0.5290, val_loss=0.7542, val_accuracy=0.6109\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8768 - accuracy: 0.5290 - val_loss: 0.7542 - val_accuracy: 0.6109 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7939 - accuracy: 0.5687Epoch 3/40: loss=0.7928, accuracy=0.5691, val_loss=0.5766, val_accuracy=0.7012\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7928 - accuracy: 0.5691 - val_loss: 0.5766 - val_accuracy: 0.7012 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7268 - accuracy: 0.6142Epoch 4/40: loss=0.7268, accuracy=0.6140, val_loss=0.5380, val_accuracy=0.7368\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7268 - accuracy: 0.6140 - val_loss: 0.5380 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.6333Epoch 5/40: loss=0.7056, accuracy=0.6333, val_loss=0.8936, val_accuracy=0.5017\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7056 - accuracy: 0.6333 - val_loss: 0.8936 - val_accuracy: 0.5017 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.6551Epoch 6/40: loss=0.6741, accuracy=0.6558, val_loss=1.0150, val_accuracy=0.4652\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6741 - accuracy: 0.6558 - val_loss: 1.0150 - val_accuracy: 0.4652 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.6618Epoch 7/40: loss=0.6533, accuracy=0.6616, val_loss=0.7412, val_accuracy=0.7161\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6533 - accuracy: 0.6616 - val_loss: 0.7412 - val_accuracy: 0.7161 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6468 - accuracy: 0.6624Epoch 8/40: loss=0.6476, accuracy=0.6620, val_loss=0.6933, val_accuracy=0.7119\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6476 - accuracy: 0.6620 - val_loss: 0.6933 - val_accuracy: 0.7119 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6452 - accuracy: 0.6578\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 9/40: loss=0.6458, accuracy=0.6575, val_loss=0.5541, val_accuracy=0.7268\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6458 - accuracy: 0.6575 - val_loss: 0.5541 - val_accuracy: 0.7268 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6203 - accuracy: 0.6740Epoch 10/40: loss=0.6205, accuracy=0.6738, val_loss=0.5178, val_accuracy=0.7111\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6205 - accuracy: 0.6738 - val_loss: 0.5178 - val_accuracy: 0.7111 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5998 - accuracy: 0.6882Epoch 11/40: loss=0.5993, accuracy=0.6883, val_loss=0.4987, val_accuracy=0.7632\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5993 - accuracy: 0.6883 - val_loss: 0.4987 - val_accuracy: 0.7632 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.6904Epoch 12/40: loss=0.6040, accuracy=0.6904, val_loss=0.5024, val_accuracy=0.7227\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6040 - accuracy: 0.6904 - val_loss: 0.5024 - val_accuracy: 0.7227 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.6907Epoch 13/40: loss=0.5977, accuracy=0.6904, val_loss=0.5163, val_accuracy=0.7583\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5977 - accuracy: 0.6904 - val_loss: 0.5163 - val_accuracy: 0.7583 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.6978Epoch 14/40: loss=0.5931, accuracy=0.6978, val_loss=0.5030, val_accuracy=0.7608\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5931 - accuracy: 0.6978 - val_loss: 0.5030 - val_accuracy: 0.7608 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5861 - accuracy: 0.7036Epoch 15/40: loss=0.5861, accuracy=0.7036, val_loss=0.5296, val_accuracy=0.7583\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5861 - accuracy: 0.7036 - val_loss: 0.5296 - val_accuracy: 0.7583 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5862 - accuracy: 0.7034\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 16/40: loss=0.5860, accuracy=0.7034, val_loss=0.5308, val_accuracy=0.7111\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5860 - accuracy: 0.7034 - val_loss: 0.5308 - val_accuracy: 0.7111 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5780 - accuracy: 0.7067Epoch 17/40: loss=0.5771, accuracy=0.7078, val_loss=0.4654, val_accuracy=0.7724\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5771 - accuracy: 0.7078 - val_loss: 0.4654 - val_accuracy: 0.7724 - lr: 4.0000e-06\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.7045Epoch 18/40: loss=0.5755, accuracy=0.7045, val_loss=0.4777, val_accuracy=0.7757\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5755 - accuracy: 0.7045 - val_loss: 0.4777 - val_accuracy: 0.7757 - lr: 4.0000e-06\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5811 - accuracy: 0.7032Epoch 19/40: loss=0.5824, accuracy=0.7026, val_loss=0.4713, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5824 - accuracy: 0.7026 - val_loss: 0.4713 - val_accuracy: 0.7740 - lr: 4.0000e-06\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5794 - accuracy: 0.6998Epoch 20/40: loss=0.5789, accuracy=0.6999, val_loss=0.4739, val_accuracy=0.7707\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5789 - accuracy: 0.6999 - val_loss: 0.4739 - val_accuracy: 0.7707 - lr: 4.0000e-06\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7092Epoch 21/40: loss=0.5801, accuracy=0.7092, val_loss=0.4777, val_accuracy=0.7740\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5801 - accuracy: 0.7092 - val_loss: 0.4777 - val_accuracy: 0.7740 - lr: 4.0000e-06\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.7078\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 22/40: loss=0.5792, accuracy=0.7078, val_loss=0.4669, val_accuracy=0.7699\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5792 - accuracy: 0.7078 - val_loss: 0.4669 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5773 - accuracy: 0.7007Epoch 23/40: loss=0.5770, accuracy=0.7010, val_loss=0.4666, val_accuracy=0.7666\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5770 - accuracy: 0.7010 - val_loss: 0.4666 - val_accuracy: 0.7666 - lr: 8.0000e-07\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.7083Epoch 24/40: loss=0.5759, accuracy=0.7082, val_loss=0.4724, val_accuracy=0.7724\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5759 - accuracy: 0.7082 - val_loss: 0.4724 - val_accuracy: 0.7724 - lr: 8.0000e-07\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5740 - accuracy: 0.7040Epoch 25/40: loss=0.5745, accuracy=0.7034, val_loss=0.4706, val_accuracy=0.7674\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5745 - accuracy: 0.7034 - val_loss: 0.4706 - val_accuracy: 0.7674 - lr: 8.0000e-07\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7026Epoch 26/40: loss=0.5772, accuracy=0.7026, val_loss=0.4719, val_accuracy=0.7715\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5772 - accuracy: 0.7026 - val_loss: 0.4719 - val_accuracy: 0.7715 - lr: 8.0000e-07\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.7170\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.5637, accuracy=0.7171, val_loss=0.4741, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5637 - accuracy: 0.7171 - val_loss: 0.4741 - val_accuracy: 0.7707 - lr: 8.0000e-07\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.7756622433662415\n",
      "\n",
      "Initial Training Combination 25/50: num_residual_blocks=5, dropout_rate=0.4, learning_rate=0.0005, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8828 - accuracy: 0.5455Epoch 1/40: loss=0.8842, accuracy=0.5447, val_loss=0.6427, val_accuracy=0.6341\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.8842 - accuracy: 0.5447 - val_loss: 0.6427 - val_accuracy: 0.6341 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.5824Epoch 2/40: loss=0.7295, accuracy=0.5824, val_loss=0.7129, val_accuracy=0.5737\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7295 - accuracy: 0.5824 - val_loss: 0.7129 - val_accuracy: 0.5737 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.6329Epoch 3/40: loss=0.6439, accuracy=0.6329, val_loss=0.8027, val_accuracy=0.6697\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6439 - accuracy: 0.6329 - val_loss: 0.8027 - val_accuracy: 0.6697 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.7082Epoch 4/40: loss=0.5756, accuracy=0.7082, val_loss=0.6147, val_accuracy=0.6788\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5756 - accuracy: 0.7082 - val_loss: 0.6147 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5586 - accuracy: 0.7228Epoch 5/40: loss=0.5588, accuracy=0.7225, val_loss=0.8188, val_accuracy=0.6225\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5588 - accuracy: 0.7225 - val_loss: 0.8188 - val_accuracy: 0.6225 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5577 - accuracy: 0.7129Epoch 6/40: loss=0.5583, accuracy=0.7127, val_loss=0.4947, val_accuracy=0.7699\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5583 - accuracy: 0.7127 - val_loss: 0.4947 - val_accuracy: 0.7699 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5446 - accuracy: 0.7345Epoch 7/40: loss=0.5441, accuracy=0.7349, val_loss=1.6146, val_accuracy=0.5000\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5441 - accuracy: 0.7349 - val_loss: 1.6146 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.7346Epoch 8/40: loss=0.5451, accuracy=0.7341, val_loss=0.5183, val_accuracy=0.7235\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5451 - accuracy: 0.7341 - val_loss: 0.5183 - val_accuracy: 0.7235 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.7438Epoch 9/40: loss=0.5361, accuracy=0.7438, val_loss=0.4891, val_accuracy=0.7632\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5361 - accuracy: 0.7438 - val_loss: 0.4891 - val_accuracy: 0.7632 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.7469Epoch 10/40: loss=0.5299, accuracy=0.7469, val_loss=0.5146, val_accuracy=0.7070\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5299 - accuracy: 0.7469 - val_loss: 0.5146 - val_accuracy: 0.7070 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7488Epoch 11/40: loss=0.5351, accuracy=0.7488, val_loss=0.6554, val_accuracy=0.6896\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5351 - accuracy: 0.7488 - val_loss: 0.6554 - val_accuracy: 0.6896 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7473Epoch 12/40: loss=0.5265, accuracy=0.7473, val_loss=1.4538, val_accuracy=0.5406\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5265 - accuracy: 0.7473 - val_loss: 1.4538 - val_accuracy: 0.5406 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.7591Epoch 13/40: loss=0.5113, accuracy=0.7589, val_loss=0.4724, val_accuracy=0.7541\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5113 - accuracy: 0.7589 - val_loss: 0.4724 - val_accuracy: 0.7541 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.7581Epoch 14/40: loss=0.5131, accuracy=0.7572, val_loss=0.4650, val_accuracy=0.8104\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5131 - accuracy: 0.7572 - val_loss: 0.4650 - val_accuracy: 0.8104 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4875 - accuracy: 0.7722Epoch 15/40: loss=0.4878, accuracy=0.7717, val_loss=0.6180, val_accuracy=0.6887\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4878 - accuracy: 0.7717 - val_loss: 0.6180 - val_accuracy: 0.6887 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.7583Epoch 16/40: loss=0.4957, accuracy=0.7583, val_loss=0.6777, val_accuracy=0.6763\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4957 - accuracy: 0.7583 - val_loss: 0.6777 - val_accuracy: 0.6763 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.7512Epoch 17/40: loss=0.4945, accuracy=0.7512, val_loss=0.5166, val_accuracy=0.7301\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4945 - accuracy: 0.7512 - val_loss: 0.5166 - val_accuracy: 0.7301 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5011 - accuracy: 0.7635Epoch 18/40: loss=0.5011, accuracy=0.7635, val_loss=0.4918, val_accuracy=0.7483\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5011 - accuracy: 0.7635 - val_loss: 0.4918 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.7741Epoch 19/40: loss=0.4867, accuracy=0.7744, val_loss=0.4487, val_accuracy=0.7715\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4867 - accuracy: 0.7744 - val_loss: 0.4487 - val_accuracy: 0.7715 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7726Epoch 20/40: loss=0.4879, accuracy=0.7726, val_loss=0.4437, val_accuracy=0.7815\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.4437 - val_accuracy: 0.7815 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.7854Epoch 21/40: loss=0.4782, accuracy=0.7854, val_loss=0.5521, val_accuracy=0.7086\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4782 - accuracy: 0.7854 - val_loss: 0.5521 - val_accuracy: 0.7086 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.7777Epoch 22/40: loss=0.4787, accuracy=0.7777, val_loss=1.0059, val_accuracy=0.5993\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4787 - accuracy: 0.7777 - val_loss: 1.0059 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7774Epoch 23/40: loss=0.4790, accuracy=0.7773, val_loss=0.4501, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4790 - accuracy: 0.7773 - val_loss: 0.4501 - val_accuracy: 0.8063 - lr: 5.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7843Epoch 24/40: loss=0.4679, accuracy=0.7848, val_loss=0.4747, val_accuracy=0.7326\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4679 - accuracy: 0.7848 - val_loss: 0.4747 - val_accuracy: 0.7326 - lr: 5.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.7863\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 25/40: loss=0.4589, accuracy=0.7864, val_loss=0.5295, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4589 - accuracy: 0.7864 - val_loss: 0.5295 - val_accuracy: 0.7947 - lr: 5.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7918Epoch 26/40: loss=0.4443, accuracy=0.7918, val_loss=0.4279, val_accuracy=0.8079\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4443 - accuracy: 0.7918 - val_loss: 0.4279 - val_accuracy: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8019Epoch 27/40: loss=0.4297, accuracy=0.8019, val_loss=0.4116, val_accuracy=0.8079\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4297 - accuracy: 0.8019 - val_loss: 0.4116 - val_accuracy: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4232 - accuracy: 0.8092Epoch 28/40: loss=0.4230, accuracy=0.8092, val_loss=0.3948, val_accuracy=0.8179\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4230 - accuracy: 0.8092 - val_loss: 0.3948 - val_accuracy: 0.8179 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4115 - accuracy: 0.8219Epoch 29/40: loss=0.4114, accuracy=0.8220, val_loss=0.3851, val_accuracy=0.8377\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4114 - accuracy: 0.8220 - val_loss: 0.3851 - val_accuracy: 0.8377 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8218Epoch 30/40: loss=0.4068, accuracy=0.8218, val_loss=0.4487, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4068 - accuracy: 0.8218 - val_loss: 0.4487 - val_accuracy: 0.7806 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4061 - accuracy: 0.8270Epoch 31/40: loss=0.4057, accuracy=0.8272, val_loss=0.3954, val_accuracy=0.8195\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4057 - accuracy: 0.8272 - val_loss: 0.3954 - val_accuracy: 0.8195 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8214Epoch 32/40: loss=0.3984, accuracy=0.8214, val_loss=0.4111, val_accuracy=0.8394\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3984 - accuracy: 0.8214 - val_loss: 0.4111 - val_accuracy: 0.8394 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8267Epoch 33/40: loss=0.3972, accuracy=0.8270, val_loss=0.4049, val_accuracy=0.8046\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3972 - accuracy: 0.8270 - val_loss: 0.4049 - val_accuracy: 0.8046 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3941 - accuracy: 0.8275\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 34/40: loss=0.3941, accuracy=0.8276, val_loss=0.3897, val_accuracy=0.8262\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3941 - accuracy: 0.8276 - val_loss: 0.3897 - val_accuracy: 0.8262 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8286Epoch 35/40: loss=0.3840, accuracy=0.8286, val_loss=0.3986, val_accuracy=0.8129\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3840 - accuracy: 0.8286 - val_loss: 0.3986 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8339Epoch 36/40: loss=0.3838, accuracy=0.8340, val_loss=0.3961, val_accuracy=0.8104\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3838 - accuracy: 0.8340 - val_loss: 0.3961 - val_accuracy: 0.8104 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3769 - accuracy: 0.8347Epoch 37/40: loss=0.3763, accuracy=0.8351, val_loss=0.3901, val_accuracy=0.8096\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.3901 - val_accuracy: 0.8096 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8397Epoch 38/40: loss=0.3704, accuracy=0.8394, val_loss=0.3952, val_accuracy=0.8146\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3704 - accuracy: 0.8394 - val_loss: 0.3952 - val_accuracy: 0.8146 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8384\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.3737, accuracy=0.8384, val_loss=0.3910, val_accuracy=0.8179\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.3737 - accuracy: 0.8384 - val_loss: 0.3910 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.8394039869308472\n",
      "\n",
      "Initial Training Combination 26/50: num_residual_blocks=3, dropout_rate=0.6, learning_rate=0.001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9184 - accuracy: 0.5207Epoch 1/40: loss=0.9184, accuracy=0.5207, val_loss=0.6857, val_accuracy=0.6217\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 0.9184 - accuracy: 0.5207 - val_loss: 0.6857 - val_accuracy: 0.6217 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7244 - accuracy: 0.5448Epoch 2/40: loss=0.7247, accuracy=0.5447, val_loss=0.8914, val_accuracy=0.4545\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7247 - accuracy: 0.5447 - val_loss: 0.8914 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.5797Epoch 3/40: loss=0.6844, accuracy=0.5797, val_loss=0.8189, val_accuracy=0.4975\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6844 - accuracy: 0.5797 - val_loss: 0.8189 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6653 - accuracy: 0.6082Epoch 4/40: loss=0.6656, accuracy=0.6080, val_loss=0.5806, val_accuracy=0.7086\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6656 - accuracy: 0.6080 - val_loss: 0.5806 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6459 - accuracy: 0.6310Epoch 5/40: loss=0.6469, accuracy=0.6304, val_loss=0.7527, val_accuracy=0.6474\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6469 - accuracy: 0.6304 - val_loss: 0.7527 - val_accuracy: 0.6474 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6031Epoch 6/40: loss=0.6695, accuracy=0.6031, val_loss=0.6491, val_accuracy=0.6010\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6695 - accuracy: 0.6031 - val_loss: 0.6491 - val_accuracy: 0.6010 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.5978Epoch 7/40: loss=0.6677, accuracy=0.5981, val_loss=0.6633, val_accuracy=0.6175\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6677 - accuracy: 0.5981 - val_loss: 0.6633 - val_accuracy: 0.6175 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.6418Epoch 8/40: loss=0.6378, accuracy=0.6418, val_loss=0.6841, val_accuracy=0.6631\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6378 - accuracy: 0.6418 - val_loss: 0.6841 - val_accuracy: 0.6631 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6303 - accuracy: 0.6445\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/40: loss=0.6302, accuracy=0.6442, val_loss=1.3371, val_accuracy=0.6606\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6302 - accuracy: 0.6442 - val_loss: 1.3371 - val_accuracy: 0.6606 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6253 - accuracy: 0.6485Epoch 10/40: loss=0.6249, accuracy=0.6488, val_loss=0.8094, val_accuracy=0.6747\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6249 - accuracy: 0.6488 - val_loss: 0.8094 - val_accuracy: 0.6747 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.6649Epoch 11/40: loss=0.6050, accuracy=0.6649, val_loss=1.1957, val_accuracy=0.5339\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6050 - accuracy: 0.6649 - val_loss: 1.1957 - val_accuracy: 0.5339 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5916 - accuracy: 0.6807Epoch 12/40: loss=0.5913, accuracy=0.6809, val_loss=0.6387, val_accuracy=0.6912\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5913 - accuracy: 0.6809 - val_loss: 0.6387 - val_accuracy: 0.6912 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.6866Epoch 13/40: loss=0.5936, accuracy=0.6863, val_loss=0.6349, val_accuracy=0.7252\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5936 - accuracy: 0.6863 - val_loss: 0.6349 - val_accuracy: 0.7252 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.7030\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 14/40: loss=0.5757, accuracy=0.7030, val_loss=0.5810, val_accuracy=0.7558\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5757 - accuracy: 0.7030 - val_loss: 0.5810 - val_accuracy: 0.7558 - lr: 2.0000e-04\n",
      "Epoch 14: early stopping\n",
      "Validation accuracy: 0.7557947039604187\n",
      "\n",
      "Initial Training Combination 27/50: num_residual_blocks=5, dropout_rate=0.6, learning_rate=0.001, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9389 - accuracy: 0.4975Epoch 1/40: loss=0.9382, accuracy=0.4977, val_loss=0.6692, val_accuracy=0.6101\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.9382 - accuracy: 0.4977 - val_loss: 0.6692 - val_accuracy: 0.6101 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.4930Epoch 2/40: loss=0.7391, accuracy=0.4930, val_loss=0.6774, val_accuracy=0.6002\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.7391 - accuracy: 0.4930 - val_loss: 0.6774 - val_accuracy: 0.6002 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7228 - accuracy: 0.4973Epoch 3/40: loss=0.7228, accuracy=0.4973, val_loss=0.6834, val_accuracy=0.5977\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7228 - accuracy: 0.4973 - val_loss: 0.6834 - val_accuracy: 0.5977 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7143 - accuracy: 0.5112Epoch 4/40: loss=0.7145, accuracy=0.5108, val_loss=0.7325, val_accuracy=0.6076\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7145 - accuracy: 0.5108 - val_loss: 0.7325 - val_accuracy: 0.6076 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5631Epoch 5/40: loss=0.6924, accuracy=0.5621, val_loss=0.6875, val_accuracy=0.6142\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6924 - accuracy: 0.5621 - val_loss: 0.6875 - val_accuracy: 0.6142 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.5746\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 6/40: loss=0.6862, accuracy=0.5749, val_loss=0.8932, val_accuracy=0.6233\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.6862 - accuracy: 0.5749 - val_loss: 0.8932 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.6055Epoch 7/40: loss=0.6725, accuracy=0.6055, val_loss=0.6886, val_accuracy=0.6656\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6725 - accuracy: 0.6055 - val_loss: 0.6886 - val_accuracy: 0.6656 - lr: 2.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6621 - accuracy: 0.6138Epoch 8/40: loss=0.6617, accuracy=0.6142, val_loss=0.6828, val_accuracy=0.6680\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6617 - accuracy: 0.6142 - val_loss: 0.6828 - val_accuracy: 0.6680 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.6310Epoch 9/40: loss=0.6511, accuracy=0.6308, val_loss=0.6693, val_accuracy=0.6755\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6511 - accuracy: 0.6308 - val_loss: 0.6693 - val_accuracy: 0.6755 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.6486Epoch 10/40: loss=0.6272, accuracy=0.6486, val_loss=0.6447, val_accuracy=0.6763\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6272 - accuracy: 0.6486 - val_loss: 0.6447 - val_accuracy: 0.6763 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6206 - accuracy: 0.6487Epoch 11/40: loss=0.6208, accuracy=0.6488, val_loss=0.7199, val_accuracy=0.6631\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6208 - accuracy: 0.6488 - val_loss: 0.7199 - val_accuracy: 0.6631 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6597Epoch 12/40: loss=0.6112, accuracy=0.6598, val_loss=1.1518, val_accuracy=0.5497\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6112 - accuracy: 0.6598 - val_loss: 1.1518 - val_accuracy: 0.5497 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5829 - accuracy: 0.6914Epoch 13/40: loss=0.5824, accuracy=0.6921, val_loss=1.0143, val_accuracy=0.6656\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5824 - accuracy: 0.6921 - val_loss: 1.0143 - val_accuracy: 0.6656 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.6958Epoch 14/40: loss=0.5831, accuracy=0.6958, val_loss=0.5878, val_accuracy=0.7318\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5831 - accuracy: 0.6958 - val_loss: 0.5878 - val_accuracy: 0.7318 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7070Epoch 15/40: loss=0.5685, accuracy=0.7065, val_loss=0.5353, val_accuracy=0.7136\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5685 - accuracy: 0.7065 - val_loss: 0.5353 - val_accuracy: 0.7136 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5524 - accuracy: 0.7338Epoch 16/40: loss=0.5520, accuracy=0.7343, val_loss=1.2771, val_accuracy=0.6391\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5520 - accuracy: 0.7343 - val_loss: 1.2771 - val_accuracy: 0.6391 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5528 - accuracy: 0.7286Epoch 17/40: loss=0.5525, accuracy=0.7287, val_loss=1.5819, val_accuracy=0.6051\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5525 - accuracy: 0.7287 - val_loss: 1.5819 - val_accuracy: 0.6051 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5554 - accuracy: 0.7274Epoch 18/40: loss=0.5552, accuracy=0.7272, val_loss=0.8680, val_accuracy=0.6432\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5552 - accuracy: 0.7272 - val_loss: 0.8680 - val_accuracy: 0.6432 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7309Epoch 19/40: loss=0.5411, accuracy=0.7308, val_loss=0.9934, val_accuracy=0.6581\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5411 - accuracy: 0.7308 - val_loss: 0.9934 - val_accuracy: 0.6581 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7403\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 20/40: loss=0.5379, accuracy=0.7403, val_loss=0.5466, val_accuracy=0.7707\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5379 - accuracy: 0.7403 - val_loss: 0.5466 - val_accuracy: 0.7707 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7405Epoch 21/40: loss=0.5315, accuracy=0.7409, val_loss=0.4990, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5315 - accuracy: 0.7409 - val_loss: 0.4990 - val_accuracy: 0.7955 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.7614Epoch 22/40: loss=0.5024, accuracy=0.7614, val_loss=0.5277, val_accuracy=0.8104\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5024 - accuracy: 0.7614 - val_loss: 0.5277 - val_accuracy: 0.8104 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.7531Epoch 23/40: loss=0.5158, accuracy=0.7531, val_loss=0.4572, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5158 - accuracy: 0.7531 - val_loss: 0.4572 - val_accuracy: 0.8137 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5152 - accuracy: 0.7498Epoch 24/40: loss=0.5155, accuracy=0.7498, val_loss=0.5071, val_accuracy=0.8005\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5155 - accuracy: 0.7498 - val_loss: 0.5071 - val_accuracy: 0.8005 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.7593Epoch 25/40: loss=0.5089, accuracy=0.7595, val_loss=0.5618, val_accuracy=0.8063\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5089 - accuracy: 0.7595 - val_loss: 0.5618 - val_accuracy: 0.8063 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7543Epoch 26/40: loss=0.5048, accuracy=0.7543, val_loss=0.5543, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5048 - accuracy: 0.7543 - val_loss: 0.5543 - val_accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.7606Epoch 27/40: loss=0.5129, accuracy=0.7606, val_loss=0.4544, val_accuracy=0.8171\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5129 - accuracy: 0.7606 - val_loss: 0.4544 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7560Epoch 28/40: loss=0.4972, accuracy=0.7560, val_loss=0.4392, val_accuracy=0.8088\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4972 - accuracy: 0.7560 - val_loss: 0.4392 - val_accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5094 - accuracy: 0.7604Epoch 29/40: loss=0.5095, accuracy=0.7599, val_loss=0.5116, val_accuracy=0.8162\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5095 - accuracy: 0.7599 - val_loss: 0.5116 - val_accuracy: 0.8162 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4967 - accuracy: 0.7662Epoch 30/40: loss=0.4964, accuracy=0.7663, val_loss=0.4649, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4964 - accuracy: 0.7663 - val_loss: 0.4649 - val_accuracy: 0.8237 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.7612Epoch 31/40: loss=0.5028, accuracy=0.7614, val_loss=0.6910, val_accuracy=0.7864\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5028 - accuracy: 0.7614 - val_loss: 0.6910 - val_accuracy: 0.7864 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5105 - accuracy: 0.7593Epoch 32/40: loss=0.5102, accuracy=0.7595, val_loss=0.5051, val_accuracy=0.7922\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5102 - accuracy: 0.7595 - val_loss: 0.5051 - val_accuracy: 0.7922 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4976 - accuracy: 0.7679\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 33/40: loss=0.4976, accuracy=0.7682, val_loss=0.5381, val_accuracy=0.8113\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4976 - accuracy: 0.7682 - val_loss: 0.5381 - val_accuracy: 0.8113 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4987 - accuracy: 0.7612Epoch 34/40: loss=0.4991, accuracy=0.7608, val_loss=0.4913, val_accuracy=0.8204\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4991 - accuracy: 0.7608 - val_loss: 0.4913 - val_accuracy: 0.8204 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.7681Epoch 35/40: loss=0.4872, accuracy=0.7680, val_loss=0.5375, val_accuracy=0.8146\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4872 - accuracy: 0.7680 - val_loss: 0.5375 - val_accuracy: 0.8146 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.7722Epoch 36/40: loss=0.4833, accuracy=0.7724, val_loss=0.5570, val_accuracy=0.8063\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4833 - accuracy: 0.7724 - val_loss: 0.5570 - val_accuracy: 0.8063 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.7697Epoch 37/40: loss=0.4877, accuracy=0.7697, val_loss=0.4747, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4877 - accuracy: 0.7697 - val_loss: 0.4747 - val_accuracy: 0.8237 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.7748\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.4831, accuracy=0.7748, val_loss=0.5125, val_accuracy=0.8154\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4831 - accuracy: 0.7748 - val_loss: 0.5125 - val_accuracy: 0.8154 - lr: 8.0000e-06\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8236755132675171\n",
      "\n",
      "Initial Training Combination 28/50: num_residual_blocks=5, dropout_rate=0.3, learning_rate=0.0001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9187 - accuracy: 0.5247Epoch 1/40: loss=0.9191, accuracy=0.5248, val_loss=0.6648, val_accuracy=0.6043\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.9191 - accuracy: 0.5248 - val_loss: 0.6648 - val_accuracy: 0.6043 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8512 - accuracy: 0.5214Epoch 2/40: loss=0.8518, accuracy=0.5211, val_loss=0.6799, val_accuracy=0.5836\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.8518 - accuracy: 0.5211 - val_loss: 0.6799 - val_accuracy: 0.5836 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.5539Epoch 3/40: loss=0.8016, accuracy=0.5538, val_loss=0.8233, val_accuracy=0.4983\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8016 - accuracy: 0.5538 - val_loss: 0.8233 - val_accuracy: 0.4983 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7449 - accuracy: 0.5862Epoch 4/40: loss=0.7448, accuracy=0.5865, val_loss=0.6532, val_accuracy=0.6242\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.7448 - accuracy: 0.5865 - val_loss: 0.6532 - val_accuracy: 0.6242 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.6084Epoch 5/40: loss=0.7233, accuracy=0.6080, val_loss=0.6053, val_accuracy=0.6788\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7233 - accuracy: 0.6080 - val_loss: 0.6053 - val_accuracy: 0.6788 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.6343Epoch 6/40: loss=0.6816, accuracy=0.6343, val_loss=0.6677, val_accuracy=0.6159\n",
      "604/604 [==============================] - 15s 26ms/step - loss: 0.6816 - accuracy: 0.6343 - val_loss: 0.6677 - val_accuracy: 0.6159 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.6424Epoch 7/40: loss=0.6747, accuracy=0.6424, val_loss=0.5168, val_accuracy=0.7293\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6747 - accuracy: 0.6424 - val_loss: 0.5168 - val_accuracy: 0.7293 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6451 - accuracy: 0.6596Epoch 8/40: loss=0.6456, accuracy=0.6594, val_loss=0.5283, val_accuracy=0.7401\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.6456 - accuracy: 0.6594 - val_loss: 0.5283 - val_accuracy: 0.7401 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6226 - accuracy: 0.6790Epoch 9/40: loss=0.6228, accuracy=0.6786, val_loss=0.7885, val_accuracy=0.6540\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.6228 - accuracy: 0.6786 - val_loss: 0.7885 - val_accuracy: 0.6540 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.6784Epoch 10/40: loss=0.6233, accuracy=0.6784, val_loss=0.5606, val_accuracy=0.7127\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6233 - accuracy: 0.6784 - val_loss: 0.5606 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.6962Epoch 11/40: loss=0.5913, accuracy=0.6962, val_loss=0.6227, val_accuracy=0.6556\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5913 - accuracy: 0.6962 - val_loss: 0.6227 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.7055\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 12/40: loss=0.5767, accuracy=0.7055, val_loss=0.5870, val_accuracy=0.6954\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5767 - accuracy: 0.7055 - val_loss: 0.5870 - val_accuracy: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7148Epoch 13/40: loss=0.5710, accuracy=0.7148, val_loss=0.4608, val_accuracy=0.7798\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5710 - accuracy: 0.7148 - val_loss: 0.4608 - val_accuracy: 0.7798 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7132Epoch 14/40: loss=0.5662, accuracy=0.7132, val_loss=0.4813, val_accuracy=0.7591\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.5662 - accuracy: 0.7132 - val_loss: 0.4813 - val_accuracy: 0.7591 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5579 - accuracy: 0.7240Epoch 15/40: loss=0.5575, accuracy=0.7241, val_loss=0.4481, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5575 - accuracy: 0.7241 - val_loss: 0.4481 - val_accuracy: 0.7889 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.7225Epoch 16/40: loss=0.5512, accuracy=0.7225, val_loss=0.4617, val_accuracy=0.7864\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5512 - accuracy: 0.7225 - val_loss: 0.4617 - val_accuracy: 0.7864 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7279Epoch 17/40: loss=0.5452, accuracy=0.7279, val_loss=0.4592, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5452 - accuracy: 0.7279 - val_loss: 0.4592 - val_accuracy: 0.7806 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.7367Epoch 18/40: loss=0.5463, accuracy=0.7368, val_loss=0.5864, val_accuracy=0.7020\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5463 - accuracy: 0.7368 - val_loss: 0.5864 - val_accuracy: 0.7020 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.7245Epoch 19/40: loss=0.5422, accuracy=0.7248, val_loss=0.4848, val_accuracy=0.7724\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5422 - accuracy: 0.7248 - val_loss: 0.4848 - val_accuracy: 0.7724 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.7376\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 20/40: loss=0.5369, accuracy=0.7376, val_loss=0.4864, val_accuracy=0.7724\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5369 - accuracy: 0.7376 - val_loss: 0.4864 - val_accuracy: 0.7724 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5461 - accuracy: 0.7334Epoch 21/40: loss=0.5465, accuracy=0.7328, val_loss=0.4682, val_accuracy=0.7773\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5465 - accuracy: 0.7328 - val_loss: 0.4682 - val_accuracy: 0.7773 - lr: 4.0000e-06\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.7374Epoch 22/40: loss=0.5283, accuracy=0.7374, val_loss=0.4552, val_accuracy=0.7906\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5283 - accuracy: 0.7374 - val_loss: 0.4552 - val_accuracy: 0.7906 - lr: 4.0000e-06\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7367Epoch 23/40: loss=0.5342, accuracy=0.7368, val_loss=0.4580, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5342 - accuracy: 0.7368 - val_loss: 0.4580 - val_accuracy: 0.7889 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.7430Epoch 24/40: loss=0.5256, accuracy=0.7430, val_loss=0.4458, val_accuracy=0.7988\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5256 - accuracy: 0.7430 - val_loss: 0.4458 - val_accuracy: 0.7988 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.7382Epoch 25/40: loss=0.5260, accuracy=0.7380, val_loss=0.4441, val_accuracy=0.7955\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5260 - accuracy: 0.7380 - val_loss: 0.4441 - val_accuracy: 0.7955 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.7350Epoch 26/40: loss=0.5398, accuracy=0.7353, val_loss=0.4906, val_accuracy=0.7649\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5398 - accuracy: 0.7353 - val_loss: 0.4906 - val_accuracy: 0.7649 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.7372Epoch 27/40: loss=0.5297, accuracy=0.7372, val_loss=0.4382, val_accuracy=0.7988\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5297 - accuracy: 0.7372 - val_loss: 0.4382 - val_accuracy: 0.7988 - lr: 4.0000e-06\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.7413Epoch 28/40: loss=0.5365, accuracy=0.7411, val_loss=0.4741, val_accuracy=0.7790\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5365 - accuracy: 0.7411 - val_loss: 0.4741 - val_accuracy: 0.7790 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7413Epoch 29/40: loss=0.5309, accuracy=0.7411, val_loss=0.4526, val_accuracy=0.7848\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5309 - accuracy: 0.7411 - val_loss: 0.4526 - val_accuracy: 0.7848 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.7419Epoch 30/40: loss=0.5268, accuracy=0.7419, val_loss=0.4882, val_accuracy=0.7616\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5268 - accuracy: 0.7419 - val_loss: 0.4882 - val_accuracy: 0.7616 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5304 - accuracy: 0.7442Epoch 31/40: loss=0.5298, accuracy=0.7446, val_loss=0.4424, val_accuracy=0.7848\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5298 - accuracy: 0.7446 - val_loss: 0.4424 - val_accuracy: 0.7848 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7431\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 32/40: loss=0.5289, accuracy=0.7432, val_loss=0.4410, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5289 - accuracy: 0.7432 - val_loss: 0.4410 - val_accuracy: 0.7906 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.7417Epoch 33/40: loss=0.5206, accuracy=0.7417, val_loss=0.4416, val_accuracy=0.7930\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5206 - accuracy: 0.7417 - val_loss: 0.4416 - val_accuracy: 0.7930 - lr: 8.0000e-07\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.7396Epoch 34/40: loss=0.5251, accuracy=0.7401, val_loss=0.4456, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5251 - accuracy: 0.7401 - val_loss: 0.4456 - val_accuracy: 0.7906 - lr: 8.0000e-07\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5245 - accuracy: 0.7392Epoch 35/40: loss=0.5242, accuracy=0.7394, val_loss=0.4482, val_accuracy=0.7881\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5242 - accuracy: 0.7394 - val_loss: 0.4482 - val_accuracy: 0.7881 - lr: 8.0000e-07\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.7386Epoch 36/40: loss=0.5256, accuracy=0.7386, val_loss=0.4509, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5256 - accuracy: 0.7386 - val_loss: 0.4509 - val_accuracy: 0.7906 - lr: 8.0000e-07\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5257 - accuracy: 0.7475\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 37/40: loss=0.5264, accuracy=0.7467, val_loss=0.4392, val_accuracy=0.7906\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5264 - accuracy: 0.7467 - val_loss: 0.4392 - val_accuracy: 0.7906 - lr: 8.0000e-07\n",
      "Epoch 37: early stopping\n",
      "Validation accuracy: 0.7988410592079163\n",
      "\n",
      "Initial Training Combination 29/50: num_residual_blocks=4, dropout_rate=0.4, learning_rate=0.01, rotation_range=30, width_shift_range=0.1, height_shift_range=0.3, shear_range=0.2, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0077 - accuracy: 0.5079Epoch 1/40: loss=1.0067, accuracy=0.5083, val_loss=0.7136, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.0067 - accuracy: 0.5083 - val_loss: 0.7136 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7004 - accuracy: 0.4846Epoch 2/40: loss=0.7003, accuracy=0.4849, val_loss=0.6882, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7003 - accuracy: 0.4849 - val_loss: 0.6882 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.4969Epoch 3/40: loss=0.6947, accuracy=0.4969, val_loss=0.6916, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6947 - accuracy: 0.4969 - val_loss: 0.6916 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5037Epoch 4/40: loss=0.6949, accuracy=0.5037, val_loss=0.6854, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6949 - accuracy: 0.5037 - val_loss: 0.6854 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5002Epoch 5/40: loss=0.6945, accuracy=0.4998, val_loss=0.6977, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6945 - accuracy: 0.4998 - val_loss: 0.6977 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.5064Epoch 6/40: loss=0.6948, accuracy=0.5064, val_loss=0.7005, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6948 - accuracy: 0.5064 - val_loss: 0.7005 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4990Epoch 7/40: loss=0.6940, accuracy=0.4988, val_loss=0.6877, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6877 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.5050Epoch 8/40: loss=0.6948, accuracy=0.5052, val_loss=0.6780, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6948 - accuracy: 0.5052 - val_loss: 0.6780 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5242Epoch 9/40: loss=0.6940, accuracy=0.5242, val_loss=0.6985, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6940 - accuracy: 0.5242 - val_loss: 0.6985 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4680Epoch 10/40: loss=0.6934, accuracy=0.4694, val_loss=0.6889, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6934 - accuracy: 0.4694 - val_loss: 0.6889 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5073Epoch 11/40: loss=0.6945, accuracy=0.5070, val_loss=0.6988, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6945 - accuracy: 0.5070 - val_loss: 0.6988 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.4928Epoch 12/40: loss=0.6945, accuracy=0.4928, val_loss=0.6968, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6945 - accuracy: 0.4928 - val_loss: 0.6968 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.4971\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 13/40: loss=0.6943, accuracy=0.4971, val_loss=0.8207, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6943 - accuracy: 0.4971 - val_loss: 0.8207 - val_accuracy: 0.5985 - lr: 0.0100\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4990Epoch 14/40: loss=0.6937, accuracy=0.4990, val_loss=0.6934, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6937 - accuracy: 0.4990 - val_loss: 0.6934 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4938Epoch 15/40: loss=0.6934, accuracy=0.4938, val_loss=0.6930, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6934 - accuracy: 0.4938 - val_loss: 0.6930 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5023Epoch 16/40: loss=0.6934, accuracy=0.5021, val_loss=0.6945, val_accuracy=0.4015\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6934 - accuracy: 0.5021 - val_loss: 0.6945 - val_accuracy: 0.4015 - lr: 0.0020\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.4583Epoch 17/40: loss=0.6934, accuracy=0.4586, val_loss=0.6909, val_accuracy=0.5985\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6934 - accuracy: 0.4586 - val_loss: 0.6909 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5178\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 18/40: loss=0.6934, accuracy=0.5178, val_loss=0.6944, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6934 - accuracy: 0.5178 - val_loss: 0.6944 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 18: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 30/50: num_residual_blocks=3, dropout_rate=0.4, learning_rate=0.01, rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.2, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9913 - accuracy: 0.5122Epoch 1/40: loss=0.9913, accuracy=0.5122, val_loss=0.6797, val_accuracy=0.6250\n",
      "604/604 [==============================] - 16s 23ms/step - loss: 0.9913 - accuracy: 0.5122 - val_loss: 0.6797 - val_accuracy: 0.6250 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.4799Epoch 2/40: loss=0.7015, accuracy=0.4799, val_loss=0.6955, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7015 - accuracy: 0.4799 - val_loss: 0.6955 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.5112Epoch 3/40: loss=0.6969, accuracy=0.5110, val_loss=0.7117, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6969 - accuracy: 0.5110 - val_loss: 0.7117 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.5046Epoch 4/40: loss=0.6948, accuracy=0.5048, val_loss=0.6988, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6948 - accuracy: 0.5048 - val_loss: 0.6988 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.4913Epoch 5/40: loss=0.6943, accuracy=0.4909, val_loss=0.7041, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6943 - accuracy: 0.4909 - val_loss: 0.7041 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4848\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 6/40: loss=0.6955, accuracy=0.4849, val_loss=0.7007, val_accuracy=0.4023\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6955 - accuracy: 0.4849 - val_loss: 0.7007 - val_accuracy: 0.4023 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.4659Epoch 7/40: loss=0.6939, accuracy=0.4665, val_loss=0.6925, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6939 - accuracy: 0.4665 - val_loss: 0.6925 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4851Epoch 8/40: loss=0.6937, accuracy=0.4849, val_loss=0.6919, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6937 - accuracy: 0.4849 - val_loss: 0.6919 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5203Epoch 9/40: loss=0.6935, accuracy=0.5203, val_loss=0.6943, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6935 - accuracy: 0.5203 - val_loss: 0.6943 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4755Epoch 10/40: loss=0.6935, accuracy=0.4760, val_loss=0.6910, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6935 - accuracy: 0.4760 - val_loss: 0.6910 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4996\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11/40: loss=0.6934, accuracy=0.4996, val_loss=0.6907, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6934 - accuracy: 0.4996 - val_loss: 0.6907 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 11: early stopping\n",
      "Validation accuracy: 0.625\n",
      "\n",
      "Initial Training Combination 31/50: num_residual_blocks=4, dropout_rate=0.6, learning_rate=0.001, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.1, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9286 - accuracy: 0.5021Epoch 1/40: loss=0.9286, accuracy=0.5021, val_loss=0.7326, val_accuracy=0.5530\n",
      "604/604 [==============================] - 16s 23ms/step - loss: 0.9286 - accuracy: 0.5021 - val_loss: 0.7326 - val_accuracy: 0.5530 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7354 - accuracy: 0.5131Epoch 2/40: loss=0.7351, accuracy=0.5137, val_loss=0.6838, val_accuracy=0.5621\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7351 - accuracy: 0.5137 - val_loss: 0.6838 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7198 - accuracy: 0.5095Epoch 3/40: loss=0.7197, accuracy=0.5091, val_loss=0.6802, val_accuracy=0.5348\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7197 - accuracy: 0.5091 - val_loss: 0.6802 - val_accuracy: 0.5348 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.4969Epoch 4/40: loss=0.7193, accuracy=0.4967, val_loss=0.6919, val_accuracy=0.5058\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7193 - accuracy: 0.4967 - val_loss: 0.6919 - val_accuracy: 0.5058 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7097 - accuracy: 0.5168Epoch 5/40: loss=0.7098, accuracy=0.5168, val_loss=0.6643, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7098 - accuracy: 0.5168 - val_loss: 0.6643 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7094 - accuracy: 0.5060Epoch 6/40: loss=0.7094, accuracy=0.5060, val_loss=0.6906, val_accuracy=0.5232\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7094 - accuracy: 0.5060 - val_loss: 0.6906 - val_accuracy: 0.5232 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.5135Epoch 7/40: loss=0.7057, accuracy=0.5135, val_loss=1.1569, val_accuracy=0.5902\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7057 - accuracy: 0.5135 - val_loss: 1.1569 - val_accuracy: 0.5902 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7024 - accuracy: 0.5224Epoch 8/40: loss=0.7026, accuracy=0.5219, val_loss=0.6878, val_accuracy=0.5364\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7026 - accuracy: 0.5219 - val_loss: 0.6878 - val_accuracy: 0.5364 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7016 - accuracy: 0.5195Epoch 9/40: loss=0.7016, accuracy=0.5190, val_loss=0.6959, val_accuracy=0.4073\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7016 - accuracy: 0.5190 - val_loss: 0.6959 - val_accuracy: 0.4073 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.5014\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40: loss=0.7024, accuracy=0.5014, val_loss=0.9830, val_accuracy=0.5621\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7024 - accuracy: 0.5014 - val_loss: 0.9830 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6975 - accuracy: 0.5017Epoch 11/40: loss=0.6975, accuracy=0.5017, val_loss=0.7045, val_accuracy=0.5132\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6975 - accuracy: 0.5017 - val_loss: 0.7045 - val_accuracy: 0.5132 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5012Epoch 12/40: loss=0.6938, accuracy=0.5012, val_loss=0.6921, val_accuracy=0.5141\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6938 - accuracy: 0.5012 - val_loss: 0.6921 - val_accuracy: 0.5141 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5151Epoch 13/40: loss=0.6932, accuracy=0.5153, val_loss=0.7170, val_accuracy=0.5215\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6932 - accuracy: 0.5153 - val_loss: 0.7170 - val_accuracy: 0.5215 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5207Epoch 14/40: loss=0.6921, accuracy=0.5209, val_loss=0.8796, val_accuracy=0.5364\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6921 - accuracy: 0.5209 - val_loss: 0.8796 - val_accuracy: 0.5364 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.5235\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 15/40: loss=0.6911, accuracy=0.5236, val_loss=0.6900, val_accuracy=0.4487\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6911 - accuracy: 0.5236 - val_loss: 0.6900 - val_accuracy: 0.4487 - lr: 2.0000e-04\n",
      "Epoch 15: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 32/50: num_residual_blocks=1, dropout_rate=0.6, learning_rate=0.0005, rotation_range=10, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9748 - accuracy: 0.4973Epoch 1/40: loss=0.9742, accuracy=0.4977, val_loss=0.6930, val_accuracy=0.4950\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.9742 - accuracy: 0.4977 - val_loss: 0.6930 - val_accuracy: 0.4950 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7877 - accuracy: 0.5046Epoch 2/40: loss=0.7877, accuracy=0.5046, val_loss=0.7116, val_accuracy=0.4040\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7877 - accuracy: 0.5046 - val_loss: 0.7116 - val_accuracy: 0.4040 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7320 - accuracy: 0.4994Epoch 3/40: loss=0.7317, accuracy=0.4990, val_loss=0.6890, val_accuracy=0.5828\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7317 - accuracy: 0.4990 - val_loss: 0.6890 - val_accuracy: 0.5828 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7119 - accuracy: 0.5054Epoch 4/40: loss=0.7119, accuracy=0.5054, val_loss=0.6791, val_accuracy=0.6407\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7119 - accuracy: 0.5054 - val_loss: 0.6791 - val_accuracy: 0.6407 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5108Epoch 5/40: loss=0.7059, accuracy=0.5108, val_loss=0.6915, val_accuracy=0.5141\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7059 - accuracy: 0.5108 - val_loss: 0.6915 - val_accuracy: 0.5141 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.5118Epoch 6/40: loss=0.7011, accuracy=0.5118, val_loss=0.6908, val_accuracy=0.6374\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7011 - accuracy: 0.5118 - val_loss: 0.6908 - val_accuracy: 0.6374 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5420Epoch 7/40: loss=0.6926, accuracy=0.5420, val_loss=0.6961, val_accuracy=0.6747\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6926 - accuracy: 0.5420 - val_loss: 0.6961 - val_accuracy: 0.6747 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6641 - accuracy: 0.6022Epoch 8/40: loss=0.6639, accuracy=0.6022, val_loss=2.1910, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6639 - accuracy: 0.6022 - val_loss: 2.1910 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.6233\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.6436, accuracy=0.6242, val_loss=0.9514, val_accuracy=0.5919\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6436 - accuracy: 0.6242 - val_loss: 0.9514 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.6469Epoch 10/40: loss=0.6321, accuracy=0.6469, val_loss=0.6020, val_accuracy=0.7086\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6321 - accuracy: 0.6469 - val_loss: 0.6020 - val_accuracy: 0.7086 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6244 - accuracy: 0.6457Epoch 11/40: loss=0.6246, accuracy=0.6457, val_loss=0.5981, val_accuracy=0.6995\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6246 - accuracy: 0.6457 - val_loss: 0.5981 - val_accuracy: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.6505Epoch 12/40: loss=0.6167, accuracy=0.6505, val_loss=0.5765, val_accuracy=0.7243\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6167 - accuracy: 0.6505 - val_loss: 0.5765 - val_accuracy: 0.7243 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6197 - accuracy: 0.6553Epoch 13/40: loss=0.6201, accuracy=0.6544, val_loss=0.8038, val_accuracy=0.6209\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6201 - accuracy: 0.6544 - val_loss: 0.8038 - val_accuracy: 0.6209 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.6574Epoch 14/40: loss=0.6152, accuracy=0.6569, val_loss=0.5915, val_accuracy=0.7169\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6152 - accuracy: 0.6569 - val_loss: 0.5915 - val_accuracy: 0.7169 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6630Epoch 15/40: loss=0.6122, accuracy=0.6620, val_loss=0.6279, val_accuracy=0.6796\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6122 - accuracy: 0.6620 - val_loss: 0.6279 - val_accuracy: 0.6796 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6079 - accuracy: 0.6658Epoch 16/40: loss=0.6075, accuracy=0.6658, val_loss=0.6088, val_accuracy=0.7086\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6075 - accuracy: 0.6658 - val_loss: 0.6088 - val_accuracy: 0.7086 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.6769\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 17/40: loss=0.6019, accuracy=0.6769, val_loss=0.6078, val_accuracy=0.7359\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6019 - accuracy: 0.6769 - val_loss: 0.6078 - val_accuracy: 0.7359 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.6658Epoch 18/40: loss=0.6045, accuracy=0.6658, val_loss=0.5438, val_accuracy=0.7533\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6045 - accuracy: 0.6658 - val_loss: 0.5438 - val_accuracy: 0.7533 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.6753Epoch 19/40: loss=0.5911, accuracy=0.6753, val_loss=0.5361, val_accuracy=0.7434\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5911 - accuracy: 0.6753 - val_loss: 0.5361 - val_accuracy: 0.7434 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5950 - accuracy: 0.6872Epoch 20/40: loss=0.5953, accuracy=0.6871, val_loss=0.5392, val_accuracy=0.7591\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5953 - accuracy: 0.6871 - val_loss: 0.5392 - val_accuracy: 0.7591 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6010 - accuracy: 0.6724Epoch 21/40: loss=0.6009, accuracy=0.6718, val_loss=0.5399, val_accuracy=0.7550\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6009 - accuracy: 0.6718 - val_loss: 0.5399 - val_accuracy: 0.7550 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.6774Epoch 22/40: loss=0.5924, accuracy=0.6776, val_loss=0.5296, val_accuracy=0.7517\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5924 - accuracy: 0.6776 - val_loss: 0.5296 - val_accuracy: 0.7517 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5913 - accuracy: 0.6828Epoch 23/40: loss=0.5912, accuracy=0.6829, val_loss=0.5408, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5912 - accuracy: 0.6829 - val_loss: 0.5408 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5908 - accuracy: 0.6818Epoch 24/40: loss=0.5909, accuracy=0.6815, val_loss=0.5474, val_accuracy=0.7525\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5909 - accuracy: 0.6815 - val_loss: 0.5474 - val_accuracy: 0.7525 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5885 - accuracy: 0.6798Epoch 25/40: loss=0.5885, accuracy=0.6798, val_loss=0.5245, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5885 - accuracy: 0.6798 - val_loss: 0.5245 - val_accuracy: 0.7624 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5927 - accuracy: 0.6758Epoch 26/40: loss=0.5925, accuracy=0.6761, val_loss=0.5423, val_accuracy=0.7575\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5925 - accuracy: 0.6761 - val_loss: 0.5423 - val_accuracy: 0.7575 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.6751Epoch 27/40: loss=0.5943, accuracy=0.6751, val_loss=0.5143, val_accuracy=0.7591\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5943 - accuracy: 0.6751 - val_loss: 0.5143 - val_accuracy: 0.7591 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.6800Epoch 28/40: loss=0.5897, accuracy=0.6805, val_loss=0.5461, val_accuracy=0.7550\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5897 - accuracy: 0.6805 - val_loss: 0.5461 - val_accuracy: 0.7550 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.6904Epoch 29/40: loss=0.5808, accuracy=0.6904, val_loss=0.5148, val_accuracy=0.7550\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5808 - accuracy: 0.6904 - val_loss: 0.5148 - val_accuracy: 0.7550 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.6873Epoch 30/40: loss=0.5823, accuracy=0.6877, val_loss=0.5160, val_accuracy=0.7583\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5823 - accuracy: 0.6877 - val_loss: 0.5160 - val_accuracy: 0.7583 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5815 - accuracy: 0.6868Epoch 31/40: loss=0.5819, accuracy=0.6863, val_loss=0.5179, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5819 - accuracy: 0.6863 - val_loss: 0.5179 - val_accuracy: 0.7608 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5835 - accuracy: 0.6879\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 32/40: loss=0.5834, accuracy=0.6881, val_loss=0.5237, val_accuracy=0.7666\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5834 - accuracy: 0.6881 - val_loss: 0.5237 - val_accuracy: 0.7666 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.6920Epoch 33/40: loss=0.5820, accuracy=0.6925, val_loss=0.5140, val_accuracy=0.7657\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5820 - accuracy: 0.6925 - val_loss: 0.5140 - val_accuracy: 0.7657 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5803 - accuracy: 0.6844Epoch 34/40: loss=0.5800, accuracy=0.6842, val_loss=0.5162, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5800 - accuracy: 0.6842 - val_loss: 0.5162 - val_accuracy: 0.7649 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5763 - accuracy: 0.6859Epoch 35/40: loss=0.5763, accuracy=0.6861, val_loss=0.5192, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5763 - accuracy: 0.6861 - val_loss: 0.5192 - val_accuracy: 0.7649 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.6898Epoch 36/40: loss=0.5822, accuracy=0.6898, val_loss=0.5275, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5822 - accuracy: 0.6898 - val_loss: 0.5275 - val_accuracy: 0.7732 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.6850Epoch 37/40: loss=0.5821, accuracy=0.6852, val_loss=0.5222, val_accuracy=0.7682\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5821 - accuracy: 0.6852 - val_loss: 0.5222 - val_accuracy: 0.7682 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 0.6865\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Epoch 38/40: loss=0.5843, accuracy=0.6867, val_loss=0.5189, val_accuracy=0.7715\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5843 - accuracy: 0.6867 - val_loss: 0.5189 - val_accuracy: 0.7715 - lr: 4.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.6929Epoch 39/40: loss=0.5787, accuracy=0.6929, val_loss=0.5136, val_accuracy=0.7690\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5787 - accuracy: 0.6929 - val_loss: 0.5136 - val_accuracy: 0.7690 - lr: 8.0000e-07\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.6902Epoch 40/40: loss=0.5829, accuracy=0.6902, val_loss=0.5144, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5829 - accuracy: 0.6902 - val_loss: 0.5144 - val_accuracy: 0.7690 - lr: 8.0000e-07\n",
      "Validation accuracy: 0.7731788158416748\n",
      "\n",
      "Initial Training Combination 33/50: num_residual_blocks=5, dropout_rate=0.4, learning_rate=0.01, rotation_range=20, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.3, zoom_range=0.2, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0261 - accuracy: 0.5335Epoch 1/40: loss=1.0261, accuracy=0.5335, val_loss=0.6524, val_accuracy=0.6656\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 1.0261 - accuracy: 0.5335 - val_loss: 0.6524 - val_accuracy: 0.6656 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6836 - accuracy: 0.5613Epoch 2/40: loss=0.6834, accuracy=0.5617, val_loss=0.6022, val_accuracy=0.6838\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6834 - accuracy: 0.5617 - val_loss: 0.6022 - val_accuracy: 0.6838 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.5392Epoch 3/40: loss=0.6794, accuracy=0.5383, val_loss=0.6787, val_accuracy=0.4843\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6794 - accuracy: 0.5383 - val_loss: 0.6787 - val_accuracy: 0.4843 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6951 - accuracy: 0.4911Epoch 4/40: loss=0.6951, accuracy=0.4907, val_loss=0.6973, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6951 - accuracy: 0.4907 - val_loss: 0.6973 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6963 - accuracy: 0.4847Epoch 5/40: loss=0.6962, accuracy=0.4853, val_loss=0.6833, val_accuracy=0.6043\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6962 - accuracy: 0.4853 - val_loss: 0.6833 - val_accuracy: 0.6043 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.4967Epoch 6/40: loss=0.6942, accuracy=0.4963, val_loss=0.7014, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6942 - accuracy: 0.4963 - val_loss: 0.7014 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5172\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 7/40: loss=0.6950, accuracy=0.5172, val_loss=0.7136, val_accuracy=0.4007\n",
      "604/604 [==============================] - 16s 27ms/step - loss: 0.6950 - accuracy: 0.5172 - val_loss: 0.7136 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.4228Epoch 8/40: loss=0.6944, accuracy=0.4228, val_loss=0.6934, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6944 - accuracy: 0.4228 - val_loss: 0.6934 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5259Epoch 9/40: loss=0.6932, accuracy=0.5259, val_loss=0.6956, val_accuracy=0.4015\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6932 - accuracy: 0.5259 - val_loss: 0.6956 - val_accuracy: 0.4015 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4992Epoch 10/40: loss=0.6938, accuracy=0.4990, val_loss=0.6955, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6938 - accuracy: 0.4990 - val_loss: 0.6955 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5246Epoch 11/40: loss=0.6934, accuracy=0.5246, val_loss=0.6940, val_accuracy=0.4007\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6934 - accuracy: 0.5246 - val_loss: 0.6940 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4880\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 12/40: loss=0.6935, accuracy=0.4878, val_loss=0.6963, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6935 - accuracy: 0.4878 - val_loss: 0.6963 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12: early stopping\n",
      "Validation accuracy: 0.6837748289108276\n",
      "\n",
      "Initial Training Combination 34/50: num_residual_blocks=1, dropout_rate=0.5, learning_rate=0.01, rotation_range=20, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0120 - accuracy: 0.4965Epoch 1/40: loss=1.0110, accuracy=0.4961, val_loss=0.7477, val_accuracy=0.4495\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 1.0110 - accuracy: 0.4961 - val_loss: 0.7477 - val_accuracy: 0.4495 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7016 - accuracy: 0.4944Epoch 2/40: loss=0.7015, accuracy=0.4946, val_loss=0.6961, val_accuracy=0.5770\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7015 - accuracy: 0.4946 - val_loss: 0.6961 - val_accuracy: 0.5770 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6987 - accuracy: 0.4832Epoch 3/40: loss=0.6988, accuracy=0.4828, val_loss=0.6957, val_accuracy=0.5919\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6988 - accuracy: 0.4828 - val_loss: 0.6957 - val_accuracy: 0.5919 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.5035Epoch 4/40: loss=0.6973, accuracy=0.5035, val_loss=1.2448, val_accuracy=0.5960\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6973 - accuracy: 0.5035 - val_loss: 1.2448 - val_accuracy: 0.5960 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.4915Epoch 5/40: loss=0.6958, accuracy=0.4913, val_loss=1.3080, val_accuracy=0.3998\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6958 - accuracy: 0.4913 - val_loss: 1.3080 - val_accuracy: 0.3998 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.4919Epoch 6/40: loss=0.6954, accuracy=0.4921, val_loss=0.9598, val_accuracy=0.3990\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6954 - accuracy: 0.4921 - val_loss: 0.9598 - val_accuracy: 0.3990 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6949 - accuracy: 0.4880Epoch 7/40: loss=0.6948, accuracy=0.4884, val_loss=2.0036, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6948 - accuracy: 0.4884 - val_loss: 2.0036 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5006\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/40: loss=0.6939, accuracy=0.5008, val_loss=2.5788, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6939 - accuracy: 0.5008 - val_loss: 2.5788 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5191Epoch 9/40: loss=0.6934, accuracy=0.5195, val_loss=1.8830, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6934 - accuracy: 0.5195 - val_loss: 1.8830 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5475Epoch 10/40: loss=0.6933, accuracy=0.5470, val_loss=2.7814, val_accuracy=0.3965\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6933 - accuracy: 0.5470 - val_loss: 2.7814 - val_accuracy: 0.3965 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.4705Epoch 11/40: loss=0.6936, accuracy=0.4702, val_loss=3.2206, val_accuracy=0.4015\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6936 - accuracy: 0.4702 - val_loss: 3.2206 - val_accuracy: 0.4015 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5245Epoch 12/40: loss=0.6932, accuracy=0.5236, val_loss=1.2227, val_accuracy=0.3965\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6932 - accuracy: 0.5236 - val_loss: 1.2227 - val_accuracy: 0.3965 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4770\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 13/40: loss=0.6934, accuracy=0.4770, val_loss=2.7546, val_accuracy=0.6002\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6934 - accuracy: 0.4770 - val_loss: 2.7546 - val_accuracy: 0.6002 - lr: 0.0020\n",
      "Epoch 13: early stopping\n",
      "Validation accuracy: 0.6001655459403992\n",
      "\n",
      "Initial Training Combination 35/50: num_residual_blocks=5, dropout_rate=0.5, learning_rate=0.0005, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9281 - accuracy: 0.5298Epoch 1/40: loss=0.9281, accuracy=0.5298, val_loss=0.6406, val_accuracy=0.6126\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 0.9281 - accuracy: 0.5298 - val_loss: 0.6406 - val_accuracy: 0.6126 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7722 - accuracy: 0.5417Epoch 2/40: loss=0.7732, accuracy=0.5414, val_loss=0.7827, val_accuracy=0.5464\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7732 - accuracy: 0.5414 - val_loss: 0.7827 - val_accuracy: 0.5464 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6891 - accuracy: 0.5939Epoch 3/40: loss=0.6890, accuracy=0.5940, val_loss=0.5963, val_accuracy=0.6921\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6890 - accuracy: 0.5940 - val_loss: 0.5963 - val_accuracy: 0.6921 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.6469Epoch 4/40: loss=0.6303, accuracy=0.6469, val_loss=0.8433, val_accuracy=0.5621\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6303 - accuracy: 0.6469 - val_loss: 0.8433 - val_accuracy: 0.5621 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6074 - accuracy: 0.6743Epoch 5/40: loss=0.6075, accuracy=0.6743, val_loss=0.8409, val_accuracy=0.6200\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6075 - accuracy: 0.6743 - val_loss: 0.8409 - val_accuracy: 0.6200 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.6949Epoch 6/40: loss=0.5937, accuracy=0.6947, val_loss=1.6058, val_accuracy=0.4760\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5937 - accuracy: 0.6947 - val_loss: 1.6058 - val_accuracy: 0.4760 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7247Epoch 7/40: loss=0.5676, accuracy=0.7252, val_loss=0.6442, val_accuracy=0.7459\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5676 - accuracy: 0.7252 - val_loss: 0.6442 - val_accuracy: 0.7459 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5721 - accuracy: 0.7141\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/40: loss=0.5720, accuracy=0.7144, val_loss=0.9244, val_accuracy=0.6391\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5720 - accuracy: 0.7144 - val_loss: 0.9244 - val_accuracy: 0.6391 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.7262Epoch 9/40: loss=0.5565, accuracy=0.7262, val_loss=0.4887, val_accuracy=0.7583\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5565 - accuracy: 0.7262 - val_loss: 0.4887 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.7319Epoch 10/40: loss=0.5400, accuracy=0.7322, val_loss=0.4962, val_accuracy=0.7839\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5400 - accuracy: 0.7322 - val_loss: 0.4962 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.7454Epoch 11/40: loss=0.5192, accuracy=0.7454, val_loss=0.7694, val_accuracy=0.6647\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5192 - accuracy: 0.7454 - val_loss: 0.7694 - val_accuracy: 0.6647 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.7436Epoch 12/40: loss=0.5278, accuracy=0.7436, val_loss=0.4522, val_accuracy=0.7972\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5278 - accuracy: 0.7436 - val_loss: 0.4522 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.7428Epoch 13/40: loss=0.5277, accuracy=0.7428, val_loss=0.4580, val_accuracy=0.8121\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5277 - accuracy: 0.7428 - val_loss: 0.4580 - val_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7546Epoch 14/40: loss=0.5093, accuracy=0.7546, val_loss=0.6626, val_accuracy=0.6838\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5093 - accuracy: 0.7546 - val_loss: 0.6626 - val_accuracy: 0.6838 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5128 - accuracy: 0.7577Epoch 15/40: loss=0.5125, accuracy=0.7581, val_loss=0.4785, val_accuracy=0.7790\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5125 - accuracy: 0.7581 - val_loss: 0.4785 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.7587Epoch 16/40: loss=0.5076, accuracy=0.7587, val_loss=0.4617, val_accuracy=0.7997\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5076 - accuracy: 0.7587 - val_loss: 0.4617 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5044 - accuracy: 0.7525Epoch 17/40: loss=0.5039, accuracy=0.7529, val_loss=0.4463, val_accuracy=0.8055\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5039 - accuracy: 0.7529 - val_loss: 0.4463 - val_accuracy: 0.8055 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7570Epoch 18/40: loss=0.5048, accuracy=0.7570, val_loss=0.4342, val_accuracy=0.8063\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5048 - accuracy: 0.7570 - val_loss: 0.4342 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.7560Epoch 19/40: loss=0.5052, accuracy=0.7566, val_loss=0.4443, val_accuracy=0.7964\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5052 - accuracy: 0.7566 - val_loss: 0.4443 - val_accuracy: 0.7964 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5033 - accuracy: 0.7539Epoch 20/40: loss=0.5033, accuracy=0.7539, val_loss=0.4213, val_accuracy=0.8022\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5033 - accuracy: 0.7539 - val_loss: 0.4213 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4933 - accuracy: 0.7637Epoch 21/40: loss=0.4933, accuracy=0.7637, val_loss=0.5257, val_accuracy=0.7392\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4933 - accuracy: 0.7637 - val_loss: 0.5257 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.7635Epoch 22/40: loss=0.4866, accuracy=0.7637, val_loss=0.4172, val_accuracy=0.8129\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4866 - accuracy: 0.7637 - val_loss: 0.4172 - val_accuracy: 0.8129 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.7655Epoch 23/40: loss=0.4868, accuracy=0.7657, val_loss=0.6706, val_accuracy=0.6705\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4868 - accuracy: 0.7657 - val_loss: 0.6706 - val_accuracy: 0.6705 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.7726Epoch 24/40: loss=0.4850, accuracy=0.7726, val_loss=0.4364, val_accuracy=0.8088\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.4364 - val_accuracy: 0.8088 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.7684Epoch 25/40: loss=0.4814, accuracy=0.7684, val_loss=0.5346, val_accuracy=0.7682\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4814 - accuracy: 0.7684 - val_loss: 0.5346 - val_accuracy: 0.7682 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.7679Epoch 26/40: loss=0.4841, accuracy=0.7674, val_loss=0.4697, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4697 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.7724Epoch 27/40: loss=0.4723, accuracy=0.7724, val_loss=0.4085, val_accuracy=0.8171\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4723 - accuracy: 0.7724 - val_loss: 0.4085 - val_accuracy: 0.8171 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.7771Epoch 28/40: loss=0.4758, accuracy=0.7771, val_loss=0.5750, val_accuracy=0.7641\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4758 - accuracy: 0.7771 - val_loss: 0.5750 - val_accuracy: 0.7641 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7857Epoch 29/40: loss=0.4682, accuracy=0.7856, val_loss=0.6328, val_accuracy=0.7177\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4682 - accuracy: 0.7856 - val_loss: 0.6328 - val_accuracy: 0.7177 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.7776Epoch 30/40: loss=0.4740, accuracy=0.7777, val_loss=0.4521, val_accuracy=0.7906\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4740 - accuracy: 0.7777 - val_loss: 0.4521 - val_accuracy: 0.7906 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.7855Epoch 31/40: loss=0.4605, accuracy=0.7856, val_loss=0.3962, val_accuracy=0.8286\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4605 - accuracy: 0.7856 - val_loss: 0.3962 - val_accuracy: 0.8286 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7893Epoch 32/40: loss=0.4601, accuracy=0.7893, val_loss=0.4685, val_accuracy=0.8063\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4601 - accuracy: 0.7893 - val_loss: 0.4685 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7772Epoch 33/40: loss=0.4659, accuracy=0.7769, val_loss=0.4302, val_accuracy=0.8005\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4659 - accuracy: 0.7769 - val_loss: 0.4302 - val_accuracy: 0.8005 - lr: 1.0000e-04\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4556 - accuracy: 0.7886Epoch 34/40: loss=0.4554, accuracy=0.7887, val_loss=0.4798, val_accuracy=0.7964\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4554 - accuracy: 0.7887 - val_loss: 0.4798 - val_accuracy: 0.7964 - lr: 1.0000e-04\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.7933Epoch 35/40: loss=0.4492, accuracy=0.7933, val_loss=0.5375, val_accuracy=0.7616\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4492 - accuracy: 0.7933 - val_loss: 0.5375 - val_accuracy: 0.7616 - lr: 1.0000e-04\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.7930\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 36/40: loss=0.4539, accuracy=0.7930, val_loss=0.4116, val_accuracy=0.8262\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4539 - accuracy: 0.7930 - val_loss: 0.4116 - val_accuracy: 0.8262 - lr: 1.0000e-04\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4390 - accuracy: 0.7919Epoch 37/40: loss=0.4392, accuracy=0.7918, val_loss=0.4038, val_accuracy=0.8187\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4392 - accuracy: 0.7918 - val_loss: 0.4038 - val_accuracy: 0.8187 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4345 - accuracy: 0.7973Epoch 38/40: loss=0.4344, accuracy=0.7974, val_loss=0.4080, val_accuracy=0.8303\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4344 - accuracy: 0.7974 - val_loss: 0.4080 - val_accuracy: 0.8303 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.7995Epoch 39/40: loss=0.4362, accuracy=0.7995, val_loss=0.4000, val_accuracy=0.8212\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4362 - accuracy: 0.7995 - val_loss: 0.4000 - val_accuracy: 0.8212 - lr: 2.0000e-05\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8130Epoch 40/40: loss=0.4136, accuracy=0.8131, val_loss=0.4641, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4136 - accuracy: 0.8131 - val_loss: 0.4641 - val_accuracy: 0.7823 - lr: 2.0000e-05\n",
      "Validation accuracy: 0.8302980065345764\n",
      "\n",
      "Initial Training Combination 36/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.0005, rotation_range=20, width_shift_range=0.3, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.4930Epoch 1/40: loss=1.0101, accuracy=0.4930, val_loss=0.7016, val_accuracy=0.4967\n",
      "604/604 [==============================] - 12s 18ms/step - loss: 1.0101 - accuracy: 0.4930 - val_loss: 0.7016 - val_accuracy: 0.4967 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.5077Epoch 2/40: loss=0.8023, accuracy=0.5077, val_loss=0.8335, val_accuracy=0.4288\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.8023 - accuracy: 0.5077 - val_loss: 0.8335 - val_accuracy: 0.4288 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7316 - accuracy: 0.5209Epoch 3/40: loss=0.7316, accuracy=0.5209, val_loss=0.6455, val_accuracy=0.6358\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7316 - accuracy: 0.5209 - val_loss: 0.6455 - val_accuracy: 0.6358 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6962 - accuracy: 0.5513Epoch 4/40: loss=0.6963, accuracy=0.5507, val_loss=1.3903, val_accuracy=0.4238\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6963 - accuracy: 0.5507 - val_loss: 1.3903 - val_accuracy: 0.4238 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.6022Epoch 5/40: loss=0.6650, accuracy=0.6022, val_loss=1.3941, val_accuracy=0.4098\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6650 - accuracy: 0.6022 - val_loss: 1.3941 - val_accuracy: 0.4098 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6500 - accuracy: 0.6236Epoch 6/40: loss=0.6500, accuracy=0.6236, val_loss=0.6351, val_accuracy=0.6854\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6500 - accuracy: 0.6236 - val_loss: 0.6351 - val_accuracy: 0.6854 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.6428Epoch 7/40: loss=0.6349, accuracy=0.6428, val_loss=3.7034, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6349 - accuracy: 0.6428 - val_loss: 3.7034 - val_accuracy: 0.4007 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.6437Epoch 8/40: loss=0.6238, accuracy=0.6438, val_loss=0.9290, val_accuracy=0.5637\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6238 - accuracy: 0.6438 - val_loss: 0.9290 - val_accuracy: 0.5637 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.6568Epoch 9/40: loss=0.6187, accuracy=0.6558, val_loss=0.8062, val_accuracy=0.6896\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6187 - accuracy: 0.6558 - val_loss: 0.8062 - val_accuracy: 0.6896 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6538Epoch 10/40: loss=0.6203, accuracy=0.6538, val_loss=2.5512, val_accuracy=0.4089\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.6203 - accuracy: 0.6538 - val_loss: 2.5512 - val_accuracy: 0.4089 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.6636\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 11/40: loss=0.6081, accuracy=0.6635, val_loss=0.9320, val_accuracy=0.6076\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6081 - accuracy: 0.6635 - val_loss: 0.9320 - val_accuracy: 0.6076 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5826 - accuracy: 0.6879Epoch 12/40: loss=0.5822, accuracy=0.6883, val_loss=0.6173, val_accuracy=0.7459\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5822 - accuracy: 0.6883 - val_loss: 0.6173 - val_accuracy: 0.7459 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.6925Epoch 13/40: loss=0.5721, accuracy=0.6925, val_loss=0.4898, val_accuracy=0.7781\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5721 - accuracy: 0.6925 - val_loss: 0.4898 - val_accuracy: 0.7781 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.6964Epoch 14/40: loss=0.5590, accuracy=0.6968, val_loss=0.5143, val_accuracy=0.7757\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5590 - accuracy: 0.6968 - val_loss: 0.5143 - val_accuracy: 0.7757 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.7040Epoch 15/40: loss=0.5618, accuracy=0.7045, val_loss=0.6307, val_accuracy=0.7268\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5618 - accuracy: 0.7045 - val_loss: 0.6307 - val_accuracy: 0.7268 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.6937Epoch 16/40: loss=0.5691, accuracy=0.6937, val_loss=0.5120, val_accuracy=0.7591\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5691 - accuracy: 0.6937 - val_loss: 0.5120 - val_accuracy: 0.7591 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5607 - accuracy: 0.7044Epoch 17/40: loss=0.5605, accuracy=0.7045, val_loss=0.5895, val_accuracy=0.7210\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5605 - accuracy: 0.7045 - val_loss: 0.5895 - val_accuracy: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7085\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 18/40: loss=0.5537, accuracy=0.7082, val_loss=0.5363, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5537 - accuracy: 0.7082 - val_loss: 0.5363 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5346 - accuracy: 0.7199Epoch 19/40: loss=0.5347, accuracy=0.7198, val_loss=0.4811, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5347 - accuracy: 0.7198 - val_loss: 0.4811 - val_accuracy: 0.7897 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.7225Epoch 20/40: loss=0.5401, accuracy=0.7227, val_loss=0.4823, val_accuracy=0.7914\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5401 - accuracy: 0.7227 - val_loss: 0.4823 - val_accuracy: 0.7914 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5417 - accuracy: 0.7201Epoch 21/40: loss=0.5413, accuracy=0.7200, val_loss=0.4861, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5413 - accuracy: 0.7200 - val_loss: 0.4861 - val_accuracy: 0.7873 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.7185Epoch 22/40: loss=0.5369, accuracy=0.7185, val_loss=0.4645, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5369 - accuracy: 0.7185 - val_loss: 0.4645 - val_accuracy: 0.7947 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5475 - accuracy: 0.7179Epoch 23/40: loss=0.5474, accuracy=0.7179, val_loss=0.4724, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5474 - accuracy: 0.7179 - val_loss: 0.4724 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7206Epoch 24/40: loss=0.5384, accuracy=0.7206, val_loss=0.4853, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5384 - accuracy: 0.7206 - val_loss: 0.4853 - val_accuracy: 0.7815 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7237Epoch 25/40: loss=0.5371, accuracy=0.7237, val_loss=0.4955, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5371 - accuracy: 0.7237 - val_loss: 0.4955 - val_accuracy: 0.7922 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.7279Epoch 26/40: loss=0.5332, accuracy=0.7279, val_loss=0.4763, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5332 - accuracy: 0.7279 - val_loss: 0.4763 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7202\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 27/40: loss=0.5396, accuracy=0.7202, val_loss=0.4728, val_accuracy=0.7873\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5396 - accuracy: 0.7202 - val_loss: 0.4728 - val_accuracy: 0.7873 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.7235Epoch 28/40: loss=0.5354, accuracy=0.7235, val_loss=0.4719, val_accuracy=0.7864\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5354 - accuracy: 0.7235 - val_loss: 0.4719 - val_accuracy: 0.7864 - lr: 4.0000e-06\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7309Epoch 29/40: loss=0.5303, accuracy=0.7312, val_loss=0.4677, val_accuracy=0.7939\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5303 - accuracy: 0.7312 - val_loss: 0.4677 - val_accuracy: 0.7939 - lr: 4.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.7181Epoch 30/40: loss=0.5392, accuracy=0.7179, val_loss=0.4662, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5392 - accuracy: 0.7179 - val_loss: 0.4662 - val_accuracy: 0.7889 - lr: 4.0000e-06\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.7262Epoch 31/40: loss=0.5383, accuracy=0.7262, val_loss=0.4660, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5383 - accuracy: 0.7262 - val_loss: 0.4660 - val_accuracy: 0.7906 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.7294\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.5344, accuracy=0.7297, val_loss=0.4658, val_accuracy=0.7922\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5344 - accuracy: 0.7297 - val_loss: 0.4658 - val_accuracy: 0.7922 - lr: 4.0000e-06\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.7955297827720642\n",
      "\n",
      "Initial Training Combination 37/50: num_residual_blocks=2, dropout_rate=0.4, learning_rate=0.001, rotation_range=10, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.3, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8447 - accuracy: 0.5732Epoch 1/40: loss=0.8442, accuracy=0.5735, val_loss=1.1374, val_accuracy=0.6465\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.8442 - accuracy: 0.5735 - val_loss: 1.1374 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.6579Epoch 2/40: loss=0.6360, accuracy=0.6579, val_loss=0.8043, val_accuracy=0.5116\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6360 - accuracy: 0.6579 - val_loss: 0.8043 - val_accuracy: 0.5116 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.6809Epoch 3/40: loss=0.6061, accuracy=0.6805, val_loss=0.6107, val_accuracy=0.7152\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6061 - accuracy: 0.6805 - val_loss: 0.6107 - val_accuracy: 0.7152 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5910 - accuracy: 0.6852Epoch 4/40: loss=0.5902, accuracy=0.6858, val_loss=0.7114, val_accuracy=0.6697\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5902 - accuracy: 0.6858 - val_loss: 0.7114 - val_accuracy: 0.6697 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.6856Epoch 5/40: loss=0.5943, accuracy=0.6856, val_loss=1.1080, val_accuracy=0.5571\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5943 - accuracy: 0.6856 - val_loss: 1.1080 - val_accuracy: 0.5571 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5869 - accuracy: 0.6949Epoch 6/40: loss=0.5872, accuracy=0.6950, val_loss=0.7780, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5872 - accuracy: 0.6950 - val_loss: 0.7780 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.7044Epoch 7/40: loss=0.5809, accuracy=0.7043, val_loss=2.0114, val_accuracy=0.4321\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5809 - accuracy: 0.7043 - val_loss: 2.0114 - val_accuracy: 0.4321 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5741 - accuracy: 0.7030\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.5741, accuracy=0.7034, val_loss=0.7633, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5741 - accuracy: 0.7034 - val_loss: 0.7633 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7193Epoch 9/40: loss=0.5499, accuracy=0.7198, val_loss=0.5698, val_accuracy=0.7417\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5499 - accuracy: 0.7198 - val_loss: 0.5698 - val_accuracy: 0.7417 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.7273Epoch 10/40: loss=0.5451, accuracy=0.7279, val_loss=0.5381, val_accuracy=0.7467\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5451 - accuracy: 0.7279 - val_loss: 0.5381 - val_accuracy: 0.7467 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7311Epoch 11/40: loss=0.5370, accuracy=0.7316, val_loss=0.7556, val_accuracy=0.6606\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5370 - accuracy: 0.7316 - val_loss: 0.7556 - val_accuracy: 0.6606 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.7305Epoch 12/40: loss=0.5369, accuracy=0.7301, val_loss=0.5217, val_accuracy=0.7666\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5369 - accuracy: 0.7301 - val_loss: 0.5217 - val_accuracy: 0.7666 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5340 - accuracy: 0.7355Epoch 13/40: loss=0.5335, accuracy=0.7359, val_loss=0.7356, val_accuracy=0.6515\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5335 - accuracy: 0.7359 - val_loss: 0.7356 - val_accuracy: 0.6515 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.7436Epoch 14/40: loss=0.5258, accuracy=0.7436, val_loss=0.4838, val_accuracy=0.7881\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5258 - accuracy: 0.7436 - val_loss: 0.4838 - val_accuracy: 0.7881 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.7401Epoch 15/40: loss=0.5162, accuracy=0.7401, val_loss=0.4919, val_accuracy=0.7425\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5162 - accuracy: 0.7401 - val_loss: 0.4919 - val_accuracy: 0.7425 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.7450Epoch 16/40: loss=0.5231, accuracy=0.7444, val_loss=0.5024, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5231 - accuracy: 0.7444 - val_loss: 0.5024 - val_accuracy: 0.7690 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.7514Epoch 17/40: loss=0.5237, accuracy=0.7514, val_loss=0.6330, val_accuracy=0.7450\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5237 - accuracy: 0.7514 - val_loss: 0.6330 - val_accuracy: 0.7450 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.7423Epoch 18/40: loss=0.5163, accuracy=0.7428, val_loss=0.5733, val_accuracy=0.7649\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5163 - accuracy: 0.7428 - val_loss: 0.5733 - val_accuracy: 0.7649 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7581\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/40: loss=0.5080, accuracy=0.7581, val_loss=0.5293, val_accuracy=0.7492\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5080 - accuracy: 0.7581 - val_loss: 0.5293 - val_accuracy: 0.7492 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4971 - accuracy: 0.7539Epoch 20/40: loss=0.4971, accuracy=0.7539, val_loss=0.5700, val_accuracy=0.7624\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4971 - accuracy: 0.7539 - val_loss: 0.5700 - val_accuracy: 0.7624 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.7556Epoch 21/40: loss=0.5010, accuracy=0.7556, val_loss=0.5871, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5010 - accuracy: 0.7556 - val_loss: 0.5871 - val_accuracy: 0.7517 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.7616Epoch 22/40: loss=0.5011, accuracy=0.7618, val_loss=0.5950, val_accuracy=0.7475\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5011 - accuracy: 0.7618 - val_loss: 0.5950 - val_accuracy: 0.7475 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.7573Epoch 23/40: loss=0.5018, accuracy=0.7575, val_loss=0.5736, val_accuracy=0.7666\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5018 - accuracy: 0.7575 - val_loss: 0.5736 - val_accuracy: 0.7666 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.7688\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 24/40: loss=0.4855, accuracy=0.7688, val_loss=0.5708, val_accuracy=0.7690\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4855 - accuracy: 0.7688 - val_loss: 0.5708 - val_accuracy: 0.7690 - lr: 4.0000e-05\n",
      "Epoch 24: early stopping\n",
      "Validation accuracy: 0.7880794405937195\n",
      "\n",
      "Initial Training Combination 38/50: num_residual_blocks=4, dropout_rate=0.5, learning_rate=0.0005, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.5145Epoch 1/40: loss=0.9513, accuracy=0.5145, val_loss=0.8328, val_accuracy=0.6225\n",
      "604/604 [==============================] - 15s 20ms/step - loss: 0.9513 - accuracy: 0.5145 - val_loss: 0.8328 - val_accuracy: 0.6225 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7482 - accuracy: 0.5834Epoch 2/40: loss=0.7482, accuracy=0.5834, val_loss=0.9309, val_accuracy=0.6134\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.7482 - accuracy: 0.5834 - val_loss: 0.9309 - val_accuracy: 0.6134 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6401 - accuracy: 0.6615Epoch 3/40: loss=0.6397, accuracy=0.6618, val_loss=0.4801, val_accuracy=0.7690\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6397 - accuracy: 0.6618 - val_loss: 0.4801 - val_accuracy: 0.7690 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5881 - accuracy: 0.6932Epoch 4/40: loss=0.5881, accuracy=0.6931, val_loss=0.5552, val_accuracy=0.7475\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5881 - accuracy: 0.6931 - val_loss: 0.5552 - val_accuracy: 0.7475 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.7191Epoch 5/40: loss=0.5630, accuracy=0.7192, val_loss=0.4694, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5630 - accuracy: 0.7192 - val_loss: 0.4694 - val_accuracy: 0.7848 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5501 - accuracy: 0.7274Epoch 6/40: loss=0.5498, accuracy=0.7276, val_loss=0.8491, val_accuracy=0.6598\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5498 - accuracy: 0.7276 - val_loss: 0.8491 - val_accuracy: 0.6598 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.7286Epoch 7/40: loss=0.5404, accuracy=0.7289, val_loss=0.5545, val_accuracy=0.7252\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5404 - accuracy: 0.7289 - val_loss: 0.5545 - val_accuracy: 0.7252 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5556 - accuracy: 0.7208Epoch 8/40: loss=0.5558, accuracy=0.7208, val_loss=0.5351, val_accuracy=0.7798\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5558 - accuracy: 0.7208 - val_loss: 0.5351 - val_accuracy: 0.7798 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.7241Epoch 9/40: loss=0.5556, accuracy=0.7241, val_loss=0.5489, val_accuracy=0.7078\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5556 - accuracy: 0.7241 - val_loss: 0.5489 - val_accuracy: 0.7078 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.7417\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/40: loss=0.5361, accuracy=0.7417, val_loss=0.5745, val_accuracy=0.7616\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5361 - accuracy: 0.7417 - val_loss: 0.5745 - val_accuracy: 0.7616 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5116 - accuracy: 0.7544Epoch 11/40: loss=0.5117, accuracy=0.7539, val_loss=0.4272, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5117 - accuracy: 0.7539 - val_loss: 0.4272 - val_accuracy: 0.8270 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.7664Epoch 12/40: loss=0.4953, accuracy=0.7659, val_loss=0.5560, val_accuracy=0.7492\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4953 - accuracy: 0.7659 - val_loss: 0.5560 - val_accuracy: 0.7492 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4990 - accuracy: 0.7639Epoch 13/40: loss=0.4988, accuracy=0.7641, val_loss=0.4500, val_accuracy=0.7839\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4988 - accuracy: 0.7641 - val_loss: 0.4500 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.7666Epoch 14/40: loss=0.4921, accuracy=0.7666, val_loss=0.4162, val_accuracy=0.7988\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4921 - accuracy: 0.7666 - val_loss: 0.4162 - val_accuracy: 0.7988 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4847 - accuracy: 0.7707Epoch 15/40: loss=0.4846, accuracy=0.7707, val_loss=0.4288, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4846 - accuracy: 0.7707 - val_loss: 0.4288 - val_accuracy: 0.8204 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7740Epoch 16/40: loss=0.4806, accuracy=0.7740, val_loss=0.4517, val_accuracy=0.8063\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4806 - accuracy: 0.7740 - val_loss: 0.4517 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4752 - accuracy: 0.7708Epoch 17/40: loss=0.4746, accuracy=0.7711, val_loss=0.4302, val_accuracy=0.7889\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4746 - accuracy: 0.7711 - val_loss: 0.4302 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.7780Epoch 18/40: loss=0.4686, accuracy=0.7781, val_loss=0.4179, val_accuracy=0.8377\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4686 - accuracy: 0.7781 - val_loss: 0.4179 - val_accuracy: 0.8377 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7774\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.4765, accuracy=0.7777, val_loss=0.4641, val_accuracy=0.7608\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4765 - accuracy: 0.7777 - val_loss: 0.4641 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.7859Epoch 20/40: loss=0.4599, accuracy=0.7854, val_loss=0.4298, val_accuracy=0.7699\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4599 - accuracy: 0.7854 - val_loss: 0.4298 - val_accuracy: 0.7699 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.7899Epoch 21/40: loss=0.4514, accuracy=0.7899, val_loss=0.4047, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4514 - accuracy: 0.7899 - val_loss: 0.4047 - val_accuracy: 0.8071 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.7895Epoch 22/40: loss=0.4531, accuracy=0.7897, val_loss=0.4088, val_accuracy=0.8179\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4531 - accuracy: 0.7897 - val_loss: 0.4088 - val_accuracy: 0.8179 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4469 - accuracy: 0.7962Epoch 23/40: loss=0.4470, accuracy=0.7959, val_loss=0.4227, val_accuracy=0.7947\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4470 - accuracy: 0.7959 - val_loss: 0.4227 - val_accuracy: 0.7947 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4489 - accuracy: 0.7847Epoch 24/40: loss=0.4484, accuracy=0.7850, val_loss=0.4065, val_accuracy=0.8286\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4484 - accuracy: 0.7850 - val_loss: 0.4065 - val_accuracy: 0.8286 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.7838Epoch 25/40: loss=0.4605, accuracy=0.7841, val_loss=0.4117, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4605 - accuracy: 0.7841 - val_loss: 0.4117 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.7910Epoch 26/40: loss=0.4453, accuracy=0.7910, val_loss=0.3904, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4453 - accuracy: 0.7910 - val_loss: 0.3904 - val_accuracy: 0.8270 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.7957Epoch 27/40: loss=0.4480, accuracy=0.7957, val_loss=0.4073, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4480 - accuracy: 0.7957 - val_loss: 0.4073 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8009Epoch 28/40: loss=0.4363, accuracy=0.8009, val_loss=0.4128, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4363 - accuracy: 0.8009 - val_loss: 0.4128 - val_accuracy: 0.8071 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4345 - accuracy: 0.7942Epoch 29/40: loss=0.4347, accuracy=0.7941, val_loss=0.4216, val_accuracy=0.8220\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4347 - accuracy: 0.7941 - val_loss: 0.4216 - val_accuracy: 0.8220 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8045Epoch 30/40: loss=0.4263, accuracy=0.8042, val_loss=0.4245, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4263 - accuracy: 0.8042 - val_loss: 0.4245 - val_accuracy: 0.8121 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.7978\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 31/40: loss=0.4433, accuracy=0.7980, val_loss=0.4585, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4433 - accuracy: 0.7980 - val_loss: 0.4585 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4345 - accuracy: 0.7939Epoch 32/40: loss=0.4343, accuracy=0.7943, val_loss=0.4457, val_accuracy=0.7773\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4343 - accuracy: 0.7943 - val_loss: 0.4457 - val_accuracy: 0.7773 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.7999Epoch 33/40: loss=0.4320, accuracy=0.7999, val_loss=0.4386, val_accuracy=0.7930\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4320 - accuracy: 0.7999 - val_loss: 0.4386 - val_accuracy: 0.7930 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4342 - accuracy: 0.8046Epoch 34/40: loss=0.4339, accuracy=0.8044, val_loss=0.4296, val_accuracy=0.8022\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4339 - accuracy: 0.8044 - val_loss: 0.4296 - val_accuracy: 0.8022 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.7993Epoch 35/40: loss=0.4359, accuracy=0.7995, val_loss=0.4428, val_accuracy=0.7881\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4359 - accuracy: 0.7995 - val_loss: 0.4428 - val_accuracy: 0.7881 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8069\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36/40: loss=0.4297, accuracy=0.8069, val_loss=0.4399, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4297 - accuracy: 0.8069 - val_loss: 0.4399 - val_accuracy: 0.7889 - lr: 4.0000e-06\n",
      "Epoch 36: early stopping\n",
      "Validation accuracy: 0.8377483487129211\n",
      "\n",
      "Initial Training Combination 39/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.0005, rotation_range=10, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9960 - accuracy: 0.4950Epoch 1/40: loss=0.9960, accuracy=0.4950, val_loss=0.7072, val_accuracy=0.4536\n",
      "604/604 [==============================] - 13s 17ms/step - loss: 0.9960 - accuracy: 0.4950 - val_loss: 0.7072 - val_accuracy: 0.4536 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8029 - accuracy: 0.5106Epoch 2/40: loss=0.8036, accuracy=0.5099, val_loss=0.6999, val_accuracy=0.4892\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8036 - accuracy: 0.5099 - val_loss: 0.6999 - val_accuracy: 0.4892 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7413 - accuracy: 0.4942Epoch 3/40: loss=0.7413, accuracy=0.4946, val_loss=0.6993, val_accuracy=0.3974\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7413 - accuracy: 0.4946 - val_loss: 0.6993 - val_accuracy: 0.3974 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.5006Epoch 4/40: loss=0.7149, accuracy=0.5006, val_loss=0.6668, val_accuracy=0.6258\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7149 - accuracy: 0.5006 - val_loss: 0.6668 - val_accuracy: 0.6258 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7068 - accuracy: 0.5044Epoch 5/40: loss=0.7068, accuracy=0.5052, val_loss=0.6783, val_accuracy=0.6134\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.7068 - accuracy: 0.5052 - val_loss: 0.6783 - val_accuracy: 0.6134 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6892 - accuracy: 0.5614Epoch 6/40: loss=0.6890, accuracy=0.5617, val_loss=0.7588, val_accuracy=0.5952\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6890 - accuracy: 0.5617 - val_loss: 0.7588 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6669 - accuracy: 0.6009Epoch 7/40: loss=0.6666, accuracy=0.6016, val_loss=0.6764, val_accuracy=0.6647\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6666 - accuracy: 0.6016 - val_loss: 0.6764 - val_accuracy: 0.6647 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6440 - accuracy: 0.6302Epoch 8/40: loss=0.6448, accuracy=0.6300, val_loss=0.8885, val_accuracy=0.6416\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6448 - accuracy: 0.6300 - val_loss: 0.8885 - val_accuracy: 0.6416 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6359 - accuracy: 0.6439Epoch 9/40: loss=0.6356, accuracy=0.6445, val_loss=0.6319, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6356 - accuracy: 0.6445 - val_loss: 0.6319 - val_accuracy: 0.7020 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6236 - accuracy: 0.6598Epoch 10/40: loss=0.6236, accuracy=0.6598, val_loss=0.5471, val_accuracy=0.7533\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6236 - accuracy: 0.6598 - val_loss: 0.5471 - val_accuracy: 0.7533 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6133 - accuracy: 0.6661Epoch 11/40: loss=0.6133, accuracy=0.6658, val_loss=1.1743, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6133 - accuracy: 0.6658 - val_loss: 1.1743 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.6687Epoch 12/40: loss=0.6142, accuracy=0.6689, val_loss=1.1715, val_accuracy=0.4959\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6142 - accuracy: 0.6689 - val_loss: 1.1715 - val_accuracy: 0.4959 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6181 - accuracy: 0.6579Epoch 13/40: loss=0.6187, accuracy=0.6577, val_loss=0.5918, val_accuracy=0.7127\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6187 - accuracy: 0.6577 - val_loss: 0.5918 - val_accuracy: 0.7127 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.6709Epoch 14/40: loss=0.6094, accuracy=0.6709, val_loss=0.5480, val_accuracy=0.7392\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6094 - accuracy: 0.6709 - val_loss: 0.5480 - val_accuracy: 0.7392 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.6819\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/40: loss=0.6000, accuracy=0.6817, val_loss=0.9163, val_accuracy=0.6854\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6000 - accuracy: 0.6817 - val_loss: 0.9163 - val_accuracy: 0.6854 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5637 - accuracy: 0.7015Epoch 16/40: loss=0.5638, accuracy=0.7016, val_loss=0.5105, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5638 - accuracy: 0.7016 - val_loss: 0.5105 - val_accuracy: 0.7773 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5613 - accuracy: 0.7085Epoch 17/40: loss=0.5611, accuracy=0.7086, val_loss=0.8155, val_accuracy=0.7061\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5611 - accuracy: 0.7086 - val_loss: 0.8155 - val_accuracy: 0.7061 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7127Epoch 18/40: loss=0.5628, accuracy=0.7127, val_loss=0.7769, val_accuracy=0.6921\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5628 - accuracy: 0.7127 - val_loss: 0.7769 - val_accuracy: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.7072Epoch 19/40: loss=0.5630, accuracy=0.7072, val_loss=0.5999, val_accuracy=0.7343\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5630 - accuracy: 0.7072 - val_loss: 0.5999 - val_accuracy: 0.7343 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.7105Epoch 20/40: loss=0.5619, accuracy=0.7105, val_loss=0.5490, val_accuracy=0.7326\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5619 - accuracy: 0.7105 - val_loss: 0.5490 - val_accuracy: 0.7326 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.7178\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 21/40: loss=0.5547, accuracy=0.7183, val_loss=0.5209, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5547 - accuracy: 0.7183 - val_loss: 0.5209 - val_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5521 - accuracy: 0.7179Epoch 22/40: loss=0.5521, accuracy=0.7179, val_loss=0.5083, val_accuracy=0.7839\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5521 - accuracy: 0.7179 - val_loss: 0.5083 - val_accuracy: 0.7839 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5469 - accuracy: 0.7234Epoch 23/40: loss=0.5464, accuracy=0.7239, val_loss=0.5003, val_accuracy=0.7831\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5464 - accuracy: 0.7239 - val_loss: 0.5003 - val_accuracy: 0.7831 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.7281Epoch 24/40: loss=0.5442, accuracy=0.7281, val_loss=0.5003, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5442 - accuracy: 0.7281 - val_loss: 0.5003 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.7184Epoch 25/40: loss=0.5526, accuracy=0.7183, val_loss=0.4902, val_accuracy=0.7798\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5526 - accuracy: 0.7183 - val_loss: 0.4902 - val_accuracy: 0.7798 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.7303Epoch 26/40: loss=0.5375, accuracy=0.7301, val_loss=0.5068, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5375 - accuracy: 0.7301 - val_loss: 0.5068 - val_accuracy: 0.7906 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5516 - accuracy: 0.7162Epoch 27/40: loss=0.5518, accuracy=0.7159, val_loss=0.5129, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5518 - accuracy: 0.7159 - val_loss: 0.5129 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.7254Epoch 28/40: loss=0.5398, accuracy=0.7254, val_loss=0.4944, val_accuracy=0.7939\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5398 - accuracy: 0.7254 - val_loss: 0.4944 - val_accuracy: 0.7939 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7301Epoch 29/40: loss=0.5368, accuracy=0.7297, val_loss=0.5013, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5368 - accuracy: 0.7297 - val_loss: 0.5013 - val_accuracy: 0.7955 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.7305\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 30/40: loss=0.5369, accuracy=0.7308, val_loss=0.5003, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5369 - accuracy: 0.7308 - val_loss: 0.5003 - val_accuracy: 0.7980 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.7347Epoch 31/40: loss=0.5304, accuracy=0.7345, val_loss=0.4880, val_accuracy=0.7939\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5304 - accuracy: 0.7345 - val_loss: 0.4880 - val_accuracy: 0.7939 - lr: 4.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7305Epoch 32/40: loss=0.5327, accuracy=0.7297, val_loss=0.4877, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5327 - accuracy: 0.7297 - val_loss: 0.4877 - val_accuracy: 0.7897 - lr: 4.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7270Epoch 33/40: loss=0.5392, accuracy=0.7270, val_loss=0.4920, val_accuracy=0.7922\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5392 - accuracy: 0.7270 - val_loss: 0.4920 - val_accuracy: 0.7922 - lr: 4.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5321 - accuracy: 0.7326Epoch 34/40: loss=0.5317, accuracy=0.7326, val_loss=0.4885, val_accuracy=0.7980\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5317 - accuracy: 0.7326 - val_loss: 0.4885 - val_accuracy: 0.7980 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7340Epoch 35/40: loss=0.5286, accuracy=0.7341, val_loss=0.4884, val_accuracy=0.7914\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5286 - accuracy: 0.7341 - val_loss: 0.4884 - val_accuracy: 0.7914 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5435 - accuracy: 0.7212Epoch 36/40: loss=0.5433, accuracy=0.7212, val_loss=0.4913, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5433 - accuracy: 0.7212 - val_loss: 0.4913 - val_accuracy: 0.7906 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7396\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Epoch 37/40: loss=0.5339, accuracy=0.7399, val_loss=0.4929, val_accuracy=0.7889\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5339 - accuracy: 0.7399 - val_loss: 0.4929 - val_accuracy: 0.7889 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5303 - accuracy: 0.7359Epoch 38/40: loss=0.5310, accuracy=0.7357, val_loss=0.4973, val_accuracy=0.7988\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5310 - accuracy: 0.7357 - val_loss: 0.4973 - val_accuracy: 0.7988 - lr: 8.0000e-07\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.7206Epoch 39/40: loss=0.5370, accuracy=0.7208, val_loss=0.4887, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5370 - accuracy: 0.7208 - val_loss: 0.4887 - val_accuracy: 0.7955 - lr: 8.0000e-07\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5388 - accuracy: 0.7324Epoch 40/40: loss=0.5385, accuracy=0.7324, val_loss=0.4895, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5385 - accuracy: 0.7324 - val_loss: 0.4895 - val_accuracy: 0.7906 - lr: 8.0000e-07\n",
      "Validation accuracy: 0.7988410592079163\n",
      "\n",
      "Initial Training Combination 40/50: num_residual_blocks=1, dropout_rate=0.4, learning_rate=0.01, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9783 - accuracy: 0.5133Epoch 1/40: loss=0.9773, accuracy=0.5126, val_loss=0.6872, val_accuracy=0.5555\n",
      "604/604 [==============================] - 13s 20ms/step - loss: 0.9773 - accuracy: 0.5126 - val_loss: 0.6872 - val_accuracy: 0.5555 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6984 - accuracy: 0.4992Epoch 2/40: loss=0.6984, accuracy=0.4994, val_loss=0.7057, val_accuracy=0.4015\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6984 - accuracy: 0.4994 - val_loss: 0.7057 - val_accuracy: 0.4015 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.4884Epoch 3/40: loss=0.6967, accuracy=0.4884, val_loss=0.6998, val_accuracy=0.4015\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6967 - accuracy: 0.4884 - val_loss: 0.6998 - val_accuracy: 0.4015 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.4880Epoch 4/40: loss=0.6960, accuracy=0.4880, val_loss=0.6981, val_accuracy=0.4015\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6960 - accuracy: 0.4880 - val_loss: 0.6981 - val_accuracy: 0.4015 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.4828Epoch 5/40: loss=0.6947, accuracy=0.4834, val_loss=1.2818, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6947 - accuracy: 0.4834 - val_loss: 1.2818 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 6/40: loss=0.6939, accuracy=0.5006, val_loss=1.6057, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6939 - accuracy: 0.5006 - val_loss: 1.6057 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4615Epoch 7/40: loss=0.6934, accuracy=0.4615, val_loss=2.1629, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6934 - accuracy: 0.4615 - val_loss: 2.1629 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4843Epoch 8/40: loss=0.6934, accuracy=0.4843, val_loss=1.5307, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6934 - accuracy: 0.4843 - val_loss: 1.5307 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5144Epoch 9/40: loss=0.6937, accuracy=0.5153, val_loss=1.1496, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6937 - accuracy: 0.5153 - val_loss: 1.1496 - val_accuracy: 0.5969 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5211Epoch 10/40: loss=0.6936, accuracy=0.5205, val_loss=1.1737, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6936 - accuracy: 0.5205 - val_loss: 1.1737 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.4792\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11/40: loss=0.6937, accuracy=0.4795, val_loss=1.0493, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6937 - accuracy: 0.4795 - val_loss: 1.0493 - val_accuracy: 0.5985 - lr: 0.0020\n",
      "Epoch 11: early stopping\n",
      "Validation accuracy: 0.5985099077224731\n",
      "\n",
      "Initial Training Combination 41/50: num_residual_blocks=3, dropout_rate=0.4, learning_rate=0.0001, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.5091Epoch 1/40: loss=0.9639, accuracy=0.5089, val_loss=0.6327, val_accuracy=0.6291\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.9639 - accuracy: 0.5089 - val_loss: 0.6327 - val_accuracy: 0.6291 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8617 - accuracy: 0.5375Epoch 2/40: loss=0.8617, accuracy=0.5375, val_loss=0.5939, val_accuracy=0.6945\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8617 - accuracy: 0.5375 - val_loss: 0.5939 - val_accuracy: 0.6945 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7827 - accuracy: 0.5914Epoch 3/40: loss=0.7824, accuracy=0.5915, val_loss=0.7995, val_accuracy=0.5687\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7824 - accuracy: 0.5915 - val_loss: 0.7995 - val_accuracy: 0.5687 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7121 - accuracy: 0.6353Epoch 4/40: loss=0.7121, accuracy=0.6353, val_loss=0.6858, val_accuracy=0.6531\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7121 - accuracy: 0.6353 - val_loss: 0.6858 - val_accuracy: 0.6531 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.6580Epoch 5/40: loss=0.6731, accuracy=0.6579, val_loss=0.7743, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6731 - accuracy: 0.6579 - val_loss: 0.7743 - val_accuracy: 0.5969 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6458 - accuracy: 0.6722Epoch 6/40: loss=0.6448, accuracy=0.6732, val_loss=1.7548, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.6448 - accuracy: 0.6732 - val_loss: 1.7548 - val_accuracy: 0.4007 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.6674\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/40: loss=0.6438, accuracy=0.6674, val_loss=2.9828, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6438 - accuracy: 0.6674 - val_loss: 2.9828 - val_accuracy: 0.5993 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6216 - accuracy: 0.6860Epoch 8/40: loss=0.6218, accuracy=0.6861, val_loss=0.5738, val_accuracy=0.6962\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6218 - accuracy: 0.6861 - val_loss: 0.5738 - val_accuracy: 0.6962 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6203 - accuracy: 0.6862Epoch 9/40: loss=0.6209, accuracy=0.6856, val_loss=0.5014, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6209 - accuracy: 0.6856 - val_loss: 0.5014 - val_accuracy: 0.7707 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.6905Epoch 10/40: loss=0.6184, accuracy=0.6904, val_loss=0.5090, val_accuracy=0.7450\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6184 - accuracy: 0.6904 - val_loss: 0.5090 - val_accuracy: 0.7450 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7076Epoch 11/40: loss=0.5843, accuracy=0.7076, val_loss=0.5409, val_accuracy=0.7616\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5843 - accuracy: 0.7076 - val_loss: 0.5409 - val_accuracy: 0.7616 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.7108Epoch 12/40: loss=0.5952, accuracy=0.7107, val_loss=0.4914, val_accuracy=0.7765\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5952 - accuracy: 0.7107 - val_loss: 0.4914 - val_accuracy: 0.7765 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7090Epoch 13/40: loss=0.5973, accuracy=0.7090, val_loss=0.6404, val_accuracy=0.6556\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5973 - accuracy: 0.7090 - val_loss: 0.6404 - val_accuracy: 0.6556 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.7084Epoch 14/40: loss=0.5851, accuracy=0.7084, val_loss=0.6191, val_accuracy=0.6672\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5851 - accuracy: 0.7084 - val_loss: 0.6191 - val_accuracy: 0.6672 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5730 - accuracy: 0.7239Epoch 15/40: loss=0.5738, accuracy=0.7233, val_loss=0.4573, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5738 - accuracy: 0.7233 - val_loss: 0.4573 - val_accuracy: 0.7848 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5609 - accuracy: 0.7274Epoch 16/40: loss=0.5608, accuracy=0.7276, val_loss=0.4519, val_accuracy=0.7922\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5608 - accuracy: 0.7276 - val_loss: 0.4519 - val_accuracy: 0.7922 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.7168Epoch 17/40: loss=0.5802, accuracy=0.7165, val_loss=0.5276, val_accuracy=0.7334\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5802 - accuracy: 0.7165 - val_loss: 0.5276 - val_accuracy: 0.7334 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7239Epoch 18/40: loss=0.5657, accuracy=0.7239, val_loss=0.5198, val_accuracy=0.7293\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5657 - accuracy: 0.7239 - val_loss: 0.5198 - val_accuracy: 0.7293 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.7214Epoch 19/40: loss=0.5675, accuracy=0.7216, val_loss=0.4581, val_accuracy=0.7873\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5675 - accuracy: 0.7216 - val_loss: 0.4581 - val_accuracy: 0.7873 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7290Epoch 20/40: loss=0.5550, accuracy=0.7287, val_loss=0.6276, val_accuracy=0.6556\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5550 - accuracy: 0.7287 - val_loss: 0.6276 - val_accuracy: 0.6556 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.7264\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 21/40: loss=0.5595, accuracy=0.7264, val_loss=0.7061, val_accuracy=0.6060\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5595 - accuracy: 0.7264 - val_loss: 0.7061 - val_accuracy: 0.6060 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5568 - accuracy: 0.7307Epoch 22/40: loss=0.5572, accuracy=0.7301, val_loss=0.4962, val_accuracy=0.7575\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5572 - accuracy: 0.7301 - val_loss: 0.4962 - val_accuracy: 0.7575 - lr: 4.0000e-06\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5539 - accuracy: 0.7305Epoch 23/40: loss=0.5535, accuracy=0.7301, val_loss=0.4768, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5535 - accuracy: 0.7301 - val_loss: 0.4768 - val_accuracy: 0.7699 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5504 - accuracy: 0.7352Epoch 24/40: loss=0.5514, accuracy=0.7347, val_loss=0.4660, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5514 - accuracy: 0.7347 - val_loss: 0.4660 - val_accuracy: 0.7823 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.7369Epoch 25/40: loss=0.5440, accuracy=0.7380, val_loss=0.4664, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5440 - accuracy: 0.7380 - val_loss: 0.4664 - val_accuracy: 0.7839 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.7388\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 26/40: loss=0.5440, accuracy=0.7388, val_loss=0.4666, val_accuracy=0.7839\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5440 - accuracy: 0.7388 - val_loss: 0.4666 - val_accuracy: 0.7839 - lr: 4.0000e-06\n",
      "Epoch 26: early stopping\n",
      "Validation accuracy: 0.7922185659408569\n",
      "\n",
      "Initial Training Combination 42/50: num_residual_blocks=1, dropout_rate=0.5, learning_rate=0.0001, rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0707 - accuracy: 0.5327Epoch 1/40: loss=1.0707, accuracy=0.5327, val_loss=1.0873, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 16ms/step - loss: 1.0707 - accuracy: 0.5327 - val_loss: 1.0873 - val_accuracy: 0.4007 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9096 - accuracy: 0.5290Epoch 2/40: loss=0.9096, accuracy=0.5290, val_loss=1.0201, val_accuracy=0.4023\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.9096 - accuracy: 0.5290 - val_loss: 1.0201 - val_accuracy: 0.4023 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.5443Epoch 3/40: loss=0.8568, accuracy=0.5443, val_loss=1.0614, val_accuracy=0.4123\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8568 - accuracy: 0.5443 - val_loss: 1.0614 - val_accuracy: 0.4123 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8182 - accuracy: 0.5564Epoch 4/40: loss=0.8176, accuracy=0.5567, val_loss=0.8233, val_accuracy=0.5008\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.8176 - accuracy: 0.5567 - val_loss: 0.8233 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.7793 - accuracy: 0.5815Epoch 5/40: loss=0.7801, accuracy=0.5807, val_loss=1.6307, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7801 - accuracy: 0.5807 - val_loss: 1.6307 - val_accuracy: 0.4007 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7480 - accuracy: 0.5953Epoch 6/40: loss=0.7484, accuracy=0.5948, val_loss=1.4246, val_accuracy=0.4023\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7484 - accuracy: 0.5948 - val_loss: 1.4246 - val_accuracy: 0.4023 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.6089Epoch 7/40: loss=0.7233, accuracy=0.6089, val_loss=1.2532, val_accuracy=0.4065\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.7233 - accuracy: 0.6089 - val_loss: 1.2532 - val_accuracy: 0.4065 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7019 - accuracy: 0.6246Epoch 8/40: loss=0.7013, accuracy=0.6250, val_loss=1.0379, val_accuracy=0.4379\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7013 - accuracy: 0.6250 - val_loss: 1.0379 - val_accuracy: 0.4379 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.6260\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 9/40: loss=0.6856, accuracy=0.6260, val_loss=0.9733, val_accuracy=0.4371\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6856 - accuracy: 0.6260 - val_loss: 0.9733 - val_accuracy: 0.4371 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6607 - accuracy: 0.6333Epoch 10/40: loss=0.6601, accuracy=0.6339, val_loss=0.7798, val_accuracy=0.5513\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6601 - accuracy: 0.6339 - val_loss: 0.7798 - val_accuracy: 0.5513 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6601 - accuracy: 0.6433Epoch 11/40: loss=0.6595, accuracy=0.6436, val_loss=0.8988, val_accuracy=0.4785\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6595 - accuracy: 0.6436 - val_loss: 0.8988 - val_accuracy: 0.4785 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.6476Epoch 12/40: loss=0.6510, accuracy=0.6476, val_loss=0.8403, val_accuracy=0.5017\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6510 - accuracy: 0.6476 - val_loss: 0.8403 - val_accuracy: 0.5017 - lr: 2.0000e-05\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.6497Epoch 13/40: loss=0.6493, accuracy=0.6496, val_loss=0.8482, val_accuracy=0.5058\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6493 - accuracy: 0.6496 - val_loss: 0.8482 - val_accuracy: 0.5058 - lr: 2.0000e-05\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6391 - accuracy: 0.6555Epoch 14/40: loss=0.6386, accuracy=0.6556, val_loss=0.8616, val_accuracy=0.4901\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6386 - accuracy: 0.6556 - val_loss: 0.8616 - val_accuracy: 0.4901 - lr: 2.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.6540Epoch 15/40: loss=0.6466, accuracy=0.6540, val_loss=0.6866, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6466 - accuracy: 0.6540 - val_loss: 0.6866 - val_accuracy: 0.5993 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6456 - accuracy: 0.6497Epoch 16/40: loss=0.6453, accuracy=0.6500, val_loss=0.8356, val_accuracy=0.5033\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6453 - accuracy: 0.6500 - val_loss: 0.8356 - val_accuracy: 0.5033 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6322 - accuracy: 0.6638Epoch 17/40: loss=0.6323, accuracy=0.6639, val_loss=0.7305, val_accuracy=0.5596\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6323 - accuracy: 0.6639 - val_loss: 0.7305 - val_accuracy: 0.5596 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.6685Epoch 18/40: loss=0.6200, accuracy=0.6685, val_loss=0.7952, val_accuracy=0.5199\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6200 - accuracy: 0.6685 - val_loss: 0.7952 - val_accuracy: 0.5199 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6141 - accuracy: 0.6688Epoch 19/40: loss=0.6138, accuracy=0.6691, val_loss=0.6559, val_accuracy=0.6225\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6138 - accuracy: 0.6691 - val_loss: 0.6559 - val_accuracy: 0.6225 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6783Epoch 20/40: loss=0.6115, accuracy=0.6780, val_loss=0.7293, val_accuracy=0.5671\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6115 - accuracy: 0.6780 - val_loss: 0.7293 - val_accuracy: 0.5671 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6078 - accuracy: 0.6779Epoch 21/40: loss=0.6077, accuracy=0.6778, val_loss=0.6808, val_accuracy=0.5911\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6077 - accuracy: 0.6778 - val_loss: 0.6808 - val_accuracy: 0.5911 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.6745Epoch 22/40: loss=0.6177, accuracy=0.6747, val_loss=0.6513, val_accuracy=0.6209\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6177 - accuracy: 0.6747 - val_loss: 0.6513 - val_accuracy: 0.6209 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6029 - accuracy: 0.6898Epoch 23/40: loss=0.6029, accuracy=0.6898, val_loss=0.8949, val_accuracy=0.4594\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6029 - accuracy: 0.6898 - val_loss: 0.8949 - val_accuracy: 0.4594 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.6748Epoch 24/40: loss=0.6197, accuracy=0.6751, val_loss=0.5938, val_accuracy=0.6689\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6197 - accuracy: 0.6751 - val_loss: 0.5938 - val_accuracy: 0.6689 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6041 - accuracy: 0.6741Epoch 25/40: loss=0.6037, accuracy=0.6743, val_loss=0.6525, val_accuracy=0.6101\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6037 - accuracy: 0.6743 - val_loss: 0.6525 - val_accuracy: 0.6101 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5939 - accuracy: 0.6841Epoch 26/40: loss=0.5939, accuracy=0.6838, val_loss=0.7691, val_accuracy=0.5290\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5939 - accuracy: 0.6838 - val_loss: 0.7691 - val_accuracy: 0.5290 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.6877Epoch 27/40: loss=0.5946, accuracy=0.6877, val_loss=0.9772, val_accuracy=0.4379\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5946 - accuracy: 0.6877 - val_loss: 0.9772 - val_accuracy: 0.4379 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.6880Epoch 28/40: loss=0.6061, accuracy=0.6879, val_loss=0.5328, val_accuracy=0.7210\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6061 - accuracy: 0.6879 - val_loss: 0.5328 - val_accuracy: 0.7210 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.6809Epoch 29/40: loss=0.6037, accuracy=0.6809, val_loss=0.6163, val_accuracy=0.6515\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6037 - accuracy: 0.6809 - val_loss: 0.6163 - val_accuracy: 0.6515 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.6817Epoch 30/40: loss=0.5953, accuracy=0.6819, val_loss=0.7438, val_accuracy=0.5422\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5953 - accuracy: 0.6819 - val_loss: 0.7438 - val_accuracy: 0.5422 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5962 - accuracy: 0.6841Epoch 31/40: loss=0.5959, accuracy=0.6844, val_loss=0.7713, val_accuracy=0.5132\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5959 - accuracy: 0.6844 - val_loss: 0.7713 - val_accuracy: 0.5132 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5887 - accuracy: 0.6880Epoch 32/40: loss=0.5895, accuracy=0.6873, val_loss=0.6406, val_accuracy=0.6184\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5895 - accuracy: 0.6873 - val_loss: 0.6406 - val_accuracy: 0.6184 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5882 - accuracy: 0.6908\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 33/40: loss=0.5877, accuracy=0.6912, val_loss=0.5379, val_accuracy=0.7020\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5877 - accuracy: 0.6912 - val_loss: 0.5379 - val_accuracy: 0.7020 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5966 - accuracy: 0.6898Epoch 34/40: loss=0.5969, accuracy=0.6892, val_loss=0.6726, val_accuracy=0.5894\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5969 - accuracy: 0.6892 - val_loss: 0.6726 - val_accuracy: 0.5894 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.6915Epoch 35/40: loss=0.5839, accuracy=0.6914, val_loss=0.6736, val_accuracy=0.5894\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5839 - accuracy: 0.6914 - val_loss: 0.6736 - val_accuracy: 0.5894 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 0.6845Epoch 36/40: loss=0.5842, accuracy=0.6844, val_loss=0.7021, val_accuracy=0.5695\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5842 - accuracy: 0.6844 - val_loss: 0.7021 - val_accuracy: 0.5695 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.6928Epoch 37/40: loss=0.5878, accuracy=0.6927, val_loss=0.6900, val_accuracy=0.5745\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5878 - accuracy: 0.6927 - val_loss: 0.6900 - val_accuracy: 0.5745 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.6941\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.5839, accuracy=0.6941, val_loss=0.6274, val_accuracy=0.6300\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5839 - accuracy: 0.6941 - val_loss: 0.6274 - val_accuracy: 0.6300 - lr: 4.0000e-06\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.7210264801979065\n",
      "\n",
      "Initial Training Combination 43/50: num_residual_blocks=1, dropout_rate=0.6, learning_rate=0.0001, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1321 - accuracy: 0.4919Epoch 1/40: loss=1.1322, accuracy=0.4917, val_loss=0.6714, val_accuracy=0.6051\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 1.1322 - accuracy: 0.4917 - val_loss: 0.6714 - val_accuracy: 0.6051 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 1.0040 - accuracy: 0.5071Epoch 2/40: loss=1.0042, accuracy=0.5070, val_loss=0.7021, val_accuracy=0.5050\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 1.0042 - accuracy: 0.5070 - val_loss: 0.7021 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9606 - accuracy: 0.5143Epoch 3/40: loss=0.9606, accuracy=0.5143, val_loss=0.6868, val_accuracy=0.5513\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.9606 - accuracy: 0.5143 - val_loss: 0.6868 - val_accuracy: 0.5513 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9315 - accuracy: 0.4979Epoch 4/40: loss=0.9325, accuracy=0.4971, val_loss=0.7292, val_accuracy=0.4214\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.9325 - accuracy: 0.4971 - val_loss: 0.7292 - val_accuracy: 0.4214 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8630 - accuracy: 0.5174Epoch 5/40: loss=0.8630, accuracy=0.5174, val_loss=0.7128, val_accuracy=0.4793\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8630 - accuracy: 0.5174 - val_loss: 0.7128 - val_accuracy: 0.4793 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8415 - accuracy: 0.5054\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/40: loss=0.8421, accuracy=0.5050, val_loss=0.6906, val_accuracy=0.5331\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8421 - accuracy: 0.5050 - val_loss: 0.6906 - val_accuracy: 0.5331 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8387 - accuracy: 0.5132Epoch 7/40: loss=0.8387, accuracy=0.5132, val_loss=0.6967, val_accuracy=0.5248\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.8387 - accuracy: 0.5132 - val_loss: 0.6967 - val_accuracy: 0.5248 - lr: 2.0000e-05\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8250 - accuracy: 0.5166Epoch 8/40: loss=0.8247, accuracy=0.5163, val_loss=0.6996, val_accuracy=0.5248\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8247 - accuracy: 0.5163 - val_loss: 0.6996 - val_accuracy: 0.5248 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8074 - accuracy: 0.5181Epoch 9/40: loss=0.8070, accuracy=0.5182, val_loss=0.6949, val_accuracy=0.5555\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8070 - accuracy: 0.5182 - val_loss: 0.6949 - val_accuracy: 0.5555 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8144 - accuracy: 0.5160Epoch 10/40: loss=0.8143, accuracy=0.5159, val_loss=0.6880, val_accuracy=0.5762\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8143 - accuracy: 0.5159 - val_loss: 0.6880 - val_accuracy: 0.5762 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8128 - accuracy: 0.5108\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11/40: loss=0.8121, accuracy=0.5112, val_loss=0.6946, val_accuracy=0.5596\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.8121 - accuracy: 0.5112 - val_loss: 0.6946 - val_accuracy: 0.5596 - lr: 2.0000e-05\n",
      "Epoch 11: early stopping\n",
      "Validation accuracy: 0.6051324605941772\n",
      "\n",
      "Initial Training Combination 44/50: num_residual_blocks=2, dropout_rate=0.6, learning_rate=0.001, rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9232 - accuracy: 0.4979Epoch 1/40: loss=0.9227, accuracy=0.4983, val_loss=0.6751, val_accuracy=0.5902\n",
      "604/604 [==============================] - 13s 20ms/step - loss: 0.9227 - accuracy: 0.4983 - val_loss: 0.6751 - val_accuracy: 0.5902 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7322 - accuracy: 0.5209Epoch 2/40: loss=0.7322, accuracy=0.5209, val_loss=0.8926, val_accuracy=0.3998\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.7322 - accuracy: 0.5209 - val_loss: 0.8926 - val_accuracy: 0.3998 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.5275Epoch 3/40: loss=0.7117, accuracy=0.5275, val_loss=0.9213, val_accuracy=0.4354\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7117 - accuracy: 0.5275 - val_loss: 0.9213 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.5517Epoch 4/40: loss=0.7014, accuracy=0.5517, val_loss=0.7170, val_accuracy=0.6623\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7014 - accuracy: 0.5517 - val_loss: 0.7170 - val_accuracy: 0.6623 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.5972Epoch 5/40: loss=0.6767, accuracy=0.5971, val_loss=1.5922, val_accuracy=0.4272\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6767 - accuracy: 0.5971 - val_loss: 1.5922 - val_accuracy: 0.4272 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.6092\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 6/40: loss=0.6682, accuracy=0.6095, val_loss=3.5707, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6682 - accuracy: 0.6095 - val_loss: 3.5707 - val_accuracy: 0.4007 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.6150Epoch 7/40: loss=0.6562, accuracy=0.6147, val_loss=0.7082, val_accuracy=0.6159\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6562 - accuracy: 0.6147 - val_loss: 0.7082 - val_accuracy: 0.6159 - lr: 2.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6343 - accuracy: 0.6346Epoch 8/40: loss=0.6342, accuracy=0.6343, val_loss=0.6588, val_accuracy=0.6581\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6342 - accuracy: 0.6343 - val_loss: 0.6588 - val_accuracy: 0.6581 - lr: 2.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.6431Epoch 9/40: loss=0.6320, accuracy=0.6428, val_loss=0.6033, val_accuracy=0.6871\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6320 - accuracy: 0.6428 - val_loss: 0.6033 - val_accuracy: 0.6871 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.6534Epoch 10/40: loss=0.6144, accuracy=0.6536, val_loss=0.6166, val_accuracy=0.6995\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6144 - accuracy: 0.6536 - val_loss: 0.6166 - val_accuracy: 0.6995 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.6618Epoch 11/40: loss=0.6064, accuracy=0.6618, val_loss=0.6763, val_accuracy=0.6300\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6064 - accuracy: 0.6618 - val_loss: 0.6763 - val_accuracy: 0.6300 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.6749Epoch 12/40: loss=0.6044, accuracy=0.6749, val_loss=0.5209, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6044 - accuracy: 0.6749 - val_loss: 0.5209 - val_accuracy: 0.7517 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5993 - accuracy: 0.6708Epoch 13/40: loss=0.5992, accuracy=0.6705, val_loss=0.7601, val_accuracy=0.5778\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5992 - accuracy: 0.6705 - val_loss: 0.7601 - val_accuracy: 0.5778 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5957 - accuracy: 0.6923Epoch 14/40: loss=0.5955, accuracy=0.6923, val_loss=0.5504, val_accuracy=0.7417\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5955 - accuracy: 0.6923 - val_loss: 0.5504 - val_accuracy: 0.7417 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.6984Epoch 15/40: loss=0.5748, accuracy=0.6989, val_loss=0.7639, val_accuracy=0.6863\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5748 - accuracy: 0.6989 - val_loss: 0.7639 - val_accuracy: 0.6863 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.6943Epoch 16/40: loss=0.5847, accuracy=0.6943, val_loss=0.5670, val_accuracy=0.7442\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5847 - accuracy: 0.6943 - val_loss: 0.5670 - val_accuracy: 0.7442 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5793 - accuracy: 0.6886\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 17/40: loss=0.5794, accuracy=0.6887, val_loss=1.4247, val_accuracy=0.4917\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5794 - accuracy: 0.6887 - val_loss: 1.4247 - val_accuracy: 0.4917 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5645 - accuracy: 0.7067Epoch 18/40: loss=0.5648, accuracy=0.7065, val_loss=0.5003, val_accuracy=0.7682\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5648 - accuracy: 0.7065 - val_loss: 0.5003 - val_accuracy: 0.7682 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.7093Epoch 19/40: loss=0.5638, accuracy=0.7096, val_loss=0.5682, val_accuracy=0.6879\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5638 - accuracy: 0.7096 - val_loss: 0.5682 - val_accuracy: 0.6879 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5561 - accuracy: 0.7146Epoch 20/40: loss=0.5560, accuracy=0.7146, val_loss=0.5183, val_accuracy=0.7566\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5560 - accuracy: 0.7146 - val_loss: 0.5183 - val_accuracy: 0.7566 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.7201Epoch 21/40: loss=0.5492, accuracy=0.7204, val_loss=0.4930, val_accuracy=0.7500\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5492 - accuracy: 0.7204 - val_loss: 0.4930 - val_accuracy: 0.7500 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5555 - accuracy: 0.7129Epoch 22/40: loss=0.5557, accuracy=0.7127, val_loss=0.4839, val_accuracy=0.7715\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5557 - accuracy: 0.7127 - val_loss: 0.4839 - val_accuracy: 0.7715 - lr: 4.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7147Epoch 23/40: loss=0.5504, accuracy=0.7146, val_loss=0.5616, val_accuracy=0.7343\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5504 - accuracy: 0.7146 - val_loss: 0.5616 - val_accuracy: 0.7343 - lr: 4.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5521 - accuracy: 0.7090Epoch 24/40: loss=0.5522, accuracy=0.7090, val_loss=0.4942, val_accuracy=0.7533\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5522 - accuracy: 0.7090 - val_loss: 0.4942 - val_accuracy: 0.7533 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7277Epoch 25/40: loss=0.5375, accuracy=0.7283, val_loss=0.5303, val_accuracy=0.7475\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5375 - accuracy: 0.7283 - val_loss: 0.5303 - val_accuracy: 0.7475 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.7199Epoch 26/40: loss=0.5487, accuracy=0.7196, val_loss=0.4956, val_accuracy=0.7732\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5487 - accuracy: 0.7196 - val_loss: 0.4956 - val_accuracy: 0.7732 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5359 - accuracy: 0.7344\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 27/40: loss=0.5365, accuracy=0.7339, val_loss=0.4944, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5365 - accuracy: 0.7339 - val_loss: 0.4944 - val_accuracy: 0.7823 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.7256Epoch 28/40: loss=0.5454, accuracy=0.7256, val_loss=0.5041, val_accuracy=0.7624\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.5454 - accuracy: 0.7256 - val_loss: 0.5041 - val_accuracy: 0.7624 - lr: 8.0000e-06\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7318Epoch 29/40: loss=0.5437, accuracy=0.7314, val_loss=0.5114, val_accuracy=0.7666\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5437 - accuracy: 0.7314 - val_loss: 0.5114 - val_accuracy: 0.7666 - lr: 8.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5335 - accuracy: 0.7272Epoch 30/40: loss=0.5334, accuracy=0.7274, val_loss=0.4952, val_accuracy=0.7773\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.5334 - accuracy: 0.7274 - val_loss: 0.4952 - val_accuracy: 0.7773 - lr: 8.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.7263Epoch 31/40: loss=0.5413, accuracy=0.7262, val_loss=0.4849, val_accuracy=0.7748\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5413 - accuracy: 0.7262 - val_loss: 0.4849 - val_accuracy: 0.7748 - lr: 8.0000e-06\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.7291\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 32/40: loss=0.5388, accuracy=0.7289, val_loss=0.4855, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5388 - accuracy: 0.7289 - val_loss: 0.4855 - val_accuracy: 0.7848 - lr: 8.0000e-06\n",
      "Epoch 32: early stopping\n",
      "Validation accuracy: 0.7847682237625122\n",
      "\n",
      "Initial Training Combination 45/50: num_residual_blocks=1, dropout_rate=0.5, learning_rate=0.01, rotation_range=20, width_shift_range=0.1, height_shift_range=0.3, shear_range=0.2, zoom_range=0.1, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.4983Epoch 1/40: loss=0.9809, accuracy=0.4977, val_loss=0.7039, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 16ms/step - loss: 0.9809 - accuracy: 0.4977 - val_loss: 0.7039 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6987 - accuracy: 0.4938Epoch 2/40: loss=0.6987, accuracy=0.4936, val_loss=0.6815, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6987 - accuracy: 0.4936 - val_loss: 0.6815 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6962 - accuracy: 0.5158Epoch 3/40: loss=0.6964, accuracy=0.5149, val_loss=0.6878, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6964 - accuracy: 0.5149 - val_loss: 0.6878 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.4869Epoch 4/40: loss=0.6971, accuracy=0.4865, val_loss=0.7064, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6971 - accuracy: 0.4865 - val_loss: 0.7064 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.4875Epoch 5/40: loss=0.6970, accuracy=0.4882, val_loss=0.6812, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6970 - accuracy: 0.4882 - val_loss: 0.6812 - val_accuracy: 0.5993 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5037Epoch 6/40: loss=0.6944, accuracy=0.5039, val_loss=1.6930, val_accuracy=0.5985\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6944 - accuracy: 0.5039 - val_loss: 1.6930 - val_accuracy: 0.5985 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.4792Epoch 7/40: loss=0.6944, accuracy=0.4799, val_loss=5.7065, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6944 - accuracy: 0.4799 - val_loss: 5.7065 - val_accuracy: 0.5985 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5012Epoch 8/40: loss=0.6941, accuracy=0.5012, val_loss=7.9825, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6941 - accuracy: 0.5012 - val_loss: 7.9825 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.4861Epoch 9/40: loss=0.6943, accuracy=0.4861, val_loss=23.0561, val_accuracy=0.4007\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.6943 - accuracy: 0.4861 - val_loss: 23.0561 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5002\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 10/40: loss=0.6944, accuracy=0.5002, val_loss=4.1435, val_accuracy=0.5977\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6944 - accuracy: 0.5002 - val_loss: 4.1435 - val_accuracy: 0.5977 - lr: 0.0100\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5305Epoch 11/40: loss=0.6934, accuracy=0.5302, val_loss=1.5442, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6934 - accuracy: 0.5302 - val_loss: 1.5442 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5044Epoch 12/40: loss=0.6934, accuracy=0.5039, val_loss=0.8055, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.8055 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 13/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5393Epoch 13/40: loss=0.6934, accuracy=0.5381, val_loss=3.3670, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6934 - accuracy: 0.5381 - val_loss: 3.3670 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4373Epoch 14/40: loss=0.6939, accuracy=0.4373, val_loss=0.6908, val_accuracy=0.5993\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6939 - accuracy: 0.4373 - val_loss: 0.6908 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5168\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 15/40: loss=0.6934, accuracy=0.5166, val_loss=0.6923, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6934 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5993 - lr: 0.0020\n",
      "Epoch 15: early stopping\n",
      "Validation accuracy: 0.5993377566337585\n",
      "\n",
      "Initial Training Combination 46/50: num_residual_blocks=1, dropout_rate=0.6, learning_rate=0.01, rotation_range=20, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.3, zoom_range=0.3, horizontal_flip=False\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0481 - accuracy: 0.4849Epoch 1/40: loss=1.0481, accuracy=0.4849, val_loss=2.9898, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 17ms/step - loss: 1.0481 - accuracy: 0.4849 - val_loss: 2.9898 - val_accuracy: 0.4007 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.4969Epoch 2/40: loss=0.6997, accuracy=0.4969, val_loss=1.9520, val_accuracy=0.6043\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6997 - accuracy: 0.4969 - val_loss: 1.9520 - val_accuracy: 0.6043 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5093Epoch 3/40: loss=0.6957, accuracy=0.5093, val_loss=5.3853, val_accuracy=0.6026\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6957 - accuracy: 0.5093 - val_loss: 5.3853 - val_accuracy: 0.6026 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.4915Epoch 4/40: loss=0.6951, accuracy=0.4915, val_loss=2.9522, val_accuracy=0.6043\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6951 - accuracy: 0.4915 - val_loss: 2.9522 - val_accuracy: 0.6043 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6955 - accuracy: 0.4977Epoch 5/40: loss=0.6954, accuracy=0.4986, val_loss=3.2278, val_accuracy=0.6035\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6954 - accuracy: 0.4986 - val_loss: 3.2278 - val_accuracy: 0.6035 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.4872Epoch 6/40: loss=0.6954, accuracy=0.4872, val_loss=3.5358, val_accuracy=0.6010\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6954 - accuracy: 0.4872 - val_loss: 3.5358 - val_accuracy: 0.6010 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6968 - accuracy: 0.4948\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 7/40: loss=0.6968, accuracy=0.4950, val_loss=253.1053, val_accuracy=0.6474\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6968 - accuracy: 0.4950 - val_loss: 253.1053 - val_accuracy: 0.6474 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.5690Epoch 8/40: loss=0.6938, accuracy=0.5689, val_loss=10.6978, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6938 - accuracy: 0.5689 - val_loss: 10.6978 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4952Epoch 9/40: loss=0.6935, accuracy=0.4948, val_loss=24.6286, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6935 - accuracy: 0.4948 - val_loss: 24.6286 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.4973Epoch 10/40: loss=0.6933, accuracy=0.4975, val_loss=68.9956, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 68.9956 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.4389Epoch 11/40: loss=0.6941, accuracy=0.4392, val_loss=47.4337, val_accuracy=0.4007\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6941 - accuracy: 0.4392 - val_loss: 47.4337 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4998\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 12/40: loss=0.6935, accuracy=0.4996, val_loss=57.4046, val_accuracy=0.4007\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6935 - accuracy: 0.4996 - val_loss: 57.4046 - val_accuracy: 0.4007 - lr: 0.0020\n",
      "Epoch 12: early stopping\n",
      "Validation accuracy: 0.6473509669303894\n",
      "\n",
      "Initial Training Combination 47/50: num_residual_blocks=3, dropout_rate=0.4, learning_rate=0.0005, rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9235 - accuracy: 0.5097Epoch 1/40: loss=0.9233, accuracy=0.5099, val_loss=0.7541, val_accuracy=0.4768\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 0.9233 - accuracy: 0.5099 - val_loss: 0.7541 - val_accuracy: 0.4768 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7579 - accuracy: 0.5540Epoch 2/40: loss=0.7579, accuracy=0.5540, val_loss=0.6197, val_accuracy=0.7152\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7579 - accuracy: 0.5540 - val_loss: 0.6197 - val_accuracy: 0.7152 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6447 - accuracy: 0.6410Epoch 3/40: loss=0.6451, accuracy=0.6407, val_loss=0.5355, val_accuracy=0.7409\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6451 - accuracy: 0.6407 - val_loss: 0.5355 - val_accuracy: 0.7409 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.6777Epoch 4/40: loss=0.6036, accuracy=0.6774, val_loss=0.9009, val_accuracy=0.4412\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6036 - accuracy: 0.6774 - val_loss: 0.9009 - val_accuracy: 0.4412 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.6928Epoch 5/40: loss=0.5930, accuracy=0.6923, val_loss=2.7341, val_accuracy=0.6035\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5930 - accuracy: 0.6923 - val_loss: 2.7341 - val_accuracy: 0.6035 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5934 - accuracy: 0.6855Epoch 6/40: loss=0.5932, accuracy=0.6858, val_loss=0.7132, val_accuracy=0.6838\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5932 - accuracy: 0.6858 - val_loss: 0.7132 - val_accuracy: 0.6838 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5764 - accuracy: 0.7120Epoch 7/40: loss=0.5759, accuracy=0.7125, val_loss=0.5790, val_accuracy=0.6962\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5759 - accuracy: 0.7125 - val_loss: 0.5790 - val_accuracy: 0.6962 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7134\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/40: loss=0.5673, accuracy=0.7134, val_loss=2.2811, val_accuracy=0.4214\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5673 - accuracy: 0.7134 - val_loss: 2.2811 - val_accuracy: 0.4214 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.7311Epoch 9/40: loss=0.5529, accuracy=0.7316, val_loss=0.4763, val_accuracy=0.7839\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5529 - accuracy: 0.7316 - val_loss: 0.4763 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.7411Epoch 10/40: loss=0.5366, accuracy=0.7411, val_loss=0.4928, val_accuracy=0.7790\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5366 - accuracy: 0.7411 - val_loss: 0.4928 - val_accuracy: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.7477Epoch 11/40: loss=0.5309, accuracy=0.7473, val_loss=0.5150, val_accuracy=0.7732\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5309 - accuracy: 0.7473 - val_loss: 0.5150 - val_accuracy: 0.7732 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5270 - accuracy: 0.7427Epoch 12/40: loss=0.5269, accuracy=0.7428, val_loss=0.8649, val_accuracy=0.5993\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5269 - accuracy: 0.7428 - val_loss: 0.8649 - val_accuracy: 0.5993 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.7330Epoch 13/40: loss=0.5299, accuracy=0.7330, val_loss=0.4802, val_accuracy=0.8022\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5299 - accuracy: 0.7330 - val_loss: 0.4802 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.7400\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 14/40: loss=0.5295, accuracy=0.7401, val_loss=0.5361, val_accuracy=0.7715\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5295 - accuracy: 0.7401 - val_loss: 0.5361 - val_accuracy: 0.7715 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5103 - accuracy: 0.7506Epoch 15/40: loss=0.5100, accuracy=0.7506, val_loss=0.4426, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5100 - accuracy: 0.7506 - val_loss: 0.4426 - val_accuracy: 0.8162 - lr: 2.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5155 - accuracy: 0.7450Epoch 16/40: loss=0.5154, accuracy=0.7448, val_loss=0.4493, val_accuracy=0.8220\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5154 - accuracy: 0.7448 - val_loss: 0.4493 - val_accuracy: 0.8220 - lr: 2.0000e-05\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.7558Epoch 17/40: loss=0.5027, accuracy=0.7558, val_loss=0.4536, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5027 - accuracy: 0.7558 - val_loss: 0.4536 - val_accuracy: 0.8096 - lr: 2.0000e-05\n",
      "Epoch 18/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5085 - accuracy: 0.7560Epoch 18/40: loss=0.5083, accuracy=0.7562, val_loss=0.4585, val_accuracy=0.8137\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5083 - accuracy: 0.7562 - val_loss: 0.4585 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.7562Epoch 19/40: loss=0.4982, accuracy=0.7564, val_loss=0.4453, val_accuracy=0.8113\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4982 - accuracy: 0.7564 - val_loss: 0.4453 - val_accuracy: 0.8113 - lr: 2.0000e-05\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5064 - accuracy: 0.7581\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 20/40: loss=0.5065, accuracy=0.7581, val_loss=0.5354, val_accuracy=0.7699\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5065 - accuracy: 0.7581 - val_loss: 0.5354 - val_accuracy: 0.7699 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.7680Epoch 21/40: loss=0.4937, accuracy=0.7680, val_loss=0.4382, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4937 - accuracy: 0.7680 - val_loss: 0.4382 - val_accuracy: 0.8129 - lr: 4.0000e-06\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4993 - accuracy: 0.7639Epoch 22/40: loss=0.4994, accuracy=0.7643, val_loss=0.4441, val_accuracy=0.8104\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4994 - accuracy: 0.7643 - val_loss: 0.4441 - val_accuracy: 0.8104 - lr: 4.0000e-06\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.7625Epoch 23/40: loss=0.4911, accuracy=0.7620, val_loss=0.4404, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4911 - accuracy: 0.7620 - val_loss: 0.4404 - val_accuracy: 0.8063 - lr: 4.0000e-06\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4894 - accuracy: 0.7660Epoch 24/40: loss=0.4898, accuracy=0.7655, val_loss=0.4424, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4898 - accuracy: 0.7655 - val_loss: 0.4424 - val_accuracy: 0.8113 - lr: 4.0000e-06\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.7693Epoch 25/40: loss=0.4889, accuracy=0.7690, val_loss=0.4383, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4889 - accuracy: 0.7690 - val_loss: 0.4383 - val_accuracy: 0.8113 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.7657\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Epoch 26/40: loss=0.4927, accuracy=0.7657, val_loss=0.4420, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4927 - accuracy: 0.7657 - val_loss: 0.4420 - val_accuracy: 0.8079 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.7606Epoch 27/40: loss=0.4975, accuracy=0.7610, val_loss=0.4465, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4975 - accuracy: 0.7610 - val_loss: 0.4465 - val_accuracy: 0.8079 - lr: 8.0000e-07\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7589Epoch 28/40: loss=0.5017, accuracy=0.7595, val_loss=0.4394, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5017 - accuracy: 0.7595 - val_loss: 0.4394 - val_accuracy: 0.8121 - lr: 8.0000e-07\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4990 - accuracy: 0.7573Epoch 29/40: loss=0.4993, accuracy=0.7570, val_loss=0.4382, val_accuracy=0.8154\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4993 - accuracy: 0.7570 - val_loss: 0.4382 - val_accuracy: 0.8154 - lr: 8.0000e-07\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7655Epoch 30/40: loss=0.4915, accuracy=0.7655, val_loss=0.4386, val_accuracy=0.8129\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4915 - accuracy: 0.7655 - val_loss: 0.4386 - val_accuracy: 0.8129 - lr: 8.0000e-07\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.7550\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.6000001323845936e-07.\n",
      "Epoch 31/40: loss=0.4956, accuracy=0.7556, val_loss=0.4427, val_accuracy=0.8096\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4956 - accuracy: 0.7556 - val_loss: 0.4427 - val_accuracy: 0.8096 - lr: 8.0000e-07\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4924 - accuracy: 0.7660Epoch 32/40: loss=0.4927, accuracy=0.7657, val_loss=0.4393, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4927 - accuracy: 0.7657 - val_loss: 0.4393 - val_accuracy: 0.8129 - lr: 1.6000e-07\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.7691Epoch 33/40: loss=0.4868, accuracy=0.7692, val_loss=0.4402, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4868 - accuracy: 0.7692 - val_loss: 0.4402 - val_accuracy: 0.8113 - lr: 1.6000e-07\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7676Epoch 34/40: loss=0.4953, accuracy=0.7676, val_loss=0.4398, val_accuracy=0.8129\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4953 - accuracy: 0.7676 - val_loss: 0.4398 - val_accuracy: 0.8129 - lr: 1.6000e-07\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.7647Epoch 35/40: loss=0.4988, accuracy=0.7647, val_loss=0.4325, val_accuracy=0.8171\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4988 - accuracy: 0.7647 - val_loss: 0.4325 - val_accuracy: 0.8171 - lr: 1.6000e-07\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.7641Epoch 36/40: loss=0.4863, accuracy=0.7645, val_loss=0.4409, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4863 - accuracy: 0.7645 - val_loss: 0.4409 - val_accuracy: 0.8129 - lr: 1.6000e-07\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.7672Epoch 37/40: loss=0.4824, accuracy=0.7672, val_loss=0.4388, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4824 - accuracy: 0.7672 - val_loss: 0.4388 - val_accuracy: 0.8129 - lr: 1.6000e-07\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7697Epoch 38/40: loss=0.4893, accuracy=0.7697, val_loss=0.4374, val_accuracy=0.8137\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4893 - accuracy: 0.7697 - val_loss: 0.4374 - val_accuracy: 0.8137 - lr: 1.6000e-07\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.7666Epoch 39/40: loss=0.4877, accuracy=0.7666, val_loss=0.4392, val_accuracy=0.8104\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4877 - accuracy: 0.7666 - val_loss: 0.4392 - val_accuracy: 0.8104 - lr: 1.6000e-07\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.7643\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 40/40: loss=0.4964, accuracy=0.7649, val_loss=0.4421, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4964 - accuracy: 0.7649 - val_loss: 0.4421 - val_accuracy: 0.8137 - lr: 1.6000e-07\n",
      "Validation accuracy: 0.8220198750495911\n",
      "\n",
      "Initial Training Combination 48/50: num_residual_blocks=3, dropout_rate=0.6, learning_rate=0.0001, rotation_range=20, width_shift_range=0.2, height_shift_range=0.3, shear_range=0.1, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 1.1281 - accuracy: 0.4938Epoch 1/40: loss=1.1269, accuracy=0.4940, val_loss=0.6694, val_accuracy=0.6142\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 1.1269 - accuracy: 0.4940 - val_loss: 0.6694 - val_accuracy: 0.6142 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.5072Epoch 2/40: loss=1.0160, accuracy=0.5072, val_loss=0.6567, val_accuracy=0.6192\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 1.0160 - accuracy: 0.5072 - val_loss: 0.6567 - val_accuracy: 0.6192 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.5000Epoch 3/40: loss=0.9646, accuracy=0.5000, val_loss=0.6812, val_accuracy=0.5629\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.9646 - accuracy: 0.5000 - val_loss: 0.6812 - val_accuracy: 0.5629 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9310 - accuracy: 0.4884Epoch 4/40: loss=0.9310, accuracy=0.4884, val_loss=0.6648, val_accuracy=0.6184\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.9310 - accuracy: 0.4884 - val_loss: 0.6648 - val_accuracy: 0.6184 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8711 - accuracy: 0.5012Epoch 5/40: loss=0.8711, accuracy=0.5012, val_loss=0.6770, val_accuracy=0.5671\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.8711 - accuracy: 0.5012 - val_loss: 0.6770 - val_accuracy: 0.5671 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.5008Epoch 6/40: loss=0.8495, accuracy=0.5008, val_loss=0.6716, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8495 - accuracy: 0.5008 - val_loss: 0.6716 - val_accuracy: 0.5969 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8215 - accuracy: 0.4988\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/40: loss=0.8215, accuracy=0.4988, val_loss=0.6857, val_accuracy=0.5389\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.8215 - accuracy: 0.4988 - val_loss: 0.6857 - val_accuracy: 0.5389 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8036 - accuracy: 0.5000Epoch 8/40: loss=0.8045, accuracy=0.4996, val_loss=0.6724, val_accuracy=0.6167\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8045 - accuracy: 0.4996 - val_loss: 0.6724 - val_accuracy: 0.6167 - lr: 2.0000e-05\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8058 - accuracy: 0.4952Epoch 9/40: loss=0.8058, accuracy=0.4952, val_loss=0.6725, val_accuracy=0.6175\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8058 - accuracy: 0.4952 - val_loss: 0.6725 - val_accuracy: 0.6175 - lr: 2.0000e-05\n",
      "Epoch 10/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8005 - accuracy: 0.5033Epoch 10/40: loss=0.8008, accuracy=0.5025, val_loss=0.6738, val_accuracy=0.6167\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.8008 - accuracy: 0.5025 - val_loss: 0.6738 - val_accuracy: 0.6167 - lr: 2.0000e-05\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.4932Epoch 11/40: loss=0.7963, accuracy=0.4932, val_loss=0.6687, val_accuracy=0.6109\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7963 - accuracy: 0.4932 - val_loss: 0.6687 - val_accuracy: 0.6109 - lr: 2.0000e-05\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.5029\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 12/40: loss=0.7797, accuracy=0.5033, val_loss=0.6721, val_accuracy=0.6217\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.7797 - accuracy: 0.5033 - val_loss: 0.6721 - val_accuracy: 0.6217 - lr: 2.0000e-05\n",
      "Epoch 12: early stopping\n",
      "Validation accuracy: 0.621688723564148\n",
      "\n",
      "Initial Training Combination 49/50: num_residual_blocks=1, dropout_rate=0.6, learning_rate=0.001, rotation_range=10, width_shift_range=0.3, height_shift_range=0.1, shear_range=0.3, zoom_range=0.3, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.9272 - accuracy: 0.5019Epoch 1/40: loss=0.9272, accuracy=0.5019, val_loss=0.7422, val_accuracy=0.4015\n",
      "604/604 [==============================] - 13s 20ms/step - loss: 0.9272 - accuracy: 0.5019 - val_loss: 0.7422 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7363 - accuracy: 0.4988Epoch 2/40: loss=0.7366, accuracy=0.4981, val_loss=0.6947, val_accuracy=0.4950\n",
      "604/604 [==============================] - 9s 15ms/step - loss: 0.7366 - accuracy: 0.4981 - val_loss: 0.6947 - val_accuracy: 0.4950 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7184 - accuracy: 0.5019Epoch 3/40: loss=0.7184, accuracy=0.5019, val_loss=0.7101, val_accuracy=0.4098\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7184 - accuracy: 0.5019 - val_loss: 0.7101 - val_accuracy: 0.4098 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7151 - accuracy: 0.5039Epoch 4/40: loss=0.7153, accuracy=0.5037, val_loss=0.7011, val_accuracy=0.4263\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.7153 - accuracy: 0.5037 - val_loss: 0.7011 - val_accuracy: 0.4263 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7201 - accuracy: 0.4903Epoch 5/40: loss=0.7199, accuracy=0.4909, val_loss=0.6887, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7199 - accuracy: 0.4909 - val_loss: 0.6887 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7124 - accuracy: 0.4990Epoch 6/40: loss=0.7125, accuracy=0.4992, val_loss=0.6856, val_accuracy=0.5969\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.7125 - accuracy: 0.4992 - val_loss: 0.6856 - val_accuracy: 0.5969 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.5075Epoch 7/40: loss=0.7064, accuracy=0.5075, val_loss=0.7632, val_accuracy=0.5174\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7064 - accuracy: 0.5075 - val_loss: 0.7632 - val_accuracy: 0.5174 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.5124Epoch 8/40: loss=0.7004, accuracy=0.5124, val_loss=0.8752, val_accuracy=0.5513\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.7004 - accuracy: 0.5124 - val_loss: 0.8752 - val_accuracy: 0.5513 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5388Epoch 9/40: loss=0.6928, accuracy=0.5389, val_loss=0.9265, val_accuracy=0.5993\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6928 - accuracy: 0.5389 - val_loss: 0.9265 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6877 - accuracy: 0.5566Epoch 10/40: loss=0.6875, accuracy=0.5565, val_loss=0.8278, val_accuracy=0.6333\n",
      "604/604 [==============================] - 9s 16ms/step - loss: 0.6875 - accuracy: 0.5565 - val_loss: 0.8278 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5584\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 11/40: loss=0.6907, accuracy=0.5584, val_loss=1.4760, val_accuracy=0.4685\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6907 - accuracy: 0.5584 - val_loss: 1.4760 - val_accuracy: 0.4685 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5804Epoch 12/40: loss=0.6725, accuracy=0.5807, val_loss=0.7147, val_accuracy=0.6540\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6725 - accuracy: 0.5807 - val_loss: 0.7147 - val_accuracy: 0.6540 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.6020Epoch 13/40: loss=0.6581, accuracy=0.6020, val_loss=0.7790, val_accuracy=0.6026\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6581 - accuracy: 0.6020 - val_loss: 0.7790 - val_accuracy: 0.6026 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.6163Epoch 14/40: loss=0.6483, accuracy=0.6163, val_loss=0.8204, val_accuracy=0.6242\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6483 - accuracy: 0.6163 - val_loss: 0.8204 - val_accuracy: 0.6242 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6448 - accuracy: 0.6233Epoch 15/40: loss=0.6449, accuracy=0.6236, val_loss=0.7950, val_accuracy=0.6821\n",
      "604/604 [==============================] - 10s 16ms/step - loss: 0.6449 - accuracy: 0.6236 - val_loss: 0.7950 - val_accuracy: 0.6821 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6416 - accuracy: 0.6285\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 16/40: loss=0.6413, accuracy=0.6289, val_loss=0.8407, val_accuracy=0.6730\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6413 - accuracy: 0.6289 - val_loss: 0.8407 - val_accuracy: 0.6730 - lr: 2.0000e-04\n",
      "Epoch 16: early stopping\n",
      "Validation accuracy: 0.6821191906929016\n",
      "\n",
      "Initial Training Combination 50/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.001, rotation_range=10, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.3, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8054 - accuracy: 0.6248Epoch 1/40: loss=0.8054, accuracy=0.6248, val_loss=1.1912, val_accuracy=0.6308\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 0.8054 - accuracy: 0.6248 - val_loss: 1.1912 - val_accuracy: 0.6308 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6065 - accuracy: 0.6913Epoch 2/40: loss=0.6069, accuracy=0.6914, val_loss=0.7802, val_accuracy=0.6656\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6069 - accuracy: 0.6914 - val_loss: 0.7802 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.7140Epoch 3/40: loss=0.5727, accuracy=0.7140, val_loss=1.6288, val_accuracy=0.4776\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5727 - accuracy: 0.7140 - val_loss: 1.6288 - val_accuracy: 0.4776 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5731 - accuracy: 0.7020Epoch 4/40: loss=0.5732, accuracy=0.7020, val_loss=1.0887, val_accuracy=0.5166\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5732 - accuracy: 0.7020 - val_loss: 1.0887 - val_accuracy: 0.5166 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5564 - accuracy: 0.7338Epoch 5/40: loss=0.5561, accuracy=0.7341, val_loss=0.5019, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5561 - accuracy: 0.7341 - val_loss: 0.5019 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5508 - accuracy: 0.7369Epoch 6/40: loss=0.5507, accuracy=0.7372, val_loss=0.6088, val_accuracy=0.7368\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.6088 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7287Epoch 7/40: loss=0.5480, accuracy=0.7287, val_loss=0.8263, val_accuracy=0.7020\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5480 - accuracy: 0.7287 - val_loss: 0.8263 - val_accuracy: 0.7020 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7403Epoch 8/40: loss=0.5428, accuracy=0.7405, val_loss=0.7750, val_accuracy=0.5240\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5428 - accuracy: 0.7405 - val_loss: 0.7750 - val_accuracy: 0.5240 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5442 - accuracy: 0.7407Epoch 9/40: loss=0.5442, accuracy=0.7409, val_loss=0.4639, val_accuracy=0.7616\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5442 - accuracy: 0.7409 - val_loss: 0.4639 - val_accuracy: 0.7616 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.7471Epoch 10/40: loss=0.5275, accuracy=0.7473, val_loss=0.4727, val_accuracy=0.7608\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5275 - accuracy: 0.7473 - val_loss: 0.4727 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.7430Epoch 11/40: loss=0.5440, accuracy=0.7430, val_loss=0.6317, val_accuracy=0.7343\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5440 - accuracy: 0.7430 - val_loss: 0.6317 - val_accuracy: 0.7343 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.7569Epoch 12/40: loss=0.5271, accuracy=0.7566, val_loss=0.8386, val_accuracy=0.7086\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5271 - accuracy: 0.7566 - val_loss: 0.8386 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.7492Epoch 13/40: loss=0.5274, accuracy=0.7496, val_loss=0.4429, val_accuracy=0.7988\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5274 - accuracy: 0.7496 - val_loss: 0.4429 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5141 - accuracy: 0.7566Epoch 14/40: loss=0.5142, accuracy=0.7566, val_loss=0.8608, val_accuracy=0.5985\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5142 - accuracy: 0.7566 - val_loss: 0.8608 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.7515Epoch 15/40: loss=0.5215, accuracy=0.7517, val_loss=0.7771, val_accuracy=0.6581\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5215 - accuracy: 0.7517 - val_loss: 0.7771 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.7606Epoch 16/40: loss=0.5135, accuracy=0.7599, val_loss=0.8252, val_accuracy=0.6200\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5135 - accuracy: 0.7599 - val_loss: 0.8252 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.7527Epoch 17/40: loss=0.5121, accuracy=0.7529, val_loss=0.5619, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5121 - accuracy: 0.7529 - val_loss: 0.5619 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.7488\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/40: loss=0.5173, accuracy=0.7490, val_loss=0.5149, val_accuracy=0.7608\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5173 - accuracy: 0.7490 - val_loss: 0.5149 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4849 - accuracy: 0.7610Epoch 19/40: loss=0.4845, accuracy=0.7612, val_loss=0.3930, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4845 - accuracy: 0.7612 - val_loss: 0.3930 - val_accuracy: 0.8270 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.7769Epoch 20/40: loss=0.4726, accuracy=0.7769, val_loss=0.3872, val_accuracy=0.8286\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4726 - accuracy: 0.7769 - val_loss: 0.3872 - val_accuracy: 0.8286 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.7837Epoch 21/40: loss=0.4711, accuracy=0.7841, val_loss=0.4125, val_accuracy=0.8320\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4125 - val_accuracy: 0.8320 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4704 - accuracy: 0.7869Epoch 22/40: loss=0.4709, accuracy=0.7866, val_loss=0.4080, val_accuracy=0.8311\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4709 - accuracy: 0.7866 - val_loss: 0.4080 - val_accuracy: 0.8311 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.7843Epoch 23/40: loss=0.4637, accuracy=0.7841, val_loss=0.4969, val_accuracy=0.7773\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4637 - accuracy: 0.7841 - val_loss: 0.4969 - val_accuracy: 0.7773 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7870Epoch 24/40: loss=0.4543, accuracy=0.7870, val_loss=0.4055, val_accuracy=0.8444\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4543 - accuracy: 0.7870 - val_loss: 0.4055 - val_accuracy: 0.8444 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.7907\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/40: loss=0.4517, accuracy=0.7908, val_loss=0.3986, val_accuracy=0.8253\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4517 - accuracy: 0.7908 - val_loss: 0.3986 - val_accuracy: 0.8253 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4459 - accuracy: 0.7940Epoch 26/40: loss=0.4458, accuracy=0.7943, val_loss=0.3841, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4458 - accuracy: 0.7943 - val_loss: 0.3841 - val_accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4453 - accuracy: 0.7984Epoch 27/40: loss=0.4459, accuracy=0.7980, val_loss=0.3941, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4459 - accuracy: 0.7980 - val_loss: 0.3941 - val_accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4463 - accuracy: 0.7964Epoch 28/40: loss=0.4459, accuracy=0.7968, val_loss=0.3979, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4459 - accuracy: 0.7968 - val_loss: 0.3979 - val_accuracy: 0.8377 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8016Epoch 29/40: loss=0.4368, accuracy=0.8019, val_loss=0.3983, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4368 - accuracy: 0.8019 - val_loss: 0.3983 - val_accuracy: 0.8377 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7928Epoch 30/40: loss=0.4423, accuracy=0.7928, val_loss=0.3822, val_accuracy=0.8386\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4423 - accuracy: 0.7928 - val_loss: 0.3822 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7995Epoch 31/40: loss=0.4422, accuracy=0.7995, val_loss=0.3934, val_accuracy=0.8353\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4422 - accuracy: 0.7995 - val_loss: 0.3934 - val_accuracy: 0.8353 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.7975Epoch 32/40: loss=0.4383, accuracy=0.7978, val_loss=0.3860, val_accuracy=0.8377\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4383 - accuracy: 0.7978 - val_loss: 0.3860 - val_accuracy: 0.8377 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.7959Epoch 33/40: loss=0.4388, accuracy=0.7964, val_loss=0.3966, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4388 - accuracy: 0.7964 - val_loss: 0.3966 - val_accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.8064Epoch 34/40: loss=0.4316, accuracy=0.8053, val_loss=0.3965, val_accuracy=0.8361\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4316 - accuracy: 0.8053 - val_loss: 0.3965 - val_accuracy: 0.8361 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7939\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 35/40: loss=0.4443, accuracy=0.7939, val_loss=0.3860, val_accuracy=0.8361\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4443 - accuracy: 0.7939 - val_loss: 0.3860 - val_accuracy: 0.8361 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8047Epoch 36/40: loss=0.4297, accuracy=0.8046, val_loss=0.3913, val_accuracy=0.8328\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4297 - accuracy: 0.8046 - val_loss: 0.3913 - val_accuracy: 0.8328 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.8015Epoch 37/40: loss=0.4253, accuracy=0.8011, val_loss=0.3980, val_accuracy=0.8278\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4253 - accuracy: 0.8011 - val_loss: 0.3980 - val_accuracy: 0.8278 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8024Epoch 38/40: loss=0.4306, accuracy=0.8024, val_loss=0.3962, val_accuracy=0.8286\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4306 - accuracy: 0.8024 - val_loss: 0.3962 - val_accuracy: 0.8286 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4322 - accuracy: 0.8075Epoch 39/40: loss=0.4329, accuracy=0.8073, val_loss=0.3871, val_accuracy=0.8344\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4329 - accuracy: 0.8073 - val_loss: 0.3871 - val_accuracy: 0.8344 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.7968\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40/40: loss=0.4346, accuracy=0.7968, val_loss=0.3858, val_accuracy=0.8411\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4346 - accuracy: 0.7968 - val_loss: 0.3858 - val_accuracy: 0.8411 - lr: 8.0000e-06\n",
      "Epoch 40: early stopping\n",
      "Validation accuracy: 0.8443708419799805\n",
      "\n",
      "Best parameters found in initial grid search: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.0005, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Best validation accuracy: 0.8642383813858032\n",
      "\n",
      "Refined Training Combination 1/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.001, rotation_range=40, width_shift_range=0.30000000000000004, height_shift_range=0.0, shear_range=0.0, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8746 - accuracy: 0.5471Epoch 1/40: loss=0.8739, accuracy=0.5474, val_loss=2.1597, val_accuracy=0.4570\n",
      "604/604 [==============================] - 14s 21ms/step - loss: 0.8739 - accuracy: 0.5474 - val_loss: 2.1597 - val_accuracy: 0.4570 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6138 - accuracy: 0.6721Epoch 2/40: loss=0.6138, accuracy=0.6722, val_loss=0.7622, val_accuracy=0.5298\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6138 - accuracy: 0.6722 - val_loss: 0.7622 - val_accuracy: 0.5298 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5783 - accuracy: 0.7085Epoch 3/40: loss=0.5779, accuracy=0.7090, val_loss=0.6238, val_accuracy=0.6954\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5779 - accuracy: 0.7090 - val_loss: 0.6238 - val_accuracy: 0.6954 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7227Epoch 4/40: loss=0.5649, accuracy=0.7227, val_loss=3.3577, val_accuracy=0.4123\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5649 - accuracy: 0.7227 - val_loss: 3.3577 - val_accuracy: 0.4123 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7171Epoch 5/40: loss=0.5671, accuracy=0.7171, val_loss=0.7212, val_accuracy=0.6531\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5671 - accuracy: 0.7171 - val_loss: 0.7212 - val_accuracy: 0.6531 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5668 - accuracy: 0.7265Epoch 6/40: loss=0.5671, accuracy=0.7264, val_loss=1.4797, val_accuracy=0.6333\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5671 - accuracy: 0.7264 - val_loss: 1.4797 - val_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.7216Epoch 7/40: loss=0.5715, accuracy=0.7216, val_loss=0.5682, val_accuracy=0.7409\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5715 - accuracy: 0.7216 - val_loss: 0.5682 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.7205Epoch 8/40: loss=0.5585, accuracy=0.7206, val_loss=0.8566, val_accuracy=0.5108\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5585 - accuracy: 0.7206 - val_loss: 0.8566 - val_accuracy: 0.5108 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5527 - accuracy: 0.7185Epoch 9/40: loss=0.5538, accuracy=0.7179, val_loss=0.6513, val_accuracy=0.6714\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5538 - accuracy: 0.7179 - val_loss: 0.6513 - val_accuracy: 0.6714 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5521 - accuracy: 0.7355Epoch 10/40: loss=0.5518, accuracy=0.7355, val_loss=1.3749, val_accuracy=0.5017\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5518 - accuracy: 0.7355 - val_loss: 1.3749 - val_accuracy: 0.5017 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7490Epoch 11/40: loss=0.5455, accuracy=0.7490, val_loss=0.5765, val_accuracy=0.7252\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5455 - accuracy: 0.7490 - val_loss: 0.5765 - val_accuracy: 0.7252 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7425\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/40: loss=0.5481, accuracy=0.7425, val_loss=0.6928, val_accuracy=0.5844\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5481 - accuracy: 0.7425 - val_loss: 0.6928 - val_accuracy: 0.5844 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.7579Epoch 13/40: loss=0.5058, accuracy=0.7577, val_loss=0.5533, val_accuracy=0.7417\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5058 - accuracy: 0.7577 - val_loss: 0.5533 - val_accuracy: 0.7417 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.7632Epoch 14/40: loss=0.4983, accuracy=0.7632, val_loss=0.4757, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4983 - accuracy: 0.7632 - val_loss: 0.4757 - val_accuracy: 0.7947 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4914 - accuracy: 0.7705Epoch 15/40: loss=0.4910, accuracy=0.7709, val_loss=0.4129, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4910 - accuracy: 0.7709 - val_loss: 0.4129 - val_accuracy: 0.8162 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.7748Epoch 16/40: loss=0.4873, accuracy=0.7748, val_loss=0.4131, val_accuracy=0.8162\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4873 - accuracy: 0.7748 - val_loss: 0.4131 - val_accuracy: 0.8162 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7726Epoch 17/40: loss=0.4807, accuracy=0.7726, val_loss=0.4215, val_accuracy=0.8137\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4807 - accuracy: 0.7726 - val_loss: 0.4215 - val_accuracy: 0.8137 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.7699Epoch 18/40: loss=0.4837, accuracy=0.7699, val_loss=0.4124, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4837 - accuracy: 0.7699 - val_loss: 0.4124 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.7720Epoch 19/40: loss=0.4845, accuracy=0.7719, val_loss=0.4668, val_accuracy=0.8013\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4845 - accuracy: 0.7719 - val_loss: 0.4668 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.7818Epoch 20/40: loss=0.4773, accuracy=0.7819, val_loss=0.4669, val_accuracy=0.8071\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4773 - accuracy: 0.7819 - val_loss: 0.4669 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.7830Epoch 21/40: loss=0.4696, accuracy=0.7833, val_loss=0.4184, val_accuracy=0.8179\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4696 - accuracy: 0.7833 - val_loss: 0.4184 - val_accuracy: 0.8179 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.7783Epoch 22/40: loss=0.4768, accuracy=0.7781, val_loss=0.4186, val_accuracy=0.8171\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4768 - accuracy: 0.7781 - val_loss: 0.4186 - val_accuracy: 0.8171 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7817\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/40: loss=0.4716, accuracy=0.7817, val_loss=0.4962, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4716 - accuracy: 0.7817 - val_loss: 0.4962 - val_accuracy: 0.7815 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.7804Epoch 24/40: loss=0.4762, accuracy=0.7800, val_loss=0.4298, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4762 - accuracy: 0.7800 - val_loss: 0.4298 - val_accuracy: 0.8038 - lr: 4.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.7950Epoch 25/40: loss=0.4467, accuracy=0.7949, val_loss=0.4225, val_accuracy=0.8129\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4467 - accuracy: 0.7949 - val_loss: 0.4225 - val_accuracy: 0.8129 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7887Epoch 26/40: loss=0.4532, accuracy=0.7887, val_loss=0.4036, val_accuracy=0.8270\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4532 - accuracy: 0.7887 - val_loss: 0.4036 - val_accuracy: 0.8270 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.7829Epoch 27/40: loss=0.4624, accuracy=0.7829, val_loss=0.4533, val_accuracy=0.7922\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4624 - accuracy: 0.7829 - val_loss: 0.4533 - val_accuracy: 0.7922 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4548 - accuracy: 0.7952Epoch 28/40: loss=0.4549, accuracy=0.7953, val_loss=0.4528, val_accuracy=0.7988\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4549 - accuracy: 0.7953 - val_loss: 0.4528 - val_accuracy: 0.7988 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.7902Epoch 29/40: loss=0.4495, accuracy=0.7906, val_loss=0.4144, val_accuracy=0.8253\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4495 - accuracy: 0.7906 - val_loss: 0.4144 - val_accuracy: 0.8253 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4604 - accuracy: 0.7919Epoch 30/40: loss=0.4602, accuracy=0.7918, val_loss=0.4233, val_accuracy=0.8146\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4602 - accuracy: 0.7918 - val_loss: 0.4233 - val_accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.8002\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 31/40: loss=0.4418, accuracy=0.8003, val_loss=0.4130, val_accuracy=0.8228\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4418 - accuracy: 0.8003 - val_loss: 0.4130 - val_accuracy: 0.8228 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.7949Epoch 32/40: loss=0.4538, accuracy=0.7949, val_loss=0.4328, val_accuracy=0.8088\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4538 - accuracy: 0.7949 - val_loss: 0.4328 - val_accuracy: 0.8088 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.7933Epoch 33/40: loss=0.4482, accuracy=0.7933, val_loss=0.4264, val_accuracy=0.8129\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4482 - accuracy: 0.7933 - val_loss: 0.4264 - val_accuracy: 0.8129 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.8010Epoch 34/40: loss=0.4384, accuracy=0.8007, val_loss=0.4328, val_accuracy=0.8104\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4384 - accuracy: 0.8007 - val_loss: 0.4328 - val_accuracy: 0.8104 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4498 - accuracy: 0.7971Epoch 35/40: loss=0.4502, accuracy=0.7968, val_loss=0.4305, val_accuracy=0.8154\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4502 - accuracy: 0.7968 - val_loss: 0.4305 - val_accuracy: 0.8154 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.7967\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 36/40: loss=0.4456, accuracy=0.7970, val_loss=0.4237, val_accuracy=0.8179\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4456 - accuracy: 0.7970 - val_loss: 0.4237 - val_accuracy: 0.8179 - lr: 8.0000e-06\n",
      "Epoch 36: early stopping\n",
      "Validation accuracy: 0.8269867300987244\n",
      "\n",
      "Refined Training Combination 2/50: num_residual_blocks=3, dropout_rate=0.4, learning_rate=0.00025, rotation_range=30, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.0, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.5460Epoch 1/40: loss=0.9182, accuracy=0.5466, val_loss=0.5654, val_accuracy=0.7111\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 0.9182 - accuracy: 0.5466 - val_loss: 0.5654 - val_accuracy: 0.7111 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7620 - accuracy: 0.6188Epoch 2/40: loss=0.7619, accuracy=0.6190, val_loss=1.7462, val_accuracy=0.4015\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7619 - accuracy: 0.6190 - val_loss: 1.7462 - val_accuracy: 0.4015 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.6677Epoch 3/40: loss=0.6630, accuracy=0.6674, val_loss=1.3916, val_accuracy=0.4081\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6630 - accuracy: 0.6674 - val_loss: 1.3916 - val_accuracy: 0.4081 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6390 - accuracy: 0.6657Epoch 4/40: loss=0.6391, accuracy=0.6658, val_loss=0.7791, val_accuracy=0.6631\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6391 - accuracy: 0.6658 - val_loss: 0.7791 - val_accuracy: 0.6631 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.6832Epoch 5/40: loss=0.6090, accuracy=0.6832, val_loss=0.5056, val_accuracy=0.7641\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6090 - accuracy: 0.6832 - val_loss: 0.5056 - val_accuracy: 0.7641 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.7105Epoch 6/40: loss=0.5708, accuracy=0.7105, val_loss=0.5628, val_accuracy=0.7409\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5708 - accuracy: 0.7105 - val_loss: 0.5628 - val_accuracy: 0.7409 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5763 - accuracy: 0.7102Epoch 7/40: loss=0.5761, accuracy=0.7103, val_loss=0.5162, val_accuracy=0.7541\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5761 - accuracy: 0.7103 - val_loss: 0.5162 - val_accuracy: 0.7541 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5657 - accuracy: 0.7182Epoch 8/40: loss=0.5656, accuracy=0.7181, val_loss=0.7059, val_accuracy=0.6647\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5656 - accuracy: 0.7181 - val_loss: 0.7059 - val_accuracy: 0.6647 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.7318Epoch 9/40: loss=0.5398, accuracy=0.7318, val_loss=0.6009, val_accuracy=0.6606\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5398 - accuracy: 0.7318 - val_loss: 0.6009 - val_accuracy: 0.6606 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5477 - accuracy: 0.7297\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 10/40: loss=0.5478, accuracy=0.7297, val_loss=1.0481, val_accuracy=0.5530\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5478 - accuracy: 0.7297 - val_loss: 1.0481 - val_accuracy: 0.5530 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.7485Epoch 11/40: loss=0.5147, accuracy=0.7488, val_loss=0.5009, val_accuracy=0.7632\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5147 - accuracy: 0.7488 - val_loss: 0.5009 - val_accuracy: 0.7632 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.7407Epoch 12/40: loss=0.5159, accuracy=0.7401, val_loss=0.4220, val_accuracy=0.8055\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5159 - accuracy: 0.7401 - val_loss: 0.4220 - val_accuracy: 0.8055 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.7570Epoch 13/40: loss=0.5103, accuracy=0.7572, val_loss=0.4427, val_accuracy=0.8079\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5103 - accuracy: 0.7572 - val_loss: 0.4427 - val_accuracy: 0.8079 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5069 - accuracy: 0.7618Epoch 14/40: loss=0.5067, accuracy=0.7618, val_loss=0.4244, val_accuracy=0.8154\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5067 - accuracy: 0.7618 - val_loss: 0.4244 - val_accuracy: 0.8154 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4885 - accuracy: 0.7675Epoch 15/40: loss=0.4882, accuracy=0.7678, val_loss=0.4809, val_accuracy=0.7815\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4882 - accuracy: 0.7678 - val_loss: 0.4809 - val_accuracy: 0.7815 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.7620Epoch 16/40: loss=0.4986, accuracy=0.7618, val_loss=0.4532, val_accuracy=0.7955\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4986 - accuracy: 0.7618 - val_loss: 0.4532 - val_accuracy: 0.7955 - lr: 5.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.7736\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 17/40: loss=0.4837, accuracy=0.7736, val_loss=0.4778, val_accuracy=0.7873\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4837 - accuracy: 0.7736 - val_loss: 0.4778 - val_accuracy: 0.7873 - lr: 5.0000e-05\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4869 - accuracy: 0.7668Epoch 18/40: loss=0.4863, accuracy=0.7672, val_loss=0.4105, val_accuracy=0.8262\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4863 - accuracy: 0.7672 - val_loss: 0.4105 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4746 - accuracy: 0.7749Epoch 19/40: loss=0.4745, accuracy=0.7750, val_loss=0.4129, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4745 - accuracy: 0.7750 - val_loss: 0.4129 - val_accuracy: 0.8195 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.7724Epoch 20/40: loss=0.4821, accuracy=0.7724, val_loss=0.4290, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4821 - accuracy: 0.7724 - val_loss: 0.4290 - val_accuracy: 0.8237 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7784Epoch 21/40: loss=0.4665, accuracy=0.7784, val_loss=0.4187, val_accuracy=0.8171\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4665 - accuracy: 0.7784 - val_loss: 0.4187 - val_accuracy: 0.8171 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.7710Epoch 22/40: loss=0.4748, accuracy=0.7709, val_loss=0.4255, val_accuracy=0.8220\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4748 - accuracy: 0.7709 - val_loss: 0.4255 - val_accuracy: 0.8220 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.7772\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Epoch 23/40: loss=0.4693, accuracy=0.7773, val_loss=0.4220, val_accuracy=0.8278\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4693 - accuracy: 0.7773 - val_loss: 0.4220 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.7775Epoch 24/40: loss=0.4638, accuracy=0.7775, val_loss=0.4160, val_accuracy=0.8228\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4638 - accuracy: 0.7775 - val_loss: 0.4160 - val_accuracy: 0.8228 - lr: 2.0000e-06\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4636 - accuracy: 0.7747Epoch 25/40: loss=0.4631, accuracy=0.7752, val_loss=0.4220, val_accuracy=0.8278\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4631 - accuracy: 0.7752 - val_loss: 0.4220 - val_accuracy: 0.8278 - lr: 2.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.7866Epoch 26/40: loss=0.4636, accuracy=0.7866, val_loss=0.4199, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4636 - accuracy: 0.7866 - val_loss: 0.4199 - val_accuracy: 0.8278 - lr: 2.0000e-06\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7792Epoch 27/40: loss=0.4707, accuracy=0.7790, val_loss=0.4200, val_accuracy=0.8286\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4707 - accuracy: 0.7790 - val_loss: 0.4200 - val_accuracy: 0.8286 - lr: 2.0000e-06\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4672 - accuracy: 0.7826\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.000000444648322e-07.\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 28/40: loss=0.4666, accuracy=0.7829, val_loss=0.4202, val_accuracy=0.8278\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4666 - accuracy: 0.7829 - val_loss: 0.4202 - val_accuracy: 0.8278 - lr: 2.0000e-06\n",
      "Epoch 28: early stopping\n",
      "Validation accuracy: 0.8286423683166504\n",
      "\n",
      "Refined Training Combination 3/50: num_residual_blocks=5, dropout_rate=0.19999999999999998, learning_rate=0.0005, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8645 - accuracy: 0.5636Epoch 1/40: loss=0.8639, accuracy=0.5642, val_loss=0.6255, val_accuracy=0.7012\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 0.8639 - accuracy: 0.5642 - val_loss: 0.6255 - val_accuracy: 0.7012 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.6617Epoch 2/40: loss=0.6518, accuracy=0.6618, val_loss=1.5517, val_accuracy=0.6093\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.6518 - accuracy: 0.6618 - val_loss: 1.5517 - val_accuracy: 0.6093 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.6902Epoch 3/40: loss=0.6086, accuracy=0.6902, val_loss=1.0671, val_accuracy=0.5629\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6086 - accuracy: 0.6902 - val_loss: 1.0671 - val_accuracy: 0.5629 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.7082Epoch 4/40: loss=0.5716, accuracy=0.7082, val_loss=0.7137, val_accuracy=0.5977\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5716 - accuracy: 0.7082 - val_loss: 0.7137 - val_accuracy: 0.5977 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.7245Epoch 5/40: loss=0.5567, accuracy=0.7245, val_loss=0.6070, val_accuracy=0.6904\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5567 - accuracy: 0.7245 - val_loss: 0.6070 - val_accuracy: 0.6904 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.7365Epoch 6/40: loss=0.5433, accuracy=0.7368, val_loss=0.5027, val_accuracy=0.7715\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5433 - accuracy: 0.7368 - val_loss: 0.5027 - val_accuracy: 0.7715 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.7506Epoch 7/40: loss=0.5216, accuracy=0.7506, val_loss=0.5816, val_accuracy=0.7343\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5216 - accuracy: 0.7506 - val_loss: 0.5816 - val_accuracy: 0.7343 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5205 - accuracy: 0.7550Epoch 8/40: loss=0.5207, accuracy=0.7546, val_loss=0.5051, val_accuracy=0.7583\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5207 - accuracy: 0.7546 - val_loss: 0.5051 - val_accuracy: 0.7583 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.7608Epoch 9/40: loss=0.5114, accuracy=0.7608, val_loss=0.6059, val_accuracy=0.7425\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5114 - accuracy: 0.7608 - val_loss: 0.6059 - val_accuracy: 0.7425 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.7527Epoch 10/40: loss=0.5211, accuracy=0.7527, val_loss=0.4859, val_accuracy=0.7715\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5211 - accuracy: 0.7527 - val_loss: 0.4859 - val_accuracy: 0.7715 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5024 - accuracy: 0.7699Epoch 11/40: loss=0.5023, accuracy=0.7699, val_loss=0.4536, val_accuracy=0.7997\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5023 - accuracy: 0.7699 - val_loss: 0.4536 - val_accuracy: 0.7997 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5041 - accuracy: 0.7564Epoch 12/40: loss=0.5046, accuracy=0.7562, val_loss=0.6853, val_accuracy=0.6937\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5046 - accuracy: 0.7562 - val_loss: 0.6853 - val_accuracy: 0.6937 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4924 - accuracy: 0.7668Epoch 13/40: loss=0.4921, accuracy=0.7670, val_loss=0.4838, val_accuracy=0.8079\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4921 - accuracy: 0.7670 - val_loss: 0.4838 - val_accuracy: 0.8079 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.7703Epoch 14/40: loss=0.4940, accuracy=0.7703, val_loss=0.4441, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4940 - accuracy: 0.7703 - val_loss: 0.4441 - val_accuracy: 0.7748 - lr: 5.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.7751Epoch 15/40: loss=0.4787, accuracy=0.7750, val_loss=0.4578, val_accuracy=0.7500\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.4787 - accuracy: 0.7750 - val_loss: 0.4578 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.7684Epoch 16/40: loss=0.4819, accuracy=0.7684, val_loss=0.4588, val_accuracy=0.7955\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4819 - accuracy: 0.7684 - val_loss: 0.4588 - val_accuracy: 0.7955 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.7728Epoch 17/40: loss=0.4831, accuracy=0.7732, val_loss=0.4669, val_accuracy=0.8079\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4831 - accuracy: 0.7732 - val_loss: 0.4669 - val_accuracy: 0.8079 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.7914Epoch 18/40: loss=0.4594, accuracy=0.7914, val_loss=0.4759, val_accuracy=0.8328\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4594 - accuracy: 0.7914 - val_loss: 0.4759 - val_accuracy: 0.8328 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4789 - accuracy: 0.7780Epoch 19/40: loss=0.4788, accuracy=0.7779, val_loss=0.4200, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4788 - accuracy: 0.7779 - val_loss: 0.4200 - val_accuracy: 0.8278 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.7919Epoch 20/40: loss=0.4561, accuracy=0.7914, val_loss=0.5521, val_accuracy=0.7376\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4561 - accuracy: 0.7914 - val_loss: 0.5521 - val_accuracy: 0.7376 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7875Epoch 21/40: loss=0.4532, accuracy=0.7875, val_loss=0.8995, val_accuracy=0.6093\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4532 - accuracy: 0.7875 - val_loss: 0.8995 - val_accuracy: 0.6093 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4482 - accuracy: 0.7895Epoch 22/40: loss=0.4492, accuracy=0.7891, val_loss=0.4377, val_accuracy=0.7930\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4492 - accuracy: 0.7891 - val_loss: 0.4377 - val_accuracy: 0.7930 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.7886Epoch 23/40: loss=0.4556, accuracy=0.7887, val_loss=0.5186, val_accuracy=0.7401\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4556 - accuracy: 0.7887 - val_loss: 0.5186 - val_accuracy: 0.7401 - lr: 5.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4396 - accuracy: 0.7958\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 24/40: loss=0.4404, accuracy=0.7951, val_loss=0.5006, val_accuracy=0.7624\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5006 - val_accuracy: 0.7624 - lr: 5.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.8158Epoch 25/40: loss=0.4177, accuracy=0.8158, val_loss=0.3509, val_accuracy=0.8485\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4177 - accuracy: 0.8158 - val_loss: 0.3509 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8212Epoch 26/40: loss=0.4050, accuracy=0.8212, val_loss=0.3503, val_accuracy=0.8609\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4050 - accuracy: 0.8212 - val_loss: 0.3503 - val_accuracy: 0.8609 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8177Epoch 27/40: loss=0.3970, accuracy=0.8177, val_loss=0.4385, val_accuracy=0.8022\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.3970 - accuracy: 0.8177 - val_loss: 0.4385 - val_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8377Epoch 28/40: loss=0.3856, accuracy=0.8375, val_loss=0.4066, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3856 - accuracy: 0.8375 - val_loss: 0.4066 - val_accuracy: 0.8237 - lr: 1.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8295Epoch 29/40: loss=0.3882, accuracy=0.8295, val_loss=0.3812, val_accuracy=0.8253\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3882 - accuracy: 0.8295 - val_loss: 0.3812 - val_accuracy: 0.8253 - lr: 1.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.8264Epoch 30/40: loss=0.3910, accuracy=0.8264, val_loss=0.3531, val_accuracy=0.8435\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3910 - accuracy: 0.8264 - val_loss: 0.3531 - val_accuracy: 0.8435 - lr: 1.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8264\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 31/40: loss=0.3826, accuracy=0.8262, val_loss=0.3775, val_accuracy=0.8320\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3826 - accuracy: 0.8262 - val_loss: 0.3775 - val_accuracy: 0.8320 - lr: 1.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8287Epoch 32/40: loss=0.3793, accuracy=0.8286, val_loss=0.3499, val_accuracy=0.8551\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3793 - accuracy: 0.8286 - val_loss: 0.3499 - val_accuracy: 0.8551 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8307Epoch 33/40: loss=0.3853, accuracy=0.8307, val_loss=0.3474, val_accuracy=0.8551\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.3853 - accuracy: 0.8307 - val_loss: 0.3474 - val_accuracy: 0.8551 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3704 - accuracy: 0.8368Epoch 34/40: loss=0.3704, accuracy=0.8369, val_loss=0.3590, val_accuracy=0.8477\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3704 - accuracy: 0.8369 - val_loss: 0.3590 - val_accuracy: 0.8477 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.8487Epoch 35/40: loss=0.3531, accuracy=0.8483, val_loss=0.3584, val_accuracy=0.8353\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3531 - accuracy: 0.8483 - val_loss: 0.3584 - val_accuracy: 0.8353 - lr: 2.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.8359Epoch 36/40: loss=0.3751, accuracy=0.8359, val_loss=0.3556, val_accuracy=0.8394\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.3751 - accuracy: 0.8359 - val_loss: 0.3556 - val_accuracy: 0.8394 - lr: 2.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8429Epoch 37/40: loss=0.3583, accuracy=0.8429, val_loss=0.3522, val_accuracy=0.8435\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3583 - accuracy: 0.8429 - val_loss: 0.3522 - val_accuracy: 0.8435 - lr: 2.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.8356\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 38/40: loss=0.3657, accuracy=0.8355, val_loss=0.3474, val_accuracy=0.8427\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3657 - accuracy: 0.8355 - val_loss: 0.3474 - val_accuracy: 0.8427 - lr: 2.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8388Epoch 39/40: loss=0.3656, accuracy=0.8388, val_loss=0.3524, val_accuracy=0.8419\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3656 - accuracy: 0.8388 - val_loss: 0.3524 - val_accuracy: 0.8419 - lr: 4.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.8360Epoch 40/40: loss=0.3603, accuracy=0.8361, val_loss=0.3447, val_accuracy=0.8444\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3603 - accuracy: 0.8361 - val_loss: 0.3447 - val_accuracy: 0.8444 - lr: 4.0000e-06\n",
      "Validation accuracy: 0.860927164554596\n",
      "\n",
      "Refined Training Combination 4/50: num_residual_blocks=5, dropout_rate=0.4, learning_rate=0.00025, rotation_range=40, width_shift_range=0.1, height_shift_range=0.0, shear_range=0.2, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9491 - accuracy: 0.5077Epoch 1/40: loss=0.9491, accuracy=0.5077, val_loss=0.8098, val_accuracy=0.4139\n",
      "604/604 [==============================] - 17s 24ms/step - loss: 0.9491 - accuracy: 0.5077 - val_loss: 0.8098 - val_accuracy: 0.4139 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8584 - accuracy: 0.5097Epoch 2/40: loss=0.8589, accuracy=0.5095, val_loss=0.7554, val_accuracy=0.4727\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.8589 - accuracy: 0.5095 - val_loss: 0.7554 - val_accuracy: 0.4727 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.5182Epoch 3/40: loss=0.7820, accuracy=0.5182, val_loss=0.6970, val_accuracy=0.5439\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.7820 - accuracy: 0.5182 - val_loss: 0.6970 - val_accuracy: 0.5439 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7440 - accuracy: 0.5397Epoch 4/40: loss=0.7436, accuracy=0.5401, val_loss=0.7328, val_accuracy=0.4462\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.7436 - accuracy: 0.5401 - val_loss: 0.7328 - val_accuracy: 0.4462 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.6348Epoch 5/40: loss=0.6531, accuracy=0.6349, val_loss=0.9483, val_accuracy=0.4048\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.6531 - accuracy: 0.6349 - val_loss: 0.9483 - val_accuracy: 0.4048 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.7070Epoch 6/40: loss=0.5789, accuracy=0.7070, val_loss=0.4679, val_accuracy=0.7798\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5789 - accuracy: 0.7070 - val_loss: 0.4679 - val_accuracy: 0.7798 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5608 - accuracy: 0.7189Epoch 7/40: loss=0.5604, accuracy=0.7190, val_loss=0.5476, val_accuracy=0.7003\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5604 - accuracy: 0.7190 - val_loss: 0.5476 - val_accuracy: 0.7003 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.7070Epoch 8/40: loss=0.5676, accuracy=0.7070, val_loss=0.6090, val_accuracy=0.6490\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5676 - accuracy: 0.7070 - val_loss: 0.6090 - val_accuracy: 0.6490 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.7270Epoch 9/40: loss=0.5547, accuracy=0.7270, val_loss=0.9722, val_accuracy=0.5265\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5547 - accuracy: 0.7270 - val_loss: 0.9722 - val_accuracy: 0.5265 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5269 - accuracy: 0.7465Epoch 10/40: loss=0.5273, accuracy=0.7461, val_loss=0.8250, val_accuracy=0.5381\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.5273 - accuracy: 0.7461 - val_loss: 0.8250 - val_accuracy: 0.5381 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7506Epoch 11/40: loss=0.5196, accuracy=0.7506, val_loss=0.4392, val_accuracy=0.7997\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5196 - accuracy: 0.7506 - val_loss: 0.4392 - val_accuracy: 0.7997 - lr: 2.5000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.7519Epoch 12/40: loss=0.5283, accuracy=0.7519, val_loss=0.5319, val_accuracy=0.7500\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5283 - accuracy: 0.7519 - val_loss: 0.5319 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.7512Epoch 13/40: loss=0.5134, accuracy=0.7514, val_loss=0.7919, val_accuracy=0.5844\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5134 - accuracy: 0.7514 - val_loss: 0.7919 - val_accuracy: 0.5844 - lr: 2.5000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.7612Epoch 14/40: loss=0.5086, accuracy=0.7614, val_loss=0.4943, val_accuracy=0.7575\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5086 - accuracy: 0.7614 - val_loss: 0.4943 - val_accuracy: 0.7575 - lr: 2.5000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.7657Epoch 15/40: loss=0.4963, accuracy=0.7657, val_loss=0.4631, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4963 - accuracy: 0.7657 - val_loss: 0.4631 - val_accuracy: 0.8113 - lr: 2.5000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.7711Epoch 16/40: loss=0.4867, accuracy=0.7711, val_loss=0.4214, val_accuracy=0.8187\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4867 - accuracy: 0.7711 - val_loss: 0.4214 - val_accuracy: 0.8187 - lr: 2.5000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4875 - accuracy: 0.7726Epoch 17/40: loss=0.4879, accuracy=0.7726, val_loss=0.4699, val_accuracy=0.7906\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4879 - accuracy: 0.7726 - val_loss: 0.4699 - val_accuracy: 0.7906 - lr: 2.5000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.7672Epoch 18/40: loss=0.4902, accuracy=0.7674, val_loss=0.6431, val_accuracy=0.6300\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4902 - accuracy: 0.7674 - val_loss: 0.6431 - val_accuracy: 0.6300 - lr: 2.5000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.7759Epoch 19/40: loss=0.4834, accuracy=0.7759, val_loss=0.4287, val_accuracy=0.8154\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4834 - accuracy: 0.7759 - val_loss: 0.4287 - val_accuracy: 0.8154 - lr: 2.5000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.7863Epoch 20/40: loss=0.4698, accuracy=0.7864, val_loss=0.4597, val_accuracy=0.8013\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4698 - accuracy: 0.7864 - val_loss: 0.4597 - val_accuracy: 0.8013 - lr: 2.5000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7836\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 21/40: loss=0.4683, accuracy=0.7835, val_loss=0.5329, val_accuracy=0.7376\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4683 - accuracy: 0.7835 - val_loss: 0.5329 - val_accuracy: 0.7376 - lr: 2.5000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.7941Epoch 22/40: loss=0.4466, accuracy=0.7941, val_loss=0.4097, val_accuracy=0.8328\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4466 - accuracy: 0.7941 - val_loss: 0.4097 - val_accuracy: 0.8328 - lr: 5.0000e-05\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4289 - accuracy: 0.8131Epoch 23/40: loss=0.4292, accuracy=0.8131, val_loss=0.4318, val_accuracy=0.8303\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4292 - accuracy: 0.8131 - val_loss: 0.4318 - val_accuracy: 0.8303 - lr: 5.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4227 - accuracy: 0.8064Epoch 24/40: loss=0.4225, accuracy=0.8065, val_loss=0.3985, val_accuracy=0.8477\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4225 - accuracy: 0.8065 - val_loss: 0.3985 - val_accuracy: 0.8477 - lr: 5.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4180 - accuracy: 0.8138Epoch 25/40: loss=0.4185, accuracy=0.8137, val_loss=0.4955, val_accuracy=0.8071\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4185 - accuracy: 0.8137 - val_loss: 0.4955 - val_accuracy: 0.8071 - lr: 5.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8114Epoch 26/40: loss=0.4153, accuracy=0.8115, val_loss=0.4400, val_accuracy=0.8179\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4153 - accuracy: 0.8115 - val_loss: 0.4400 - val_accuracy: 0.8179 - lr: 5.0000e-05\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4070 - accuracy: 0.8183Epoch 27/40: loss=0.4077, accuracy=0.8181, val_loss=0.5141, val_accuracy=0.7881\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4077 - accuracy: 0.8181 - val_loss: 0.5141 - val_accuracy: 0.7881 - lr: 5.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4057 - accuracy: 0.8210Epoch 28/40: loss=0.4050, accuracy=0.8216, val_loss=0.4446, val_accuracy=0.8361\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4050 - accuracy: 0.8216 - val_loss: 0.4446 - val_accuracy: 0.8361 - lr: 5.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8242\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 29/40: loss=0.4025, accuracy=0.8243, val_loss=0.4024, val_accuracy=0.8402\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4025 - accuracy: 0.8243 - val_loss: 0.4024 - val_accuracy: 0.8402 - lr: 5.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8264Epoch 30/40: loss=0.3928, accuracy=0.8257, val_loss=0.4391, val_accuracy=0.8377\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3928 - accuracy: 0.8257 - val_loss: 0.4391 - val_accuracy: 0.8377 - lr: 1.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8257Epoch 31/40: loss=0.3886, accuracy=0.8260, val_loss=0.4326, val_accuracy=0.8361\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.3886 - accuracy: 0.8260 - val_loss: 0.4326 - val_accuracy: 0.8361 - lr: 1.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8352Epoch 32/40: loss=0.3857, accuracy=0.8355, val_loss=0.4178, val_accuracy=0.8427\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3857 - accuracy: 0.8355 - val_loss: 0.4178 - val_accuracy: 0.8427 - lr: 1.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8275Epoch 33/40: loss=0.3906, accuracy=0.8278, val_loss=0.4474, val_accuracy=0.8311\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3906 - accuracy: 0.8278 - val_loss: 0.4474 - val_accuracy: 0.8311 - lr: 1.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8272\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 34/40: loss=0.3904, accuracy=0.8272, val_loss=0.4167, val_accuracy=0.8535\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3904 - accuracy: 0.8272 - val_loss: 0.4167 - val_accuracy: 0.8535 - lr: 1.0000e-05\n",
      "Epoch 34: early stopping\n",
      "Validation accuracy: 0.8534768223762512\n",
      "\n",
      "Refined Training Combination 5/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.001, rotation_range=30, width_shift_range=0.30000000000000004, height_shift_range=0.2, shear_range=0.2, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8346 - accuracy: 0.5933Epoch 1/40: loss=0.8341, accuracy=0.5935, val_loss=0.6603, val_accuracy=0.7227\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 0.8341 - accuracy: 0.5935 - val_loss: 0.6603 - val_accuracy: 0.7227 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.6783Epoch 2/40: loss=0.6173, accuracy=0.6784, val_loss=1.2624, val_accuracy=0.4793\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6173 - accuracy: 0.6784 - val_loss: 1.2624 - val_accuracy: 0.4793 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.6960Epoch 3/40: loss=0.5935, accuracy=0.6960, val_loss=0.8778, val_accuracy=0.6507\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5935 - accuracy: 0.6960 - val_loss: 0.8778 - val_accuracy: 0.6507 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.7098Epoch 4/40: loss=0.5710, accuracy=0.7099, val_loss=0.6418, val_accuracy=0.7161\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5710 - accuracy: 0.7099 - val_loss: 0.6418 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.7092Epoch 5/40: loss=0.5820, accuracy=0.7090, val_loss=0.8648, val_accuracy=0.5033\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5820 - accuracy: 0.7090 - val_loss: 0.8648 - val_accuracy: 0.5033 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.7177Epoch 6/40: loss=0.5657, accuracy=0.7177, val_loss=0.5527, val_accuracy=0.7831\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5657 - accuracy: 0.7177 - val_loss: 0.5527 - val_accuracy: 0.7831 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.7181Epoch 7/40: loss=0.5665, accuracy=0.7181, val_loss=0.5016, val_accuracy=0.7558\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5665 - accuracy: 0.7181 - val_loss: 0.5016 - val_accuracy: 0.7558 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5729 - accuracy: 0.7127Epoch 8/40: loss=0.5725, accuracy=0.7130, val_loss=0.4821, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5725 - accuracy: 0.7130 - val_loss: 0.4821 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.7344Epoch 9/40: loss=0.5547, accuracy=0.7347, val_loss=0.5562, val_accuracy=0.7434\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5547 - accuracy: 0.7347 - val_loss: 0.5562 - val_accuracy: 0.7434 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5513 - accuracy: 0.7284Epoch 10/40: loss=0.5511, accuracy=0.7289, val_loss=1.0016, val_accuracy=0.6424\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5511 - accuracy: 0.7289 - val_loss: 1.0016 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5559 - accuracy: 0.7293Epoch 11/40: loss=0.5558, accuracy=0.7293, val_loss=0.5308, val_accuracy=0.7864\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5558 - accuracy: 0.7293 - val_loss: 0.5308 - val_accuracy: 0.7864 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7352Epoch 12/40: loss=0.5495, accuracy=0.7359, val_loss=0.5132, val_accuracy=0.7699\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5495 - accuracy: 0.7359 - val_loss: 0.5132 - val_accuracy: 0.7699 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5475 - accuracy: 0.7384\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40: loss=0.5472, accuracy=0.7388, val_loss=0.7038, val_accuracy=0.7243\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5472 - accuracy: 0.7388 - val_loss: 0.7038 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.7544Epoch 14/40: loss=0.5045, accuracy=0.7543, val_loss=0.4386, val_accuracy=0.8030\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5045 - accuracy: 0.7543 - val_loss: 0.4386 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5114 - accuracy: 0.7554Epoch 15/40: loss=0.5105, accuracy=0.7562, val_loss=0.4378, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5105 - accuracy: 0.7562 - val_loss: 0.4378 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7726Epoch 16/40: loss=0.4893, accuracy=0.7726, val_loss=0.4274, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4893 - accuracy: 0.7726 - val_loss: 0.4274 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4916 - accuracy: 0.7697Epoch 17/40: loss=0.4915, accuracy=0.7699, val_loss=0.4406, val_accuracy=0.8038\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4915 - accuracy: 0.7699 - val_loss: 0.4406 - val_accuracy: 0.8038 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4935 - accuracy: 0.7655Epoch 18/40: loss=0.4931, accuracy=0.7659, val_loss=0.4449, val_accuracy=0.8171\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4931 - accuracy: 0.7659 - val_loss: 0.4449 - val_accuracy: 0.8171 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.7688Epoch 19/40: loss=0.4887, accuracy=0.7688, val_loss=0.4161, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4887 - accuracy: 0.7688 - val_loss: 0.4161 - val_accuracy: 0.8146 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4884 - accuracy: 0.7693Epoch 20/40: loss=0.4875, accuracy=0.7703, val_loss=0.4390, val_accuracy=0.8063\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4875 - accuracy: 0.7703 - val_loss: 0.4390 - val_accuracy: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.7778Epoch 21/40: loss=0.4848, accuracy=0.7773, val_loss=0.4243, val_accuracy=0.8253\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4848 - accuracy: 0.7773 - val_loss: 0.4243 - val_accuracy: 0.8253 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.7798Epoch 22/40: loss=0.4721, accuracy=0.7798, val_loss=0.4254, val_accuracy=0.8212\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4721 - accuracy: 0.7798 - val_loss: 0.4254 - val_accuracy: 0.8212 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.7782Epoch 23/40: loss=0.4786, accuracy=0.7784, val_loss=0.4220, val_accuracy=0.8113\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4786 - accuracy: 0.7784 - val_loss: 0.4220 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.7770\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 24/40: loss=0.4746, accuracy=0.7767, val_loss=0.5427, val_accuracy=0.7210\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4746 - accuracy: 0.7767 - val_loss: 0.5427 - val_accuracy: 0.7210 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.7770Epoch 25/40: loss=0.4629, accuracy=0.7767, val_loss=0.4024, val_accuracy=0.8237\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4629 - accuracy: 0.7767 - val_loss: 0.4024 - val_accuracy: 0.8237 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7809Epoch 26/40: loss=0.4704, accuracy=0.7810, val_loss=0.3971, val_accuracy=0.8303\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4704 - accuracy: 0.7810 - val_loss: 0.3971 - val_accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.7790Epoch 27/40: loss=0.4689, accuracy=0.7790, val_loss=0.4079, val_accuracy=0.8344\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4689 - accuracy: 0.7790 - val_loss: 0.4079 - val_accuracy: 0.8344 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.7885Epoch 28/40: loss=0.4521, accuracy=0.7885, val_loss=0.3989, val_accuracy=0.8353\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4521 - accuracy: 0.7885 - val_loss: 0.3989 - val_accuracy: 0.8353 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.7897Epoch 29/40: loss=0.4588, accuracy=0.7899, val_loss=0.3838, val_accuracy=0.8361\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4588 - accuracy: 0.7899 - val_loss: 0.3838 - val_accuracy: 0.8361 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4544 - accuracy: 0.7863Epoch 30/40: loss=0.4552, accuracy=0.7858, val_loss=0.3881, val_accuracy=0.8386\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4552 - accuracy: 0.7858 - val_loss: 0.3881 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.7844Epoch 31/40: loss=0.4606, accuracy=0.7844, val_loss=0.3909, val_accuracy=0.8344\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4606 - accuracy: 0.7844 - val_loss: 0.3909 - val_accuracy: 0.8344 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.7906Epoch 32/40: loss=0.4516, accuracy=0.7906, val_loss=0.4105, val_accuracy=0.8262\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4516 - accuracy: 0.7906 - val_loss: 0.4105 - val_accuracy: 0.8262 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4538 - accuracy: 0.7881Epoch 33/40: loss=0.4538, accuracy=0.7881, val_loss=0.4150, val_accuracy=0.8262\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4538 - accuracy: 0.7881 - val_loss: 0.4150 - val_accuracy: 0.8262 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.8029\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 34/40: loss=0.4401, accuracy=0.8024, val_loss=0.3896, val_accuracy=0.8270\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4401 - accuracy: 0.8024 - val_loss: 0.3896 - val_accuracy: 0.8270 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.7939Epoch 35/40: loss=0.4477, accuracy=0.7943, val_loss=0.3979, val_accuracy=0.8311\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4477 - accuracy: 0.7943 - val_loss: 0.3979 - val_accuracy: 0.8311 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.7900Epoch 36/40: loss=0.4575, accuracy=0.7901, val_loss=0.3932, val_accuracy=0.8344\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4575 - accuracy: 0.7901 - val_loss: 0.3932 - val_accuracy: 0.8344 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.7972Epoch 37/40: loss=0.4464, accuracy=0.7976, val_loss=0.3928, val_accuracy=0.8336\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4464 - accuracy: 0.7976 - val_loss: 0.3928 - val_accuracy: 0.8336 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.7962Epoch 38/40: loss=0.4368, accuracy=0.7962, val_loss=0.3985, val_accuracy=0.8344\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4368 - accuracy: 0.7962 - val_loss: 0.3985 - val_accuracy: 0.8344 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.7992\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 39/40: loss=0.4420, accuracy=0.7988, val_loss=0.3894, val_accuracy=0.8336\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4420 - accuracy: 0.7988 - val_loss: 0.3894 - val_accuracy: 0.8336 - lr: 8.0000e-06\n",
      "Epoch 39: early stopping\n",
      "Validation accuracy: 0.8385761380195618\n",
      "\n",
      "Refined Training Combination 6/50: num_residual_blocks=4, dropout_rate=0.4, learning_rate=0.001, rotation_range=30, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.2, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.8588 - accuracy: 0.5613Epoch 1/40: loss=0.8583, accuracy=0.5611, val_loss=0.9306, val_accuracy=0.5050\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.8583 - accuracy: 0.5611 - val_loss: 0.9306 - val_accuracy: 0.5050 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6425 - accuracy: 0.6431Epoch 2/40: loss=0.6427, accuracy=0.6426, val_loss=0.5946, val_accuracy=0.6838\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6427 - accuracy: 0.6426 - val_loss: 0.5946 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5927 - accuracy: 0.6983Epoch 3/40: loss=0.5926, accuracy=0.6985, val_loss=0.8913, val_accuracy=0.6217\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5926 - accuracy: 0.6985 - val_loss: 0.8913 - val_accuracy: 0.6217 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.6945Epoch 4/40: loss=0.5857, accuracy=0.6945, val_loss=1.8318, val_accuracy=0.6035\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5857 - accuracy: 0.6945 - val_loss: 1.8318 - val_accuracy: 0.6035 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5797 - accuracy: 0.7133Epoch 5/40: loss=0.5798, accuracy=0.7132, val_loss=0.6521, val_accuracy=0.6416\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5798 - accuracy: 0.7132 - val_loss: 0.6521 - val_accuracy: 0.6416 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5620 - accuracy: 0.7189Epoch 6/40: loss=0.5618, accuracy=0.7190, val_loss=0.4739, val_accuracy=0.7873\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5618 - accuracy: 0.7190 - val_loss: 0.4739 - val_accuracy: 0.7873 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5648 - accuracy: 0.7276Epoch 7/40: loss=0.5648, accuracy=0.7279, val_loss=1.1088, val_accuracy=0.6018\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5648 - accuracy: 0.7279 - val_loss: 1.1088 - val_accuracy: 0.6018 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5620 - accuracy: 0.7193Epoch 8/40: loss=0.5614, accuracy=0.7196, val_loss=0.6316, val_accuracy=0.7657\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5614 - accuracy: 0.7196 - val_loss: 0.6316 - val_accuracy: 0.7657 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.7328Epoch 9/40: loss=0.5449, accuracy=0.7332, val_loss=0.5853, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5449 - accuracy: 0.7332 - val_loss: 0.5853 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5531 - accuracy: 0.7413Epoch 10/40: loss=0.5531, accuracy=0.7413, val_loss=0.7044, val_accuracy=0.6283\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5531 - accuracy: 0.7413 - val_loss: 0.7044 - val_accuracy: 0.6283 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5441 - accuracy: 0.7450Epoch 11/40: loss=0.5440, accuracy=0.7450, val_loss=0.4477, val_accuracy=0.8055\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5440 - accuracy: 0.7450 - val_loss: 0.4477 - val_accuracy: 0.8055 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5542 - accuracy: 0.7334Epoch 12/40: loss=0.5546, accuracy=0.7337, val_loss=0.6273, val_accuracy=0.7368\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5546 - accuracy: 0.7337 - val_loss: 0.6273 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5454 - accuracy: 0.7419Epoch 13/40: loss=0.5456, accuracy=0.7415, val_loss=0.4442, val_accuracy=0.7988\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5456 - accuracy: 0.7415 - val_loss: 0.4442 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.7535Epoch 14/40: loss=0.5328, accuracy=0.7533, val_loss=0.6006, val_accuracy=0.6242\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5328 - accuracy: 0.7533 - val_loss: 0.6006 - val_accuracy: 0.6242 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7436Epoch 15/40: loss=0.5261, accuracy=0.7436, val_loss=0.6357, val_accuracy=0.7757\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5261 - accuracy: 0.7436 - val_loss: 0.6357 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.7583Epoch 16/40: loss=0.5261, accuracy=0.7583, val_loss=0.6762, val_accuracy=0.7045\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5261 - accuracy: 0.7583 - val_loss: 0.6762 - val_accuracy: 0.7045 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.7506Epoch 17/40: loss=0.5304, accuracy=0.7506, val_loss=0.6324, val_accuracy=0.7376\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5304 - accuracy: 0.7506 - val_loss: 0.6324 - val_accuracy: 0.7376 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.7523\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/40: loss=0.5131, accuracy=0.7525, val_loss=0.4759, val_accuracy=0.7384\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5131 - accuracy: 0.7525 - val_loss: 0.4759 - val_accuracy: 0.7384 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.7655Epoch 19/40: loss=0.4992, accuracy=0.7655, val_loss=0.4106, val_accuracy=0.8278\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4992 - accuracy: 0.7655 - val_loss: 0.4106 - val_accuracy: 0.8278 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7760Epoch 20/40: loss=0.4741, accuracy=0.7763, val_loss=0.3990, val_accuracy=0.8113\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4741 - accuracy: 0.7763 - val_loss: 0.3990 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.7794Epoch 21/40: loss=0.4841, accuracy=0.7794, val_loss=0.4208, val_accuracy=0.8295\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4841 - accuracy: 0.7794 - val_loss: 0.4208 - val_accuracy: 0.8295 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.7788Epoch 22/40: loss=0.4675, accuracy=0.7788, val_loss=0.4234, val_accuracy=0.8320\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4675 - accuracy: 0.7788 - val_loss: 0.4234 - val_accuracy: 0.8320 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.7894Epoch 23/40: loss=0.4535, accuracy=0.7897, val_loss=0.4493, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4535 - accuracy: 0.7897 - val_loss: 0.4493 - val_accuracy: 0.8212 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.7837Epoch 24/40: loss=0.4618, accuracy=0.7837, val_loss=0.3905, val_accuracy=0.8353\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4618 - accuracy: 0.7837 - val_loss: 0.3905 - val_accuracy: 0.8353 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.7953Epoch 25/40: loss=0.4636, accuracy=0.7955, val_loss=0.4084, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4636 - accuracy: 0.7955 - val_loss: 0.4084 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.7909Epoch 26/40: loss=0.4572, accuracy=0.7906, val_loss=0.4137, val_accuracy=0.8154\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4572 - accuracy: 0.7906 - val_loss: 0.4137 - val_accuracy: 0.8154 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4569 - accuracy: 0.7876Epoch 27/40: loss=0.4566, accuracy=0.7881, val_loss=0.3917, val_accuracy=0.8303\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4566 - accuracy: 0.7881 - val_loss: 0.3917 - val_accuracy: 0.8303 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4485 - accuracy: 0.8028Epoch 28/40: loss=0.4482, accuracy=0.8028, val_loss=0.3836, val_accuracy=0.8469\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4482 - accuracy: 0.8028 - val_loss: 0.3836 - val_accuracy: 0.8469 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.8072Epoch 29/40: loss=0.4382, accuracy=0.8073, val_loss=0.3708, val_accuracy=0.8402\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4382 - accuracy: 0.8073 - val_loss: 0.3708 - val_accuracy: 0.8402 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4487 - accuracy: 0.7913Epoch 30/40: loss=0.4489, accuracy=0.7912, val_loss=0.3878, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4489 - accuracy: 0.7912 - val_loss: 0.3878 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4414 - accuracy: 0.7964Epoch 31/40: loss=0.4414, accuracy=0.7964, val_loss=0.3635, val_accuracy=0.8493\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4414 - accuracy: 0.7964 - val_loss: 0.3635 - val_accuracy: 0.8493 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7899Epoch 32/40: loss=0.4509, accuracy=0.7899, val_loss=0.3866, val_accuracy=0.8386\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.3866 - val_accuracy: 0.8386 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.8051Epoch 33/40: loss=0.4304, accuracy=0.8055, val_loss=0.4425, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4304 - accuracy: 0.8055 - val_loss: 0.4425 - val_accuracy: 0.8220 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7908Epoch 34/40: loss=0.4501, accuracy=0.7908, val_loss=0.3955, val_accuracy=0.8394\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4501 - accuracy: 0.7908 - val_loss: 0.3955 - val_accuracy: 0.8394 - lr: 2.0000e-04\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8067Epoch 35/40: loss=0.4270, accuracy=0.8065, val_loss=0.4421, val_accuracy=0.8353\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4270 - accuracy: 0.8065 - val_loss: 0.4421 - val_accuracy: 0.8353 - lr: 2.0000e-04\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.8050\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40: loss=0.4362, accuracy=0.8048, val_loss=0.3971, val_accuracy=0.8460\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4362 - accuracy: 0.8048 - val_loss: 0.3971 - val_accuracy: 0.8460 - lr: 2.0000e-04\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.7997Epoch 37/40: loss=0.4226, accuracy=0.7997, val_loss=0.3710, val_accuracy=0.8543\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4226 - accuracy: 0.7997 - val_loss: 0.3710 - val_accuracy: 0.8543 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.8093Epoch 38/40: loss=0.4221, accuracy=0.8094, val_loss=0.3700, val_accuracy=0.8593\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4221 - accuracy: 0.8094 - val_loss: 0.3700 - val_accuracy: 0.8593 - lr: 4.0000e-05\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8133Epoch 39/40: loss=0.4129, accuracy=0.8133, val_loss=0.3626, val_accuracy=0.8576\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4129 - accuracy: 0.8133 - val_loss: 0.3626 - val_accuracy: 0.8576 - lr: 4.0000e-05\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8135Epoch 40/40: loss=0.4170, accuracy=0.8137, val_loss=0.3621, val_accuracy=0.8568\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4170 - accuracy: 0.8137 - val_loss: 0.3621 - val_accuracy: 0.8568 - lr: 4.0000e-05\n",
      "Validation accuracy: 0.8592715263366699\n",
      "\n",
      "Refined Training Combination 7/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.00025, rotation_range=30, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8173 - accuracy: 0.5977Epoch 1/40: loss=0.8173, accuracy=0.5977, val_loss=2.7505, val_accuracy=0.4007\n",
      "604/604 [==============================] - 13s 18ms/step - loss: 0.8173 - accuracy: 0.5977 - val_loss: 2.7505 - val_accuracy: 0.4007 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.6552Epoch 2/40: loss=0.6945, accuracy=0.6552, val_loss=1.8545, val_accuracy=0.4031\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6945 - accuracy: 0.6552 - val_loss: 1.8545 - val_accuracy: 0.4031 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6399 - accuracy: 0.6787Epoch 3/40: loss=0.6397, accuracy=0.6788, val_loss=1.9905, val_accuracy=0.4007\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.6397 - accuracy: 0.6788 - val_loss: 1.9905 - val_accuracy: 0.4007 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.6931Epoch 4/40: loss=0.6111, accuracy=0.6931, val_loss=1.0760, val_accuracy=0.4685\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6111 - accuracy: 0.6931 - val_loss: 1.0760 - val_accuracy: 0.4685 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7001Epoch 5/40: loss=0.5970, accuracy=0.7001, val_loss=0.4644, val_accuracy=0.7806\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5970 - accuracy: 0.7001 - val_loss: 0.4644 - val_accuracy: 0.7806 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5766 - accuracy: 0.7104Epoch 6/40: loss=0.5776, accuracy=0.7105, val_loss=0.8370, val_accuracy=0.6300\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5776 - accuracy: 0.7105 - val_loss: 0.8370 - val_accuracy: 0.6300 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.7361Epoch 7/40: loss=0.5434, accuracy=0.7361, val_loss=0.7465, val_accuracy=0.5902\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5434 - accuracy: 0.7361 - val_loss: 0.7465 - val_accuracy: 0.5902 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.7197Epoch 8/40: loss=0.5496, accuracy=0.7198, val_loss=0.5369, val_accuracy=0.7425\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5496 - accuracy: 0.7198 - val_loss: 0.5369 - val_accuracy: 0.7425 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.7346Epoch 9/40: loss=0.5374, accuracy=0.7345, val_loss=0.5098, val_accuracy=0.7194\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5374 - accuracy: 0.7345 - val_loss: 0.5098 - val_accuracy: 0.7194 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5303 - accuracy: 0.7361\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 10/40: loss=0.5300, accuracy=0.7363, val_loss=0.4915, val_accuracy=0.7873\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5300 - accuracy: 0.7363 - val_loss: 0.4915 - val_accuracy: 0.7873 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7592Epoch 11/40: loss=0.5018, accuracy=0.7593, val_loss=0.5029, val_accuracy=0.7467\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5018 - accuracy: 0.7593 - val_loss: 0.5029 - val_accuracy: 0.7467 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.7687Epoch 12/40: loss=0.4850, accuracy=0.7692, val_loss=0.4387, val_accuracy=0.7906\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4850 - accuracy: 0.7692 - val_loss: 0.4387 - val_accuracy: 0.7906 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7684Epoch 13/40: loss=0.4929, accuracy=0.7684, val_loss=0.4135, val_accuracy=0.8278\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4929 - accuracy: 0.7684 - val_loss: 0.4135 - val_accuracy: 0.8278 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4827 - accuracy: 0.7678Epoch 14/40: loss=0.4828, accuracy=0.7676, val_loss=0.4557, val_accuracy=0.7790\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4828 - accuracy: 0.7676 - val_loss: 0.4557 - val_accuracy: 0.7790 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.7713Epoch 15/40: loss=0.4718, accuracy=0.7713, val_loss=0.5339, val_accuracy=0.7649\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4718 - accuracy: 0.7713 - val_loss: 0.5339 - val_accuracy: 0.7649 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.7724Epoch 16/40: loss=0.4765, accuracy=0.7724, val_loss=0.4298, val_accuracy=0.7972\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4765 - accuracy: 0.7724 - val_loss: 0.4298 - val_accuracy: 0.7972 - lr: 5.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4587 - accuracy: 0.7825Epoch 17/40: loss=0.4587, accuracy=0.7827, val_loss=0.7266, val_accuracy=0.6589\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4587 - accuracy: 0.7827 - val_loss: 0.7266 - val_accuracy: 0.6589 - lr: 5.0000e-05\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.7711Epoch 18/40: loss=0.4701, accuracy=0.7711, val_loss=0.3978, val_accuracy=0.8204\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4701 - accuracy: 0.7711 - val_loss: 0.3978 - val_accuracy: 0.8204 - lr: 5.0000e-05\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7787Epoch 19/40: loss=0.4667, accuracy=0.7786, val_loss=0.4690, val_accuracy=0.7906\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4667 - accuracy: 0.7786 - val_loss: 0.4690 - val_accuracy: 0.7906 - lr: 5.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.7881Epoch 20/40: loss=0.4428, accuracy=0.7883, val_loss=0.4591, val_accuracy=0.7823\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4428 - accuracy: 0.7883 - val_loss: 0.4591 - val_accuracy: 0.7823 - lr: 5.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.7937Epoch 21/40: loss=0.4411, accuracy=0.7937, val_loss=0.4308, val_accuracy=0.7930\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4411 - accuracy: 0.7937 - val_loss: 0.4308 - val_accuracy: 0.7930 - lr: 5.0000e-05\n",
      "Epoch 22/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.7835Epoch 22/40: loss=0.4591, accuracy=0.7829, val_loss=0.4074, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4591 - accuracy: 0.7829 - val_loss: 0.4074 - val_accuracy: 0.8071 - lr: 5.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.7821Epoch 23/40: loss=0.4537, accuracy=0.7823, val_loss=0.3975, val_accuracy=0.8245\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4537 - accuracy: 0.7823 - val_loss: 0.3975 - val_accuracy: 0.8245 - lr: 5.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.7834Epoch 24/40: loss=0.4615, accuracy=0.7833, val_loss=0.4579, val_accuracy=0.7856\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4615 - accuracy: 0.7833 - val_loss: 0.4579 - val_accuracy: 0.7856 - lr: 5.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.7984Epoch 25/40: loss=0.4333, accuracy=0.7984, val_loss=0.4502, val_accuracy=0.8005\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4333 - accuracy: 0.7984 - val_loss: 0.4502 - val_accuracy: 0.8005 - lr: 5.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.7913Epoch 26/40: loss=0.4495, accuracy=0.7910, val_loss=0.6733, val_accuracy=0.7094\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4495 - accuracy: 0.7910 - val_loss: 0.6733 - val_accuracy: 0.7094 - lr: 5.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7949Epoch 27/40: loss=0.4376, accuracy=0.7949, val_loss=0.3903, val_accuracy=0.8129\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4376 - accuracy: 0.7949 - val_loss: 0.3903 - val_accuracy: 0.8129 - lr: 5.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.7888Epoch 28/40: loss=0.4428, accuracy=0.7889, val_loss=0.4362, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4428 - accuracy: 0.7889 - val_loss: 0.4362 - val_accuracy: 0.8071 - lr: 5.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.7978Epoch 29/40: loss=0.4373, accuracy=0.7978, val_loss=0.5037, val_accuracy=0.7649\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4373 - accuracy: 0.7978 - val_loss: 0.5037 - val_accuracy: 0.7649 - lr: 5.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.7944Epoch 30/40: loss=0.4425, accuracy=0.7945, val_loss=0.4914, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4425 - accuracy: 0.7945 - val_loss: 0.4914 - val_accuracy: 0.7856 - lr: 5.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.8031Epoch 31/40: loss=0.4324, accuracy=0.8028, val_loss=0.6131, val_accuracy=0.7334\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4324 - accuracy: 0.8028 - val_loss: 0.6131 - val_accuracy: 0.7334 - lr: 5.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.8014\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 32/40: loss=0.4394, accuracy=0.8017, val_loss=0.4336, val_accuracy=0.8088\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4394 - accuracy: 0.8017 - val_loss: 0.4336 - val_accuracy: 0.8088 - lr: 5.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4157 - accuracy: 0.8064Epoch 33/40: loss=0.4161, accuracy=0.8063, val_loss=0.3913, val_accuracy=0.8245\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4161 - accuracy: 0.8063 - val_loss: 0.3913 - val_accuracy: 0.8245 - lr: 1.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.8016Epoch 34/40: loss=0.4200, accuracy=0.8015, val_loss=0.3952, val_accuracy=0.8262\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4200 - accuracy: 0.8015 - val_loss: 0.3952 - val_accuracy: 0.8262 - lr: 1.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4085 - accuracy: 0.8136Epoch 35/40: loss=0.4087, accuracy=0.8133, val_loss=0.3968, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4087 - accuracy: 0.8133 - val_loss: 0.3968 - val_accuracy: 0.8204 - lr: 1.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8061Epoch 36/40: loss=0.4140, accuracy=0.8061, val_loss=0.4157, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4140 - accuracy: 0.8061 - val_loss: 0.4157 - val_accuracy: 0.8113 - lr: 1.0000e-05\n",
      "Epoch 37/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4167 - accuracy: 0.8111\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 37/40: loss=0.4158, accuracy=0.8119, val_loss=0.3931, val_accuracy=0.8228\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4158 - accuracy: 0.8119 - val_loss: 0.3931 - val_accuracy: 0.8228 - lr: 1.0000e-05\n",
      "Epoch 37: early stopping\n",
      "Validation accuracy: 0.8278145790100098\n",
      "\n",
      "Refined Training Combination 8/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.00025, rotation_range=20, width_shift_range=0.30000000000000004, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8561 - accuracy: 0.5630Epoch 1/40: loss=0.8563, accuracy=0.5629, val_loss=0.7208, val_accuracy=0.6647\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.8563 - accuracy: 0.5629 - val_loss: 0.7208 - val_accuracy: 0.6647 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.6457Epoch 2/40: loss=0.7109, accuracy=0.6457, val_loss=0.6205, val_accuracy=0.7103\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.7109 - accuracy: 0.6457 - val_loss: 0.6205 - val_accuracy: 0.7103 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6477 - accuracy: 0.6816Epoch 3/40: loss=0.6476, accuracy=0.6815, val_loss=0.5046, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6476 - accuracy: 0.6815 - val_loss: 0.5046 - val_accuracy: 0.7517 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.6735Epoch 4/40: loss=0.6384, accuracy=0.6738, val_loss=1.0495, val_accuracy=0.6151\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6384 - accuracy: 0.6738 - val_loss: 1.0495 - val_accuracy: 0.6151 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.6934Epoch 5/40: loss=0.6054, accuracy=0.6937, val_loss=0.8506, val_accuracy=0.5273\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6054 - accuracy: 0.6937 - val_loss: 0.8506 - val_accuracy: 0.5273 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5846 - accuracy: 0.7028Epoch 6/40: loss=0.5842, accuracy=0.7028, val_loss=0.5250, val_accuracy=0.7285\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5842 - accuracy: 0.7028 - val_loss: 0.5250 - val_accuracy: 0.7285 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.7225Epoch 7/40: loss=0.5605, accuracy=0.7225, val_loss=0.6417, val_accuracy=0.6581\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5605 - accuracy: 0.7225 - val_loss: 0.6417 - val_accuracy: 0.6581 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5597 - accuracy: 0.7191Epoch 8/40: loss=0.5597, accuracy=0.7190, val_loss=0.4799, val_accuracy=0.7599\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5597 - accuracy: 0.7190 - val_loss: 0.4799 - val_accuracy: 0.7599 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7252Epoch 9/40: loss=0.5492, accuracy=0.7252, val_loss=0.4701, val_accuracy=0.7889\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5492 - accuracy: 0.7252 - val_loss: 0.4701 - val_accuracy: 0.7889 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.7259Epoch 10/40: loss=0.5505, accuracy=0.7260, val_loss=0.7279, val_accuracy=0.6614\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5505 - accuracy: 0.7260 - val_loss: 0.7279 - val_accuracy: 0.6614 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.7392Epoch 11/40: loss=0.5352, accuracy=0.7392, val_loss=0.4581, val_accuracy=0.7690\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5352 - accuracy: 0.7392 - val_loss: 0.4581 - val_accuracy: 0.7690 - lr: 2.5000e-04\n",
      "Epoch 12/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.7471Epoch 12/40: loss=0.5245, accuracy=0.7475, val_loss=1.6017, val_accuracy=0.4619\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5245 - accuracy: 0.7475 - val_loss: 1.6017 - val_accuracy: 0.4619 - lr: 2.5000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7579Epoch 13/40: loss=0.5134, accuracy=0.7579, val_loss=0.4254, val_accuracy=0.8079\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5134 - accuracy: 0.7579 - val_loss: 0.4254 - val_accuracy: 0.8079 - lr: 2.5000e-04\n",
      "Epoch 14/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.7529Epoch 14/40: loss=0.5172, accuracy=0.7533, val_loss=0.5199, val_accuracy=0.7442\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5172 - accuracy: 0.7533 - val_loss: 0.5199 - val_accuracy: 0.7442 - lr: 2.5000e-04\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7554Epoch 15/40: loss=0.5075, accuracy=0.7552, val_loss=0.9454, val_accuracy=0.6192\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5075 - accuracy: 0.7552 - val_loss: 0.9454 - val_accuracy: 0.6192 - lr: 2.5000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7514Epoch 16/40: loss=0.5135, accuracy=0.7514, val_loss=0.5613, val_accuracy=0.6854\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5135 - accuracy: 0.7514 - val_loss: 0.5613 - val_accuracy: 0.6854 - lr: 2.5000e-04\n",
      "Epoch 17/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.7556Epoch 17/40: loss=0.5052, accuracy=0.7556, val_loss=0.5631, val_accuracy=0.7078\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5052 - accuracy: 0.7556 - val_loss: 0.5631 - val_accuracy: 0.7078 - lr: 2.5000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4945 - accuracy: 0.7633\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 18/40: loss=0.4946, accuracy=0.7630, val_loss=0.4437, val_accuracy=0.7831\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4946 - accuracy: 0.7630 - val_loss: 0.4437 - val_accuracy: 0.7831 - lr: 2.5000e-04\n",
      "Epoch 19/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.7756Epoch 19/40: loss=0.4814, accuracy=0.7757, val_loss=0.4190, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4814 - accuracy: 0.7757 - val_loss: 0.4190 - val_accuracy: 0.8121 - lr: 5.0000e-05\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4674 - accuracy: 0.7763Epoch 20/40: loss=0.4673, accuracy=0.7763, val_loss=0.3937, val_accuracy=0.8220\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4673 - accuracy: 0.7763 - val_loss: 0.3937 - val_accuracy: 0.8220 - lr: 5.0000e-05\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.7828Epoch 21/40: loss=0.4642, accuracy=0.7827, val_loss=0.4115, val_accuracy=0.8063\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4642 - accuracy: 0.7827 - val_loss: 0.4115 - val_accuracy: 0.8063 - lr: 5.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7870Epoch 22/40: loss=0.4579, accuracy=0.7866, val_loss=0.5477, val_accuracy=0.7442\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4579 - accuracy: 0.7866 - val_loss: 0.5477 - val_accuracy: 0.7442 - lr: 5.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4567 - accuracy: 0.7834Epoch 23/40: loss=0.4568, accuracy=0.7831, val_loss=0.6003, val_accuracy=0.7318\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4568 - accuracy: 0.7831 - val_loss: 0.6003 - val_accuracy: 0.7318 - lr: 5.0000e-05\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.7841Epoch 24/40: loss=0.4582, accuracy=0.7841, val_loss=0.4402, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4582 - accuracy: 0.7841 - val_loss: 0.4402 - val_accuracy: 0.7997 - lr: 5.0000e-05\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8019\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 25/40: loss=0.4397, accuracy=0.8019, val_loss=0.4308, val_accuracy=0.7997\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4397 - accuracy: 0.8019 - val_loss: 0.4308 - val_accuracy: 0.7997 - lr: 5.0000e-05\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7968Epoch 26/40: loss=0.4382, accuracy=0.7968, val_loss=0.4263, val_accuracy=0.7997\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4382 - accuracy: 0.7968 - val_loss: 0.4263 - val_accuracy: 0.7997 - lr: 1.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4403 - accuracy: 0.7950Epoch 27/40: loss=0.4403, accuracy=0.7949, val_loss=0.4114, val_accuracy=0.8079\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4403 - accuracy: 0.7949 - val_loss: 0.4114 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.8036Epoch 28/40: loss=0.4327, accuracy=0.8036, val_loss=0.4133, val_accuracy=0.8055\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4327 - accuracy: 0.8036 - val_loss: 0.4133 - val_accuracy: 0.8055 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.8080Epoch 29/40: loss=0.4271, accuracy=0.8079, val_loss=0.4018, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4271 - accuracy: 0.8079 - val_loss: 0.4018 - val_accuracy: 0.8204 - lr: 1.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8065\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 30/40: loss=0.4256, accuracy=0.8065, val_loss=0.4101, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4256 - accuracy: 0.8065 - val_loss: 0.4101 - val_accuracy: 0.8104 - lr: 1.0000e-05\n",
      "Epoch 30: early stopping\n",
      "Validation accuracy: 0.8220198750495911\n",
      "\n",
      "Refined Training Combination 9/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.00025, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.5702Epoch 1/40: loss=0.8383, accuracy=0.5702, val_loss=0.8442, val_accuracy=0.4280\n",
      "604/604 [==============================] - 16s 24ms/step - loss: 0.8383 - accuracy: 0.5702 - val_loss: 0.8442 - val_accuracy: 0.4280 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6983 - accuracy: 0.6413Epoch 2/40: loss=0.6983, accuracy=0.6413, val_loss=0.7442, val_accuracy=0.5513\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6983 - accuracy: 0.6413 - val_loss: 0.7442 - val_accuracy: 0.5513 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.6717Epoch 3/40: loss=0.6496, accuracy=0.6709, val_loss=0.7064, val_accuracy=0.6945\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6496 - accuracy: 0.6709 - val_loss: 0.7064 - val_accuracy: 0.6945 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6099 - accuracy: 0.6896Epoch 4/40: loss=0.6095, accuracy=0.6898, val_loss=1.1039, val_accuracy=0.4180\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6095 - accuracy: 0.6898 - val_loss: 1.1039 - val_accuracy: 0.4180 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.7119Epoch 5/40: loss=0.5767, accuracy=0.7119, val_loss=0.5069, val_accuracy=0.7575\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5767 - accuracy: 0.7119 - val_loss: 0.5069 - val_accuracy: 0.7575 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7180Epoch 6/40: loss=0.5683, accuracy=0.7177, val_loss=0.5730, val_accuracy=0.7094\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5683 - accuracy: 0.7177 - val_loss: 0.5730 - val_accuracy: 0.7094 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5606 - accuracy: 0.7183Epoch 7/40: loss=0.5611, accuracy=0.7179, val_loss=0.5156, val_accuracy=0.7566\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5611 - accuracy: 0.7179 - val_loss: 0.5156 - val_accuracy: 0.7566 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5557 - accuracy: 0.7257Epoch 8/40: loss=0.5553, accuracy=0.7258, val_loss=0.5343, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5553 - accuracy: 0.7258 - val_loss: 0.5343 - val_accuracy: 0.7459 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.7311Epoch 9/40: loss=0.5316, accuracy=0.7314, val_loss=0.4524, val_accuracy=0.7897\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.5316 - accuracy: 0.7314 - val_loss: 0.4524 - val_accuracy: 0.7897 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7461Epoch 10/40: loss=0.5277, accuracy=0.7457, val_loss=1.1175, val_accuracy=0.6498\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5277 - accuracy: 0.7457 - val_loss: 1.1175 - val_accuracy: 0.6498 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.7475Epoch 11/40: loss=0.5261, accuracy=0.7475, val_loss=0.5322, val_accuracy=0.7144\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5261 - accuracy: 0.7475 - val_loss: 0.5322 - val_accuracy: 0.7144 - lr: 2.5000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.7523Epoch 12/40: loss=0.5079, accuracy=0.7525, val_loss=0.6598, val_accuracy=0.7103\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5079 - accuracy: 0.7525 - val_loss: 0.6598 - val_accuracy: 0.7103 - lr: 2.5000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7504Epoch 13/40: loss=0.5190, accuracy=0.7504, val_loss=0.4873, val_accuracy=0.7169\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5190 - accuracy: 0.7504 - val_loss: 0.4873 - val_accuracy: 0.7169 - lr: 2.5000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.7647Epoch 14/40: loss=0.4991, accuracy=0.7643, val_loss=0.4287, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4991 - accuracy: 0.7643 - val_loss: 0.4287 - val_accuracy: 0.8121 - lr: 2.5000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7639Epoch 15/40: loss=0.5032, accuracy=0.7639, val_loss=0.4617, val_accuracy=0.8121\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5032 - accuracy: 0.7639 - val_loss: 0.4617 - val_accuracy: 0.8121 - lr: 2.5000e-04\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.7733Epoch 16/40: loss=0.4889, accuracy=0.7732, val_loss=0.5049, val_accuracy=0.7773\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4889 - accuracy: 0.7732 - val_loss: 0.5049 - val_accuracy: 0.7773 - lr: 2.5000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.7724Epoch 17/40: loss=0.4810, accuracy=0.7721, val_loss=0.4962, val_accuracy=0.7641\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4810 - accuracy: 0.7721 - val_loss: 0.4962 - val_accuracy: 0.7641 - lr: 2.5000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.7658Epoch 18/40: loss=0.4869, accuracy=0.7659, val_loss=0.4662, val_accuracy=0.7707\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4869 - accuracy: 0.7659 - val_loss: 0.4662 - val_accuracy: 0.7707 - lr: 2.5000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4728 - accuracy: 0.7774\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 19/40: loss=0.4739, accuracy=0.7767, val_loss=0.4803, val_accuracy=0.7533\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4739 - accuracy: 0.7767 - val_loss: 0.4803 - val_accuracy: 0.7533 - lr: 2.5000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.7856Epoch 20/40: loss=0.4547, accuracy=0.7856, val_loss=0.3960, val_accuracy=0.8195\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4547 - accuracy: 0.7856 - val_loss: 0.3960 - val_accuracy: 0.8195 - lr: 5.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.7926Epoch 21/40: loss=0.4487, accuracy=0.7926, val_loss=0.4245, val_accuracy=0.7856\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4487 - accuracy: 0.7926 - val_loss: 0.4245 - val_accuracy: 0.7856 - lr: 5.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7982Epoch 22/40: loss=0.4353, accuracy=0.7982, val_loss=0.4361, val_accuracy=0.7823\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4353 - accuracy: 0.7982 - val_loss: 0.4361 - val_accuracy: 0.7823 - lr: 5.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8055Epoch 23/40: loss=0.4296, accuracy=0.8055, val_loss=0.4733, val_accuracy=0.7558\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4296 - accuracy: 0.8055 - val_loss: 0.4733 - val_accuracy: 0.7558 - lr: 5.0000e-05\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4224 - accuracy: 0.8010Epoch 24/40: loss=0.4222, accuracy=0.8011, val_loss=0.4063, val_accuracy=0.8361\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4222 - accuracy: 0.8011 - val_loss: 0.4063 - val_accuracy: 0.8361 - lr: 5.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4323 - accuracy: 0.8044Epoch 25/40: loss=0.4328, accuracy=0.8042, val_loss=0.3888, val_accuracy=0.8146\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4328 - accuracy: 0.8042 - val_loss: 0.3888 - val_accuracy: 0.8146 - lr: 5.0000e-05\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.8044Epoch 26/40: loss=0.4349, accuracy=0.8044, val_loss=0.3897, val_accuracy=0.8262\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4349 - accuracy: 0.8044 - val_loss: 0.3897 - val_accuracy: 0.8262 - lr: 5.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4201 - accuracy: 0.8157Epoch 27/40: loss=0.4197, accuracy=0.8160, val_loss=0.3808, val_accuracy=0.8411\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4197 - accuracy: 0.8160 - val_loss: 0.3808 - val_accuracy: 0.8411 - lr: 5.0000e-05\n",
      "Epoch 28/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4225 - accuracy: 0.8069Epoch 28/40: loss=0.4225, accuracy=0.8071, val_loss=0.3744, val_accuracy=0.8419\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4225 - accuracy: 0.8071 - val_loss: 0.3744 - val_accuracy: 0.8419 - lr: 5.0000e-05\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.8160Epoch 29/40: loss=0.4125, accuracy=0.8160, val_loss=0.3909, val_accuracy=0.8353\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.3909 - val_accuracy: 0.8353 - lr: 5.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8143Epoch 30/40: loss=0.4062, accuracy=0.8144, val_loss=0.4326, val_accuracy=0.7964\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4062 - accuracy: 0.8144 - val_loss: 0.4326 - val_accuracy: 0.7964 - lr: 5.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4034 - accuracy: 0.8183Epoch 31/40: loss=0.4035, accuracy=0.8185, val_loss=0.4959, val_accuracy=0.7202\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4035 - accuracy: 0.8185 - val_loss: 0.4959 - val_accuracy: 0.7202 - lr: 5.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.8185Epoch 32/40: loss=0.4117, accuracy=0.8185, val_loss=0.3725, val_accuracy=0.8253\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4117 - accuracy: 0.8185 - val_loss: 0.3725 - val_accuracy: 0.8253 - lr: 5.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.8148Epoch 33/40: loss=0.4120, accuracy=0.8148, val_loss=0.4165, val_accuracy=0.7873\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4120 - accuracy: 0.8148 - val_loss: 0.4165 - val_accuracy: 0.7873 - lr: 5.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8312Epoch 34/40: loss=0.3900, accuracy=0.8311, val_loss=0.3911, val_accuracy=0.8286\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3900 - accuracy: 0.8311 - val_loss: 0.3911 - val_accuracy: 0.8286 - lr: 5.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4118 - accuracy: 0.8170Epoch 35/40: loss=0.4115, accuracy=0.8171, val_loss=0.3961, val_accuracy=0.8195\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4115 - accuracy: 0.8171 - val_loss: 0.3961 - val_accuracy: 0.8195 - lr: 5.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.8223Epoch 36/40: loss=0.3998, accuracy=0.8222, val_loss=0.4261, val_accuracy=0.7864\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3998 - accuracy: 0.8222 - val_loss: 0.4261 - val_accuracy: 0.7864 - lr: 5.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8306\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 37/40: loss=0.3869, accuracy=0.8303, val_loss=0.4208, val_accuracy=0.8013\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3869 - accuracy: 0.8303 - val_loss: 0.4208 - val_accuracy: 0.8013 - lr: 5.0000e-05\n",
      "Epoch 38/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8290Epoch 38/40: loss=0.3920, accuracy=0.8288, val_loss=0.4259, val_accuracy=0.7748\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3920 - accuracy: 0.8288 - val_loss: 0.4259 - val_accuracy: 0.7748 - lr: 1.0000e-05\n",
      "Epoch 39/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8389Epoch 39/40: loss=0.3734, accuracy=0.8388, val_loss=0.4280, val_accuracy=0.7732\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3734 - accuracy: 0.8388 - val_loss: 0.4280 - val_accuracy: 0.7732 - lr: 1.0000e-05\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3764 - accuracy: 0.8316Epoch 40/40: loss=0.3761, accuracy=0.8320, val_loss=0.3980, val_accuracy=0.8046\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3761 - accuracy: 0.8320 - val_loss: 0.3980 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Validation accuracy: 0.8418874144554138\n",
      "\n",
      "Refined Training Combination 10/50: num_residual_blocks=4, dropout_rate=0.3, learning_rate=0.001, rotation_range=30, width_shift_range=0.1, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8007 - accuracy: 0.6007Epoch 1/40: loss=0.8000, accuracy=0.6012, val_loss=0.5868, val_accuracy=0.7293\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 0.8000 - accuracy: 0.6012 - val_loss: 0.5868 - val_accuracy: 0.7293 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6025 - accuracy: 0.6811Epoch 2/40: loss=0.6029, accuracy=0.6807, val_loss=1.1210, val_accuracy=0.4445\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.6029 - accuracy: 0.6807 - val_loss: 1.1210 - val_accuracy: 0.4445 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7112Epoch 3/40: loss=0.5776, accuracy=0.7111, val_loss=0.7419, val_accuracy=0.5993\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5776 - accuracy: 0.7111 - val_loss: 0.7419 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7250Epoch 4/40: loss=0.5634, accuracy=0.7250, val_loss=0.5876, val_accuracy=0.7136\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5634 - accuracy: 0.7250 - val_loss: 0.5876 - val_accuracy: 0.7136 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.7232Epoch 5/40: loss=0.5590, accuracy=0.7237, val_loss=0.5553, val_accuracy=0.7276\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5590 - accuracy: 0.7237 - val_loss: 0.5553 - val_accuracy: 0.7276 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5527 - accuracy: 0.7392Epoch 6/40: loss=0.5530, accuracy=0.7390, val_loss=0.6071, val_accuracy=0.7657\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5530 - accuracy: 0.7390 - val_loss: 0.6071 - val_accuracy: 0.7657 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7378Epoch 7/40: loss=0.5446, accuracy=0.7378, val_loss=0.5244, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5446 - accuracy: 0.7378 - val_loss: 0.5244 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.7276Epoch 8/40: loss=0.5539, accuracy=0.7276, val_loss=0.7281, val_accuracy=0.6689\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5539 - accuracy: 0.7276 - val_loss: 0.7281 - val_accuracy: 0.6689 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.7446Epoch 9/40: loss=0.5421, accuracy=0.7448, val_loss=0.4648, val_accuracy=0.7831\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5421 - accuracy: 0.7448 - val_loss: 0.4648 - val_accuracy: 0.7831 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.7427Epoch 10/40: loss=0.5433, accuracy=0.7430, val_loss=1.0315, val_accuracy=0.5695\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5433 - accuracy: 0.7430 - val_loss: 1.0315 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5334 - accuracy: 0.7427Epoch 11/40: loss=0.5329, accuracy=0.7432, val_loss=0.4723, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5329 - accuracy: 0.7432 - val_loss: 0.4723 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5477 - accuracy: 0.7336Epoch 12/40: loss=0.5472, accuracy=0.7337, val_loss=0.5364, val_accuracy=0.7616\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5472 - accuracy: 0.7337 - val_loss: 0.5364 - val_accuracy: 0.7616 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.7442Epoch 13/40: loss=0.5360, accuracy=0.7436, val_loss=0.5123, val_accuracy=0.7575\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5360 - accuracy: 0.7436 - val_loss: 0.5123 - val_accuracy: 0.7575 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7508\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 14/40: loss=0.5185, accuracy=0.7508, val_loss=0.4894, val_accuracy=0.7997\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5185 - accuracy: 0.7508 - val_loss: 0.4894 - val_accuracy: 0.7997 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4977 - accuracy: 0.7718Epoch 15/40: loss=0.4977, accuracy=0.7717, val_loss=0.4097, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4977 - accuracy: 0.7717 - val_loss: 0.4097 - val_accuracy: 0.8328 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.7759Epoch 16/40: loss=0.4787, accuracy=0.7759, val_loss=0.3985, val_accuracy=0.8237\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4787 - accuracy: 0.7759 - val_loss: 0.3985 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.7848Epoch 17/40: loss=0.4631, accuracy=0.7852, val_loss=0.4171, val_accuracy=0.8286\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4631 - accuracy: 0.7852 - val_loss: 0.4171 - val_accuracy: 0.8286 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.7828Epoch 18/40: loss=0.4648, accuracy=0.7827, val_loss=0.4347, val_accuracy=0.8104\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4648 - accuracy: 0.7827 - val_loss: 0.4347 - val_accuracy: 0.8104 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.7763Epoch 19/40: loss=0.4762, accuracy=0.7761, val_loss=0.3814, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4762 - accuracy: 0.7761 - val_loss: 0.3814 - val_accuracy: 0.8320 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.7823Epoch 20/40: loss=0.4685, accuracy=0.7823, val_loss=0.4395, val_accuracy=0.8055\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4685 - accuracy: 0.7823 - val_loss: 0.4395 - val_accuracy: 0.8055 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.7876Epoch 21/40: loss=0.4575, accuracy=0.7875, val_loss=0.4161, val_accuracy=0.8096\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4575 - accuracy: 0.7875 - val_loss: 0.4161 - val_accuracy: 0.8096 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.7853Epoch 22/40: loss=0.4610, accuracy=0.7856, val_loss=0.4679, val_accuracy=0.8071\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4610 - accuracy: 0.7856 - val_loss: 0.4679 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.7922Epoch 23/40: loss=0.4406, accuracy=0.7924, val_loss=0.3834, val_accuracy=0.8320\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4406 - accuracy: 0.7924 - val_loss: 0.3834 - val_accuracy: 0.8320 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.7899\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 24/40: loss=0.4432, accuracy=0.7899, val_loss=0.4245, val_accuracy=0.8055\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.4245 - val_accuracy: 0.8055 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.7886Epoch 25/40: loss=0.4405, accuracy=0.7881, val_loss=0.3813, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4405 - accuracy: 0.7881 - val_loss: 0.3813 - val_accuracy: 0.8377 - lr: 4.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.8019Epoch 26/40: loss=0.4351, accuracy=0.8017, val_loss=0.3733, val_accuracy=0.8452\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4351 - accuracy: 0.8017 - val_loss: 0.3733 - val_accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8068Epoch 27/40: loss=0.4299, accuracy=0.8065, val_loss=0.3727, val_accuracy=0.8402\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4299 - accuracy: 0.8065 - val_loss: 0.3727 - val_accuracy: 0.8402 - lr: 4.0000e-05\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4184 - accuracy: 0.8101Epoch 28/40: loss=0.4180, accuracy=0.8104, val_loss=0.3700, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4180 - accuracy: 0.8104 - val_loss: 0.3700 - val_accuracy: 0.8485 - lr: 4.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8022Epoch 29/40: loss=0.4256, accuracy=0.8026, val_loss=0.3771, val_accuracy=0.8502\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4256 - accuracy: 0.8026 - val_loss: 0.3771 - val_accuracy: 0.8502 - lr: 4.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8038Epoch 30/40: loss=0.4269, accuracy=0.8038, val_loss=0.3586, val_accuracy=0.8551\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.3586 - val_accuracy: 0.8551 - lr: 4.0000e-05\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.8096Epoch 31/40: loss=0.4131, accuracy=0.8098, val_loss=0.3641, val_accuracy=0.8469\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4131 - accuracy: 0.8098 - val_loss: 0.3641 - val_accuracy: 0.8469 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4114 - accuracy: 0.8004Epoch 32/40: loss=0.4116, accuracy=0.8003, val_loss=0.3719, val_accuracy=0.8477\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.3719 - val_accuracy: 0.8477 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8096Epoch 33/40: loss=0.4185, accuracy=0.8088, val_loss=0.3645, val_accuracy=0.8526\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4185 - accuracy: 0.8088 - val_loss: 0.3645 - val_accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.8064Epoch 34/40: loss=0.4224, accuracy=0.8055, val_loss=0.3670, val_accuracy=0.8477\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4224 - accuracy: 0.8055 - val_loss: 0.3670 - val_accuracy: 0.8477 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4217 - accuracy: 0.8077\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 35/40: loss=0.4217, accuracy=0.8077, val_loss=0.3732, val_accuracy=0.8477\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4217 - accuracy: 0.8077 - val_loss: 0.3732 - val_accuracy: 0.8477 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.8063Epoch 36/40: loss=0.4202, accuracy=0.8063, val_loss=0.3773, val_accuracy=0.8502\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4202 - accuracy: 0.8063 - val_loss: 0.3773 - val_accuracy: 0.8502 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4111 - accuracy: 0.8164Epoch 37/40: loss=0.4107, accuracy=0.8168, val_loss=0.3722, val_accuracy=0.8510\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4107 - accuracy: 0.8168 - val_loss: 0.3722 - val_accuracy: 0.8510 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8005Epoch 38/40: loss=0.4135, accuracy=0.8005, val_loss=0.3685, val_accuracy=0.8502\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4135 - accuracy: 0.8005 - val_loss: 0.3685 - val_accuracy: 0.8502 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8096Epoch 39/40: loss=0.4147, accuracy=0.8096, val_loss=0.3670, val_accuracy=0.8485\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4147 - accuracy: 0.8096 - val_loss: 0.3670 - val_accuracy: 0.8485 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.8105\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40/40: loss=0.4101, accuracy=0.8106, val_loss=0.3695, val_accuracy=0.8477\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4101 - accuracy: 0.8106 - val_loss: 0.3695 - val_accuracy: 0.8477 - lr: 8.0000e-06\n",
      "Epoch 40: early stopping\n",
      "Validation accuracy: 0.8551324605941772\n",
      "\n",
      "Refined Training Combination 11/50: num_residual_blocks=3, dropout_rate=0.4, learning_rate=0.0005, rotation_range=40, width_shift_range=0.2, height_shift_range=0.0, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.8326 - accuracy: 0.5805Epoch 1/40: loss=0.8325, accuracy=0.5805, val_loss=0.9722, val_accuracy=0.5935\n",
      "604/604 [==============================] - 14s 21ms/step - loss: 0.8325 - accuracy: 0.5805 - val_loss: 0.9722 - val_accuracy: 0.5935 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.6488Epoch 2/40: loss=0.6705, accuracy=0.6490, val_loss=1.6610, val_accuracy=0.4056\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6705 - accuracy: 0.6490 - val_loss: 1.6610 - val_accuracy: 0.4056 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.6034 - accuracy: 0.6924Epoch 3/40: loss=0.6037, accuracy=0.6921, val_loss=0.6554, val_accuracy=0.6689\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6037 - accuracy: 0.6921 - val_loss: 0.6554 - val_accuracy: 0.6689 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.7125Epoch 4/40: loss=0.5695, accuracy=0.7125, val_loss=0.5130, val_accuracy=0.7599\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5695 - accuracy: 0.7125 - val_loss: 0.5130 - val_accuracy: 0.7599 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7152Epoch 5/40: loss=0.5599, accuracy=0.7152, val_loss=0.8252, val_accuracy=0.5157\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5599 - accuracy: 0.7152 - val_loss: 0.8252 - val_accuracy: 0.5157 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.7234Epoch 6/40: loss=0.5433, accuracy=0.7231, val_loss=0.5588, val_accuracy=0.7483\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5433 - accuracy: 0.7231 - val_loss: 0.5588 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7398Epoch 7/40: loss=0.5474, accuracy=0.7399, val_loss=0.5439, val_accuracy=0.7343\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5474 - accuracy: 0.7399 - val_loss: 0.5439 - val_accuracy: 0.7343 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5473 - accuracy: 0.7282Epoch 8/40: loss=0.5475, accuracy=0.7279, val_loss=0.5211, val_accuracy=0.6738\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5475 - accuracy: 0.7279 - val_loss: 0.5211 - val_accuracy: 0.6738 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7372\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.5376, accuracy=0.7372, val_loss=0.8902, val_accuracy=0.6051\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5376 - accuracy: 0.7372 - val_loss: 0.8902 - val_accuracy: 0.6051 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.7558Epoch 10/40: loss=0.5147, accuracy=0.7558, val_loss=0.4470, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5147 - accuracy: 0.7558 - val_loss: 0.4470 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.7548Epoch 11/40: loss=0.5047, accuracy=0.7548, val_loss=0.8535, val_accuracy=0.6921\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5047 - accuracy: 0.7548 - val_loss: 0.8535 - val_accuracy: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4986 - accuracy: 0.7666Epoch 12/40: loss=0.4987, accuracy=0.7666, val_loss=0.4465, val_accuracy=0.7848\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4987 - accuracy: 0.7666 - val_loss: 0.4465 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.7649Epoch 13/40: loss=0.5004, accuracy=0.7649, val_loss=0.5867, val_accuracy=0.7583\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5004 - accuracy: 0.7649 - val_loss: 0.5867 - val_accuracy: 0.7583 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4882 - accuracy: 0.7668Epoch 14/40: loss=0.4882, accuracy=0.7670, val_loss=0.4255, val_accuracy=0.8063\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4882 - accuracy: 0.7670 - val_loss: 0.4255 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4908 - accuracy: 0.7596Epoch 15/40: loss=0.4902, accuracy=0.7601, val_loss=0.4611, val_accuracy=0.7839\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4902 - accuracy: 0.7601 - val_loss: 0.4611 - val_accuracy: 0.7839 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.7693Epoch 16/40: loss=0.4826, accuracy=0.7690, val_loss=0.4460, val_accuracy=0.7873\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4826 - accuracy: 0.7690 - val_loss: 0.4460 - val_accuracy: 0.7873 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.7579Epoch 17/40: loss=0.4948, accuracy=0.7579, val_loss=0.4758, val_accuracy=0.7972\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4948 - accuracy: 0.7579 - val_loss: 0.4758 - val_accuracy: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7695Epoch 18/40: loss=0.4849, accuracy=0.7695, val_loss=0.4856, val_accuracy=0.7343\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4849 - accuracy: 0.7695 - val_loss: 0.4856 - val_accuracy: 0.7343 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4736 - accuracy: 0.7788\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 19/40: loss=0.4733, accuracy=0.7790, val_loss=0.4306, val_accuracy=0.8096\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4733 - accuracy: 0.7790 - val_loss: 0.4306 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.7846Epoch 20/40: loss=0.4588, accuracy=0.7850, val_loss=0.4274, val_accuracy=0.8129\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4588 - accuracy: 0.7850 - val_loss: 0.4274 - val_accuracy: 0.8129 - lr: 2.0000e-05\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.7862Epoch 21/40: loss=0.4534, accuracy=0.7862, val_loss=0.4029, val_accuracy=0.8204\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4534 - accuracy: 0.7862 - val_loss: 0.4029 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.7899Epoch 22/40: loss=0.4568, accuracy=0.7899, val_loss=0.4154, val_accuracy=0.8187\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4568 - accuracy: 0.7899 - val_loss: 0.4154 - val_accuracy: 0.8187 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4532 - accuracy: 0.7904Epoch 23/40: loss=0.4528, accuracy=0.7908, val_loss=0.4380, val_accuracy=0.8137\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4528 - accuracy: 0.7908 - val_loss: 0.4380 - val_accuracy: 0.8137 - lr: 2.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4464 - accuracy: 0.7899Epoch 24/40: loss=0.4472, accuracy=0.7895, val_loss=0.4015, val_accuracy=0.8204\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4472 - accuracy: 0.7895 - val_loss: 0.4015 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4451 - accuracy: 0.7991Epoch 25/40: loss=0.4449, accuracy=0.7993, val_loss=0.3964, val_accuracy=0.8171\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4449 - accuracy: 0.7993 - val_loss: 0.3964 - val_accuracy: 0.8171 - lr: 2.0000e-05\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.7874Epoch 26/40: loss=0.4589, accuracy=0.7873, val_loss=0.4019, val_accuracy=0.8162\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4589 - accuracy: 0.7873 - val_loss: 0.4019 - val_accuracy: 0.8162 - lr: 2.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.7899Epoch 27/40: loss=0.4495, accuracy=0.7899, val_loss=0.4140, val_accuracy=0.8171\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4140 - val_accuracy: 0.8171 - lr: 2.0000e-05\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.7820Epoch 28/40: loss=0.4622, accuracy=0.7825, val_loss=0.3854, val_accuracy=0.8295\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4622 - accuracy: 0.7825 - val_loss: 0.3854 - val_accuracy: 0.8295 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.7936Epoch 29/40: loss=0.4503, accuracy=0.7933, val_loss=0.4024, val_accuracy=0.8245\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4503 - accuracy: 0.7933 - val_loss: 0.4024 - val_accuracy: 0.8245 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.7962Epoch 30/40: loss=0.4413, accuracy=0.7964, val_loss=0.3941, val_accuracy=0.8228\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4413 - accuracy: 0.7964 - val_loss: 0.3941 - val_accuracy: 0.8228 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4485 - accuracy: 0.7886Epoch 31/40: loss=0.4483, accuracy=0.7887, val_loss=0.4071, val_accuracy=0.8253\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4483 - accuracy: 0.7887 - val_loss: 0.4071 - val_accuracy: 0.8253 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4407 - accuracy: 0.7941Epoch 32/40: loss=0.4410, accuracy=0.7937, val_loss=0.4283, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4410 - accuracy: 0.7937 - val_loss: 0.4283 - val_accuracy: 0.8204 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.7910\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Epoch 33/40: loss=0.4469, accuracy=0.7910, val_loss=0.4103, val_accuracy=0.8088\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4469 - accuracy: 0.7910 - val_loss: 0.4103 - val_accuracy: 0.8088 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.7968Epoch 34/40: loss=0.4395, accuracy=0.7972, val_loss=0.4199, val_accuracy=0.8146\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4395 - accuracy: 0.7972 - val_loss: 0.4199 - val_accuracy: 0.8146 - lr: 4.0000e-06\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8042Epoch 35/40: loss=0.4279, accuracy=0.8042, val_loss=0.4067, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4279 - accuracy: 0.8042 - val_loss: 0.4067 - val_accuracy: 0.8204 - lr: 4.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4241 - accuracy: 0.8080Epoch 36/40: loss=0.4240, accuracy=0.8082, val_loss=0.4072, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4240 - accuracy: 0.8082 - val_loss: 0.4072 - val_accuracy: 0.8204 - lr: 4.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.8040Epoch 37/40: loss=0.4345, accuracy=0.8036, val_loss=0.4182, val_accuracy=0.8171\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4345 - accuracy: 0.8036 - val_loss: 0.4182 - val_accuracy: 0.8171 - lr: 4.0000e-06\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.7928\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.4394, accuracy=0.7928, val_loss=0.3978, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4394 - accuracy: 0.7928 - val_loss: 0.3978 - val_accuracy: 0.8204 - lr: 4.0000e-06\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8294702172279358\n",
      "\n",
      "Refined Training Combination 12/50: num_residual_blocks=3, dropout_rate=0.3, learning_rate=0.001, rotation_range=30, width_shift_range=0.30000000000000004, height_shift_range=0.1, shear_range=0.1, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7853 - accuracy: 0.6020Epoch 1/40: loss=0.7853, accuracy=0.6020, val_loss=2.4627, val_accuracy=0.4048\n",
      "604/604 [==============================] - 12s 18ms/step - loss: 0.7853 - accuracy: 0.6020 - val_loss: 2.4627 - val_accuracy: 0.4048 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.6796Epoch 2/40: loss=0.6021, accuracy=0.6796, val_loss=0.7421, val_accuracy=0.6879\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6021 - accuracy: 0.6796 - val_loss: 0.7421 - val_accuracy: 0.6879 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7086Epoch 3/40: loss=0.5765, accuracy=0.7086, val_loss=0.5075, val_accuracy=0.7558\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5765 - accuracy: 0.7086 - val_loss: 0.5075 - val_accuracy: 0.7558 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7148Epoch 4/40: loss=0.5653, accuracy=0.7146, val_loss=0.5556, val_accuracy=0.7492\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5653 - accuracy: 0.7146 - val_loss: 0.5556 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.7195Epoch 5/40: loss=0.5675, accuracy=0.7192, val_loss=0.5630, val_accuracy=0.7541\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5675 - accuracy: 0.7192 - val_loss: 0.5630 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5649 - accuracy: 0.7171Epoch 6/40: loss=0.5665, accuracy=0.7165, val_loss=0.6499, val_accuracy=0.7492\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5665 - accuracy: 0.7165 - val_loss: 0.6499 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.7227Epoch 7/40: loss=0.5623, accuracy=0.7227, val_loss=0.4981, val_accuracy=0.7707\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5623 - accuracy: 0.7227 - val_loss: 0.4981 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7326Epoch 8/40: loss=0.5574, accuracy=0.7326, val_loss=0.4957, val_accuracy=0.7517\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5574 - accuracy: 0.7326 - val_loss: 0.4957 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7236Epoch 9/40: loss=0.5540, accuracy=0.7237, val_loss=1.1419, val_accuracy=0.4818\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5540 - accuracy: 0.7237 - val_loss: 1.1419 - val_accuracy: 0.4818 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.7281Epoch 10/40: loss=0.5519, accuracy=0.7281, val_loss=0.6059, val_accuracy=0.6978\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5519 - accuracy: 0.7281 - val_loss: 0.6059 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7247Epoch 11/40: loss=0.5571, accuracy=0.7248, val_loss=0.4717, val_accuracy=0.8071\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5571 - accuracy: 0.7248 - val_loss: 0.4717 - val_accuracy: 0.8071 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7355Epoch 12/40: loss=0.5552, accuracy=0.7355, val_loss=0.5219, val_accuracy=0.7492\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5552 - accuracy: 0.7355 - val_loss: 0.5219 - val_accuracy: 0.7492 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7398Epoch 13/40: loss=0.5423, accuracy=0.7399, val_loss=0.6461, val_accuracy=0.6656\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5423 - accuracy: 0.7399 - val_loss: 0.6461 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7423Epoch 14/40: loss=0.5242, accuracy=0.7428, val_loss=0.6415, val_accuracy=0.6598\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5242 - accuracy: 0.7428 - val_loss: 0.6415 - val_accuracy: 0.6598 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5314 - accuracy: 0.7456Epoch 15/40: loss=0.5313, accuracy=0.7452, val_loss=0.4942, val_accuracy=0.7666\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5313 - accuracy: 0.7452 - val_loss: 0.4942 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5285 - accuracy: 0.7465\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 16/40: loss=0.5282, accuracy=0.7465, val_loss=0.4987, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5282 - accuracy: 0.7465 - val_loss: 0.4987 - val_accuracy: 0.7964 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4864 - accuracy: 0.7770Epoch 17/40: loss=0.4859, accuracy=0.7773, val_loss=0.4406, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4859 - accuracy: 0.7773 - val_loss: 0.4406 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.7686Epoch 18/40: loss=0.4853, accuracy=0.7686, val_loss=0.4084, val_accuracy=0.8187\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4853 - accuracy: 0.7686 - val_loss: 0.4084 - val_accuracy: 0.8187 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.7763Epoch 19/40: loss=0.4728, accuracy=0.7763, val_loss=0.4078, val_accuracy=0.8245\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4728 - accuracy: 0.7763 - val_loss: 0.4078 - val_accuracy: 0.8245 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.7751Epoch 20/40: loss=0.4762, accuracy=0.7750, val_loss=0.4019, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4762 - accuracy: 0.7750 - val_loss: 0.4019 - val_accuracy: 0.8212 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.7757Epoch 21/40: loss=0.4806, accuracy=0.7763, val_loss=0.4265, val_accuracy=0.8162\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4806 - accuracy: 0.7763 - val_loss: 0.4265 - val_accuracy: 0.8162 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.7794Epoch 22/40: loss=0.4675, accuracy=0.7796, val_loss=0.4202, val_accuracy=0.8079\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4675 - accuracy: 0.7796 - val_loss: 0.4202 - val_accuracy: 0.8079 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.7821Epoch 23/40: loss=0.4633, accuracy=0.7821, val_loss=0.3884, val_accuracy=0.8344\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4633 - accuracy: 0.7821 - val_loss: 0.3884 - val_accuracy: 0.8344 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.7900Epoch 24/40: loss=0.4624, accuracy=0.7897, val_loss=0.4305, val_accuracy=0.8046\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4624 - accuracy: 0.7897 - val_loss: 0.4305 - val_accuracy: 0.8046 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4530 - accuracy: 0.7990Epoch 25/40: loss=0.4527, accuracy=0.7990, val_loss=0.3876, val_accuracy=0.8303\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4527 - accuracy: 0.7990 - val_loss: 0.3876 - val_accuracy: 0.8303 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.7998Epoch 26/40: loss=0.4475, accuracy=0.7999, val_loss=0.3991, val_accuracy=0.8237\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4475 - accuracy: 0.7999 - val_loss: 0.3991 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4529 - accuracy: 0.7899Epoch 27/40: loss=0.4540, accuracy=0.7893, val_loss=0.4059, val_accuracy=0.8262\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4540 - accuracy: 0.7893 - val_loss: 0.4059 - val_accuracy: 0.8262 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.7977Epoch 28/40: loss=0.4463, accuracy=0.7976, val_loss=0.3772, val_accuracy=0.8328\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4463 - accuracy: 0.7976 - val_loss: 0.3772 - val_accuracy: 0.8328 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.7939Epoch 29/40: loss=0.4415, accuracy=0.7941, val_loss=0.3832, val_accuracy=0.8212\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4415 - accuracy: 0.7941 - val_loss: 0.3832 - val_accuracy: 0.8212 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.7901Epoch 30/40: loss=0.4451, accuracy=0.7904, val_loss=0.4344, val_accuracy=0.8146\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4451 - accuracy: 0.7904 - val_loss: 0.4344 - val_accuracy: 0.8146 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.7968Epoch 31/40: loss=0.4362, accuracy=0.7968, val_loss=0.4328, val_accuracy=0.8005\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4362 - accuracy: 0.7968 - val_loss: 0.4328 - val_accuracy: 0.8005 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7924Epoch 32/40: loss=0.4433, accuracy=0.7924, val_loss=0.4661, val_accuracy=0.8013\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4433 - accuracy: 0.7924 - val_loss: 0.4661 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4400 - accuracy: 0.7966\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 33/40: loss=0.4393, accuracy=0.7968, val_loss=0.4653, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4393 - accuracy: 0.7968 - val_loss: 0.4653 - val_accuracy: 0.7980 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4134 - accuracy: 0.8118Epoch 34/40: loss=0.4133, accuracy=0.8121, val_loss=0.4097, val_accuracy=0.8220\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4133 - accuracy: 0.8121 - val_loss: 0.4097 - val_accuracy: 0.8220 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8122Epoch 35/40: loss=0.4153, accuracy=0.8119, val_loss=0.4039, val_accuracy=0.8187\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4153 - accuracy: 0.8119 - val_loss: 0.4039 - val_accuracy: 0.8187 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4172 - accuracy: 0.8079Epoch 36/40: loss=0.4165, accuracy=0.8086, val_loss=0.4155, val_accuracy=0.8146\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4165 - accuracy: 0.8086 - val_loss: 0.4155 - val_accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4110 - accuracy: 0.8167Epoch 37/40: loss=0.4110, accuracy=0.8162, val_loss=0.4283, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4110 - accuracy: 0.8162 - val_loss: 0.4283 - val_accuracy: 0.8121 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.8117\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.4145, accuracy=0.8117, val_loss=0.4010, val_accuracy=0.8245\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4145 - accuracy: 0.8117 - val_loss: 0.4010 - val_accuracy: 0.8245 - lr: 4.0000e-05\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8344370722770691\n",
      "\n",
      "Refined Training Combination 13/50: num_residual_blocks=4, dropout_rate=0.19999999999999998, learning_rate=0.00025, rotation_range=30, width_shift_range=0.2, height_shift_range=0.1, shear_range=0.2, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.5784Epoch 1/40: loss=0.8067, accuracy=0.5784, val_loss=0.6574, val_accuracy=0.6647\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.8067 - accuracy: 0.5784 - val_loss: 0.6574 - val_accuracy: 0.6647 - lr: 2.5000e-04\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.6621Epoch 2/40: loss=0.6729, accuracy=0.6623, val_loss=0.9467, val_accuracy=0.6540\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6729 - accuracy: 0.6623 - val_loss: 0.9467 - val_accuracy: 0.6540 - lr: 2.5000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6205 - accuracy: 0.6929Epoch 3/40: loss=0.6203, accuracy=0.6929, val_loss=1.0010, val_accuracy=0.5224\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6203 - accuracy: 0.6929 - val_loss: 1.0010 - val_accuracy: 0.5224 - lr: 2.5000e-04\n",
      "Epoch 4/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.6937Epoch 4/40: loss=0.6018, accuracy=0.6939, val_loss=0.4806, val_accuracy=0.7781\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6018 - accuracy: 0.6939 - val_loss: 0.4806 - val_accuracy: 0.7781 - lr: 2.5000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5641 - accuracy: 0.7195Epoch 5/40: loss=0.5642, accuracy=0.7188, val_loss=0.4766, val_accuracy=0.7897\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5642 - accuracy: 0.7188 - val_loss: 0.4766 - val_accuracy: 0.7897 - lr: 2.5000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.7191Epoch 6/40: loss=0.5663, accuracy=0.7192, val_loss=0.6082, val_accuracy=0.6772\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5663 - accuracy: 0.7192 - val_loss: 0.6082 - val_accuracy: 0.6772 - lr: 2.5000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5465 - accuracy: 0.7276Epoch 7/40: loss=0.5467, accuracy=0.7274, val_loss=0.4832, val_accuracy=0.7699\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5467 - accuracy: 0.7274 - val_loss: 0.4832 - val_accuracy: 0.7699 - lr: 2.5000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5211 - accuracy: 0.7537Epoch 8/40: loss=0.5205, accuracy=0.7541, val_loss=0.5242, val_accuracy=0.7450\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5205 - accuracy: 0.7541 - val_loss: 0.5242 - val_accuracy: 0.7450 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7591Epoch 9/40: loss=0.5034, accuracy=0.7591, val_loss=0.5469, val_accuracy=0.7657\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5034 - accuracy: 0.7591 - val_loss: 0.5469 - val_accuracy: 0.7657 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.7581\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 10/40: loss=0.5095, accuracy=0.7583, val_loss=0.4911, val_accuracy=0.7690\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5095 - accuracy: 0.7583 - val_loss: 0.4911 - val_accuracy: 0.7690 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7741Epoch 11/40: loss=0.4808, accuracy=0.7740, val_loss=0.4773, val_accuracy=0.7906\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4808 - accuracy: 0.7740 - val_loss: 0.4773 - val_accuracy: 0.7906 - lr: 5.0000e-05\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8265Epoch 32/40: loss=0.3804, accuracy=0.8264, val_loss=0.3536, val_accuracy=0.8427\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3804 - accuracy: 0.8264 - val_loss: 0.3536 - val_accuracy: 0.8427 - lr: 1.0000e-05\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8308Epoch 33/40: loss=0.3843, accuracy=0.8303, val_loss=0.3546, val_accuracy=0.8427\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3843 - accuracy: 0.8303 - val_loss: 0.3546 - val_accuracy: 0.8427 - lr: 1.0000e-05\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8342Epoch 34/40: loss=0.3704, accuracy=0.8342, val_loss=0.3553, val_accuracy=0.8386\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.3704 - accuracy: 0.8342 - val_loss: 0.3553 - val_accuracy: 0.8386 - lr: 1.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8101Epoch 35/40: loss=0.3998, accuracy=0.8104, val_loss=0.3636, val_accuracy=0.8411\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3998 - accuracy: 0.8104 - val_loss: 0.3636 - val_accuracy: 0.8411 - lr: 1.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8324Epoch 36/40: loss=0.3658, accuracy=0.8324, val_loss=0.3551, val_accuracy=0.8377\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.3658 - accuracy: 0.8324 - val_loss: 0.3551 - val_accuracy: 0.8377 - lr: 1.0000e-05\n",
      "Epoch 37/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8313\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Epoch 37/40: loss=0.3804, accuracy=0.8313, val_loss=0.3598, val_accuracy=0.8411\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.3804 - accuracy: 0.8313 - val_loss: 0.3598 - val_accuracy: 0.8411 - lr: 1.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8315Epoch 38/40: loss=0.3792, accuracy=0.8315, val_loss=0.3569, val_accuracy=0.8444\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3792 - accuracy: 0.8315 - val_loss: 0.3569 - val_accuracy: 0.8444 - lr: 2.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.7568Epoch 11/40: loss=0.5173, accuracy=0.7568, val_loss=0.4684, val_accuracy=0.7724\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5173 - accuracy: 0.7568 - val_loss: 0.4684 - val_accuracy: 0.7724 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5089 - accuracy: 0.7637Epoch 12/40: loss=0.5087, accuracy=0.7639, val_loss=0.4399, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.5087 - accuracy: 0.7639 - val_loss: 0.4399 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.7670Epoch 13/40: loss=0.5014, accuracy=0.7678, val_loss=0.7066, val_accuracy=0.6366\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5014 - accuracy: 0.7678 - val_loss: 0.7066 - val_accuracy: 0.6366 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.7612Epoch 14/40: loss=0.4970, accuracy=0.7612, val_loss=0.4633, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4970 - accuracy: 0.7612 - val_loss: 0.4633 - val_accuracy: 0.7806 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4946 - accuracy: 0.7739Epoch 15/40: loss=0.4942, accuracy=0.7740, val_loss=0.5045, val_accuracy=0.7649\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4942 - accuracy: 0.7740 - val_loss: 0.5045 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.7742Epoch 16/40: loss=0.4836, accuracy=0.7742, val_loss=0.8172, val_accuracy=0.4901\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4836 - accuracy: 0.7742 - val_loss: 0.8172 - val_accuracy: 0.4901 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.7724\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 17/40: loss=0.4807, accuracy=0.7728, val_loss=0.5489, val_accuracy=0.7624\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4807 - accuracy: 0.7728 - val_loss: 0.5489 - val_accuracy: 0.7624 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7988Epoch 18/40: loss=0.4443, accuracy=0.7988, val_loss=0.4459, val_accuracy=0.8022\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4443 - accuracy: 0.7988 - val_loss: 0.4459 - val_accuracy: 0.8022 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.8061Epoch 19/40: loss=0.4328, accuracy=0.8061, val_loss=0.3587, val_accuracy=0.8402\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4328 - accuracy: 0.8061 - val_loss: 0.3587 - val_accuracy: 0.8402 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3937 - accuracy: 0.8267Epoch 30/40: loss=0.3937, accuracy=0.8266, val_loss=0.3502, val_accuracy=0.8568\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3937 - accuracy: 0.8266 - val_loss: 0.3502 - val_accuracy: 0.8568 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.8355Epoch 31/40: loss=0.3734, accuracy=0.8361, val_loss=0.3264, val_accuracy=0.8642\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3734 - accuracy: 0.8361 - val_loss: 0.3264 - val_accuracy: 0.8642 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8324Epoch 32/40: loss=0.3728, accuracy=0.8324, val_loss=0.3381, val_accuracy=0.8626\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3728 - accuracy: 0.8324 - val_loss: 0.3381 - val_accuracy: 0.8626 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8295\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 33/40: loss=0.3846, accuracy=0.8297, val_loss=0.3269, val_accuracy=0.8651\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3846 - accuracy: 0.8297 - val_loss: 0.3269 - val_accuracy: 0.8651 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.8389Epoch 34/40: loss=0.3631, accuracy=0.8392, val_loss=0.3214, val_accuracy=0.8717\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3631 - accuracy: 0.8392 - val_loss: 0.3214 - val_accuracy: 0.8717 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8481Epoch 35/40: loss=0.3557, accuracy=0.8481, val_loss=0.3156, val_accuracy=0.8742\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3557 - accuracy: 0.8481 - val_loss: 0.3156 - val_accuracy: 0.8742 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4314 - accuracy: 0.8002Epoch 19/40: loss=0.4313, accuracy=0.8003, val_loss=0.3932, val_accuracy=0.8353\n",
      "604/604 [==============================] - 16s 26ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.3932 - val_accuracy: 0.8353 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.7993Epoch 20/40: loss=0.4426, accuracy=0.7997, val_loss=0.3670, val_accuracy=0.8394\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4426 - accuracy: 0.7997 - val_loss: 0.3670 - val_accuracy: 0.8394 - lr: 1.0000e-04\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.7986Epoch 21/40: loss=0.4305, accuracy=0.7986, val_loss=0.3887, val_accuracy=0.8195\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.3887 - val_accuracy: 0.8195 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8014Epoch 22/40: loss=0.4248, accuracy=0.8017, val_loss=0.4531, val_accuracy=0.7450\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4248 - accuracy: 0.8017 - val_loss: 0.4531 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8018Epoch 23/40: loss=0.4300, accuracy=0.8015, val_loss=0.4276, val_accuracy=0.7930\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4300 - accuracy: 0.8015 - val_loss: 0.4276 - val_accuracy: 0.7930 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4266 - accuracy: 0.8117Epoch 24/40: loss=0.4267, accuracy=0.8115, val_loss=0.3782, val_accuracy=0.8469\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4267 - accuracy: 0.8115 - val_loss: 0.3782 - val_accuracy: 0.8469 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8160\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 25/40: loss=0.4086, accuracy=0.8160, val_loss=0.3688, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.3688 - val_accuracy: 0.8278 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.6029Epoch 1/40: loss=0.7947, accuracy=0.6029, val_loss=1.0622, val_accuracy=0.4570\n",
      "604/604 [==============================] - 15s 22ms/step - loss: 0.7947 - accuracy: 0.6029 - val_loss: 1.0622 - val_accuracy: 0.4570 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.6807Epoch 2/40: loss=0.6088, accuracy=0.6807, val_loss=0.5527, val_accuracy=0.7318\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6088 - accuracy: 0.6807 - val_loss: 0.5527 - val_accuracy: 0.7318 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 0.7056Epoch 3/40: loss=0.5830, accuracy=0.7057, val_loss=0.8954, val_accuracy=0.5397\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5830 - accuracy: 0.7057 - val_loss: 0.8954 - val_accuracy: 0.5397 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5672 - accuracy: 0.7164Epoch 4/40: loss=0.5668, accuracy=0.7167, val_loss=0.4980, val_accuracy=0.7856\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5668 - accuracy: 0.7167 - val_loss: 0.4980 - val_accuracy: 0.7856 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7148Epoch 5/40: loss=0.5750, accuracy=0.7148, val_loss=0.5031, val_accuracy=0.7260\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5750 - accuracy: 0.7148 - val_loss: 0.5031 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.7230Epoch 6/40: loss=0.5613, accuracy=0.7229, val_loss=0.7090, val_accuracy=0.7301\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5613 - accuracy: 0.7229 - val_loss: 0.7090 - val_accuracy: 0.7301 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5567 - accuracy: 0.7274Epoch 7/40: loss=0.5569, accuracy=0.7274, val_loss=0.6072, val_accuracy=0.7243\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5569 - accuracy: 0.7274 - val_loss: 0.6072 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5556 - accuracy: 0.7303Epoch 8/40: loss=0.5557, accuracy=0.7303, val_loss=0.7245, val_accuracy=0.6159\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5557 - accuracy: 0.7303 - val_loss: 0.7245 - val_accuracy: 0.6159 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7343\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/40: loss=0.5550, accuracy=0.7343, val_loss=0.4998, val_accuracy=0.7839\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5550 - accuracy: 0.7343 - val_loss: 0.4998 - val_accuracy: 0.7839 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8077Epoch 29/40: loss=0.4339, accuracy=0.8077, val_loss=0.3923, val_accuracy=0.8336\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4339 - accuracy: 0.8077 - val_loss: 0.3923 - val_accuracy: 0.8336 - lr: 8.0000e-06\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.7975Epoch 30/40: loss=0.4387, accuracy=0.7974, val_loss=0.3909, val_accuracy=0.8303\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4387 - accuracy: 0.7974 - val_loss: 0.3909 - val_accuracy: 0.8303 - lr: 8.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4308 - accuracy: 0.8034Epoch 31/40: loss=0.4306, accuracy=0.8032, val_loss=0.3982, val_accuracy=0.8295\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4306 - accuracy: 0.8032 - val_loss: 0.3982 - val_accuracy: 0.8295 - lr: 8.0000e-06\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.7986Epoch 32/40: loss=0.4423, accuracy=0.7986, val_loss=0.3957, val_accuracy=0.8336\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4423 - accuracy: 0.7986 - val_loss: 0.3957 - val_accuracy: 0.8336 - lr: 8.0000e-06\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.8032Epoch 33/40: loss=0.4280, accuracy=0.8032, val_loss=0.3933, val_accuracy=0.8303\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4280 - accuracy: 0.8032 - val_loss: 0.3933 - val_accuracy: 0.8303 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8028Epoch 34/40: loss=0.4407, accuracy=0.8028, val_loss=0.3989, val_accuracy=0.8278\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4407 - accuracy: 0.8028 - val_loss: 0.3989 - val_accuracy: 0.8278 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4267 - accuracy: 0.8037\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 35/40: loss=0.4272, accuracy=0.8034, val_loss=0.3933, val_accuracy=0.8311\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4272 - accuracy: 0.8034 - val_loss: 0.3933 - val_accuracy: 0.8311 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8072Epoch 36/40: loss=0.4358, accuracy=0.8073, val_loss=0.3998, val_accuracy=0.8344\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4358 - accuracy: 0.8073 - val_loss: 0.3998 - val_accuracy: 0.8344 - lr: 1.6000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4354 - accuracy: 0.8038Epoch 37/40: loss=0.4353, accuracy=0.8040, val_loss=0.3990, val_accuracy=0.8295\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4353 - accuracy: 0.8040 - val_loss: 0.3990 - val_accuracy: 0.8295 - lr: 1.6000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7996Epoch 23/40: loss=0.4384, accuracy=0.7995, val_loss=0.4252, val_accuracy=0.7848\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4384 - accuracy: 0.7995 - val_loss: 0.4252 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.8025Epoch 24/40: loss=0.4367, accuracy=0.8026, val_loss=0.4071, val_accuracy=0.8046\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4367 - accuracy: 0.8026 - val_loss: 0.4071 - val_accuracy: 0.8046 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4293 - accuracy: 0.8067Epoch 25/40: loss=0.4290, accuracy=0.8069, val_loss=0.4149, val_accuracy=0.7972\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4290 - accuracy: 0.8069 - val_loss: 0.4149 - val_accuracy: 0.7972 - lr: 1.0000e-05\n",
      "Epoch 26/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4322 - accuracy: 0.8003Epoch 26/40: loss=0.4316, accuracy=0.8005, val_loss=0.4150, val_accuracy=0.7964\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4316 - accuracy: 0.8005 - val_loss: 0.4150 - val_accuracy: 0.7964 - lr: 1.0000e-05\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8005Epoch 27/40: loss=0.4369, accuracy=0.8005, val_loss=0.4254, val_accuracy=0.7922\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4369 - accuracy: 0.8005 - val_loss: 0.4254 - val_accuracy: 0.7922 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.7988Epoch 28/40: loss=0.4309, accuracy=0.7988, val_loss=0.4108, val_accuracy=0.8022\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4309 - accuracy: 0.7988 - val_loss: 0.4108 - val_accuracy: 0.8022 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4184 - accuracy: 0.8128Epoch 29/40: loss=0.4191, accuracy=0.8123, val_loss=0.4052, val_accuracy=0.8096\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4191 - accuracy: 0.8123 - val_loss: 0.4052 - val_accuracy: 0.8096 - lr: 1.0000e-05\n",
      "Epoch 30/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.7993Epoch 30/40: loss=0.4330, accuracy=0.7997, val_loss=0.4239, val_accuracy=0.7955\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4330 - accuracy: 0.7997 - val_loss: 0.4239 - val_accuracy: 0.7955 - lr: 1.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8074Epoch 31/40: loss=0.4297, accuracy=0.8075, val_loss=0.4471, val_accuracy=0.7740\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4297 - accuracy: 0.8075 - val_loss: 0.4471 - val_accuracy: 0.7740 - lr: 1.0000e-05\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.7243Epoch 7/40: loss=0.5557, accuracy=0.7243, val_loss=1.7977, val_accuracy=0.6060\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5557 - accuracy: 0.7243 - val_loss: 1.7977 - val_accuracy: 0.6060 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5614 - accuracy: 0.7253Epoch 8/40: loss=0.5611, accuracy=0.7254, val_loss=0.5464, val_accuracy=0.7558\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5611 - accuracy: 0.7254 - val_loss: 0.5464 - val_accuracy: 0.7558 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5729 - accuracy: 0.7131Epoch 9/40: loss=0.5736, accuracy=0.7125, val_loss=0.4989, val_accuracy=0.7823\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5736 - accuracy: 0.7125 - val_loss: 0.4989 - val_accuracy: 0.7823 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7317Epoch 10/40: loss=0.5471, accuracy=0.7318, val_loss=1.0551, val_accuracy=0.4868\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5471 - accuracy: 0.7318 - val_loss: 1.0551 - val_accuracy: 0.4868 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7181Epoch 11/40: loss=0.5452, accuracy=0.7181, val_loss=0.5975, val_accuracy=0.7243\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5452 - accuracy: 0.7181 - val_loss: 0.5975 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.7264Epoch 12/40: loss=0.5441, accuracy=0.7264, val_loss=0.6657, val_accuracy=0.6813\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5441 - accuracy: 0.7264 - val_loss: 0.6657 - val_accuracy: 0.6813 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7401Epoch 13/40: loss=0.5434, accuracy=0.7401, val_loss=0.6705, val_accuracy=0.7219\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5434 - accuracy: 0.7401 - val_loss: 0.6705 - val_accuracy: 0.7219 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5480 - accuracy: 0.7234Epoch 14/40: loss=0.5478, accuracy=0.7235, val_loss=0.4571, val_accuracy=0.7881\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5478 - accuracy: 0.7235 - val_loss: 0.4571 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.7848Epoch 27/40: loss=0.4658, accuracy=0.7852, val_loss=0.4860, val_accuracy=0.8046\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4658 - accuracy: 0.7852 - val_loss: 0.4860 - val_accuracy: 0.8046 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.7863Epoch 28/40: loss=0.4602, accuracy=0.7862, val_loss=0.4613, val_accuracy=0.7930\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4602 - accuracy: 0.7862 - val_loss: 0.4613 - val_accuracy: 0.7930 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7803Epoch 29/40: loss=0.4705, accuracy=0.7804, val_loss=0.4340, val_accuracy=0.8187\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4705 - accuracy: 0.7804 - val_loss: 0.4340 - val_accuracy: 0.8187 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.7926\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 30/40: loss=0.4533, accuracy=0.7926, val_loss=0.4062, val_accuracy=0.8204\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4533 - accuracy: 0.7926 - val_loss: 0.4062 - val_accuracy: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4548 - accuracy: 0.7865Epoch 31/40: loss=0.4544, accuracy=0.7868, val_loss=0.4048, val_accuracy=0.8336\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4544 - accuracy: 0.7868 - val_loss: 0.4048 - val_accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.7917Epoch 32/40: loss=0.4517, accuracy=0.7912, val_loss=0.4074, val_accuracy=0.8328\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4517 - accuracy: 0.7912 - val_loss: 0.4074 - val_accuracy: 0.8328 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4438 - accuracy: 0.7985Epoch 33/40: loss=0.4439, accuracy=0.7986, val_loss=0.3987, val_accuracy=0.8336\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4439 - accuracy: 0.7986 - val_loss: 0.3987 - val_accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.7272Epoch 7/40: loss=0.5581, accuracy=0.7272, val_loss=0.8092, val_accuracy=0.6118\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5581 - accuracy: 0.7272 - val_loss: 0.8092 - val_accuracy: 0.6118 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.5700 - accuracy: 0.7163Epoch 8/40: loss=0.5702, accuracy=0.7163, val_loss=0.6005, val_accuracy=0.7036\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5702 - accuracy: 0.7163 - val_loss: 0.6005 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7294Epoch 9/40: loss=0.5496, accuracy=0.7297, val_loss=0.4966, val_accuracy=0.7790\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5496 - accuracy: 0.7297 - val_loss: 0.4966 - val_accuracy: 0.7790 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.7409Epoch 10/40: loss=0.5476, accuracy=0.7409, val_loss=0.5457, val_accuracy=0.7334\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5476 - accuracy: 0.7409 - val_loss: 0.5457 - val_accuracy: 0.7334 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.7314Epoch 11/40: loss=0.5454, accuracy=0.7314, val_loss=1.3290, val_accuracy=0.4015\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.5454 - accuracy: 0.7314 - val_loss: 1.3290 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.7365Epoch 12/40: loss=0.5464, accuracy=0.7365, val_loss=1.0556, val_accuracy=0.6151\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5464 - accuracy: 0.7365 - val_loss: 1.0556 - val_accuracy: 0.6151 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.7363Epoch 13/40: loss=0.5498, accuracy=0.7363, val_loss=0.4677, val_accuracy=0.7897\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5498 - accuracy: 0.7363 - val_loss: 0.4677 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5424 - accuracy: 0.7209Epoch 14/40: loss=0.5422, accuracy=0.7208, val_loss=0.6069, val_accuracy=0.7028\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5422 - accuracy: 0.7208 - val_loss: 0.6069 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.7363Epoch 15/40: loss=0.5370, accuracy=0.7361, val_loss=0.4817, val_accuracy=0.7765\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5370 - accuracy: 0.7361 - val_loss: 0.4817 - val_accuracy: 0.7765 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.7894Epoch 31/40: loss=0.4612, accuracy=0.7891, val_loss=0.4382, val_accuracy=0.8137\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4612 - accuracy: 0.7891 - val_loss: 0.4382 - val_accuracy: 0.8137 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7962Epoch 32/40: loss=0.4500, accuracy=0.7962, val_loss=0.5498, val_accuracy=0.7492\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4500 - accuracy: 0.7962 - val_loss: 0.5498 - val_accuracy: 0.7492 - lr: 2.0000e-04\n",
      "Epoch 33/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.7954\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 33/40: loss=0.4486, accuracy=0.7953, val_loss=0.4466, val_accuracy=0.7906\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4486 - accuracy: 0.7953 - val_loss: 0.4466 - val_accuracy: 0.7906 - lr: 2.0000e-04\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.7990Epoch 34/40: loss=0.4354, accuracy=0.7990, val_loss=0.4422, val_accuracy=0.8022\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4354 - accuracy: 0.7990 - val_loss: 0.4422 - val_accuracy: 0.8022 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4328 - accuracy: 0.7980Epoch 35/40: loss=0.4330, accuracy=0.7980, val_loss=0.4376, val_accuracy=0.8038\n",
      "604/604 [==============================] - 11s 17ms/step - loss: 0.4330 - accuracy: 0.7980 - val_loss: 0.4376 - val_accuracy: 0.8038 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4322 - accuracy: 0.7984Epoch 36/40: loss=0.4324, accuracy=0.7980, val_loss=0.4159, val_accuracy=0.8171\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4324 - accuracy: 0.7980 - val_loss: 0.4159 - val_accuracy: 0.8171 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8068Epoch 37/40: loss=0.4300, accuracy=0.8071, val_loss=0.4210, val_accuracy=0.8195\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4300 - accuracy: 0.8071 - val_loss: 0.4210 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4359 - accuracy: 0.7976\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 38/40: loss=0.4361, accuracy=0.7972, val_loss=0.4259, val_accuracy=0.8195\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4361 - accuracy: 0.7972 - val_loss: 0.4259 - val_accuracy: 0.8195 - lr: 4.0000e-05\n",
      "Epoch 38: early stopping\n",
      "Validation accuracy: 0.8302980065345764\n",
      "\n",
      "Refined Training Combination 38/50: num_residual_blocks=3, dropout_rate=0.19999999999999998, learning_rate=0.001, rotation_range=40, width_shift_range=0.30000000000000004, height_shift_range=0.0, shear_range=0.1, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5256 - accuracy: 0.7506Epoch 14/40: loss=0.5260, accuracy=0.7504, val_loss=0.5412, val_accuracy=0.7599\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5260 - accuracy: 0.7504 - val_loss: 0.5412 - val_accuracy: 0.7599 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.7537Epoch 15/40: loss=0.5172, accuracy=0.7531, val_loss=0.4536, val_accuracy=0.7781\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5172 - accuracy: 0.7531 - val_loss: 0.4536 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.7643Epoch 16/40: loss=0.5129, accuracy=0.7641, val_loss=0.4742, val_accuracy=0.7690\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5129 - accuracy: 0.7641 - val_loss: 0.4742 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.7581Epoch 17/40: loss=0.5057, accuracy=0.7581, val_loss=0.4865, val_accuracy=0.7757\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5057 - accuracy: 0.7581 - val_loss: 0.4865 - val_accuracy: 0.7757 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.7684Epoch 18/40: loss=0.5082, accuracy=0.7684, val_loss=0.5571, val_accuracy=0.7450\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5082 - accuracy: 0.7684 - val_loss: 0.5571 - val_accuracy: 0.7450 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5097 - accuracy: 0.7655Epoch 19/40: loss=0.5094, accuracy=0.7657, val_loss=0.5805, val_accuracy=0.7310\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5094 - accuracy: 0.7657 - val_loss: 0.5805 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5004 - accuracy: 0.7656\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 20/40: loss=0.4999, accuracy=0.7659, val_loss=0.5058, val_accuracy=0.7790\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4999 - accuracy: 0.7659 - val_loss: 0.5058 - val_accuracy: 0.7790 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.7763Epoch 21/40: loss=0.4748, accuracy=0.7763, val_loss=0.4367, val_accuracy=0.8013\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4748 - accuracy: 0.7763 - val_loss: 0.4367 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.6611 - accuracy: 0.6343Epoch 3/40: loss=0.6609, accuracy=0.6345, val_loss=0.8346, val_accuracy=0.4214\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.6609 - accuracy: 0.6345 - val_loss: 0.8346 - val_accuracy: 0.4214 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5857 - accuracy: 0.6951Epoch 4/40: loss=0.5859, accuracy=0.6945, val_loss=0.5076, val_accuracy=0.7541\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5859 - accuracy: 0.6945 - val_loss: 0.5076 - val_accuracy: 0.7541 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5625 - accuracy: 0.7164Epoch 5/40: loss=0.5622, accuracy=0.7161, val_loss=0.5528, val_accuracy=0.7086\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5622 - accuracy: 0.7161 - val_loss: 0.5528 - val_accuracy: 0.7086 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.7196Epoch 6/40: loss=0.5547, accuracy=0.7196, val_loss=0.7745, val_accuracy=0.7219\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5547 - accuracy: 0.7196 - val_loss: 0.7745 - val_accuracy: 0.7219 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.7384Epoch 7/40: loss=0.5406, accuracy=0.7382, val_loss=0.5689, val_accuracy=0.7260\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5406 - accuracy: 0.7382 - val_loss: 0.5689 - val_accuracy: 0.7260 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.7415Epoch 8/40: loss=0.5407, accuracy=0.7415, val_loss=0.7690, val_accuracy=0.6912\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5407 - accuracy: 0.7415 - val_loss: 0.7690 - val_accuracy: 0.6912 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7409\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/40: loss=0.5470, accuracy=0.7411, val_loss=0.5357, val_accuracy=0.7583\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5470 - accuracy: 0.7411 - val_loss: 0.5357 - val_accuracy: 0.7583 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8059Epoch 21/40: loss=0.4363, accuracy=0.8059, val_loss=0.4497, val_accuracy=0.8104\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4363 - accuracy: 0.8059 - val_loss: 0.4497 - val_accuracy: 0.8104 - lr: 2.0000e-05\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4359 - accuracy: 0.8000Epoch 22/40: loss=0.4358, accuracy=0.8003, val_loss=0.4613, val_accuracy=0.8046\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.4613 - val_accuracy: 0.8046 - lr: 2.0000e-05\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8106\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 23/40: loss=0.4257, accuracy=0.8106, val_loss=0.5107, val_accuracy=0.7806\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4257 - accuracy: 0.8106 - val_loss: 0.5107 - val_accuracy: 0.7806 - lr: 2.0000e-05\n",
      "Epoch 23: early stopping\n",
      "Validation accuracy: 0.8236755132675171\n",
      "\n",
      "Refined Training Combination 40/50: num_residual_blocks=4, dropout_rate=0.19999999999999998, learning_rate=0.001, rotation_range=30, width_shift_range=0.30000000000000004, height_shift_range=0.2, shear_range=0.2, zoom_range=0.1, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.8231 - accuracy: 0.5820Epoch 1/40: loss=0.8231, accuracy=0.5820, val_loss=0.5774, val_accuracy=0.7152\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.8231 - accuracy: 0.5820 - val_loss: 0.5774 - val_accuracy: 0.7152 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.6778Epoch 2/40: loss=0.6188, accuracy=0.6778, val_loss=0.5415, val_accuracy=0.7517\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6188 - accuracy: 0.6778 - val_loss: 0.5415 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7040Epoch 3/40: loss=0.5852, accuracy=0.7034, val_loss=0.6181, val_accuracy=0.6995\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5852 - accuracy: 0.7034 - val_loss: 0.6181 - val_accuracy: 0.6995 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7041Epoch 4/40: loss=0.5776, accuracy=0.7041, val_loss=0.5383, val_accuracy=0.7459\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.5776 - accuracy: 0.7041 - val_loss: 0.5383 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.7235Epoch 5/40: loss=0.5646, accuracy=0.7235, val_loss=1.1834, val_accuracy=0.4520\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5646 - accuracy: 0.7235 - val_loss: 1.1834 - val_accuracy: 0.4520 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7256Epoch 6/40: loss=0.5641, accuracy=0.7256, val_loss=0.5045, val_accuracy=0.7798\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5641 - accuracy: 0.7256 - val_loss: 0.5045 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.7790Epoch 22/40: loss=0.4656, accuracy=0.7790, val_loss=0.3877, val_accuracy=0.8311\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4656 - accuracy: 0.7790 - val_loss: 0.3877 - val_accuracy: 0.8311 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.7780Epoch 23/40: loss=0.4641, accuracy=0.7777, val_loss=0.4458, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4641 - accuracy: 0.7777 - val_loss: 0.4458 - val_accuracy: 0.8121 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4482 - accuracy: 0.7962Epoch 24/40: loss=0.4480, accuracy=0.7964, val_loss=0.4340, val_accuracy=0.8154\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4480 - accuracy: 0.7964 - val_loss: 0.4340 - val_accuracy: 0.8154 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.7997Epoch 25/40: loss=0.4438, accuracy=0.7997, val_loss=0.3871, val_accuracy=0.8377\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4438 - accuracy: 0.7997 - val_loss: 0.3871 - val_accuracy: 0.8377 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.7996Epoch 26/40: loss=0.4390, accuracy=0.7999, val_loss=0.3967, val_accuracy=0.8286\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4390 - accuracy: 0.7999 - val_loss: 0.3967 - val_accuracy: 0.8286 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.8052Epoch 27/40: loss=0.4281, accuracy=0.8050, val_loss=0.3784, val_accuracy=0.8411\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4281 - accuracy: 0.8050 - val_loss: 0.3784 - val_accuracy: 0.8411 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4248 - accuracy: 0.8153Epoch 28/40: loss=0.4249, accuracy=0.8152, val_loss=0.3797, val_accuracy=0.8386\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4249 - accuracy: 0.8152 - val_loss: 0.3797 - val_accuracy: 0.8386 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.6816Epoch 2/40: loss=0.6316, accuracy=0.6819, val_loss=0.7894, val_accuracy=0.5397\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.6316 - accuracy: 0.6819 - val_loss: 0.7894 - val_accuracy: 0.5397 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.7141Epoch 3/40: loss=0.5727, accuracy=0.7138, val_loss=0.8429, val_accuracy=0.4801\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5727 - accuracy: 0.7138 - val_loss: 0.8429 - val_accuracy: 0.4801 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.7369Epoch 4/40: loss=0.5417, accuracy=0.7370, val_loss=0.5790, val_accuracy=0.7301\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5417 - accuracy: 0.7370 - val_loss: 0.5790 - val_accuracy: 0.7301 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.7256Epoch 5/40: loss=0.5488, accuracy=0.7256, val_loss=0.4941, val_accuracy=0.7053\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5488 - accuracy: 0.7256 - val_loss: 0.4941 - val_accuracy: 0.7053 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5166 - accuracy: 0.7519Epoch 6/40: loss=0.5164, accuracy=0.7523, val_loss=0.5767, val_accuracy=0.7136\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5164 - accuracy: 0.7523 - val_loss: 0.5767 - val_accuracy: 0.7136 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.7608Epoch 7/40: loss=0.5083, accuracy=0.7608, val_loss=0.4852, val_accuracy=0.7773\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5083 - accuracy: 0.7608 - val_loss: 0.4852 - val_accuracy: 0.7773 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5077 - accuracy: 0.7674Epoch 8/40: loss=0.5073, accuracy=0.7676, val_loss=0.5376, val_accuracy=0.7301\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5073 - accuracy: 0.7676 - val_loss: 0.5376 - val_accuracy: 0.7301 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7514Epoch 9/40: loss=0.5123, accuracy=0.7514, val_loss=0.4451, val_accuracy=0.7674\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5123 - accuracy: 0.7514 - val_loss: 0.4451 - val_accuracy: 0.7674 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8094Epoch 21/40: loss=0.4228, accuracy=0.8094, val_loss=0.3977, val_accuracy=0.8137\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4228 - accuracy: 0.8094 - val_loss: 0.3977 - val_accuracy: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 22/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3992 - accuracy: 0.8159Epoch 22/40: loss=0.3989, accuracy=0.8160, val_loss=0.3482, val_accuracy=0.8361\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3989 - accuracy: 0.8160 - val_loss: 0.3482 - val_accuracy: 0.8361 - lr: 1.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8239Epoch 23/40: loss=0.3964, accuracy=0.8239, val_loss=0.3624, val_accuracy=0.8427\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3964 - accuracy: 0.8239 - val_loss: 0.3624 - val_accuracy: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.8202Epoch 24/40: loss=0.4006, accuracy=0.8202, val_loss=0.3868, val_accuracy=0.8137\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4006 - accuracy: 0.8202 - val_loss: 0.3868 - val_accuracy: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 25/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8265Epoch 25/40: loss=0.3866, accuracy=0.8264, val_loss=0.4103, val_accuracy=0.8121\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3866 - accuracy: 0.8264 - val_loss: 0.4103 - val_accuracy: 0.8121 - lr: 1.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.8268Epoch 26/40: loss=0.3959, accuracy=0.8272, val_loss=0.3727, val_accuracy=0.8154\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3959 - accuracy: 0.8272 - val_loss: 0.3727 - val_accuracy: 0.8154 - lr: 1.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8270\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 27/40: loss=0.3964, accuracy=0.8270, val_loss=0.3722, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3964 - accuracy: 0.8270 - val_loss: 0.3722 - val_accuracy: 0.8485 - lr: 1.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.7763Epoch 10/40: loss=0.4857, accuracy=0.7763, val_loss=0.4286, val_accuracy=0.8071\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4857 - accuracy: 0.7763 - val_loss: 0.4286 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.7743Epoch 11/40: loss=0.4698, accuracy=0.7750, val_loss=0.4107, val_accuracy=0.8179\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.4698 - accuracy: 0.7750 - val_loss: 0.4107 - val_accuracy: 0.8179 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4561 - accuracy: 0.7874Epoch 12/40: loss=0.4563, accuracy=0.7875, val_loss=0.4627, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4563 - accuracy: 0.7875 - val_loss: 0.4627 - val_accuracy: 0.8146 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.7919Epoch 13/40: loss=0.4609, accuracy=0.7918, val_loss=0.4322, val_accuracy=0.7765\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4609 - accuracy: 0.7918 - val_loss: 0.4322 - val_accuracy: 0.7765 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.7890Epoch 14/40: loss=0.4541, accuracy=0.7887, val_loss=0.4571, val_accuracy=0.8013\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4541 - accuracy: 0.7887 - val_loss: 0.4571 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4443 - accuracy: 0.7954Epoch 15/40: loss=0.4446, accuracy=0.7955, val_loss=0.4238, val_accuracy=0.8063\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4446 - accuracy: 0.7955 - val_loss: 0.4238 - val_accuracy: 0.8063 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.7983Epoch 16/40: loss=0.4494, accuracy=0.7986, val_loss=0.4021, val_accuracy=0.8311\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4494 - accuracy: 0.7986 - val_loss: 0.4021 - val_accuracy: 0.8311 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.7883Epoch 17/40: loss=0.4379, accuracy=0.7883, val_loss=0.4331, val_accuracy=0.7798\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4379 - accuracy: 0.7883 - val_loss: 0.4331 - val_accuracy: 0.7798 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3468 - accuracy: 0.8501Epoch 33/40: loss=0.3468, accuracy=0.8500, val_loss=0.3538, val_accuracy=0.8369\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3468 - accuracy: 0.8500 - val_loss: 0.3538 - val_accuracy: 0.8369 - lr: 8.0000e-06\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8430Epoch 34/40: loss=0.3534, accuracy=0.8429, val_loss=0.3574, val_accuracy=0.8394\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3534 - accuracy: 0.8429 - val_loss: 0.3574 - val_accuracy: 0.8394 - lr: 8.0000e-06\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.8459Epoch 35/40: loss=0.3590, accuracy=0.8460, val_loss=0.3608, val_accuracy=0.8353\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3590 - accuracy: 0.8460 - val_loss: 0.3608 - val_accuracy: 0.8353 - lr: 8.0000e-06\n",
      "Epoch 36/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8389Epoch 36/40: loss=0.3672, accuracy=0.8388, val_loss=0.3501, val_accuracy=0.8369\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.3672 - accuracy: 0.8388 - val_loss: 0.3501 - val_accuracy: 0.8369 - lr: 8.0000e-06\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.8399Epoch 37/40: loss=0.3556, accuracy=0.8404, val_loss=0.3536, val_accuracy=0.8419\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.3556 - accuracy: 0.8404 - val_loss: 0.3536 - val_accuracy: 0.8419 - lr: 8.0000e-06\n",
      "Epoch 38/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3549 - accuracy: 0.8403Epoch 38/40: loss=0.3554, accuracy=0.8398, val_loss=0.3463, val_accuracy=0.8402\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3554 - accuracy: 0.8398 - val_loss: 0.3463 - val_accuracy: 0.8402 - lr: 8.0000e-06\n",
      "Epoch 39/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.8431Epoch 39/40: loss=0.3568, accuracy=0.8433, val_loss=0.3470, val_accuracy=0.8353\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.3568 - accuracy: 0.8433 - val_loss: 0.3470 - val_accuracy: 0.8353 - lr: 8.0000e-06\n",
      "Epoch 40/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5369 - accuracy: 0.7436Epoch 12/40: loss=0.5369, accuracy=0.7436, val_loss=0.5164, val_accuracy=0.7575\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5369 - accuracy: 0.7436 - val_loss: 0.5164 - val_accuracy: 0.7575 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.7477Epoch 13/40: loss=0.5278, accuracy=0.7475, val_loss=1.3652, val_accuracy=0.6291\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5278 - accuracy: 0.7475 - val_loss: 1.3652 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.7519\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 14/40: loss=0.5186, accuracy=0.7519, val_loss=0.6349, val_accuracy=0.7012\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5186 - accuracy: 0.7519 - val_loss: 0.6349 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.7676Epoch 15/40: loss=0.4950, accuracy=0.7676, val_loss=0.4276, val_accuracy=0.8162\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4950 - accuracy: 0.7676 - val_loss: 0.4276 - val_accuracy: 0.8162 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.7689Epoch 16/40: loss=0.4824, accuracy=0.7690, val_loss=0.4848, val_accuracy=0.7848\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4824 - accuracy: 0.7690 - val_loss: 0.4848 - val_accuracy: 0.7848 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.7794Epoch 17/40: loss=0.4737, accuracy=0.7794, val_loss=0.4100, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4737 - accuracy: 0.7794 - val_loss: 0.4100 - val_accuracy: 0.8270 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.7826Epoch 18/40: loss=0.4674, accuracy=0.7827, val_loss=0.4060, val_accuracy=0.8237\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.4674 - accuracy: 0.7827 - val_loss: 0.4060 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 19/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.7736Epoch 19/40: loss=0.4720, accuracy=0.7736, val_loss=0.4030, val_accuracy=0.8204\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4720 - accuracy: 0.7736 - val_loss: 0.4030 - val_accuracy: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.8157Epoch 31/40: loss=0.4194, accuracy=0.8156, val_loss=0.3841, val_accuracy=0.8402\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4194 - accuracy: 0.8156 - val_loss: 0.3841 - val_accuracy: 0.8402 - lr: 4.0000e-05\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8042Epoch 32/40: loss=0.4281, accuracy=0.8038, val_loss=0.3881, val_accuracy=0.8444\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4281 - accuracy: 0.8038 - val_loss: 0.3881 - val_accuracy: 0.8444 - lr: 4.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8160Epoch 33/40: loss=0.4115, accuracy=0.8160, val_loss=0.3824, val_accuracy=0.8386\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4115 - accuracy: 0.8160 - val_loss: 0.3824 - val_accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 34/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4236 - accuracy: 0.8069Epoch 34/40: loss=0.4236, accuracy=0.8067, val_loss=0.3799, val_accuracy=0.8419\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4236 - accuracy: 0.8067 - val_loss: 0.3799 - val_accuracy: 0.8419 - lr: 4.0000e-05\n",
      "Epoch 35/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.8140Epoch 35/40: loss=0.4111, accuracy=0.8139, val_loss=0.3740, val_accuracy=0.8469\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4111 - accuracy: 0.8139 - val_loss: 0.3740 - val_accuracy: 0.8469 - lr: 4.0000e-05\n",
      "Epoch 36/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.8142Epoch 36/40: loss=0.4026, accuracy=0.8142, val_loss=0.3778, val_accuracy=0.8452\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4026 - accuracy: 0.8142 - val_loss: 0.3778 - val_accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 37/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.8146Epoch 37/40: loss=0.4112, accuracy=0.8150, val_loss=0.3936, val_accuracy=0.8187\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4112 - accuracy: 0.8150 - val_loss: 0.3936 - val_accuracy: 0.8187 - lr: 4.0000e-05\n",
      "Epoch 38/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.7512Epoch 10/40: loss=0.5087, accuracy=0.7512, val_loss=0.7018, val_accuracy=0.6639\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5087 - accuracy: 0.7512 - val_loss: 0.7018 - val_accuracy: 0.6639 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.7517Epoch 11/40: loss=0.5047, accuracy=0.7519, val_loss=0.4996, val_accuracy=0.7939\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5047 - accuracy: 0.7519 - val_loss: 0.4996 - val_accuracy: 0.7939 - lr: 2.5000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.7608Epoch 12/40: loss=0.5014, accuracy=0.7608, val_loss=0.4961, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5014 - accuracy: 0.7608 - val_loss: 0.4961 - val_accuracy: 0.7889 - lr: 2.5000e-04\n",
      "Epoch 13/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.7737Epoch 13/40: loss=0.4860, accuracy=0.7738, val_loss=0.8156, val_accuracy=0.6126\n",
      "604/604 [==============================] - 15s 24ms/step - loss: 0.4860 - accuracy: 0.7738 - val_loss: 0.8156 - val_accuracy: 0.6126 - lr: 2.5000e-04\n",
      "Epoch 14/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4929 - accuracy: 0.7577\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 14/40: loss=0.4930, accuracy=0.7575, val_loss=0.6939, val_accuracy=0.6093\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4930 - accuracy: 0.7575 - val_loss: 0.6939 - val_accuracy: 0.6093 - lr: 2.5000e-04\n",
      "Epoch 15/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.7866Epoch 15/40: loss=0.4664, accuracy=0.7866, val_loss=0.4067, val_accuracy=0.8295\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4664 - accuracy: 0.7866 - val_loss: 0.4067 - val_accuracy: 0.8295 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.7859Epoch 16/40: loss=0.4495, accuracy=0.7858, val_loss=0.3991, val_accuracy=0.8328\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4495 - accuracy: 0.7858 - val_loss: 0.3991 - val_accuracy: 0.8328 - lr: 5.0000e-05\n",
      "Epoch 17/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.8399 - accuracy: 0.5730Epoch 1/40: loss=0.8394, accuracy=0.5733, val_loss=0.5763, val_accuracy=0.7086\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.8394 - accuracy: 0.5733 - val_loss: 0.5763 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.6825Epoch 2/40: loss=0.6094, accuracy=0.6825, val_loss=2.6011, val_accuracy=0.4065\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.6094 - accuracy: 0.6825 - val_loss: 2.6011 - val_accuracy: 0.4065 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.6917Epoch 3/40: loss=0.5874, accuracy=0.6921, val_loss=0.4867, val_accuracy=0.7475\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5874 - accuracy: 0.6921 - val_loss: 0.4867 - val_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5731 - accuracy: 0.7100Epoch 4/40: loss=0.5728, accuracy=0.7103, val_loss=0.5850, val_accuracy=0.7533\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5728 - accuracy: 0.7103 - val_loss: 0.5850 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.7152Epoch 5/40: loss=0.5725, accuracy=0.7152, val_loss=0.5265, val_accuracy=0.7740\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5725 - accuracy: 0.7152 - val_loss: 0.5265 - val_accuracy: 0.7740 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7219Epoch 6/40: loss=0.5607, accuracy=0.7219, val_loss=0.8372, val_accuracy=0.5944\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5607 - accuracy: 0.7219 - val_loss: 0.8372 - val_accuracy: 0.5944 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7390Epoch 7/40: loss=0.5470, accuracy=0.7390, val_loss=0.9249, val_accuracy=0.5960\n",
      "604/604 [==============================] - 15s 25ms/step - loss: 0.5470 - accuracy: 0.7390 - val_loss: 0.9249 - val_accuracy: 0.5960 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.7365\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40: loss=0.5385, accuracy=0.7361, val_loss=0.5907, val_accuracy=0.7409\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5385 - accuracy: 0.7361 - val_loss: 0.5907 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5150 - accuracy: 0.7465Epoch 9/40: loss=0.5157, accuracy=0.7461, val_loss=0.4476, val_accuracy=0.8113\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5157 - accuracy: 0.7461 - val_loss: 0.4476 - val_accuracy: 0.8113 - lr: 2.0000e-04\n",
      "Epoch 10/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4987 - accuracy: 0.7649Epoch 10/40: loss=0.4991, accuracy=0.7649, val_loss=0.4360, val_accuracy=0.8096\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4991 - accuracy: 0.7649 - val_loss: 0.4360 - val_accuracy: 0.8096 - lr: 2.0000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.7697Epoch 11/40: loss=0.4900, accuracy=0.7699, val_loss=0.4901, val_accuracy=0.7649\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4900 - accuracy: 0.7699 - val_loss: 0.4901 - val_accuracy: 0.7649 - lr: 2.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.7716Epoch 12/40: loss=0.4913, accuracy=0.7711, val_loss=0.4593, val_accuracy=0.8079\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4913 - accuracy: 0.7711 - val_loss: 0.4593 - val_accuracy: 0.8079 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.7728Epoch 13/40: loss=0.4810, accuracy=0.7728, val_loss=0.4949, val_accuracy=0.8013\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.4810 - accuracy: 0.7728 - val_loss: 0.4949 - val_accuracy: 0.8013 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.7857Epoch 19/40: loss=0.4548, accuracy=0.7858, val_loss=0.5138, val_accuracy=0.7508\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4548 - accuracy: 0.7858 - val_loss: 0.5138 - val_accuracy: 0.7508 - lr: 2.0000e-04\n",
      "Epoch 20/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4527 - accuracy: 0.7937Epoch 20/40: loss=0.4526, accuracy=0.7939, val_loss=0.3942, val_accuracy=0.8171\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4526 - accuracy: 0.7939 - val_loss: 0.3942 - val_accuracy: 0.8171 - lr: 2.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4437 - accuracy: 0.7942Epoch 21/40: loss=0.4439, accuracy=0.7943, val_loss=0.4157, val_accuracy=0.8030\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4439 - accuracy: 0.7943 - val_loss: 0.4157 - val_accuracy: 0.8030 - lr: 2.0000e-04\n",
      "Epoch 22/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7918Epoch 22/40: loss=0.4565, accuracy=0.7918, val_loss=0.4522, val_accuracy=0.7906\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4565 - accuracy: 0.7918 - val_loss: 0.4522 - val_accuracy: 0.7906 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4354 - accuracy: 0.8002Epoch 23/40: loss=0.4360, accuracy=0.8003, val_loss=0.3926, val_accuracy=0.8386\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.3926 - val_accuracy: 0.8386 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8048Epoch 24/40: loss=0.4322, accuracy=0.8048, val_loss=0.5075, val_accuracy=0.7202\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4322 - accuracy: 0.8048 - val_loss: 0.5075 - val_accuracy: 0.7202 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8048Epoch 25/40: loss=0.4336, accuracy=0.8048, val_loss=0.4276, val_accuracy=0.8237\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4336 - accuracy: 0.8048 - val_loss: 0.4276 - val_accuracy: 0.8237 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4223 - accuracy: 0.8038Epoch 26/40: loss=0.4224, accuracy=0.8040, val_loss=0.4393, val_accuracy=0.7889\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4224 - accuracy: 0.8040 - val_loss: 0.4393 - val_accuracy: 0.7889 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8115Epoch 27/40: loss=0.4147, accuracy=0.8115, val_loss=0.5023, val_accuracy=0.7359\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4147 - accuracy: 0.8115 - val_loss: 0.5023 - val_accuracy: 0.7359 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.7790Epoch 16/40: loss=0.4681, accuracy=0.7790, val_loss=0.4167, val_accuracy=0.8237\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4681 - accuracy: 0.7790 - val_loss: 0.4167 - val_accuracy: 0.8237 - lr: 5.0000e-04\n",
      "Epoch 17/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4777 - accuracy: 0.7743Epoch 17/40: loss=0.4776, accuracy=0.7742, val_loss=0.4563, val_accuracy=0.8195\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.4776 - accuracy: 0.7742 - val_loss: 0.4563 - val_accuracy: 0.8195 - lr: 5.0000e-04\n",
      "Epoch 18/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.7857Epoch 18/40: loss=0.4684, accuracy=0.7856, val_loss=0.4618, val_accuracy=0.8344\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4684 - accuracy: 0.7856 - val_loss: 0.4618 - val_accuracy: 0.8344 - lr: 5.0000e-04\n",
      "Epoch 19/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.7876Epoch 19/40: loss=0.4584, accuracy=0.7881, val_loss=0.4010, val_accuracy=0.8146\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4584 - accuracy: 0.7881 - val_loss: 0.4010 - val_accuracy: 0.8146 - lr: 5.0000e-04\n",
      "Epoch 20/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.7899Epoch 20/40: loss=0.4574, accuracy=0.7899, val_loss=0.4992, val_accuracy=0.7425\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4574 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7425 - lr: 5.0000e-04\n",
      "Epoch 21/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.7879Epoch 21/40: loss=0.4514, accuracy=0.7881, val_loss=0.4143, val_accuracy=0.8137\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4514 - accuracy: 0.7881 - val_loss: 0.4143 - val_accuracy: 0.8137 - lr: 5.0000e-04\n",
      "Epoch 22/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8017Epoch 22/40: loss=0.4435, accuracy=0.8011, val_loss=0.8085, val_accuracy=0.6482\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4435 - accuracy: 0.8011 - val_loss: 0.8085 - val_accuracy: 0.6482 - lr: 5.0000e-04\n",
      "Epoch 23/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7933Epoch 23/40: loss=0.4502, accuracy=0.7933, val_loss=0.4285, val_accuracy=0.8245\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4502 - accuracy: 0.7933 - val_loss: 0.4285 - val_accuracy: 0.8245 - lr: 5.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.5199Epoch 1/40: loss=0.9150, accuracy=0.5199, val_loss=0.7072, val_accuracy=0.4818\n",
      "604/604 [==============================] - 13s 19ms/step - loss: 0.9150 - accuracy: 0.5199 - val_loss: 0.7072 - val_accuracy: 0.4818 - lr: 5.0000e-04\n",
      "Epoch 2/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.5170Epoch 2/40: loss=0.7801, accuracy=0.5168, val_loss=0.7218, val_accuracy=0.5886\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.7801 - accuracy: 0.5168 - val_loss: 0.7218 - val_accuracy: 0.5886 - lr: 5.0000e-04\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.5929Epoch 3/40: loss=0.6826, accuracy=0.5931, val_loss=0.9550, val_accuracy=0.6440\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.6826 - accuracy: 0.5931 - val_loss: 0.9550 - val_accuracy: 0.6440 - lr: 5.0000e-04\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6070 - accuracy: 0.6785Epoch 4/40: loss=0.6067, accuracy=0.6784, val_loss=0.7385, val_accuracy=0.7086\n",
      "604/604 [==============================] - 11s 19ms/step - loss: 0.6067 - accuracy: 0.6784 - val_loss: 0.7385 - val_accuracy: 0.7086 - lr: 5.0000e-04\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.7078Epoch 5/40: loss=0.5774, accuracy=0.7078, val_loss=0.7362, val_accuracy=0.7152\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5774 - accuracy: 0.7078 - val_loss: 0.7362 - val_accuracy: 0.7152 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5567 - accuracy: 0.7239\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/40: loss=0.5567, accuracy=0.7239, val_loss=1.6538, val_accuracy=0.4023\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5567 - accuracy: 0.7239 - val_loss: 1.6538 - val_accuracy: 0.4023 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.7425Epoch 7/40: loss=0.5324, accuracy=0.7428, val_loss=0.5564, val_accuracy=0.7392\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5324 - accuracy: 0.7428 - val_loss: 0.5564 - val_accuracy: 0.7392 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7413Epoch 8/40: loss=0.5326, accuracy=0.7413, val_loss=0.4998, val_accuracy=0.7740\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5326 - accuracy: 0.7413 - val_loss: 0.4998 - val_accuracy: 0.7740 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4365 - accuracy: 0.8002Epoch 25/40: loss=0.4367, accuracy=0.8001, val_loss=0.4659, val_accuracy=0.7930\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4367 - accuracy: 0.8001 - val_loss: 0.4659 - val_accuracy: 0.7930 - lr: 4.0000e-06\n",
      "Epoch 26/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8036Epoch 26/40: loss=0.4361, accuracy=0.8036, val_loss=0.4362, val_accuracy=0.8113\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4361 - accuracy: 0.8036 - val_loss: 0.4362 - val_accuracy: 0.8113 - lr: 4.0000e-06\n",
      "Epoch 27/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.7995\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 27/40: loss=0.4412, accuracy=0.7999, val_loss=0.4641, val_accuracy=0.7930\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4412 - accuracy: 0.7999 - val_loss: 0.4641 - val_accuracy: 0.7930 - lr: 4.0000e-06\n",
      "Epoch 27: early stopping\n",
      "Validation accuracy: 0.8211920261383057\n",
      "\n",
      "Refined Training Combination 48/50: num_residual_blocks=3, dropout_rate=0.19999999999999998, learning_rate=0.001, rotation_range=20, width_shift_range=0.30000000000000004, height_shift_range=0.1, shear_range=0.0, zoom_range=0.0, horizontal_flip=True\n",
      "Epoch 1/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.6327Epoch 1/40: loss=0.7603, accuracy=0.6327, val_loss=0.8252, val_accuracy=0.6449\n",
      "604/604 [==============================] - 14s 19ms/step - loss: 0.7603 - accuracy: 0.6327 - val_loss: 0.8252 - val_accuracy: 0.6449 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.6924Epoch 2/40: loss=0.6001, accuracy=0.6925, val_loss=0.6296, val_accuracy=0.7012\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.6001 - accuracy: 0.6925 - val_loss: 0.6296 - val_accuracy: 0.7012 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7160Epoch 3/40: loss=0.5681, accuracy=0.7161, val_loss=0.8796, val_accuracy=0.6457\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5681 - accuracy: 0.7161 - val_loss: 0.8796 - val_accuracy: 0.6457 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5705 - accuracy: 0.7094Epoch 4/40: loss=0.5703, accuracy=0.7094, val_loss=0.5185, val_accuracy=0.7575\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5703 - accuracy: 0.7094 - val_loss: 0.5185 - val_accuracy: 0.7575 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.7152Epoch 5/40: loss=0.5626, accuracy=0.7152, val_loss=0.6751, val_accuracy=0.6051\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5626 - accuracy: 0.7152 - val_loss: 0.6751 - val_accuracy: 0.6051 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7276Epoch 6/40: loss=0.5574, accuracy=0.7272, val_loss=0.4797, val_accuracy=0.7517\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.5574 - accuracy: 0.7272 - val_loss: 0.4797 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4445 - accuracy: 0.7973Epoch 23/40: loss=0.4446, accuracy=0.7970, val_loss=0.4103, val_accuracy=0.8162\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4446 - accuracy: 0.7970 - val_loss: 0.4103 - val_accuracy: 0.8162 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.7908Epoch 24/40: loss=0.4421, accuracy=0.7908, val_loss=0.4013, val_accuracy=0.8129\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4421 - accuracy: 0.7908 - val_loss: 0.4013 - val_accuracy: 0.8129 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.7899Epoch 25/40: loss=0.4555, accuracy=0.7904, val_loss=0.4223, val_accuracy=0.8137\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4555 - accuracy: 0.7904 - val_loss: 0.4223 - val_accuracy: 0.8137 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.7886Epoch 26/40: loss=0.4444, accuracy=0.7887, val_loss=0.4200, val_accuracy=0.8154\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4444 - accuracy: 0.7887 - val_loss: 0.4200 - val_accuracy: 0.8154 - lr: 2.0000e-04\n",
      "Epoch 27/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.7958Epoch 27/40: loss=0.4387, accuracy=0.7966, val_loss=0.3963, val_accuracy=0.8171\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4387 - accuracy: 0.7966 - val_loss: 0.3963 - val_accuracy: 0.8171 - lr: 2.0000e-04\n",
      "Epoch 28/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7923Epoch 28/40: loss=0.4421, accuracy=0.7926, val_loss=0.4729, val_accuracy=0.7781\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4421 - accuracy: 0.7926 - val_loss: 0.4729 - val_accuracy: 0.7781 - lr: 2.0000e-04\n",
      "Epoch 29/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.7968Epoch 29/40: loss=0.4395, accuracy=0.7968, val_loss=0.4032, val_accuracy=0.8104\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4395 - accuracy: 0.7968 - val_loss: 0.4032 - val_accuracy: 0.8104 - lr: 2.0000e-04\n",
      "Epoch 30/40\n",
      "601/604 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8016Epoch 30/40: loss=0.4322, accuracy=0.8013, val_loss=0.4374, val_accuracy=0.8038\n",
      "604/604 [==============================] - 10s 17ms/step - loss: 0.4322 - accuracy: 0.8013 - val_loss: 0.4374 - val_accuracy: 0.8038 - lr: 2.0000e-04\n",
      "Epoch 31/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8053Epoch 31/40: loss=0.4206, accuracy=0.8053, val_loss=0.3922, val_accuracy=0.8278\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4206 - accuracy: 0.8053 - val_loss: 0.3922 - val_accuracy: 0.8278 - lr: 2.0000e-04\n",
      "Epoch 32/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.7452Epoch 7/40: loss=0.5244, accuracy=0.7457, val_loss=0.7621, val_accuracy=0.6680\n",
      "604/604 [==============================] - 14s 24ms/step - loss: 0.5244 - accuracy: 0.7457 - val_loss: 0.7621 - val_accuracy: 0.6680 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.7498Epoch 8/40: loss=0.5212, accuracy=0.7496, val_loss=0.7876, val_accuracy=0.6730\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5212 - accuracy: 0.7496 - val_loss: 0.7876 - val_accuracy: 0.6730 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.7504Epoch 9/40: loss=0.5199, accuracy=0.7506, val_loss=0.5799, val_accuracy=0.6490\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5199 - accuracy: 0.7506 - val_loss: 0.5799 - val_accuracy: 0.6490 - lr: 5.0000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.7575Epoch 10/40: loss=0.5144, accuracy=0.7575, val_loss=0.4655, val_accuracy=0.7823\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5144 - accuracy: 0.7575 - val_loss: 0.4655 - val_accuracy: 0.7823 - lr: 5.0000e-04\n",
      "Epoch 11/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.7583Epoch 11/40: loss=0.5136, accuracy=0.7583, val_loss=0.5892, val_accuracy=0.7533\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.5136 - accuracy: 0.7583 - val_loss: 0.5892 - val_accuracy: 0.7533 - lr: 5.0000e-04\n",
      "Epoch 12/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.7527Epoch 12/40: loss=0.5055, accuracy=0.7531, val_loss=0.5195, val_accuracy=0.7285\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5055 - accuracy: 0.7531 - val_loss: 0.5195 - val_accuracy: 0.7285 - lr: 5.0000e-04\n",
      "Epoch 13/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7748Epoch 13/40: loss=0.4929, accuracy=0.7748, val_loss=0.6439, val_accuracy=0.7268\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4929 - accuracy: 0.7748 - val_loss: 0.6439 - val_accuracy: 0.7268 - lr: 5.0000e-04\n",
      "Epoch 14/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3980 - accuracy: 0.8265Epoch 28/40: loss=0.3979, accuracy=0.8264, val_loss=0.3583, val_accuracy=0.8419\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.3583 - val_accuracy: 0.8419 - lr: 2.0000e-05\n",
      "Epoch 29/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8317Epoch 29/40: loss=0.3807, accuracy=0.8317, val_loss=0.3600, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3807 - accuracy: 0.8317 - val_loss: 0.3600 - val_accuracy: 0.8485 - lr: 2.0000e-05\n",
      "Epoch 30/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8317Epoch 30/40: loss=0.3827, accuracy=0.8317, val_loss=0.3610, val_accuracy=0.8411\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3827 - accuracy: 0.8317 - val_loss: 0.3610 - val_accuracy: 0.8411 - lr: 2.0000e-05\n",
      "Epoch 31/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8375Epoch 31/40: loss=0.3731, accuracy=0.8375, val_loss=0.3530, val_accuracy=0.8444\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.3731 - accuracy: 0.8375 - val_loss: 0.3530 - val_accuracy: 0.8444 - lr: 2.0000e-05\n",
      "Epoch 32/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8317Epoch 32/40: loss=0.3737, accuracy=0.8317, val_loss=0.3577, val_accuracy=0.8353\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3737 - accuracy: 0.8317 - val_loss: 0.3577 - val_accuracy: 0.8353 - lr: 2.0000e-05\n",
      "Epoch 33/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8365Epoch 33/40: loss=0.3728, accuracy=0.8365, val_loss=0.3572, val_accuracy=0.8419\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3728 - accuracy: 0.8365 - val_loss: 0.3572 - val_accuracy: 0.8419 - lr: 2.0000e-05\n",
      "Epoch 34/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.8425Epoch 34/40: loss=0.3619, accuracy=0.8421, val_loss=0.3477, val_accuracy=0.8435\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3619 - accuracy: 0.8421 - val_loss: 0.3477 - val_accuracy: 0.8435 - lr: 2.0000e-05\n",
      "Epoch 35/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.7303Epoch 8/40: loss=0.5386, accuracy=0.7305, val_loss=0.5520, val_accuracy=0.7045\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5386 - accuracy: 0.7305 - val_loss: 0.5520 - val_accuracy: 0.7045 - lr: 2.5000e-04\n",
      "Epoch 9/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7413Epoch 9/40: loss=0.5250, accuracy=0.7413, val_loss=0.4893, val_accuracy=0.7674\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.5250 - accuracy: 0.7413 - val_loss: 0.4893 - val_accuracy: 0.7674 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.7606Epoch 10/40: loss=0.5213, accuracy=0.7606, val_loss=0.4754, val_accuracy=0.7368\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5213 - accuracy: 0.7606 - val_loss: 0.4754 - val_accuracy: 0.7368 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5268 - accuracy: 0.7519\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 11/40: loss=0.5266, accuracy=0.7519, val_loss=0.4938, val_accuracy=0.7939\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5266 - accuracy: 0.7519 - val_loss: 0.4938 - val_accuracy: 0.7939 - lr: 2.5000e-04\n",
      "Epoch 12/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7612Epoch 12/40: loss=0.4899, accuracy=0.7612, val_loss=0.4330, val_accuracy=0.8121\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4899 - accuracy: 0.7612 - val_loss: 0.4330 - val_accuracy: 0.8121 - lr: 5.0000e-05\n",
      "Epoch 13/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.7761Epoch 13/40: loss=0.4755, accuracy=0.7765, val_loss=0.4298, val_accuracy=0.8245\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4755 - accuracy: 0.7765 - val_loss: 0.4298 - val_accuracy: 0.8245 - lr: 5.0000e-05\n",
      "Epoch 14/40\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.7800Epoch 14/40: loss=0.4773, accuracy=0.7800, val_loss=0.4510, val_accuracy=0.8270\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4773 - accuracy: 0.7800 - val_loss: 0.4510 - val_accuracy: 0.8270 - lr: 5.0000e-05\n",
      "Epoch 15/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.7788Epoch 15/40: loss=0.4670, accuracy=0.7788, val_loss=0.4146, val_accuracy=0.8146\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4670 - accuracy: 0.7788 - val_loss: 0.4146 - val_accuracy: 0.8146 - lr: 5.0000e-05\n",
      "Epoch 16/40\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8099Epoch 29/40: loss=0.4178, accuracy=0.8096, val_loss=0.4257, val_accuracy=0.7980\n",
      "604/604 [==============================] - 11s 18ms/step - loss: 0.4178 - accuracy: 0.8096 - val_loss: 0.4257 - val_accuracy: 0.7980 - lr: 2.0000e-06\n",
      "Epoch 30/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8073Epoch 30/40: loss=0.4225, accuracy=0.8073, val_loss=0.4280, val_accuracy=0.7947\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4225 - accuracy: 0.8073 - val_loss: 0.4280 - val_accuracy: 0.7947 - lr: 2.0000e-06\n",
      "Epoch 31/40\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8108\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.000000444648322e-07.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 31/40: loss=0.4221, accuracy=0.8113, val_loss=0.4191, val_accuracy=0.8055\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4221 - accuracy: 0.8113 - val_loss: 0.4191 - val_accuracy: 0.8055 - lr: 2.0000e-06\n",
      "Epoch 31: early stopping\n",
      "Validation accuracy: 0.8269867300987244\n",
      "\n",
      "Refined best parameters found: num_residual_blocks=5, dropout_rate=0.19999999999999998, learning_rate=0.001, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
      "Refined best validation accuracy: 0.8741722106933594\n",
      "Epoch 1/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.6161Epoch 1/50: loss=0.7735, accuracy=0.6161, val_loss=1.7054, val_accuracy=0.4015\n",
      "604/604 [==============================] - 15s 21ms/step - loss: 0.7735 - accuracy: 0.6161 - val_loss: 1.7054 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.6995Epoch 2/50: loss=0.5903, accuracy=0.6995, val_loss=0.7325, val_accuracy=0.6440\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5903 - accuracy: 0.6995 - val_loss: 0.7325 - val_accuracy: 0.6440 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7171Epoch 3/50: loss=0.5653, accuracy=0.7171, val_loss=0.5666, val_accuracy=0.6714\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5653 - accuracy: 0.7171 - val_loss: 0.5666 - val_accuracy: 0.6714 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7225Epoch 4/50: loss=0.5690, accuracy=0.7225, val_loss=1.0071, val_accuracy=0.4329\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.5690 - accuracy: 0.7225 - val_loss: 1.0071 - val_accuracy: 0.4329 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.7361Epoch 5/50: loss=0.5454, accuracy=0.7361, val_loss=0.7427, val_accuracy=0.6217\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.5454 - accuracy: 0.7361 - val_loss: 0.7427 - val_accuracy: 0.6217 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7485Epoch 6/50: loss=0.5401, accuracy=0.7490, val_loss=0.5419, val_accuracy=0.7392\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.5401 - accuracy: 0.7490 - val_loss: 0.5419 - val_accuracy: 0.7392 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8153Epoch 24/50: loss=0.4185, accuracy=0.8154, val_loss=0.3680, val_accuracy=0.8493\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.4185 - accuracy: 0.8154 - val_loss: 0.3680 - val_accuracy: 0.8493 - lr: 4.0000e-05\n",
      "Epoch 25/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8214Epoch 25/50: loss=0.4007, accuracy=0.8214, val_loss=0.3636, val_accuracy=0.8493\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4007 - accuracy: 0.8214 - val_loss: 0.3636 - val_accuracy: 0.8493 - lr: 4.0000e-05\n",
      "Epoch 26/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.8082Epoch 26/50: loss=0.4127, accuracy=0.8082, val_loss=0.3753, val_accuracy=0.8452\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4127 - accuracy: 0.8082 - val_loss: 0.3753 - val_accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 27/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.8204Epoch 27/50: loss=0.4004, accuracy=0.8206, val_loss=0.3699, val_accuracy=0.8460\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4004 - accuracy: 0.8206 - val_loss: 0.3699 - val_accuracy: 0.8460 - lr: 4.0000e-05\n",
      "Epoch 28/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.8150Epoch 28/50: loss=0.4075, accuracy=0.8142, val_loss=0.3512, val_accuracy=0.8469\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4075 - accuracy: 0.8142 - val_loss: 0.3512 - val_accuracy: 0.8469 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8185Epoch 29/50: loss=0.4068, accuracy=0.8185, val_loss=0.3587, val_accuracy=0.8551\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4068 - accuracy: 0.8185 - val_loss: 0.3587 - val_accuracy: 0.8551 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.8079Epoch 30/50: loss=0.4159, accuracy=0.8079, val_loss=0.3796, val_accuracy=0.8477\n",
      "604/604 [==============================] - 13s 21ms/step - loss: 0.4159 - accuracy: 0.8079 - val_loss: 0.3796 - val_accuracy: 0.8477 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4005 - accuracy: 0.8197Epoch 31/50: loss=0.4009, accuracy=0.8195, val_loss=0.3559, val_accuracy=0.8518\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4009 - accuracy: 0.8195 - val_loss: 0.3559 - val_accuracy: 0.8518 - lr: 4.0000e-05\n",
      "Epoch 32/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4143 - accuracy: 0.8100Epoch 32/50: loss=0.4143, accuracy=0.8098, val_loss=0.3527, val_accuracy=0.8485\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4143 - accuracy: 0.8098 - val_loss: 0.3527 - val_accuracy: 0.8485 - lr: 4.0000e-05\n",
      "Epoch 33/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8286Epoch 45/50: loss=0.3822, accuracy=0.8284, val_loss=0.3459, val_accuracy=0.8485\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3822 - accuracy: 0.8284 - val_loss: 0.3459 - val_accuracy: 0.8485 - lr: 8.0000e-06\n",
      "Epoch 46/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8299Epoch 46/50: loss=0.3776, accuracy=0.8303, val_loss=0.3383, val_accuracy=0.8518\n",
      "604/604 [==============================] - 13s 22ms/step - loss: 0.3776 - accuracy: 0.8303 - val_loss: 0.3383 - val_accuracy: 0.8518 - lr: 8.0000e-06\n",
      "Epoch 47/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8275Epoch 47/50: loss=0.3872, accuracy=0.8278, val_loss=0.3388, val_accuracy=0.8526\n",
      "604/604 [==============================] - 14s 22ms/step - loss: 0.3872 - accuracy: 0.8278 - val_loss: 0.3388 - val_accuracy: 0.8526 - lr: 8.0000e-06\n",
      "Epoch 48/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8305Epoch 48/50: loss=0.3746, accuracy=0.8305, val_loss=0.3361, val_accuracy=0.8551\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3746 - accuracy: 0.8305 - val_loss: 0.3361 - val_accuracy: 0.8551 - lr: 8.0000e-06\n",
      "Epoch 49/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8298Epoch 49/50: loss=0.3878, accuracy=0.8299, val_loss=0.3397, val_accuracy=0.8560\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3878 - accuracy: 0.8299 - val_loss: 0.3397 - val_accuracy: 0.8560 - lr: 8.0000e-06\n",
      "Epoch 50/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3685 - accuracy: 0.8355Epoch 50/50: loss=0.3683, accuracy=0.8359, val_loss=0.3366, val_accuracy=0.8535\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3683 - accuracy: 0.8359 - val_loss: 0.3366 - val_accuracy: 0.8535 - lr: 8.0000e-06\n",
      "38/38 [==============================] - 1s 5ms/step\n",
      "Confusion Matrix:\n",
      "[[623 101]\n",
      " [ 76 408]]\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Healthy_augmented       0.89      0.86      0.88       724\n",
      "Damaged_augmented       0.80      0.84      0.82       484\n",
      "\n",
      "         accuracy                           0.85      1208\n",
      "        macro avg       0.85      0.85      0.85      1208\n",
      "     weighted avg       0.86      0.85      0.85      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from itertools import product\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\\\\\Desktop\\\\Thesis Thanasis\\\\data_aug_3'\n",
    "subfolders = ['clear', 'clouds']\n",
    "categories = ['Healthy_augmented', 'Damaged_augmented']\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def load_data(base_dir, subfolders, categories, img_height, img_width):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        class_num = categories.index(category)\n",
    "        clear_path = os.path.join(base_dir, subfolders[0], category)\n",
    "        clouds_path = os.path.join(base_dir, subfolders[1], category)\n",
    "        clear_images = sorted(os.listdir(clear_path))\n",
    "        clouds_images = sorted(os.listdir(clouds_path))\n",
    "        \n",
    "        for clear_img_name, clouds_img_name in zip(clear_images, clouds_images):\n",
    "            if clear_img_name.endswith('.png') and clouds_img_name.endswith('.png'):\n",
    "                clear_img_path = os.path.join(clear_path, clear_img_name)\n",
    "                clouds_img_path = os.path.join(clouds_path, clouds_img_name)\n",
    "                \n",
    "                clear_img = tf.keras.preprocessing.image.load_img(clear_img_path, target_size=(img_height, img_width))\n",
    "                clouds_img = tf.keras.preprocessing.image.load_img(clouds_img_path, target_size=(img_height, img_width))\n",
    "                \n",
    "                clear_img_array = tf.keras.preprocessing.image.img_to_array(clear_img)\n",
    "                clouds_img_array = tf.keras.preprocessing.image.img_to_array(clouds_img)\n",
    "                \n",
    "                combined_img = np.concatenate((clear_img_array, clouds_img_array), axis=-1)\n",
    "                \n",
    "                data.append(combined_img)\n",
    "                labels.append(class_num)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "data, labels = load_data(base_dir, subfolders, categories, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Normalize the images\n",
    "data = data / 255.0\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae94da-37c1-4bbd-b36c-859a13ccc1d8",
   "metadata": {},
   "source": [
    "# Finding the best combination of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e579c-62ef-4a72-9cc9-ecbbbd68a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation\n",
    "def create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip):\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=rotation_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1, 1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate):\n",
    "    # Input layer for combined images\n",
    "    combined_input = Input(shape=(input_shape[1], input_shape[2], input_shape[3]), name='combined_input')\n",
    "    \n",
    "    # Convolutional base\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(combined_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, 64)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# Grid search parameters\n",
    "num_residual_blocks_options = [1, 2, 3, 4, 5]\n",
    "dropout_rate_options = [0.3, 0.4, 0.5, 0.6]\n",
    "learning_rate_options = [1e-2, 1e-3, 5e-4, 1e-4]\n",
    "rotation_range_options = [10, 20, 30]\n",
    "width_shift_range_options = [0.1, 0.2, 0.3]\n",
    "height_shift_range_options = [0.1, 0.2, 0.3]\n",
    "shear_range_options = [0.1, 0.2, 0.3]\n",
    "zoom_range_options = [0.1, 0.2, 0.3]\n",
    "horizontal_flip_options = [True, False]\n",
    "\n",
    "# Create grid search parameter combinations\n",
    "parameter_combinations = list(product(num_residual_blocks_options, dropout_rate_options, learning_rate_options,\n",
    "                                      rotation_range_options, width_shift_range_options, height_shift_range_options,\n",
    "                                      shear_range_options, zoom_range_options, horizontal_flip_options))\n",
    "\n",
    "# Select 50 unique combinations\n",
    "np.random.seed(42)\n",
    "selected_combinations = np.random.choice(len(parameter_combinations), 50, replace=False)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Callbacks for training\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Custom callback to print epoch details\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']}: loss={logs['loss']:.4f}, accuracy={logs['accuracy']:.4f}, val_loss={logs['val_loss']:.4f}, val_accuracy={logs['val_accuracy']:.4f}\")\n",
    "\n",
    "# Perform grid search\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for idx, combination_idx in enumerate(selected_combinations):\n",
    "    num_residual_blocks, dropout_rate, learning_rate, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip = parameter_combinations[combination_idx]\n",
    "    print(f\"\\nInitial Training Combination {idx + 1}/50: num_residual_blocks={num_residual_blocks}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, rotation_range={rotation_range}, width_shift_range={width_shift_range}, height_shift_range={height_shift_range}, shear_range={shear_range}, zoom_range={zoom_range}, horizontal_flip={horizontal_flip}\")\n",
    "    \n",
    "    datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "    datagen.fit(X_train)\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "            epochs=40,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = (num_residual_blocks, dropout_rate, learning_rate, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "\n",
    "print(f\"\\nBest parameters found in initial grid search: num_residual_blocks={best_params[0]}, dropout_rate={best_params[1]}, learning_rate={best_params[2]}, rotation_range={best_params[3]}, width_shift_range={best_params[4]}, height_shift_range={best_params[5]}, shear_range={best_params[6]}, zoom_range={best_params[7]}, horizontal_flip={best_params[8]}\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
    "\n",
    "# Refine grid search around best parameters\n",
    "refined_num_residual_blocks_options = [best_params[0] - 1, best_params[0], best_params[0] + 1]\n",
    "refined_dropout_rate_options = [max(0.0, best_params[1] - 0.1), best_params[1], min(1.0, best_params[1] + 0.1)]\n",
    "refined_learning_rate_options = [best_params[2] * 0.5, best_params[2], best_params[2] * 2]\n",
    "refined_rotation_range_options = [max(0, best_params[3] - 10), best_params[3], best_params[3] + 10]\n",
    "refined_width_shift_range_options = [max(0.0, best_params[4] - 0.1), best_params[4], min(1.0, best_params[4] + 0.1)]\n",
    "refined_height_shift_range_options = [max(0.0, best_params[5] - 0.1), best_params[5], min(1.0, best_params[5] + 0.1)]\n",
    "refined_shear_range_options = [max(0.0, best_params[6] - 0.1), best_params[6], min(1.0, best_params[6] + 0.1)]\n",
    "refined_zoom_range_options = [max(0.0, best_params[7] - 0.1), best_params[7], min(1.0, best_params[7] + 0.1)]\n",
    "refined_horizontal_flip_options = [best_params[8]]\n",
    "\n",
    "refined_parameter_combinations = list(product(refined_num_residual_blocks_options, refined_dropout_rate_options, refined_learning_rate_options,\n",
    "                                              refined_rotation_range_options, refined_width_shift_range_options, refined_height_shift_range_options,\n",
    "                                              refined_shear_range_options, refined_zoom_range_options, refined_horizontal_flip_options))\n",
    "\n",
    "# Select 50 unique combinations for refined search\n",
    "np.random.seed(42)\n",
    "selected_refined_combinations = np.random.choice(len(refined_parameter_combinations), 50, replace=False)\n",
    "\n",
    "# Perform refined grid search\n",
    "best_val_accuracy_refined = 0\n",
    "best_params_refined = None\n",
    "\n",
    "for idx, combination_idx in enumerate(selected_refined_combinations):\n",
    "    num_residual_blocks, dropout_rate, learning_rate, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip = refined_parameter_combinations[combination_idx]\n",
    "    print(f\"\\nRefined Training Combination {idx + 1}/50: num_residual_blocks={num_residual_blocks}, dropout_rate={dropout_rate}, learning_rate={learning_rate}, rotation_range={rotation_range}, width_shift_range={width_shift_range}, height_shift_range={height_shift_range}, shear_range={shear_range}, zoom_range={zoom_range}, horizontal_flip={horizontal_flip}\")\n",
    "    \n",
    "    datagen = create_datagen(rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "    datagen.fit(X_train)\n",
    "    train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = build_complex_model(input_shape, num_residual_blocks, dropout_rate, learning_rate)\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "            epochs=40,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy_refined:\n",
    "        best_val_accuracy_refined = val_accuracy\n",
    "        best_params_refined = (num_residual_blocks, dropout_rate, learning_rate, rotation_range, width_shift_range, height_shift_range, shear_range, zoom_range, horizontal_flip)\n",
    "\n",
    "print(f\"\\nRefined best parameters found: num_residual_blocks={best_params_refined[0]}, dropout_rate={best_params_refined[1]}, learning_rate={best_params_refined[2]}, rotation_range={best_params_refined[3]}, width_shift_range={best_params_refined[4]}, height_shift_range={best_params_refined[5]}, shear_range={best_params_refined[6]}, zoom_range={best_params_refined[7]}, horizontal_flip={best_params_refined[8]}\")\n",
    "print(f\"Refined best validation accuracy: {best_val_accuracy_refined}\")\n",
    "\n",
    "# Train the final model with the refined best parameters found\n",
    "final_model = build_complex_model(input_shape, best_params_refined[0], best_params_refined[1], best_params_refined[2])\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    final_history = final_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Make predictions\n",
    "with tf.device('/GPU:0'):\n",
    "    val_predictions = final_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_val_true, y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d279d1-f936-4fdc-8a6a-5269b80f00ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0233777a-9d19-479d-8aa2-9dd3b8a818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params_refined = (5, 0.19999999999999998, 0.001, 40, 0.1, 0.1, 0.2, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce52832-3178-4253-b8a8-ae6756c79982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0.19999999999999998, 0.001, 40, 0.1, 0.1, 0.2, 0.2, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9377826f-eccd-4417-b214-d0d4fd28a157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741722106933594"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_accuracy_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1d4f5-59ca-4a16-ba33-2da408cc3063",
   "metadata": {},
   "source": [
    "# Re-training the best model (NOT REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56137a9-cecd-4767-b3f2-8192360c83f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:2094: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n",
      "C:\\Users\\NickZografos\\anaconda3\\envs\\thesis\\lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4832, 64, 64, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.7992 - accuracy: 0.6026Epoch 1/50: loss=0.7987, accuracy=0.6026, val_loss=0.8140, val_accuracy=0.6581\n",
      "604/604 [==============================] - 14s 20ms/step - loss: 0.7987 - accuracy: 0.6026 - val_loss: 0.8140 - val_accuracy: 0.6581 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7059Epoch 2/50: loss=0.5945, accuracy=0.7059, val_loss=0.7182, val_accuracy=0.6010\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5945 - accuracy: 0.7059 - val_loss: 0.7182 - val_accuracy: 0.6010 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7363Epoch 3/50: loss=0.5505, accuracy=0.7363, val_loss=0.5268, val_accuracy=0.7334\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5505 - accuracy: 0.7363 - val_loss: 0.5268 - val_accuracy: 0.7334 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.7355Epoch 4/50: loss=0.5537, accuracy=0.7355, val_loss=0.5170, val_accuracy=0.7732\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5537 - accuracy: 0.7355 - val_loss: 0.5170 - val_accuracy: 0.7732 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.7457Epoch 5/50: loss=0.5472, accuracy=0.7457, val_loss=0.5730, val_accuracy=0.7028\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5472 - accuracy: 0.7457 - val_loss: 0.5730 - val_accuracy: 0.7028 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7363Epoch 6/50: loss=0.5432, accuracy=0.7363, val_loss=0.6746, val_accuracy=0.6225\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5432 - accuracy: 0.7363 - val_loss: 0.6746 - val_accuracy: 0.6225 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7527Epoch 7/50: loss=0.5326, accuracy=0.7527, val_loss=0.6757, val_accuracy=0.5621\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5326 - accuracy: 0.7527 - val_loss: 0.6757 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.7568Epoch 8/50: loss=0.5231, accuracy=0.7568, val_loss=0.5262, val_accuracy=0.7922\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5231 - accuracy: 0.7568 - val_loss: 0.5262 - val_accuracy: 0.7922 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.5261 - accuracy: 0.7506\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 9/50: loss=0.5254, accuracy=0.7510, val_loss=0.5690, val_accuracy=0.7177\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.5254 - accuracy: 0.7510 - val_loss: 0.5690 - val_accuracy: 0.7177 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7775Epoch 10/50: loss=0.4922, accuracy=0.7775, val_loss=0.4119, val_accuracy=0.8262\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4922 - accuracy: 0.7775 - val_loss: 0.4119 - val_accuracy: 0.8262 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7844Epoch 11/50: loss=0.4846, accuracy=0.7844, val_loss=0.4466, val_accuracy=0.8071\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4846 - accuracy: 0.7844 - val_loss: 0.4466 - val_accuracy: 0.8071 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.7838Epoch 12/50: loss=0.4740, accuracy=0.7839, val_loss=0.4487, val_accuracy=0.7856\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4740 - accuracy: 0.7839 - val_loss: 0.4487 - val_accuracy: 0.7856 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.7881Epoch 13/50: loss=0.4598, accuracy=0.7881, val_loss=0.3949, val_accuracy=0.8270\n",
      "604/604 [==============================] - 12s 19ms/step - loss: 0.4598 - accuracy: 0.7881 - val_loss: 0.3949 - val_accuracy: 0.8270 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7871Epoch 14/50: loss=0.4688, accuracy=0.7873, val_loss=0.4909, val_accuracy=0.7599\n",
      "604/604 [==============================] - 14s 23ms/step - loss: 0.4688 - accuracy: 0.7873 - val_loss: 0.4909 - val_accuracy: 0.7599 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.7888Epoch 15/50: loss=0.4612, accuracy=0.7891, val_loss=0.4158, val_accuracy=0.8228\n",
      "604/604 [==============================] - 12s 21ms/step - loss: 0.4612 - accuracy: 0.7891 - val_loss: 0.4158 - val_accuracy: 0.8228 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4433 - accuracy: 0.8012Epoch 16/50: loss=0.4436, accuracy=0.8009, val_loss=0.3917, val_accuracy=0.8220\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4436 - accuracy: 0.8009 - val_loss: 0.3917 - val_accuracy: 0.8220 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.4533 - accuracy: 0.7872Epoch 17/50: loss=0.4533, accuracy=0.7866, val_loss=0.4470, val_accuracy=0.8320\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4533 - accuracy: 0.7866 - val_loss: 0.4470 - val_accuracy: 0.8320 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8024Epoch 18/50: loss=0.4408, accuracy=0.8024, val_loss=0.4277, val_accuracy=0.8204\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4408 - accuracy: 0.8024 - val_loss: 0.4277 - val_accuracy: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4259 - accuracy: 0.8114Epoch 19/50: loss=0.4256, accuracy=0.8115, val_loss=0.3960, val_accuracy=0.8253\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4256 - accuracy: 0.8115 - val_loss: 0.3960 - val_accuracy: 0.8253 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4354 - accuracy: 0.8002Epoch 20/50: loss=0.4351, accuracy=0.8003, val_loss=0.3740, val_accuracy=0.8402\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.3740 - val_accuracy: 0.8402 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.8037Epoch 21/50: loss=0.4269, accuracy=0.8038, val_loss=0.4317, val_accuracy=0.8245\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.4317 - val_accuracy: 0.8245 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8043Epoch 22/50: loss=0.4361, accuracy=0.8040, val_loss=0.4674, val_accuracy=0.7889\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4361 - accuracy: 0.8040 - val_loss: 0.4674 - val_accuracy: 0.7889 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.8029Epoch 23/50: loss=0.4344, accuracy=0.8026, val_loss=0.3819, val_accuracy=0.8394\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4344 - accuracy: 0.8026 - val_loss: 0.3819 - val_accuracy: 0.8394 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8012Epoch 24/50: loss=0.4296, accuracy=0.8013, val_loss=0.5703, val_accuracy=0.7136\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4296 - accuracy: 0.8013 - val_loss: 0.5703 - val_accuracy: 0.7136 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.8074\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/50: loss=0.4248, accuracy=0.8071, val_loss=0.3787, val_accuracy=0.8402\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.4248 - accuracy: 0.8071 - val_loss: 0.3787 - val_accuracy: 0.8402 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8222Epoch 26/50: loss=0.3906, accuracy=0.8222, val_loss=0.3556, val_accuracy=0.8576\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3906 - accuracy: 0.8222 - val_loss: 0.3556 - val_accuracy: 0.8576 - lr: 4.0000e-05\n",
      "Epoch 27/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8332Epoch 27/50: loss=0.3823, accuracy=0.8332, val_loss=0.3664, val_accuracy=0.8460\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3823 - accuracy: 0.8332 - val_loss: 0.3664 - val_accuracy: 0.8460 - lr: 4.0000e-05\n",
      "Epoch 28/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8263Epoch 28/50: loss=0.3877, accuracy=0.8264, val_loss=0.3519, val_accuracy=0.8510\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3877 - accuracy: 0.8264 - val_loss: 0.3519 - val_accuracy: 0.8510 - lr: 4.0000e-05\n",
      "Epoch 29/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8224Epoch 29/50: loss=0.3872, accuracy=0.8224, val_loss=0.3566, val_accuracy=0.8560\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3872 - accuracy: 0.8224 - val_loss: 0.3566 - val_accuracy: 0.8560 - lr: 4.0000e-05\n",
      "Epoch 30/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8259Epoch 30/50: loss=0.3824, accuracy=0.8260, val_loss=0.3660, val_accuracy=0.8510\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3824 - accuracy: 0.8260 - val_loss: 0.3660 - val_accuracy: 0.8510 - lr: 4.0000e-05\n",
      "Epoch 31/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8266Epoch 31/50: loss=0.3800, accuracy=0.8266, val_loss=0.3687, val_accuracy=0.8510\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3800 - accuracy: 0.8266 - val_loss: 0.3687 - val_accuracy: 0.8510 - lr: 4.0000e-05\n",
      "Epoch 32/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8349Epoch 32/50: loss=0.3642, accuracy=0.8349, val_loss=0.3601, val_accuracy=0.8369\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3642 - accuracy: 0.8349 - val_loss: 0.3601 - val_accuracy: 0.8369 - lr: 4.0000e-05\n",
      "Epoch 33/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3690 - accuracy: 0.8354\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 33/50: loss=0.3689, accuracy=0.8355, val_loss=0.3522, val_accuracy=0.8609\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3689 - accuracy: 0.8355 - val_loss: 0.3522 - val_accuracy: 0.8609 - lr: 4.0000e-05\n",
      "Epoch 34/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8295Epoch 34/50: loss=0.3822, accuracy=0.8295, val_loss=0.3437, val_accuracy=0.8568\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3822 - accuracy: 0.8295 - val_loss: 0.3437 - val_accuracy: 0.8568 - lr: 8.0000e-06\n",
      "Epoch 35/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8421Epoch 35/50: loss=0.3645, accuracy=0.8421, val_loss=0.3500, val_accuracy=0.8584\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3645 - accuracy: 0.8421 - val_loss: 0.3500 - val_accuracy: 0.8584 - lr: 8.0000e-06\n",
      "Epoch 36/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3729 - accuracy: 0.8362Epoch 36/50: loss=0.3730, accuracy=0.8359, val_loss=0.3469, val_accuracy=0.8560\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3730 - accuracy: 0.8359 - val_loss: 0.3469 - val_accuracy: 0.8560 - lr: 8.0000e-06\n",
      "Epoch 37/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8261Epoch 37/50: loss=0.3816, accuracy=0.8262, val_loss=0.3481, val_accuracy=0.8593\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3816 - accuracy: 0.8262 - val_loss: 0.3481 - val_accuracy: 0.8593 - lr: 8.0000e-06\n",
      "Epoch 38/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3666 - accuracy: 0.8362Epoch 38/50: loss=0.3663, accuracy=0.8363, val_loss=0.3480, val_accuracy=0.8593\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3663 - accuracy: 0.8363 - val_loss: 0.3480 - val_accuracy: 0.8593 - lr: 8.0000e-06\n",
      "Epoch 39/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3646 - accuracy: 0.8380\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 39/50: loss=0.3643, accuracy=0.8384, val_loss=0.3460, val_accuracy=0.8576\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3643 - accuracy: 0.8384 - val_loss: 0.3460 - val_accuracy: 0.8576 - lr: 8.0000e-06\n",
      "Epoch 40/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8478Epoch 40/50: loss=0.3492, accuracy=0.8481, val_loss=0.3444, val_accuracy=0.8568\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3492 - accuracy: 0.8481 - val_loss: 0.3444 - val_accuracy: 0.8568 - lr: 1.6000e-06\n",
      "Epoch 41/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3663 - accuracy: 0.8350Epoch 41/50: loss=0.3659, accuracy=0.8353, val_loss=0.3435, val_accuracy=0.8568\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3659 - accuracy: 0.8353 - val_loss: 0.3435 - val_accuracy: 0.8568 - lr: 1.6000e-06\n",
      "Epoch 42/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8328Epoch 42/50: loss=0.3792, accuracy=0.8334, val_loss=0.3444, val_accuracy=0.8584\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3792 - accuracy: 0.8334 - val_loss: 0.3444 - val_accuracy: 0.8584 - lr: 1.6000e-06\n",
      "Epoch 43/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8367Epoch 43/50: loss=0.3700, accuracy=0.8367, val_loss=0.3454, val_accuracy=0.8576\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3700 - accuracy: 0.8367 - val_loss: 0.3454 - val_accuracy: 0.8576 - lr: 1.6000e-06\n",
      "Epoch 44/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8410Epoch 44/50: loss=0.3666, accuracy=0.8411, val_loss=0.3416, val_accuracy=0.8551\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3666 - accuracy: 0.8411 - val_loss: 0.3416 - val_accuracy: 0.8551 - lr: 1.6000e-06\n",
      "Epoch 45/50\n",
      "604/604 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8369Epoch 45/50: loss=0.3690, accuracy=0.8369, val_loss=0.3449, val_accuracy=0.8593\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3690 - accuracy: 0.8369 - val_loss: 0.3449 - val_accuracy: 0.8593 - lr: 1.6000e-06\n",
      "Epoch 46/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.8396Epoch 46/50: loss=0.3599, accuracy=0.8398, val_loss=0.3465, val_accuracy=0.8576\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3599 - accuracy: 0.8398 - val_loss: 0.3465 - val_accuracy: 0.8576 - lr: 1.6000e-06\n",
      "Epoch 47/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8327Epoch 47/50: loss=0.3734, accuracy=0.8326, val_loss=0.3424, val_accuracy=0.8568\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3734 - accuracy: 0.8326 - val_loss: 0.3424 - val_accuracy: 0.8568 - lr: 1.6000e-06\n",
      "Epoch 48/50\n",
      "602/604 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8405Epoch 48/50: loss=0.3605, accuracy=0.8411, val_loss=0.3426, val_accuracy=0.8584\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3605 - accuracy: 0.8411 - val_loss: 0.3426 - val_accuracy: 0.8584 - lr: 1.6000e-06\n",
      "Epoch 49/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.8470Epoch 49/50: loss=0.3463, accuracy=0.8469, val_loss=0.3414, val_accuracy=0.8626\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3463 - accuracy: 0.8469 - val_loss: 0.3414 - val_accuracy: 0.8626 - lr: 1.6000e-06\n",
      "Epoch 50/50\n",
      "603/604 [============================>.] - ETA: 0s - loss: 0.3700 - accuracy: 0.8412Epoch 50/50: loss=0.3702, accuracy=0.8406, val_loss=0.3434, val_accuracy=0.8584\n",
      "604/604 [==============================] - 12s 20ms/step - loss: 0.3702 - accuracy: 0.8406 - val_loss: 0.3434 - val_accuracy: 0.8584 - lr: 1.6000e-06\n",
      "38/38 [==============================] - 0s 5ms/step\n",
      "Confusion Matrix:\n",
      "[[632  92]\n",
      " [ 79 405]]\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Healthy_augmented       0.89      0.87      0.88       724\n",
      "Damaged_augmented       0.81      0.84      0.83       484\n",
      "\n",
      "         accuracy                           0.86      1208\n",
      "        macro avg       0.85      0.85      0.85      1208\n",
      "     weighted avg       0.86      0.86      0.86      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params_refined = (5, 0.19999999999999998, 0.001, 40, 0.1, 0.1, 0.2, 0.2, True)\n",
    "datagen = create_datagen(best_params_refined[3], best_params_refined[4], best_params_refined[5], best_params_refined[6], best_params_refined[7], best_params_refined[8])\n",
    "datagen.fit(X_train)\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train the final model with the refined best parameters found\n",
    "final_model = build_complex_model(input_shape, best_params_refined[0], best_params_refined[1], best_params_refined[2])\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    final_history = final_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[reduce_lr, early_stopping, CustomCallback()],\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Make predictions\n",
    "with tf.device('/GPU:0'):\n",
    "    val_predictions = final_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report = classification_report(y_val_true, y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccaedc-7b0a-4b5b-bfbc-07151a969d53",
   "metadata": {},
   "source": [
    "# Save the Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e850d4-bf71-485c-8d5d-f5bead9b3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the best model to a local directory\n",
    "#model_save_path = 'best_model.h5'\n",
    "#final_model.save(model_save_path)\n",
    "#print(f\"Best model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f0f14-dcba-4b06-bd22-c82297ccbc90",
   "metadata": {},
   "source": [
    "# Load the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340765ab-ff2b-4ed8-8b96-69f96db86c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best model from the local directory\n",
    "model_save_path = 'best_model.h5'\n",
    "loaded_model = load_model(model_save_path)\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "with tf.device('/GPU:0'):\n",
    "    loaded_val_predictions = loaded_model.predict(X_val)\n",
    "\n",
    "# Convert one-hot encoded predictions and true labels to label indices\n",
    "loaded_y_val_pred = np.argmax(loaded_val_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix for the loaded model\n",
    "loaded_conf_matrix = confusion_matrix(y_val_true, loaded_y_val_pred)\n",
    "\n",
    "print(\"Confusion Matrix for loaded model:\")\n",
    "print(loaded_conf_matrix)\n",
    "\n",
    "# Generate the classification report for the loaded model\n",
    "loaded_class_report = classification_report(y_val_true, loaded_y_val_pred, target_names=categories)\n",
    "\n",
    "print(\"Classification Report for loaded model:\")\n",
    "print(loaded_class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis Thanasis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
